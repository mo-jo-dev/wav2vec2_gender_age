{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f0c507d6",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.preprocessing import LabelEncoder, StandardScaler\n",
    "from sklearn.metrics import accuracy_score, classification_report\n",
    "import tensorflow as tf\n",
    "from tensorflow.keras.models import Sequential\n",
    "from tensorflow.keras.layers import Conv1D, Flatten, Dense, Dropout\n",
    "import torch\n",
    "from torch.utils.data import DataLoader, TensorDataset\n",
    "import torch.nn as nn\n",
    "import torch.optim as optim\n",
    "\n",
    "# Disable GPU and force TensorFlow to run on CPU\n",
    "os.environ['CUDA_VISIBLE_DEVICES'] = '-1'\n",
    "\n",
    "\n",
    "# Load the data\n",
    "train_data = np.load('../Files/extracted_features/layer_features_lv60_self/train_0.npz')\n",
    "test_data = np.load('../Files/extracted_features/layer_features_lv60_self/test_0.npz')\n",
    "\n",
    "train_features = train_data['features']\n",
    "test_features = test_data['features']\n",
    "\n",
    "train_labels = pd.read_csv('../Files/labels/y_train.csv').Gender_bin\n",
    "test_labels = pd.read_csv('../Files/labels/y_test.csv').Gender_bin\n",
    "\n",
    "# Encode the labels\n",
    "label_encoder = LabelEncoder()\n",
    "train_labels_encoded = label_encoder.fit_transform(train_labels)\n",
    "test_labels_encoded = label_encoder.transform(test_labels)\n",
    "\n",
    "# Normalize the features\n",
    "scaler = StandardScaler()\n",
    "train_features_normalized = scaler.fit_transform(train_features)\n",
    "test_features_normalized = scaler.transform(test_features)\n",
    "\n",
    "# Reshape the data for CNN\n",
    "train_features_cnn = np.expand_dims(train_features_normalized, axis=-1)\n",
    "test_features_cnn = np.expand_dims(test_features_normalized, axis=-1)\n",
    "\n",
    "# TensorFlow CNN Model\n",
    "cnn_model = Sequential([\n",
    "    Conv1D(64, kernel_size=5, activation='relu', input_shape=(train_features_cnn.shape[1], 1)),\n",
    "    Conv1D(128, kernel_size=5, activation='relu'),\n",
    "    Conv1D(256, kernel_size=5, activation='relu'),\n",
    "    Flatten(),\n",
    "    Dense(256, activation='relu'),\n",
    "    Dropout(0.5),\n",
    "    Dense(len(label_encoder.classes_), activation='softmax')\n",
    "])\n",
    "\n",
    "cnn_model.compile(optimizer='adam', loss='sparse_categorical_crossentropy', metrics=['accuracy'])\n",
    "\n",
    "# Train the TensorFlow CNN\n",
    "history = cnn_model.fit(\n",
    "    train_features_cnn, \n",
    "    train_labels_encoded, \n",
    "    epochs=50, \n",
    "    batch_size=32, \n",
    "    validation_split=0.2,\n",
    "    callbacks=[tf.keras.callbacks.EarlyStopping(patience=5)]\n",
    ")\n",
    "\n",
    "# Evaluate the TensorFlow CNN\n",
    "cnn_predictions = np.argmax(cnn_model.predict(test_features_cnn), axis=1)\n",
    "cnn_balanced_accuracy = balanced_accuracy_score(test_labels_encoded, cnn_predictions)\n",
    "\n",
    "print(f\"TensorFlow CNN Balanced Accuracy Score: {cnn_balanced_accuracy:.4f}\")\n",
    "print(\"TensorFlow CNN Classification Report:\")\n",
    "print(classification_report(test_labels_encoded, cnn_predictions))\n",
    "\n",
    "\n",
    "# # SVM Classification\n",
    "# from sklearn.svm import SVC\n",
    "\n",
    "# svm_model = SVC(kernel='linear', C=10.0, gamma='scale', random_state=42)\n",
    "# svm_model.fit(train_features, train_labels_encoded)\n",
    "# svm_predictions = svm_model.predict(test_features)\n",
    "\n",
    "# svm_accuracy = accuracy_score(test_labels_encoded, svm_predictions)\n",
    "# print(f\"SVM Accuracy: {svm_accuracy:.4f}\")\n",
    "# print(\"SVM Classification Report:\")\n",
    "# print(classification_report(test_labels_encoded, svm_predictions))\n",
    "\n",
    "# ANN Model\n",
    "# ann_model = Sequential([\n",
    "#     Dense(512, activation='relu', input_shape=(train_features_normalized.shape[1],)),\n",
    "#     Dropout(0.5),\n",
    "#     Dense(256, activation='relu'),\n",
    "#     Dropout(0.5),\n",
    "#     Dense(128, activation='relu'),\n",
    "#     Dropout(0.5),\n",
    "#     Dense(len(label_encoder.classes_), activation='softmax')\n",
    "# ])\n",
    "\n",
    "# ann_model.compile(optimizer='adam', loss='sparse_categorical_crossentropy', metrics=['accuracy'])\n",
    "\n",
    "# # Train the ANN\n",
    "# ann_history = ann_model.fit(\n",
    "#     train_features_normalized, \n",
    "#     train_labels_encoded, \n",
    "#     epochs=50, \n",
    "#     batch_size=32, \n",
    "#     validation_split=0.2,\n",
    "#     callbacks=[tf.keras.callbacks.EarlyStopping(patience=5)]\n",
    "# )\n",
    "\n",
    "# # Evaluate the ANN\n",
    "# ann_test_loss, ann_test_accuracy = ann_model.evaluate(test_features_normalized, test_labels_encoded)\n",
    "# print(f\"ANN Test Accuracy: {ann_test_accuracy:.4f}\")\n",
    "\n",
    "# # ANN Predictions and Classification Report\n",
    "# ann_predictions = np.argmax(ann_model.predict(test_features_normalized), axis=1)\n",
    "# print(\"ANN Classification Report:\")\n",
    "# print(classification_report(test_labels_encoded, ann_predictions))\n",
    "\n",
    "# PyTorch CNN Model\n",
    "# class CNN1DModel(nn.Module):\n",
    "#     def __init__(self, input_channels, num_classes):\n",
    "#         super(CNN1DModel, self).__init__()\n",
    "#         self.conv1 = nn.Conv1d(input_channels, 32, kernel_size=5, stride=1, padding=2)\n",
    "#         self.bn1 = nn.BatchNorm1d(32)\n",
    "#         self.relu = nn.ReLU()\n",
    "#         self.conv2 = nn.Conv1d(32, 64, kernel_size=5, stride=1, padding=2)\n",
    "#         self.bn2 = nn.BatchNorm1d(64)\n",
    "#         self.conv3 = nn.Conv1d(64, 128, kernel_size=5, stride=1, padding=2)\n",
    "#         self.bn3 = nn.BatchNorm1d(128)\n",
    "#         self.flatten = nn.Flatten()\n",
    "#         self.fc1 = nn.Linear(128 * train_features_cnn.shape[1], 512)  # Adjusted based on your data\n",
    "#         self.fc2 = nn.Linear(512, num_classes)\n",
    "#         self.dropout = nn.Dropout(0.5)\n",
    "    \n",
    "#     def forward(self, x):\n",
    "#         x = self.relu(self.bn1(self.conv1(x)))\n",
    "#         x = self.relu(self.bn2(self.conv2(x)))\n",
    "#         x = self.relu(self.bn3(self.conv3(x)))\n",
    "#         x = self.flatten(x)\n",
    "#         x = self.dropout(self.relu(self.fc1(x)))\n",
    "#         x = self.fc2(x)\n",
    "#         return x\n",
    "\n",
    "# # Prepare tensors for PyTorch\n",
    "# X_train_tensor = torch.tensor(train_features_cnn, dtype=torch.float32).permute(0, 2, 1)  # Channels first for PyTorch\n",
    "# y_train_tensor = torch.tensor(train_labels_encoded, dtype=torch.long)\n",
    "# X_test_tensor = torch.tensor(test_features_cnn, dtype=torch.float32).permute(0, 2, 1)\n",
    "# y_test_tensor = torch.tensor(test_labels_encoded, dtype=torch.long)\n",
    "\n",
    "# train_dataset = TensorDataset(X_train_tensor, y_train_tensor)\n",
    "# test_dataset = TensorDataset(X_test_tensor, y_test_tensor)\n",
    "\n",
    "# train_loader = DataLoader(train_dataset, batch_size=64, shuffle=True)\n",
    "# test_loader = DataLoader(test_dataset, batch_size=64, shuffle=False)\n",
    "\n",
    "# # Initialize PyTorch model, loss, and optimizer\n",
    "# input_channels = 1\n",
    "# num_classes = len(label_encoder.classes_)\n",
    "# model = CNN1DModel(input_channels, num_classes)\n",
    "# criterion = nn.CrossEntropyLoss()\n",
    "# optimizer = optim.Adam(model.parameters(), lr=0.001)\n",
    "\n",
    "# # PyTorch Training Loop\n",
    "# epochs = 100\n",
    "# for epoch in range(epochs):\n",
    "#     model.train()\n",
    "#     running_loss = 0.0\n",
    "#     for inputs, labels in train_loader:\n",
    "#         optimizer.zero_grad()\n",
    "#         outputs = model(inputs)\n",
    "#         loss = criterion(outputs, labels)\n",
    "#         loss.backward()\n",
    "#         optimizer.step()\n",
    "#         running_loss += loss.item() * inputs.size(0)\n",
    "\n",
    "#     epoch_loss = running_loss / len(train_loader.dataset)\n",
    "#     print(f\"Epoch {epoch+1}: Loss = {epoch_loss:.4f}\")\n",
    "\n",
    "# # Test PyTorch model\n",
    "# def test_model(model, test_loader, criterion):\n",
    "#     model.eval()\n",
    "#     test_loss = 0.0\n",
    "#     correct = 0\n",
    "#     total = 0\n",
    "\n",
    "#     with torch.no_grad():\n",
    "#         for inputs, labels in test_loader:\n",
    "#             outputs = model(inputs)\n",
    "#             loss = criterion(outputs, labels)\n",
    "#             test_loss += loss.item() * inputs.size(0)\n",
    "#             _, predicted = torch.max(outputs, 1)\n",
    "#             total += labels.size(0)\n",
    "#             correct += (predicted == labels).sum().item()\n",
    "\n",
    "#     avg_loss = test_loss / total\n",
    "#     accuracy = correct / total\n",
    "#     return avg_loss, accuracy\n",
    "\n",
    "# # Evaluate PyTorch model\n",
    "# test_loss, test_accuracy = test_model(model, test_loader, criterion)\n",
    "# print(f\"PyTorch CNN Test Accuracy: {test_accuracy:.4f}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0bcb7ce3",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "\n",
    "torch.cuda.is_available()\n",
    "# True\n",
    "torch.cuda.device_count()\n",
    "# 1\n",
    "torch.cuda.current_device()\n",
    "# 0\n",
    "torch.cuda.device(0)\n",
    "# <torch.cuda.device at 0x7efce0b03be0>\n",
    "torch.cuda.get_device_name(0)\n",
    "# 'GeForce GTX 950M'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fd900cf1",
   "metadata": {},
   "outputs": [],
   "source": [
    "# base 960h"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "afd694e3",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2024-12-28 15:28:47.456557: E external/local_xla/xla/stream_executor/cuda/cuda_fft.cc:485] Unable to register cuFFT factory: Attempting to register factory for plugin cuFFT when one has already been registered\n",
      "2024-12-28 15:28:47.469005: E external/local_xla/xla/stream_executor/cuda/cuda_dnn.cc:8454] Unable to register cuDNN factory: Attempting to register factory for plugin cuDNN when one has already been registered\n",
      "2024-12-28 15:28:47.472429: E external/local_xla/xla/stream_executor/cuda/cuda_blas.cc:1452] Unable to register cuBLAS factory: Attempting to register factory for plugin cuBLAS when one has already been registered\n",
      "2024-12-28 15:28:47.482741: I tensorflow/core/platform/cpu_feature_guard.cc:210] This TensorFlow binary is optimized to use available CPU instructions in performance-critical operations.\n",
      "To enable the following instructions: AVX2 FMA, in other operations, rebuild TensorFlow with the appropriate compiler flags.\n",
      "2024-12-28 15:28:48.299568: W tensorflow/compiler/tf2tensorrt/utils/py_utils.cc:38] TF-TRT Warning: Could not find TensorRT\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/50\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/mojo/.local/lib/python3.12/site-packages/keras/src/layers/convolutional/base_conv.py:107: UserWarning: Do not pass an `input_shape`/`input_dim` argument to a layer. When using Sequential models, prefer using an `Input(shape)` object as the first layer in the model instead.\n",
      "  super().__init__(activity_regularizer=activity_regularizer, **kwargs)\n",
      "2024-12-28 15:28:50.372547: E external/local_xla/xla/stream_executor/cuda/cuda_driver.cc:266] failed call to cuInit: CUDA_ERROR_NO_DEVICE: no CUDA-capable device is detected\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m9s\u001b[0m 362ms/step - accuracy: 0.6031 - loss: 1.4178 - val_accuracy: 0.7907 - val_loss: 0.5343\n",
      "Epoch 2/50\n",
      "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m8s\u001b[0m 369ms/step - accuracy: 0.8442 - loss: 0.3790 - val_accuracy: 0.7907 - val_loss: 0.6223\n",
      "Epoch 3/50\n",
      "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m8s\u001b[0m 362ms/step - accuracy: 0.9351 - loss: 0.1760 - val_accuracy: 0.7849 - val_loss: 0.7865\n",
      "Epoch 4/50\n",
      "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m8s\u001b[0m 358ms/step - accuracy: 0.9614 - loss: 0.1115 - val_accuracy: 0.7907 - val_loss: 0.8392\n",
      "Epoch 5/50\n",
      "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m8s\u001b[0m 363ms/step - accuracy: 0.9810 - loss: 0.0590 - val_accuracy: 0.7965 - val_loss: 0.7601\n",
      "Epoch 6/50\n",
      "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m8s\u001b[0m 354ms/step - accuracy: 0.9939 - loss: 0.0323 - val_accuracy: 0.7965 - val_loss: 1.0268\n",
      "\u001b[1m5/5\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 43ms/step\n",
      "TensorFlow CNN Balanced Accuracy Score: 0.8711\n",
      "TensorFlow CNN Classification Report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.82      0.89      0.85        56\n",
      "           1       0.91      0.85      0.88        73\n",
      "\n",
      "    accuracy                           0.87       129\n",
      "   macro avg       0.87      0.87      0.87       129\n",
      "weighted avg       0.87      0.87      0.87       129\n",
      "\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "from sklearn.preprocessing import LabelEncoder, StandardScaler\n",
    "from sklearn.metrics import classification_report, balanced_accuracy_score\n",
    "import tensorflow as tf\n",
    "from tensorflow.keras.models import Sequential\n",
    "from tensorflow.keras.layers import Conv1D, Flatten, Dense, Dropout\n",
    "\n",
    "os.environ['CUDA_VISIBLE_DEVICES'] = '-1'\n",
    "\n",
    "# Load the data\n",
    "train_data = np.load('./train_0.npz')\n",
    "test_data = np.load('./test_0.npz')\n",
    "\n",
    "train_features = train_data['features']\n",
    "test_features = test_data['features']\n",
    "\n",
    "train_labels = pd.read_csv('../y_train.csv').Gender_bin\n",
    "test_labels = pd.read_csv('../y_test_age_group.csv').Gender_bin  \n",
    "\n",
    "# Encode the labels\n",
    "label_encoder = LabelEncoder()\n",
    "train_labels_encoded = label_encoder.fit_transform(train_labels)\n",
    "test_labels_encoded = label_encoder.transform(test_labels)\n",
    "\n",
    "# Normalize the features\n",
    "scaler = StandardScaler()\n",
    "train_features_normalized = scaler.fit_transform(train_features)\n",
    "test_features_normalized = scaler.transform(test_features)\n",
    "\n",
    "# Reshape the data for CNN\n",
    "train_features_cnn = np.expand_dims(train_features_normalized, axis=-1)\n",
    "test_features_cnn = np.expand_dims(test_features_normalized, axis=-1)\n",
    "\n",
    "# TensorFlow CNN Model\n",
    "cnn_model = Sequential([\n",
    "    Conv1D(64, kernel_size=5, activation='relu', input_shape=(train_features_cnn.shape[1], 1)),\n",
    "    Conv1D(128, kernel_size=5, activation='relu'),\n",
    "    Conv1D(256, kernel_size=5, activation='relu'),\n",
    "    Flatten(),\n",
    "    Dense(256, activation='relu'),\n",
    "    Dropout(0.5),\n",
    "    Dense(len(label_encoder.classes_), activation='softmax')\n",
    "])\n",
    "\n",
    "cnn_model.compile(optimizer='adam', loss='sparse_categorical_crossentropy', metrics=['accuracy'])\n",
    "\n",
    "# Train the TensorFlow CNN\n",
    "history = cnn_model.fit(\n",
    "    train_features_cnn, \n",
    "    train_labels_encoded, \n",
    "    epochs=50, \n",
    "    batch_size=32, \n",
    "    validation_split=0.2,\n",
    "    callbacks=[tf.keras.callbacks.EarlyStopping(patience=5)]\n",
    ")\n",
    "\n",
    "# Evaluate the TensorFlow CNN\n",
    "cnn_predictions = np.argmax(cnn_model.predict(test_features_cnn), axis=1)\n",
    "cnn_balanced_accuracy = balanced_accuracy_score(test_labels_encoded, cnn_predictions)\n",
    "\n",
    "print(f\"TensorFlow CNN Balanced Accuracy Score: {cnn_balanced_accuracy:.4f}\")\n",
    "print(\"TensorFlow CNN Classification Report:\")\n",
    "print(classification_report(test_labels_encoded, cnn_predictions))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "08459045",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/50\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/mojo/.local/lib/python3.12/site-packages/keras/src/layers/convolutional/base_conv.py:107: UserWarning: Do not pass an `input_shape`/`input_dim` argument to a layer. When using Sequential models, prefer using an `Input(shape)` object as the first layer in the model instead.\n",
      "  super().__init__(activity_regularizer=activity_regularizer, **kwargs)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m9s\u001b[0m 365ms/step - accuracy: 0.6637 - loss: 1.5025 - val_accuracy: 0.8081 - val_loss: 0.3940\n",
      "Epoch 2/50\n",
      "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m8s\u001b[0m 357ms/step - accuracy: 0.9002 - loss: 0.2663 - val_accuracy: 0.7907 - val_loss: 0.5852\n",
      "Epoch 3/50\n",
      "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m8s\u001b[0m 359ms/step - accuracy: 0.9703 - loss: 0.1058 - val_accuracy: 0.8372 - val_loss: 0.6529\n",
      "Epoch 4/50\n",
      "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m8s\u001b[0m 358ms/step - accuracy: 0.9901 - loss: 0.0479 - val_accuracy: 0.8256 - val_loss: 0.7855\n",
      "Epoch 5/50\n",
      "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m8s\u001b[0m 361ms/step - accuracy: 0.9915 - loss: 0.0262 - val_accuracy: 0.8140 - val_loss: 0.7427\n",
      "Epoch 6/50\n",
      "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m8s\u001b[0m 359ms/step - accuracy: 0.9989 - loss: 0.0144 - val_accuracy: 0.8081 - val_loss: 0.9622\n",
      "\u001b[1m5/5\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 42ms/step\n",
      "TensorFlow CNN Balanced Accuracy Score: 0.8505\n",
      "TensorFlow CNN Classification Report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.78      0.89      0.83        56\n",
      "           1       0.91      0.81      0.86        73\n",
      "\n",
      "    accuracy                           0.84       129\n",
      "   macro avg       0.84      0.85      0.84       129\n",
      "weighted avg       0.85      0.84      0.85       129\n",
      "\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "from sklearn.preprocessing import LabelEncoder, StandardScaler\n",
    "from sklearn.metrics import classification_report, balanced_accuracy_score\n",
    "import tensorflow as tf\n",
    "from tensorflow.keras.models import Sequential\n",
    "from tensorflow.keras.layers import Conv1D, Flatten, Dense, Dropout\n",
    "\n",
    "os.environ['CUDA_VISIBLE_DEVICES'] = '-1'\n",
    "\n",
    "# Load the data\n",
    "train_data = np.load('../Files/extracted_features/layer_features_base_100/train_1.npz')\n",
    "test_data = np.load('../Files/extracted_features/layer_features_base_100/test_1.npz')\n",
    "\n",
    "train_features = train_data['features']\n",
    "test_features = test_data['features']\n",
    "\n",
    "train_labels = pd.read_csv('../Files/labels/y_train.csv').Gender_bin\n",
    "test_labels = pd.read_csv('../Files/labels/y_test.csv').Gender_bin\n",
    "\n",
    "# Encode the labels\n",
    "label_encoder = LabelEncoder()\n",
    "train_labels_encoded = label_encoder.fit_transform(train_labels)\n",
    "test_labels_encoded = label_encoder.transform(test_labels)\n",
    "\n",
    "# Normalize the features\n",
    "scaler = StandardScaler()\n",
    "train_features_normalized = scaler.fit_transform(train_features)\n",
    "test_features_normalized = scaler.transform(test_features)\n",
    "\n",
    "# Reshape the data for CNN\n",
    "train_features_cnn = np.expand_dims(train_features_normalized, axis=-1)\n",
    "test_features_cnn = np.expand_dims(test_features_normalized, axis=-1)\n",
    "\n",
    "# TensorFlow CNN Model\n",
    "cnn_model = Sequential([\n",
    "    Conv1D(64, kernel_size=5, activation='relu', input_shape=(train_features_cnn.shape[1], 1)),\n",
    "    Conv1D(128, kernel_size=5, activation='relu'),\n",
    "    Conv1D(256, kernel_size=5, activation='relu'),\n",
    "    Flatten(),\n",
    "    Dense(256, activation='relu'),\n",
    "    Dropout(0.5),\n",
    "    Dense(len(label_encoder.classes_), activation='softmax')\n",
    "])\n",
    "\n",
    "cnn_model.compile(optimizer='adam', loss='sparse_categorical_crossentropy', metrics=['accuracy'])\n",
    "\n",
    "# Train the TensorFlow CNN\n",
    "history = cnn_model.fit(\n",
    "    train_features_cnn, \n",
    "    train_labels_encoded, \n",
    "    epochs=50, \n",
    "    batch_size=32, \n",
    "    validation_split=0.2,\n",
    "    callbacks=[tf.keras.callbacks.EarlyStopping(patience=5)]\n",
    ")\n",
    "\n",
    "# Evaluate the TensorFlow CNN\n",
    "cnn_predictions = np.argmax(cnn_model.predict(test_features_cnn), axis=1)\n",
    "cnn_balanced_accuracy = balanced_accuracy_score(test_labels_encoded, cnn_predictions)\n",
    "\n",
    "print(f\"TensorFlow CNN Balanced Accuracy Score: {cnn_balanced_accuracy:.4f}\")\n",
    "print(\"TensorFlow CNN Classification Report:\")\n",
    "print(classification_report(test_labels_encoded, cnn_predictions))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "682d20fa",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/50\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/mojo/.local/lib/python3.12/site-packages/keras/src/layers/convolutional/base_conv.py:107: UserWarning: Do not pass an `input_shape`/`input_dim` argument to a layer. When using Sequential models, prefer using an `Input(shape)` object as the first layer in the model instead.\n",
      "  super().__init__(activity_regularizer=activity_regularizer, **kwargs)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m9s\u001b[0m 370ms/step - accuracy: 0.6397 - loss: 1.2704 - val_accuracy: 0.8256 - val_loss: 0.3737\n",
      "Epoch 2/50\n",
      "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m8s\u001b[0m 363ms/step - accuracy: 0.9528 - loss: 0.2045 - val_accuracy: 0.9186 - val_loss: 0.1882\n",
      "Epoch 3/50\n",
      "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m8s\u001b[0m 362ms/step - accuracy: 0.9620 - loss: 0.1087 - val_accuracy: 0.9012 - val_loss: 0.3353\n",
      "Epoch 4/50\n",
      "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m8s\u001b[0m 360ms/step - accuracy: 0.9932 - loss: 0.0164 - val_accuracy: 0.8953 - val_loss: 0.4840\n",
      "Epoch 5/50\n",
      "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m8s\u001b[0m 361ms/step - accuracy: 0.9938 - loss: 0.0172 - val_accuracy: 0.8314 - val_loss: 0.7282\n",
      "Epoch 6/50\n",
      "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m8s\u001b[0m 359ms/step - accuracy: 0.9934 - loss: 0.0168 - val_accuracy: 0.8605 - val_loss: 0.6717\n",
      "Epoch 7/50\n",
      "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m8s\u001b[0m 377ms/step - accuracy: 0.9954 - loss: 0.0296 - val_accuracy: 0.8663 - val_loss: 0.3875\n",
      "WARNING:tensorflow:5 out of the last 11 calls to <function TensorFlowTrainer.make_predict_function.<locals>.one_step_on_data_distributed at 0x7bdab6c63ce0> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has reduce_retracing=True option that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/guide/function#controlling_retracing and https://www.tensorflow.org/api_docs/python/tf/function for  more details.\n",
      "\u001b[1m3/5\u001b[0m \u001b[32m━━━━━━━━━━━━\u001b[0m\u001b[37m━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 42ms/stepWARNING:tensorflow:5 out of the last 11 calls to <function TensorFlowTrainer.make_predict_function.<locals>.one_step_on_data_distributed at 0x7bdab6c63ce0> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has reduce_retracing=True option that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/guide/function#controlling_retracing and https://www.tensorflow.org/api_docs/python/tf/function for  more details.\n",
      "\u001b[1m5/5\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 44ms/step\n",
      "TensorFlow CNN Balanced Accuracy Score: 0.8883\n",
      "TensorFlow CNN Classification Report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.79      0.98      0.87        56\n",
      "           1       0.98      0.79      0.88        73\n",
      "\n",
      "    accuracy                           0.88       129\n",
      "   macro avg       0.88      0.89      0.88       129\n",
      "weighted avg       0.90      0.88      0.88       129\n",
      "\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "from sklearn.preprocessing import LabelEncoder, StandardScaler\n",
    "from sklearn.metrics import classification_report, balanced_accuracy_score\n",
    "import tensorflow as tf\n",
    "from tensorflow.keras.models import Sequential\n",
    "from tensorflow.keras.layers import Conv1D, Flatten, Dense, Dropout\n",
    "\n",
    "os.environ['CUDA_VISIBLE_DEVICES'] = '-1'\n",
    "\n",
    "# Load the data\n",
    "train_data = np.load('../Files/extracted_features/layer_features_base_100/train_2.npz')\n",
    "test_data = np.load('../Files/extracted_features/layer_features_base_100/test_2.npz')\n",
    "\n",
    "train_features = train_data['features']\n",
    "test_features = test_data['features']\n",
    "\n",
    "train_labels = pd.read_csv('../Files/labels/y_train.csv').Gender_bin\n",
    "test_labels = pd.read_csv('../Files/labels/y_test.csv').Gender_bin\n",
    "\n",
    "# Encode the labels\n",
    "label_encoder = LabelEncoder()\n",
    "train_labels_encoded = label_encoder.fit_transform(train_labels)\n",
    "test_labels_encoded = label_encoder.transform(test_labels)\n",
    "\n",
    "# Normalize the features\n",
    "scaler = StandardScaler()\n",
    "train_features_normalized = scaler.fit_transform(train_features)\n",
    "test_features_normalized = scaler.transform(test_features)\n",
    "\n",
    "# Reshape the data for CNN\n",
    "train_features_cnn = np.expand_dims(train_features_normalized, axis=-1)\n",
    "test_features_cnn = np.expand_dims(test_features_normalized, axis=-1)\n",
    "\n",
    "# TensorFlow CNN Model\n",
    "cnn_model = Sequential([\n",
    "    Conv1D(64, kernel_size=5, activation='relu', input_shape=(train_features_cnn.shape[1], 1)),\n",
    "    Conv1D(128, kernel_size=5, activation='relu'),\n",
    "    Conv1D(256, kernel_size=5, activation='relu'),\n",
    "    Flatten(),\n",
    "    Dense(256, activation='relu'),\n",
    "    Dropout(0.5),\n",
    "    Dense(len(label_encoder.classes_), activation='softmax')\n",
    "])\n",
    "\n",
    "cnn_model.compile(optimizer='adam', loss='sparse_categorical_crossentropy', metrics=['accuracy'])\n",
    "\n",
    "# Train the TensorFlow CNN\n",
    "history = cnn_model.fit(\n",
    "    train_features_cnn, \n",
    "    train_labels_encoded, \n",
    "    epochs=50, \n",
    "    batch_size=32, \n",
    "    validation_split=0.2,\n",
    "    callbacks=[tf.keras.callbacks.EarlyStopping(patience=5)]\n",
    ")\n",
    "\n",
    "# Evaluate the TensorFlow CNN\n",
    "cnn_predictions = np.argmax(cnn_model.predict(test_features_cnn), axis=1)\n",
    "cnn_balanced_accuracy = balanced_accuracy_score(test_labels_encoded, cnn_predictions)\n",
    "\n",
    "print(f\"TensorFlow CNN Balanced Accuracy Score: {cnn_balanced_accuracy:.4f}\")\n",
    "print(\"TensorFlow CNN Classification Report:\")\n",
    "print(classification_report(test_labels_encoded, cnn_predictions))\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
