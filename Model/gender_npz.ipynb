{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f0c507d6",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.preprocessing import LabelEncoder, StandardScaler\n",
    "from sklearn.metrics import accuracy_score, classification_report\n",
    "import tensorflow as tf\n",
    "from tensorflow.keras.models import Sequential\n",
    "from tensorflow.keras.layers import Conv1D, Flatten, Dense, Dropout\n",
    "import torch\n",
    "from torch.utils.data import DataLoader, TensorDataset\n",
    "import torch.nn as nn\n",
    "import torch.optim as optim\n",
    "\n",
    "# Disable GPU and force TensorFlow to run on CPU\n",
    "os.environ['CUDA_VISIBLE_DEVICES'] = '-1'\n",
    "\n",
    "\n",
    "# Load the data\n",
    "train_data = np.load('../Files/extracted_features/layer_features_lv60_self/train_0.npz')\n",
    "test_data = np.load('../Files/extracted_features/layer_features_lv60_self/test_0.npz')\n",
    "\n",
    "train_features = train_data['features']\n",
    "test_features = test_data['features']\n",
    "\n",
    "train_labels = pd.read_csv('../Files/labels/y_train.csv').Gender_bin\n",
    "test_labels = pd.read_csv('../Files/labels/y_test.csv').Gender_bin\n",
    "\n",
    "# Encode the labels\n",
    "label_encoder = LabelEncoder()\n",
    "train_labels_encoded = label_encoder.fit_transform(train_labels)\n",
    "test_labels_encoded = label_encoder.transform(test_labels)\n",
    "\n",
    "# Normalize the features\n",
    "scaler = StandardScaler()\n",
    "train_features_normalized = scaler.fit_transform(train_features)\n",
    "test_features_normalized = scaler.transform(test_features)\n",
    "\n",
    "# Reshape the data for CNN\n",
    "train_features_cnn = np.expand_dims(train_features_normalized, axis=-1)\n",
    "test_features_cnn = np.expand_dims(test_features_normalized, axis=-1)\n",
    "\n",
    "# TensorFlow CNN Model\n",
    "cnn_model = Sequential([\n",
    "    Conv1D(64, kernel_size=5, activation='relu', input_shape=(train_features_cnn.shape[1], 1)),\n",
    "    Conv1D(128, kernel_size=5, activation='relu'),\n",
    "    Conv1D(256, kernel_size=5, activation='relu'),\n",
    "    Flatten(),\n",
    "    Dense(256, activation='relu'),\n",
    "    Dropout(0.5),\n",
    "    Dense(len(label_encoder.classes_), activation='softmax')\n",
    "])\n",
    "\n",
    "cnn_model.compile(optimizer='adam', loss='sparse_categorical_crossentropy', metrics=['accuracy'])\n",
    "\n",
    "# Train the TensorFlow CNN\n",
    "history = cnn_model.fit(\n",
    "    train_features_cnn, \n",
    "    train_labels_encoded, \n",
    "    epochs=50, \n",
    "    batch_size=32, \n",
    "    validation_split=0.2,\n",
    "    callbacks=[tf.keras.callbacks.EarlyStopping(patience=5)]\n",
    ")\n",
    "\n",
    "# Evaluate the TensorFlow CNN\n",
    "cnn_predictions = np.argmax(cnn_model.predict(test_features_cnn), axis=1)\n",
    "cnn_balanced_accuracy = balanced_accuracy_score(test_labels_encoded, cnn_predictions)\n",
    "\n",
    "print(f\"TensorFlow CNN Balanced Accuracy Score: {cnn_balanced_accuracy:.4f}\")\n",
    "print(\"TensorFlow CNN Classification Report:\")\n",
    "print(classification_report(test_labels_encoded, cnn_predictions))\n",
    "\n",
    "\n",
    "# # SVM Classification\n",
    "# from sklearn.svm import SVC\n",
    "\n",
    "# svm_model = SVC(kernel='linear', C=10.0, gamma='scale', random_state=42)\n",
    "# svm_model.fit(train_features, train_labels_encoded)\n",
    "# svm_predictions = svm_model.predict(test_features)\n",
    "\n",
    "# svm_accuracy = accuracy_score(test_labels_encoded, svm_predictions)\n",
    "# print(f\"SVM Accuracy: {svm_accuracy:.4f}\")\n",
    "# print(\"SVM Classification Report:\")\n",
    "# print(classification_report(test_labels_encoded, svm_predictions))\n",
    "\n",
    "# ANN Model\n",
    "# ann_model = Sequential([\n",
    "#     Dense(512, activation='relu', input_shape=(train_features_normalized.shape[1],)),\n",
    "#     Dropout(0.5),\n",
    "#     Dense(256, activation='relu'),\n",
    "#     Dropout(0.5),\n",
    "#     Dense(128, activation='relu'),\n",
    "#     Dropout(0.5),\n",
    "#     Dense(len(label_encoder.classes_), activation='softmax')\n",
    "# ])\n",
    "\n",
    "# ann_model.compile(optimizer='adam', loss='sparse_categorical_crossentropy', metrics=['accuracy'])\n",
    "\n",
    "# # Train the ANN\n",
    "# ann_history = ann_model.fit(\n",
    "#     train_features_normalized, \n",
    "#     train_labels_encoded, \n",
    "#     epochs=50, \n",
    "#     batch_size=32, \n",
    "#     validation_split=0.2,\n",
    "#     callbacks=[tf.keras.callbacks.EarlyStopping(patience=5)]\n",
    "# )\n",
    "\n",
    "# # Evaluate the ANN\n",
    "# ann_test_loss, ann_test_accuracy = ann_model.evaluate(test_features_normalized, test_labels_encoded)\n",
    "# print(f\"ANN Test Accuracy: {ann_test_accuracy:.4f}\")\n",
    "\n",
    "# # ANN Predictions and Classification Report\n",
    "# ann_predictions = np.argmax(ann_model.predict(test_features_normalized), axis=1)\n",
    "# print(\"ANN Classification Report:\")\n",
    "# print(classification_report(test_labels_encoded, ann_predictions))\n",
    "\n",
    "# PyTorch CNN Model\n",
    "# class CNN1DModel(nn.Module):\n",
    "#     def __init__(self, input_channels, num_classes):\n",
    "#         super(CNN1DModel, self).__init__()\n",
    "#         self.conv1 = nn.Conv1d(input_channels, 32, kernel_size=5, stride=1, padding=2)\n",
    "#         self.bn1 = nn.BatchNorm1d(32)\n",
    "#         self.relu = nn.ReLU()\n",
    "#         self.conv2 = nn.Conv1d(32, 64, kernel_size=5, stride=1, padding=2)\n",
    "#         self.bn2 = nn.BatchNorm1d(64)\n",
    "#         self.conv3 = nn.Conv1d(64, 128, kernel_size=5, stride=1, padding=2)\n",
    "#         self.bn3 = nn.BatchNorm1d(128)\n",
    "#         self.flatten = nn.Flatten()\n",
    "#         self.fc1 = nn.Linear(128 * train_features_cnn.shape[1], 512)  # Adjusted based on your data\n",
    "#         self.fc2 = nn.Linear(512, num_classes)\n",
    "#         self.dropout = nn.Dropout(0.5)\n",
    "    \n",
    "#     def forward(self, x):\n",
    "#         x = self.relu(self.bn1(self.conv1(x)))\n",
    "#         x = self.relu(self.bn2(self.conv2(x)))\n",
    "#         x = self.relu(self.bn3(self.conv3(x)))\n",
    "#         x = self.flatten(x)\n",
    "#         x = self.dropout(self.relu(self.fc1(x)))\n",
    "#         x = self.fc2(x)\n",
    "#         return x\n",
    "\n",
    "# # Prepare tensors for PyTorch\n",
    "# X_train_tensor = torch.tensor(train_features_cnn, dtype=torch.float32).permute(0, 2, 1)  # Channels first for PyTorch\n",
    "# y_train_tensor = torch.tensor(train_labels_encoded, dtype=torch.long)\n",
    "# X_test_tensor = torch.tensor(test_features_cnn, dtype=torch.float32).permute(0, 2, 1)\n",
    "# y_test_tensor = torch.tensor(test_labels_encoded, dtype=torch.long)\n",
    "\n",
    "# train_dataset = TensorDataset(X_train_tensor, y_train_tensor)\n",
    "# test_dataset = TensorDataset(X_test_tensor, y_test_tensor)\n",
    "\n",
    "# train_loader = DataLoader(train_dataset, batch_size=64, shuffle=True)\n",
    "# test_loader = DataLoader(test_dataset, batch_size=64, shuffle=False)\n",
    "\n",
    "# # Initialize PyTorch model, loss, and optimizer\n",
    "# input_channels = 1\n",
    "# num_classes = len(label_encoder.classes_)\n",
    "# model = CNN1DModel(input_channels, num_classes)\n",
    "# criterion = nn.CrossEntropyLoss()\n",
    "# optimizer = optim.Adam(model.parameters(), lr=0.001)\n",
    "\n",
    "# # PyTorch Training Loop\n",
    "# epochs = 100\n",
    "# for epoch in range(epochs):\n",
    "#     model.train()\n",
    "#     running_loss = 0.0\n",
    "#     for inputs, labels in train_loader:\n",
    "#         optimizer.zero_grad()\n",
    "#         outputs = model(inputs)\n",
    "#         loss = criterion(outputs, labels)\n",
    "#         loss.backward()\n",
    "#         optimizer.step()\n",
    "#         running_loss += loss.item() * inputs.size(0)\n",
    "\n",
    "#     epoch_loss = running_loss / len(train_loader.dataset)\n",
    "#     print(f\"Epoch {epoch+1}: Loss = {epoch_loss:.4f}\")\n",
    "\n",
    "# # Test PyTorch model\n",
    "# def test_model(model, test_loader, criterion):\n",
    "#     model.eval()\n",
    "#     test_loss = 0.0\n",
    "#     correct = 0\n",
    "#     total = 0\n",
    "\n",
    "#     with torch.no_grad():\n",
    "#         for inputs, labels in test_loader:\n",
    "#             outputs = model(inputs)\n",
    "#             loss = criterion(outputs, labels)\n",
    "#             test_loss += loss.item() * inputs.size(0)\n",
    "#             _, predicted = torch.max(outputs, 1)\n",
    "#             total += labels.size(0)\n",
    "#             correct += (predicted == labels).sum().item()\n",
    "\n",
    "#     avg_loss = test_loss / total\n",
    "#     accuracy = correct / total\n",
    "#     return avg_loss, accuracy\n",
    "\n",
    "# # Evaluate PyTorch model\n",
    "# test_loss, test_accuracy = test_model(model, test_loader, criterion)\n",
    "# print(f\"PyTorch CNN Test Accuracy: {test_accuracy:.4f}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "63da7e64",
   "metadata": {},
   "outputs": [],
   "source": [
    "# base 100h"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "08459045",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "from sklearn.preprocessing import LabelEncoder, StandardScaler\n",
    "from sklearn.metrics import classification_report, balanced_accuracy_score\n",
    "import tensorflow as tf\n",
    "from tensorflow.keras.models import Sequential\n",
    "from tensorflow.keras.layers import Conv1D, Flatten, Dense, Dropout\n",
    "\n",
    "os.environ['CUDA_VISIBLE_DEVICES'] = '-1'\n",
    "\n",
    "# Load the data\n",
    "train_data = np.load('../Files/extracted_features/layer_features_base_100/train_1.npz')\n",
    "test_data = np.load('../Files/extracted_features/layer_features_base_100/test_1.npz')\n",
    "\n",
    "train_features = train_data['features']\n",
    "test_features = test_data['features']\n",
    "\n",
    "train_labels = pd.read_csv('../Files/labels/y_train.csv').Gender_bin\n",
    "test_labels = pd.read_csv('../Files/labels/y_test.csv').Gender_bin\n",
    "\n",
    "# Encode the labels\n",
    "label_encoder = LabelEncoder()\n",
    "train_labels_encoded = label_encoder.fit_transform(train_labels)\n",
    "test_labels_encoded = label_encoder.transform(test_labels)\n",
    "\n",
    "# Normalize the features\n",
    "scaler = StandardScaler()\n",
    "train_features_normalized = scaler.fit_transform(train_features)\n",
    "test_features_normalized = scaler.transform(test_features)\n",
    "\n",
    "# Reshape the data for CNN\n",
    "train_features_cnn = np.expand_dims(train_features_normalized, axis=-1)\n",
    "test_features_cnn = np.expand_dims(test_features_normalized, axis=-1)\n",
    "\n",
    "# TensorFlow CNN Model\n",
    "cnn_model = Sequential([\n",
    "    Conv1D(64, kernel_size=5, activation='relu', input_shape=(train_features_cnn.shape[1], 1)),\n",
    "    Conv1D(128, kernel_size=5, activation='relu'),\n",
    "    Conv1D(256, kernel_size=5, activation='relu'),\n",
    "    Flatten(),\n",
    "    Dense(256, activation='relu'),\n",
    "    Dropout(0.5),\n",
    "    Dense(len(label_encoder.classes_), activation='softmax')\n",
    "])\n",
    "\n",
    "cnn_model.compile(optimizer='adam', loss='sparse_categorical_crossentropy', metrics=['accuracy'])\n",
    "\n",
    "# Train the TensorFlow CNN\n",
    "history = cnn_model.fit(\n",
    "    train_features_cnn, \n",
    "    train_labels_encoded, \n",
    "    epochs=50, \n",
    "    batch_size=32, \n",
    "    validation_split=0.2,\n",
    "    callbacks=[tf.keras.callbacks.EarlyStopping(patience=5)]\n",
    ")\n",
    "\n",
    "# Evaluate the TensorFlow CNN\n",
    "cnn_predictions = np.argmax(cnn_model.predict(test_features_cnn), axis=1)\n",
    "cnn_balanced_accuracy = balanced_accuracy_score(test_labels_encoded, cnn_predictions)\n",
    "\n",
    "print(f\"TensorFlow CNN Balanced Accuracy Score: {cnn_balanced_accuracy:.4f}\")\n",
    "print(\"TensorFlow CNN Classification Report:\")\n",
    "print(classification_report(test_labels_encoded, cnn_predictions))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fd900cf1",
   "metadata": {},
   "outputs": [],
   "source": [
    "# base 960h"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "682d20fa",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "from sklearn.preprocessing import LabelEncoder, StandardScaler\n",
    "from sklearn.metrics import classification_report, balanced_accuracy_score\n",
    "import tensorflow as tf\n",
    "from tensorflow.keras.models import Sequential\n",
    "from tensorflow.keras.layers import Conv1D, Flatten, Dense, Dropout\n",
    "\n",
    "os.environ['CUDA_VISIBLE_DEVICES'] = '-1'\n",
    "\n",
    "# Load the data\n",
    "train_data = np.load('../Files/extracted_features/layer_features_base_960/train_2.npz')\n",
    "test_data = np.load('../Files/extracted_features/layer_features_base_960/test_2.npz')\n",
    "\n",
    "train_features = train_data['features']\n",
    "test_features = test_data['features']\n",
    "\n",
    "train_labels = pd.read_csv('../Files/labels/y_train.csv').Gender_bin\n",
    "test_labels = pd.read_csv('../Files/labels/y_test.csv').Gender_bin\n",
    "\n",
    "# Encode the labels\n",
    "label_encoder = LabelEncoder()\n",
    "train_labels_encoded = label_encoder.fit_transform(train_labels)\n",
    "test_labels_encoded = label_encoder.transform(test_labels)\n",
    "\n",
    "# Normalize the features\n",
    "scaler = StandardScaler()\n",
    "train_features_normalized = scaler.fit_transform(train_features)\n",
    "test_features_normalized = scaler.transform(test_features)\n",
    "\n",
    "# Reshape the data for CNN\n",
    "train_features_cnn = np.expand_dims(train_features_normalized, axis=-1)\n",
    "test_features_cnn = np.expand_dims(test_features_normalized, axis=-1)\n",
    "\n",
    "# TensorFlow CNN Model\n",
    "cnn_model = Sequential([\n",
    "    Conv1D(64, kernel_size=5, activation='relu', input_shape=(train_features_cnn.shape[1], 1)),\n",
    "    Conv1D(128, kernel_size=5, activation='relu'),\n",
    "    Conv1D(256, kernel_size=5, activation='relu'),\n",
    "    Flatten(),\n",
    "    Dense(256, activation='relu'),\n",
    "    Dropout(0.5),\n",
    "    Dense(len(label_encoder.classes_), activation='softmax')\n",
    "])\n",
    "\n",
    "cnn_model.compile(optimizer='adam', loss='sparse_categorical_crossentropy', metrics=['accuracy'])\n",
    "\n",
    "# Train the TensorFlow CNN\n",
    "history = cnn_model.fit(\n",
    "    train_features_cnn, \n",
    "    train_labels_encoded, \n",
    "    epochs=50, \n",
    "    batch_size=32, \n",
    "    validation_split=0.2,\n",
    "    callbacks=[tf.keras.callbacks.EarlyStopping(patience=5)]\n",
    ")\n",
    "\n",
    "# Evaluate the TensorFlow CNN\n",
    "cnn_predictions = np.argmax(cnn_model.predict(test_features_cnn), axis=1)\n",
    "cnn_balanced_accuracy = balanced_accuracy_score(test_labels_encoded, cnn_predictions)\n",
    "\n",
    "print(f\"TensorFlow CNN Balanced Accuracy Score: {cnn_balanced_accuracy:.4f}\")\n",
    "print(\"TensorFlow CNN Classification Report:\")\n",
    "print(classification_report(test_labels_encoded, cnn_predictions))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "121d3f67",
   "metadata": {},
   "outputs": [],
   "source": [
    "# hubert"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9d4d3444",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 0\n",
    "import os\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.preprocessing import LabelEncoder, StandardScaler\n",
    "from sklearn.metrics import accuracy_score, classification_report, confusion_matrix\n",
    "import tensorflow as tf\n",
    "from tensorflow.keras.models import Sequential\n",
    "from tensorflow.keras.layers import Conv1D, Flatten, Dense, Dropout\n",
    "import torch\n",
    "from torch.utils.data import DataLoader, TensorDataset\n",
    "import torch.nn as nn\n",
    "import torch.optim as optim\n",
    "import seaborn as sns\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "# Load the data\n",
    "train_data = np.load('../Files/extracted_features/hubert_large/train_0.npz')\n",
    "test_data = np.load('../Files/extracted_features/hubert_large/test_0.npz')\n",
    "\n",
    "train_features = train_data['features']\n",
    "test_features = test_data['features']\n",
    "\n",
    "train_labels = pd.read_csv('../Files/labels/y_train.csv').Gender_bin\n",
    "test_labels = pd.read_csv('../Files/labels/y_test.csv').Gender_bin\n",
    "\n",
    "# Encode the labels\n",
    "label_encoder = LabelEncoder()\n",
    "train_labels_encoded = label_encoder.fit_transform(train_labels)\n",
    "test_labels_encoded = label_encoder.transform(test_labels)\n",
    "\n",
    "# Normalize the features\n",
    "scaler = StandardScaler()\n",
    "train_features_normalized = scaler.fit_transform(train_features)\n",
    "test_features_normalized = scaler.transform(test_features)\n",
    "\n",
    "# SVM Classification\n",
    "from sklearn.svm import SVC\n",
    "\n",
    "svm_model = SVC(kernel='linear', C=10.0, gamma='scale', random_state=42)\n",
    "svm_model.fit(train_features, train_labels_encoded)\n",
    "svm_predictions = svm_model.predict(test_features)\n",
    "\n",
    "svm_accuracy = accuracy_score(test_labels_encoded, svm_predictions)\n",
    "print(f\"SVM Accuracy: {svm_accuracy:.4f}\")\n",
    "print(\"SVM Classification Report:\")\n",
    "print(classification_report(test_labels_encoded, svm_predictions))\n",
    "\n",
    "# Function to save confusion matrix\n",
    "def save_confusion_matrix(conf_matrix, labels, model_name, layer_number, folder_name):\n",
    "    os.makedirs(folder_name, exist_ok=True)  # Ensure the folder exists\n",
    "    plt.figure(figsize=(10, 8))\n",
    "    sns.set(font_scale=1.2)\n",
    "    sns.heatmap(conf_matrix, annot=True, fmt='d', cmap='viridis', xticklabels=labels, yticklabels=labels)\n",
    "    plt.title(f'{model_name} Confusion Matrix')\n",
    "    plt.xlabel('Predicted Labels')\n",
    "    plt.ylabel('True Labels')\n",
    "    plt.tight_layout()\n",
    "    save_path = os.path.join(folder_name, f'conf_matrix_layer_{layer_number}.png')\n",
    "    plt.savefig(save_path)\n",
    "    plt.close()\n",
    "    print(f\"Saved confusion matrix for {model_name}: {save_path}\")\n",
    "\n",
    "# SVM Confusion Matrix\n",
    "svm_conf_matrix = confusion_matrix(test_labels_encoded, svm_predictions)\n",
    "save_confusion_matrix(svm_conf_matrix, label_encoder.classes_, \"SVM\", 0, \"../Files/confusion_matrix/balanced_accuracy_gender_hubert/svm_conf_matrix\")\n",
    "\n",
    "# ANN Model\n",
    "ann_model = Sequential([\n",
    "    Dense(512, activation='relu', input_shape=(train_features_normalized.shape[1],)),\n",
    "    Dropout(0.5),\n",
    "    Dense(256, activation='relu'),\n",
    "    Dropout(0.5),\n",
    "    Dense(128, activation='relu'),\n",
    "    Dropout(0.5),\n",
    "    Dense(len(label_encoder.classes_), activation='softmax')\n",
    "])\n",
    "\n",
    "ann_model.compile(optimizer='adam', loss='sparse_categorical_crossentropy', metrics=['accuracy'])\n",
    "\n",
    "# Train the ANN\n",
    "ann_history = ann_model.fit(\n",
    "    train_features_normalized, \n",
    "    train_labels_encoded, \n",
    "    epochs=50, \n",
    "    batch_size=32, \n",
    "    validation_split=0.2,\n",
    "    callbacks=[tf.keras.callbacks.EarlyStopping(patience=5)]\n",
    ")\n",
    "\n",
    "# Evaluate the ANN\n",
    "ann_test_loss, ann_test_accuracy = ann_model.evaluate(test_features_normalized, test_labels_encoded)\n",
    "print(f\"ANN Test Accuracy: {ann_test_accuracy:.4f}\")\n",
    "\n",
    "# ANN Predictions and Classification Report\n",
    "ann_predictions = np.argmax(ann_model.predict(test_features_normalized), axis=1)\n",
    "print(\"ANN Classification Report:\")\n",
    "print(classification_report(test_labels_encoded, ann_predictions))\n",
    "\n",
    "# ANN Confusion Matrix\n",
    "ann_conf_matrix = confusion_matrix(test_labels_encoded, ann_predictions)\n",
    "save_confusion_matrix(ann_conf_matrix, label_encoder.classes_, \"ANN\", 0, \"../Files/confusion_matrix/balanced_accuracy_gender_hubert/ann_conf_matrix\")\n",
    "\n",
    "# Reshape the data for CNN\n",
    "train_features_cnn = np.expand_dims(train_features_normalized, axis=-1)\n",
    "test_features_cnn = np.expand_dims(test_features_normalized, axis=-1)\n",
    "\n",
    "# TensorFlow CNN Model\n",
    "cnn_model = Sequential([\n",
    "    Conv1D(64, kernel_size=5, activation='relu', input_shape=(train_features_cnn.shape[1], 1)),\n",
    "    Conv1D(128, kernel_size=5, activation='relu'),\n",
    "    Conv1D(256, kernel_size=5, activation='relu'),\n",
    "    Flatten(),\n",
    "    Dense(256, activation='relu'),\n",
    "    Dropout(0.5),\n",
    "    Dense(len(label_encoder.classes_), activation='softmax')\n",
    "])\n",
    "\n",
    "cnn_model.compile(optimizer='adam', loss='sparse_categorical_crossentropy', metrics=['accuracy'])\n",
    "\n",
    "# Train the TensorFlow CNN\n",
    "history = cnn_model.fit(\n",
    "    train_features_cnn, \n",
    "    train_labels_encoded, \n",
    "    epochs=50, \n",
    "    batch_size=32, \n",
    "    validation_split=0.2,\n",
    "    callbacks=[tf.keras.callbacks.EarlyStopping(patience=5)]\n",
    ")\n",
    "\n",
    "# Evaluate the TensorFlow CNN\n",
    "cnn_predictions = np.argmax(cnn_model.predict(test_features_cnn), axis=1)\n",
    "cnn_balanced_accuracy = accuracy_score(test_labels_encoded, cnn_predictions)\n",
    "\n",
    "print(f\"TensorFlow CNN Balanced Accuracy Score: {cnn_balanced_accuracy:.4f}\")\n",
    "print(\"TensorFlow CNN Classification Report:\")\n",
    "print(classification_report(test_labels_encoded, cnn_predictions))\n",
    "\n",
    "# CNN Confusion Matrix\n",
    "cnn_conf_matrix = confusion_matrix(test_labels_encoded, cnn_predictions)\n",
    "save_confusion_matrix(cnn_conf_matrix, label_encoder.classes_, \"CNN\", 0, \"../Files/confusion_matrix/balanced_accuracy_gender_hubert/cnn_conf_matrix\")\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "380b5bc1",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 1\n",
    "import os\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.preprocessing import LabelEncoder, StandardScaler\n",
    "from sklearn.metrics import accuracy_score, classification_report, confusion_matrix\n",
    "import tensorflow as tf\n",
    "from tensorflow.keras.models import Sequential\n",
    "from tensorflow.keras.layers import Conv1D, Flatten, Dense, Dropout\n",
    "import torch\n",
    "from torch.utils.data import DataLoader, TensorDataset\n",
    "import torch.nn as nn\n",
    "import torch.optim as optim\n",
    "import seaborn as sns\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "# Load the data\n",
    "train_data = np.load('../Files/extracted_features/hubert_large/train_1.npz')\n",
    "test_data = np.load('../Files/extracted_features/hubert_large/test_1.npz')\n",
    "\n",
    "train_features = train_data['features']\n",
    "test_features = test_data['features']\n",
    "\n",
    "train_labels = pd.read_csv('../Files/labels/y_train.csv').Gender_bin\n",
    "test_labels = pd.read_csv('../Files/labels/y_test.csv').Gender_bin\n",
    "\n",
    "# Encode the labels\n",
    "label_encoder = LabelEncoder()\n",
    "train_labels_encoded = label_encoder.fit_transform(train_labels)\n",
    "test_labels_encoded = label_encoder.transform(test_labels)\n",
    "\n",
    "# Normalize the features\n",
    "scaler = StandardScaler()\n",
    "train_features_normalized = scaler.fit_transform(train_features)\n",
    "test_features_normalized = scaler.transform(test_features)\n",
    "\n",
    "# SVM Classification\n",
    "from sklearn.svm import SVC\n",
    "\n",
    "svm_model = SVC(kernel='linear', C=10.0, gamma='scale', random_state=42)\n",
    "svm_model.fit(train_features, train_labels_encoded)\n",
    "svm_predictions = svm_model.predict(test_features)\n",
    "\n",
    "svm_accuracy = accuracy_score(test_labels_encoded, svm_predictions)\n",
    "print(f\"SVM Accuracy: {svm_accuracy:.4f}\")\n",
    "print(\"SVM Classification Report:\")\n",
    "print(classification_report(test_labels_encoded, svm_predictions))\n",
    "\n",
    "# Function to save confusion matrix\n",
    "def save_confusion_matrix(conf_matrix, labels, model_name, layer_number, folder_name):\n",
    "    os.makedirs(folder_name, exist_ok=True)  # Ensure the folder exists\n",
    "    plt.figure(figsize=(10, 8))\n",
    "    sns.set(font_scale=1.2)\n",
    "    sns.heatmap(conf_matrix, annot=True, fmt='d', cmap='viridis', xticklabels=labels, yticklabels=labels)\n",
    "    plt.title(f'{model_name} Confusion Matrix')\n",
    "    plt.xlabel('Predicted Labels')\n",
    "    plt.ylabel('True Labels')\n",
    "    plt.tight_layout()\n",
    "    save_path = os.path.join(folder_name, f'conf_matrix_layer_{layer_number}.png')\n",
    "    plt.savefig(save_path)\n",
    "    plt.close()\n",
    "    print(f\"Saved confusion matrix for {model_name}: {save_path}\")\n",
    "\n",
    "# SVM Confusion Matrix\n",
    "svm_conf_matrix = confusion_matrix(test_labels_encoded, svm_predictions)\n",
    "save_confusion_matrix(svm_conf_matrix, label_encoder.classes_, \"SVM\", 1, \"../Files/confusion_matrix/balanced_accuracy_gender_hubert/svm_conf_matrix\")\n",
    "\n",
    "# ANN Model\n",
    "ann_model = Sequential([\n",
    "    Dense(512, activation='relu', input_shape=(train_features_normalized.shape[1],)),\n",
    "    Dropout(0.5),\n",
    "    Dense(256, activation='relu'),\n",
    "    Dropout(0.5),\n",
    "    Dense(128, activation='relu'),\n",
    "    Dropout(0.5),\n",
    "    Dense(len(label_encoder.classes_), activation='softmax')\n",
    "])\n",
    "\n",
    "ann_model.compile(optimizer='adam', loss='sparse_categorical_crossentropy', metrics=['accuracy'])\n",
    "\n",
    "# Train the ANN\n",
    "ann_history = ann_model.fit(\n",
    "    train_features_normalized, \n",
    "    train_labels_encoded, \n",
    "    epochs=50, \n",
    "    batch_size=32, \n",
    "    validation_split=0.2,\n",
    "    callbacks=[tf.keras.callbacks.EarlyStopping(patience=5)]\n",
    ")\n",
    "\n",
    "# Evaluate the ANN\n",
    "ann_test_loss, ann_test_accuracy = ann_model.evaluate(test_features_normalized, test_labels_encoded)\n",
    "print(f\"ANN Test Accuracy: {ann_test_accuracy:.4f}\")\n",
    "\n",
    "# ANN Predictions and Classification Report\n",
    "ann_predictions = np.argmax(ann_model.predict(test_features_normalized), axis=1)\n",
    "print(\"ANN Classification Report:\")\n",
    "print(classification_report(test_labels_encoded, ann_predictions))\n",
    "\n",
    "# ANN Confusion Matrix\n",
    "ann_conf_matrix = confusion_matrix(test_labels_encoded, ann_predictions)\n",
    "save_confusion_matrix(ann_conf_matrix, label_encoder.classes_, \"ANN\", 1, \"../Files/confusion_matrix/balanced_accuracy_gender_hubert/ann_conf_matrix\")\n",
    "\n",
    "# Reshape the data for CNN\n",
    "train_features_cnn = np.expand_dims(train_features_normalized, axis=-1)\n",
    "test_features_cnn = np.expand_dims(test_features_normalized, axis=-1)\n",
    "\n",
    "# TensorFlow CNN Model\n",
    "cnn_model = Sequential([\n",
    "    Conv1D(64, kernel_size=5, activation='relu', input_shape=(train_features_cnn.shape[1], 1)),\n",
    "    Conv1D(128, kernel_size=5, activation='relu'),\n",
    "    Conv1D(256, kernel_size=5, activation='relu'),\n",
    "    Flatten(),\n",
    "    Dense(256, activation='relu'),\n",
    "    Dropout(0.5),\n",
    "    Dense(len(label_encoder.classes_), activation='softmax')\n",
    "])\n",
    "\n",
    "cnn_model.compile(optimizer='adam', loss='sparse_categorical_crossentropy', metrics=['accuracy'])\n",
    "\n",
    "# Train the TensorFlow CNN\n",
    "history = cnn_model.fit(\n",
    "    train_features_cnn, \n",
    "    train_labels_encoded, \n",
    "    epochs=50, \n",
    "    batch_size=32, \n",
    "    validation_split=0.2,\n",
    "    callbacks=[tf.keras.callbacks.EarlyStopping(patience=5)]\n",
    ")\n",
    "\n",
    "# Evaluate the TensorFlow CNN\n",
    "cnn_predictions = np.argmax(cnn_model.predict(test_features_cnn), axis=1)\n",
    "cnn_balanced_accuracy = accuracy_score(test_labels_encoded, cnn_predictions)\n",
    "\n",
    "print(f\"TensorFlow CNN Balanced Accuracy Score: {cnn_balanced_accuracy:.4f}\")\n",
    "print(\"TensorFlow CNN Classification Report:\")\n",
    "print(classification_report(test_labels_encoded, cnn_predictions))\n",
    "\n",
    "# CNN Confusion Matrix\n",
    "cnn_conf_matrix = confusion_matrix(test_labels_encoded, cnn_predictions)\n",
    "save_confusion_matrix(cnn_conf_matrix, label_encoder.classes_, \"CNN\", 1, \"../Files/confusion_matrix/balanced_accuracy_gender_hubert/cnn_conf_matrix\")\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5c9b517f",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 2\n",
    "import os\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.preprocessing import LabelEncoder, StandardScaler\n",
    "from sklearn.metrics import accuracy_score, classification_report, confusion_matrix\n",
    "import tensorflow as tf\n",
    "from tensorflow.keras.models import Sequential\n",
    "from tensorflow.keras.layers import Conv1D, Flatten, Dense, Dropout\n",
    "import torch\n",
    "from torch.utils.data import DataLoader, TensorDataset\n",
    "import torch.nn as nn\n",
    "import torch.optim as optim\n",
    "import seaborn as sns\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "# Load the data\n",
    "train_data = np.load('../Files/extracted_features/hubert_large/train_2.npz')\n",
    "test_data = np.load('../Files/extracted_features/hubert_large/test_2.npz')\n",
    "\n",
    "train_features = train_data['features']\n",
    "test_features = test_data['features']\n",
    "\n",
    "train_labels = pd.read_csv('../Files/labels/y_train.csv').Gender_bin\n",
    "test_labels = pd.read_csv('../Files/labels/y_test.csv').Gender_bin\n",
    "\n",
    "# Encode the labels\n",
    "label_encoder = LabelEncoder()\n",
    "train_labels_encoded = label_encoder.fit_transform(train_labels)\n",
    "test_labels_encoded = label_encoder.transform(test_labels)\n",
    "\n",
    "# Normalize the features\n",
    "scaler = StandardScaler()\n",
    "train_features_normalized = scaler.fit_transform(train_features)\n",
    "test_features_normalized = scaler.transform(test_features)\n",
    "\n",
    "# SVM Classification\n",
    "from sklearn.svm import SVC\n",
    "\n",
    "svm_model = SVC(kernel='linear', C=10.0, gamma='scale', random_state=42)\n",
    "svm_model.fit(train_features, train_labels_encoded)\n",
    "svm_predictions = svm_model.predict(test_features)\n",
    "\n",
    "svm_accuracy = accuracy_score(test_labels_encoded, svm_predictions)\n",
    "print(f\"SVM Accuracy: {svm_accuracy:.4f}\")\n",
    "print(\"SVM Classification Report:\")\n",
    "print(classification_report(test_labels_encoded, svm_predictions))\n",
    "\n",
    "# Function to save confusion matrix\n",
    "def save_confusion_matrix(conf_matrix, labels, model_name, layer_number, folder_name):\n",
    "    os.makedirs(folder_name, exist_ok=True)  # Ensure the folder exists\n",
    "    plt.figure(figsize=(10, 8))\n",
    "    sns.set(font_scale=1.2)\n",
    "    sns.heatmap(conf_matrix, annot=True, fmt='d', cmap='viridis', xticklabels=labels, yticklabels=labels)\n",
    "    plt.title(f'{model_name} Confusion Matrix')\n",
    "    plt.xlabel('Predicted Labels')\n",
    "    plt.ylabel('True Labels')\n",
    "    plt.tight_layout()\n",
    "    save_path = os.path.join(folder_name, f'conf_matrix_layer_{layer_number}.png')\n",
    "    plt.savefig(save_path)\n",
    "    plt.close()\n",
    "    print(f\"Saved confusion matrix for {model_name}: {save_path}\")\n",
    "\n",
    "# SVM Confusion Matrix\n",
    "svm_conf_matrix = confusion_matrix(test_labels_encoded, svm_predictions)\n",
    "save_confusion_matrix(svm_conf_matrix, label_encoder.classes_, \"SVM\", 2, \"../Files/confusion_matrix/balanced_accuracy_gender_hubert/svm_conf_matrix\")\n",
    "\n",
    "# ANN Model\n",
    "ann_model = Sequential([\n",
    "    Dense(512, activation='relu', input_shape=(train_features_normalized.shape[1],)),\n",
    "    Dropout(0.5),\n",
    "    Dense(256, activation='relu'),\n",
    "    Dropout(0.5),\n",
    "    Dense(128, activation='relu'),\n",
    "    Dropout(0.5),\n",
    "    Dense(len(label_encoder.classes_), activation='softmax')\n",
    "])\n",
    "\n",
    "ann_model.compile(optimizer='adam', loss='sparse_categorical_crossentropy', metrics=['accuracy'])\n",
    "\n",
    "# Train the ANN\n",
    "ann_history = ann_model.fit(\n",
    "    train_features_normalized, \n",
    "    train_labels_encoded, \n",
    "    epochs=50, \n",
    "    batch_size=32, \n",
    "    validation_split=0.2,\n",
    "    callbacks=[tf.keras.callbacks.EarlyStopping(patience=5)]\n",
    ")\n",
    "\n",
    "# Evaluate the ANN\n",
    "ann_test_loss, ann_test_accuracy = ann_model.evaluate(test_features_normalized, test_labels_encoded)\n",
    "print(f\"ANN Test Accuracy: {ann_test_accuracy:.4f}\")\n",
    "\n",
    "# ANN Predictions and Classification Report\n",
    "ann_predictions = np.argmax(ann_model.predict(test_features_normalized), axis=1)\n",
    "print(\"ANN Classification Report:\")\n",
    "print(classification_report(test_labels_encoded, ann_predictions))\n",
    "\n",
    "# ANN Confusion Matrix\n",
    "ann_conf_matrix = confusion_matrix(test_labels_encoded, ann_predictions)\n",
    "save_confusion_matrix(ann_conf_matrix, label_encoder.classes_, \"ANN\", 2, \"../Files/confusion_matrix/balanced_accuracy_gender_hubert/ann_conf_matrix\")\n",
    "\n",
    "# Reshape the data for CNN\n",
    "train_features_cnn = np.expand_dims(train_features_normalized, axis=-1)\n",
    "test_features_cnn = np.expand_dims(test_features_normalized, axis=-1)\n",
    "\n",
    "# TensorFlow CNN Model\n",
    "cnn_model = Sequential([\n",
    "    Conv1D(64, kernel_size=5, activation='relu', input_shape=(train_features_cnn.shape[1], 1)),\n",
    "    Conv1D(128, kernel_size=5, activation='relu'),\n",
    "    Conv1D(256, kernel_size=5, activation='relu'),\n",
    "    Flatten(),\n",
    "    Dense(256, activation='relu'),\n",
    "    Dropout(0.5),\n",
    "    Dense(len(label_encoder.classes_), activation='softmax')\n",
    "])\n",
    "\n",
    "cnn_model.compile(optimizer='adam', loss='sparse_categorical_crossentropy', metrics=['accuracy'])\n",
    "\n",
    "# Train the TensorFlow CNN\n",
    "history = cnn_model.fit(\n",
    "    train_features_cnn, \n",
    "    train_labels_encoded, \n",
    "    epochs=50, \n",
    "    batch_size=32, \n",
    "    validation_split=0.2,\n",
    "    callbacks=[tf.keras.callbacks.EarlyStopping(patience=5)]\n",
    ")\n",
    "\n",
    "# Evaluate the TensorFlow CNN\n",
    "cnn_predictions = np.argmax(cnn_model.predict(test_features_cnn), axis=1)\n",
    "cnn_balanced_accuracy = accuracy_score(test_labels_encoded, cnn_predictions)\n",
    "\n",
    "print(f\"TensorFlow CNN Balanced Accuracy Score: {cnn_balanced_accuracy:.4f}\")\n",
    "print(\"TensorFlow CNN Classification Report:\")\n",
    "print(classification_report(test_labels_encoded, cnn_predictions))\n",
    "\n",
    "# CNN Confusion Matrix\n",
    "cnn_conf_matrix = confusion_matrix(test_labels_encoded, cnn_predictions)\n",
    "save_confusion_matrix(cnn_conf_matrix, label_encoder.classes_, \"CNN\", 2, \"../Files/confusion_matrix/balanced_accuracy_gender_hubert/cnn_conf_matrix\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e66ca0a1",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 3\n",
    "import os\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.preprocessing import LabelEncoder, StandardScaler\n",
    "from sklearn.metrics import accuracy_score, classification_report, confusion_matrix\n",
    "import tensorflow as tf\n",
    "from tensorflow.keras.models import Sequential\n",
    "from tensorflow.keras.layers import Conv1D, Flatten, Dense, Dropout\n",
    "import torch\n",
    "from torch.utils.data import DataLoader, TensorDataset\n",
    "import torch.nn as nn\n",
    "import torch.optim as optim\n",
    "import seaborn as sns\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "# Load the data\n",
    "train_data = np.load('../Files/extracted_features/hubert_large/train_3.npz')\n",
    "test_data = np.load('../Files/extracted_features/hubert_large/test_3.npz')\n",
    "\n",
    "train_features = train_data['features']\n",
    "test_features = test_data['features']\n",
    "\n",
    "train_labels = pd.read_csv('../Files/labels/y_train.csv').Gender_bin\n",
    "test_labels = pd.read_csv('../Files/labels/y_test.csv').Gender_bin\n",
    "\n",
    "# Encode the labels\n",
    "label_encoder = LabelEncoder()\n",
    "train_labels_encoded = label_encoder.fit_transform(train_labels)\n",
    "test_labels_encoded = label_encoder.transform(test_labels)\n",
    "\n",
    "# Normalize the features\n",
    "scaler = StandardScaler()\n",
    "train_features_normalized = scaler.fit_transform(train_features)\n",
    "test_features_normalized = scaler.transform(test_features)\n",
    "\n",
    "# SVM Classification\n",
    "from sklearn.svm import SVC\n",
    "\n",
    "svm_model = SVC(kernel='linear', C=10.0, gamma='scale', random_state=42)\n",
    "svm_model.fit(train_features, train_labels_encoded)\n",
    "svm_predictions = svm_model.predict(test_features)\n",
    "\n",
    "svm_accuracy = accuracy_score(test_labels_encoded, svm_predictions)\n",
    "print(f\"SVM Accuracy: {svm_accuracy:.4f}\")\n",
    "print(\"SVM Classification Report:\")\n",
    "print(classification_report(test_labels_encoded, svm_predictions))\n",
    "\n",
    "# Function to save confusion matrix\n",
    "def save_confusion_matrix(conf_matrix, labels, model_name, layer_number, folder_name):\n",
    "    os.makedirs(folder_name, exist_ok=True)  # Ensure the folder exists\n",
    "    plt.figure(figsize=(10, 8))\n",
    "    sns.set(font_scale=1.2)\n",
    "    sns.heatmap(conf_matrix, annot=True, fmt='d', cmap='viridis', xticklabels=labels, yticklabels=labels)\n",
    "    plt.title(f'{model_name} Confusion Matrix')\n",
    "    plt.xlabel('Predicted Labels')\n",
    "    plt.ylabel('True Labels')\n",
    "    plt.tight_layout()\n",
    "    save_path = os.path.join(folder_name, f'conf_matrix_layer_{layer_number}.png')\n",
    "    plt.savefig(save_path)\n",
    "    plt.close()\n",
    "    print(f\"Saved confusion matrix for {model_name}: {save_path}\")\n",
    "\n",
    "# SVM Confusion Matrix\n",
    "svm_conf_matrix = confusion_matrix(test_labels_encoded, svm_predictions)\n",
    "save_confusion_matrix(svm_conf_matrix, label_encoder.classes_, \"SVM\", 3, \"../Files/confusion_matrix/balanced_accuracy_gender_hubert/svm_conf_matrix\")\n",
    "\n",
    "# ANN Model\n",
    "ann_model = Sequential([\n",
    "    Dense(512, activation='relu', input_shape=(train_features_normalized.shape[1],)),\n",
    "    Dropout(0.5),\n",
    "    Dense(256, activation='relu'),\n",
    "    Dropout(0.5),\n",
    "    Dense(128, activation='relu'),\n",
    "    Dropout(0.5),\n",
    "    Dense(len(label_encoder.classes_), activation='softmax')\n",
    "])\n",
    "\n",
    "ann_model.compile(optimizer='adam', loss='sparse_categorical_crossentropy', metrics=['accuracy'])\n",
    "\n",
    "# Train the ANN\n",
    "ann_history = ann_model.fit(\n",
    "    train_features_normalized, \n",
    "    train_labels_encoded, \n",
    "    epochs=50, \n",
    "    batch_size=32, \n",
    "    validation_split=0.2,\n",
    "    callbacks=[tf.keras.callbacks.EarlyStopping(patience=5)]\n",
    ")\n",
    "\n",
    "# Evaluate the ANN\n",
    "ann_test_loss, ann_test_accuracy = ann_model.evaluate(test_features_normalized, test_labels_encoded)\n",
    "print(f\"ANN Test Accuracy: {ann_test_accuracy:.4f}\")\n",
    "\n",
    "# ANN Predictions and Classification Report\n",
    "ann_predictions = np.argmax(ann_model.predict(test_features_normalized), axis=1)\n",
    "print(\"ANN Classification Report:\")\n",
    "print(classification_report(test_labels_encoded, ann_predictions))\n",
    "\n",
    "# ANN Confusion Matrix\n",
    "ann_conf_matrix = confusion_matrix(test_labels_encoded, ann_predictions)\n",
    "save_confusion_matrix(ann_conf_matrix, label_encoder.classes_, \"ANN\", 3, \"../Files/confusion_matrix/balanced_accuracy_gender_hubert/ann_conf_matrix\")\n",
    "\n",
    "# Reshape the data for CNN\n",
    "train_features_cnn = np.expand_dims(train_features_normalized, axis=-1)\n",
    "test_features_cnn = np.expand_dims(test_features_normalized, axis=-1)\n",
    "\n",
    "# TensorFlow CNN Model\n",
    "cnn_model = Sequential([\n",
    "    Conv1D(64, kernel_size=5, activation='relu', input_shape=(train_features_cnn.shape[1], 1)),\n",
    "    Conv1D(128, kernel_size=5, activation='relu'),\n",
    "    Conv1D(256, kernel_size=5, activation='relu'),\n",
    "    Flatten(),\n",
    "    Dense(256, activation='relu'),\n",
    "    Dropout(0.5),\n",
    "    Dense(len(label_encoder.classes_), activation='softmax')\n",
    "])\n",
    "\n",
    "cnn_model.compile(optimizer='adam', loss='sparse_categorical_crossentropy', metrics=['accuracy'])\n",
    "\n",
    "# Train the TensorFlow CNN\n",
    "history = cnn_model.fit(\n",
    "    train_features_cnn, \n",
    "    train_labels_encoded, \n",
    "    epochs=50, \n",
    "    batch_size=32, \n",
    "    validation_split=0.2,\n",
    "    callbacks=[tf.keras.callbacks.EarlyStopping(patience=5)]\n",
    ")\n",
    "\n",
    "# Evaluate the TensorFlow CNN\n",
    "cnn_predictions = np.argmax(cnn_model.predict(test_features_cnn), axis=1)\n",
    "cnn_balanced_accuracy = accuracy_score(test_labels_encoded, cnn_predictions)\n",
    "\n",
    "print(f\"TensorFlow CNN Balanced Accuracy Score: {cnn_balanced_accuracy:.4f}\")\n",
    "print(\"TensorFlow CNN Classification Report:\")\n",
    "print(classification_report(test_labels_encoded, cnn_predictions))\n",
    "\n",
    "# CNN Confusion Matrix\n",
    "cnn_conf_matrix = confusion_matrix(test_labels_encoded, cnn_predictions)\n",
    "save_confusion_matrix(cnn_conf_matrix, label_encoder.classes_, \"CNN\", 3, \"../Files/confusion_matrix/balanced_accuracy_gender_hubert/cnn_conf_matrix\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "88682fb4",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 4\n",
    "import os\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.preprocessing import LabelEncoder, StandardScaler\n",
    "from sklearn.metrics import accuracy_score, classification_report, confusion_matrix\n",
    "import tensorflow as tf\n",
    "from tensorflow.keras.models import Sequential\n",
    "from tensorflow.keras.layers import Conv1D, Flatten, Dense, Dropout\n",
    "import torch\n",
    "from torch.utils.data import DataLoader, TensorDataset\n",
    "import torch.nn as nn\n",
    "import torch.optim as optim\n",
    "import seaborn as sns\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "# Load the data\n",
    "train_data = np.load('../Files/extracted_features/hubert_large/train_4.npz')\n",
    "test_data = np.load('../Files/extracted_features/hubert_large/test_4.npz')\n",
    "\n",
    "train_features = train_data['features']\n",
    "test_features = test_data['features']\n",
    "\n",
    "train_labels = pd.read_csv('../Files/labels/y_train.csv').Gender_bin\n",
    "test_labels = pd.read_csv('../Files/labels/y_test.csv').Gender_bin\n",
    "\n",
    "# Encode the labels\n",
    "label_encoder = LabelEncoder()\n",
    "train_labels_encoded = label_encoder.fit_transform(train_labels)\n",
    "test_labels_encoded = label_encoder.transform(test_labels)\n",
    "\n",
    "# Normalize the features\n",
    "scaler = StandardScaler()\n",
    "train_features_normalized = scaler.fit_transform(train_features)\n",
    "test_features_normalized = scaler.transform(test_features)\n",
    "\n",
    "# SVM Classification\n",
    "from sklearn.svm import SVC\n",
    "\n",
    "svm_model = SVC(kernel='linear', C=10.0, gamma='scale', random_state=42)\n",
    "svm_model.fit(train_features, train_labels_encoded)\n",
    "svm_predictions = svm_model.predict(test_features)\n",
    "\n",
    "svm_accuracy = accuracy_score(test_labels_encoded, svm_predictions)\n",
    "print(f\"SVM Accuracy: {svm_accuracy:.4f}\")\n",
    "print(\"SVM Classification Report:\")\n",
    "print(classification_report(test_labels_encoded, svm_predictions))\n",
    "\n",
    "# Function to save confusion matrix\n",
    "def save_confusion_matrix(conf_matrix, labels, model_name, layer_number, folder_name):\n",
    "    os.makedirs(folder_name, exist_ok=True)  # Ensure the folder exists\n",
    "    plt.figure(figsize=(10, 8))\n",
    "    sns.set(font_scale=1.2)\n",
    "    sns.heatmap(conf_matrix, annot=True, fmt='d', cmap='viridis', xticklabels=labels, yticklabels=labels)\n",
    "    plt.title(f'{model_name} Confusion Matrix')\n",
    "    plt.xlabel('Predicted Labels')\n",
    "    plt.ylabel('True Labels')\n",
    "    plt.tight_layout()\n",
    "    save_path = os.path.join(folder_name, f'conf_matrix_layer_{layer_number}.png')\n",
    "    plt.savefig(save_path)\n",
    "    plt.close()\n",
    "    print(f\"Saved confusion matrix for {model_name}: {save_path}\")\n",
    "\n",
    "# SVM Confusion Matrix\n",
    "svm_conf_matrix = confusion_matrix(test_labels_encoded, svm_predictions)\n",
    "save_confusion_matrix(svm_conf_matrix, label_encoder.classes_, \"SVM\", 4, \"../Files/confusion_matrix/balanced_accuracy_gender_hubert/svm_conf_matrix\")\n",
    "\n",
    "# ANN Model\n",
    "ann_model = Sequential([\n",
    "    Dense(512, activation='relu', input_shape=(train_features_normalized.shape[1],)),\n",
    "    Dropout(0.5),\n",
    "    Dense(256, activation='relu'),\n",
    "    Dropout(0.5),\n",
    "    Dense(128, activation='relu'),\n",
    "    Dropout(0.5),\n",
    "    Dense(len(label_encoder.classes_), activation='softmax')\n",
    "])\n",
    "\n",
    "ann_model.compile(optimizer='adam', loss='sparse_categorical_crossentropy', metrics=['accuracy'])\n",
    "\n",
    "# Train the ANN\n",
    "ann_history = ann_model.fit(\n",
    "    train_features_normalized, \n",
    "    train_labels_encoded, \n",
    "    epochs=50, \n",
    "    batch_size=32, \n",
    "    validation_split=0.2,\n",
    "    callbacks=[tf.keras.callbacks.EarlyStopping(patience=5)]\n",
    ")\n",
    "\n",
    "# Evaluate the ANN\n",
    "ann_test_loss, ann_test_accuracy = ann_model.evaluate(test_features_normalized, test_labels_encoded)\n",
    "print(f\"ANN Test Accuracy: {ann_test_accuracy:.4f}\")\n",
    "\n",
    "# ANN Predictions and Classification Report\n",
    "ann_predictions = np.argmax(ann_model.predict(test_features_normalized), axis=1)\n",
    "print(\"ANN Classification Report:\")\n",
    "print(classification_report(test_labels_encoded, ann_predictions))\n",
    "\n",
    "# ANN Confusion Matrix\n",
    "ann_conf_matrix = confusion_matrix(test_labels_encoded, ann_predictions)\n",
    "save_confusion_matrix(ann_conf_matrix, label_encoder.classes_, \"ANN\", 4, \"../Files/confusion_matrix/balanced_accuracy_gender_hubert/ann_conf_matrix\")\n",
    "\n",
    "# Reshape the data for CNN\n",
    "train_features_cnn = np.expand_dims(train_features_normalized, axis=-1)\n",
    "test_features_cnn = np.expand_dims(test_features_normalized, axis=-1)\n",
    "\n",
    "# TensorFlow CNN Model\n",
    "cnn_model = Sequential([\n",
    "    Conv1D(64, kernel_size=5, activation='relu', input_shape=(train_features_cnn.shape[1], 1)),\n",
    "    Conv1D(128, kernel_size=5, activation='relu'),\n",
    "    Conv1D(256, kernel_size=5, activation='relu'),\n",
    "    Flatten(),\n",
    "    Dense(256, activation='relu'),\n",
    "    Dropout(0.5),\n",
    "    Dense(len(label_encoder.classes_), activation='softmax')\n",
    "])\n",
    "\n",
    "cnn_model.compile(optimizer='adam', loss='sparse_categorical_crossentropy', metrics=['accuracy'])\n",
    "\n",
    "# Train the TensorFlow CNN\n",
    "history = cnn_model.fit(\n",
    "    train_features_cnn, \n",
    "    train_labels_encoded, \n",
    "    epochs=50, \n",
    "    batch_size=32, \n",
    "    validation_split=0.2,\n",
    "    callbacks=[tf.keras.callbacks.EarlyStopping(patience=5)]\n",
    ")\n",
    "\n",
    "# Evaluate the TensorFlow CNN\n",
    "cnn_predictions = np.argmax(cnn_model.predict(test_features_cnn), axis=1)\n",
    "cnn_balanced_accuracy = accuracy_score(test_labels_encoded, cnn_predictions)\n",
    "\n",
    "print(f\"TensorFlow CNN Balanced Accuracy Score: {cnn_balanced_accuracy:.4f}\")\n",
    "print(\"TensorFlow CNN Classification Report:\")\n",
    "print(classification_report(test_labels_encoded, cnn_predictions))\n",
    "\n",
    "# CNN Confusion Matrix\n",
    "cnn_conf_matrix = confusion_matrix(test_labels_encoded, cnn_predictions)\n",
    "save_confusion_matrix(cnn_conf_matrix, label_encoder.classes_, \"CNN\", 4, \"../Files/confusion_matrix/balanced_accuracy_gender_hubert/cnn_conf_matrix\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "49f8cd2a",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 5\n",
    "import os\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.preprocessing import LabelEncoder, StandardScaler\n",
    "from sklearn.metrics import accuracy_score, classification_report, confusion_matrix\n",
    "import tensorflow as tf\n",
    "from tensorflow.keras.models import Sequential\n",
    "from tensorflow.keras.layers import Conv1D, Flatten, Dense, Dropout\n",
    "import torch\n",
    "from torch.utils.data import DataLoader, TensorDataset\n",
    "import torch.nn as nn\n",
    "import torch.optim as optim\n",
    "import seaborn as sns\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "# Load the data\n",
    "train_data = np.load('../Files/extracted_features/hubert_large/train_5.npz')\n",
    "test_data = np.load('../Files/extracted_features/hubert_large/test_5.npz')\n",
    "\n",
    "train_features = train_data['features']\n",
    "test_features = test_data['features']\n",
    "\n",
    "train_labels = pd.read_csv('../Files/labels/y_train.csv').Gender_bin\n",
    "test_labels = pd.read_csv('../Files/labels/y_test.csv').Gender_bin\n",
    "\n",
    "# Encode the labels\n",
    "label_encoder = LabelEncoder()\n",
    "train_labels_encoded = label_encoder.fit_transform(train_labels)\n",
    "test_labels_encoded = label_encoder.transform(test_labels)\n",
    "\n",
    "# Normalize the features\n",
    "scaler = StandardScaler()\n",
    "train_features_normalized = scaler.fit_transform(train_features)\n",
    "test_features_normalized = scaler.transform(test_features)\n",
    "\n",
    "# SVM Classification\n",
    "from sklearn.svm import SVC\n",
    "\n",
    "svm_model = SVC(kernel='linear', C=10.0, gamma='scale', random_state=42)\n",
    "svm_model.fit(train_features, train_labels_encoded)\n",
    "svm_predictions = svm_model.predict(test_features)\n",
    "\n",
    "svm_accuracy = accuracy_score(test_labels_encoded, svm_predictions)\n",
    "print(f\"SVM Accuracy: {svm_accuracy:.4f}\")\n",
    "print(\"SVM Classification Report:\")\n",
    "print(classification_report(test_labels_encoded, svm_predictions))\n",
    "\n",
    "# Function to save confusion matrix\n",
    "def save_confusion_matrix(conf_matrix, labels, model_name, layer_number, folder_name):\n",
    "    os.makedirs(folder_name, exist_ok=True)  # Ensure the folder exists\n",
    "    plt.figure(figsize=(10, 8))\n",
    "    sns.set(font_scale=1.2)\n",
    "    sns.heatmap(conf_matrix, annot=True, fmt='d', cmap='viridis', xticklabels=labels, yticklabels=labels)\n",
    "    plt.title(f'{model_name} Confusion Matrix')\n",
    "    plt.xlabel('Predicted Labels')\n",
    "    plt.ylabel('True Labels')\n",
    "    plt.tight_layout()\n",
    "    save_path = os.path.join(folder_name, f'conf_matrix_layer_{layer_number}.png')\n",
    "    plt.savefig(save_path)\n",
    "    plt.close()\n",
    "    print(f\"Saved confusion matrix for {model_name}: {save_path}\")\n",
    "\n",
    "# SVM Confusion Matrix\n",
    "svm_conf_matrix = confusion_matrix(test_labels_encoded, svm_predictions)\n",
    "save_confusion_matrix(svm_conf_matrix, label_encoder.classes_, \"SVM\", 5, \"../Files/confusion_matrix/balanced_accuracy_gender_hubert/svm_conf_matrix\")\n",
    "\n",
    "# ANN Model\n",
    "ann_model = Sequential([\n",
    "    Dense(512, activation='relu', input_shape=(train_features_normalized.shape[1],)),\n",
    "    Dropout(0.5),\n",
    "    Dense(256, activation='relu'),\n",
    "    Dropout(0.5),\n",
    "    Dense(128, activation='relu'),\n",
    "    Dropout(0.5),\n",
    "    Dense(len(label_encoder.classes_), activation='softmax')\n",
    "])\n",
    "\n",
    "ann_model.compile(optimizer='adam', loss='sparse_categorical_crossentropy', metrics=['accuracy'])\n",
    "\n",
    "# Train the ANN\n",
    "ann_history = ann_model.fit(\n",
    "    train_features_normalized, \n",
    "    train_labels_encoded, \n",
    "    epochs=50, \n",
    "    batch_size=32, \n",
    "    validation_split=0.2,\n",
    "    callbacks=[tf.keras.callbacks.EarlyStopping(patience=5)]\n",
    ")\n",
    "\n",
    "# Evaluate the ANN\n",
    "ann_test_loss, ann_test_accuracy = ann_model.evaluate(test_features_normalized, test_labels_encoded)\n",
    "print(f\"ANN Test Accuracy: {ann_test_accuracy:.4f}\")\n",
    "\n",
    "# ANN Predictions and Classification Report\n",
    "ann_predictions = np.argmax(ann_model.predict(test_features_normalized), axis=1)\n",
    "print(\"ANN Classification Report:\")\n",
    "print(classification_report(test_labels_encoded, ann_predictions))\n",
    "\n",
    "# ANN Confusion Matrix\n",
    "ann_conf_matrix = confusion_matrix(test_labels_encoded, ann_predictions)\n",
    "save_confusion_matrix(ann_conf_matrix, label_encoder.classes_, \"ANN\", 5, \"../Files/confusion_matrix/balanced_accuracy_gender_hubert/ann_conf_matrix\")\n",
    "\n",
    "# Reshape the data for CNN\n",
    "train_features_cnn = np.expand_dims(train_features_normalized, axis=-1)\n",
    "test_features_cnn = np.expand_dims(test_features_normalized, axis=-1)\n",
    "\n",
    "# TensorFlow CNN Model\n",
    "cnn_model = Sequential([\n",
    "    Conv1D(64, kernel_size=5, activation='relu', input_shape=(train_features_cnn.shape[1], 1)),\n",
    "    Conv1D(128, kernel_size=5, activation='relu'),\n",
    "    Conv1D(256, kernel_size=5, activation='relu'),\n",
    "    Flatten(),\n",
    "    Dense(256, activation='relu'),\n",
    "    Dropout(0.5),\n",
    "    Dense(len(label_encoder.classes_), activation='softmax')\n",
    "])\n",
    "\n",
    "cnn_model.compile(optimizer='adam', loss='sparse_categorical_crossentropy', metrics=['accuracy'])\n",
    "\n",
    "# Train the TensorFlow CNN\n",
    "history = cnn_model.fit(\n",
    "    train_features_cnn, \n",
    "    train_labels_encoded, \n",
    "    epochs=50, \n",
    "    batch_size=32, \n",
    "    validation_split=0.2,\n",
    "    callbacks=[tf.keras.callbacks.EarlyStopping(patience=5)]\n",
    ")\n",
    "\n",
    "# Evaluate the TensorFlow CNN\n",
    "cnn_predictions = np.argmax(cnn_model.predict(test_features_cnn), axis=1)\n",
    "cnn_balanced_accuracy = accuracy_score(test_labels_encoded, cnn_predictions)\n",
    "\n",
    "print(f\"TensorFlow CNN Balanced Accuracy Score: {cnn_balanced_accuracy:.4f}\")\n",
    "print(\"TensorFlow CNN Classification Report:\")\n",
    "print(classification_report(test_labels_encoded, cnn_predictions))\n",
    "\n",
    "# CNN Confusion Matrix\n",
    "cnn_conf_matrix = confusion_matrix(test_labels_encoded, cnn_predictions)\n",
    "save_confusion_matrix(cnn_conf_matrix, label_encoder.classes_, \"CNN\", 5, \"../Files/confusion_matrix/balanced_accuracy_gender_hubert/cnn_conf_matrix\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b6653c26",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 6\n",
    "import os\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.preprocessing import LabelEncoder, StandardScaler\n",
    "from sklearn.metrics import accuracy_score, classification_report, confusion_matrix\n",
    "import tensorflow as tf\n",
    "from tensorflow.keras.models import Sequential\n",
    "from tensorflow.keras.layers import Conv1D, Flatten, Dense, Dropout\n",
    "import torch\n",
    "from torch.utils.data import DataLoader, TensorDataset\n",
    "import torch.nn as nn\n",
    "import torch.optim as optim\n",
    "import seaborn as sns\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "# Load the data\n",
    "train_data = np.load('../Files/extracted_features/hubert_large/train_6.npz')\n",
    "test_data = np.load('../Files/extracted_features/hubert_large/test_6.npz')\n",
    "\n",
    "train_features = train_data['features']\n",
    "test_features = test_data['features']\n",
    "\n",
    "train_labels = pd.read_csv('../Files/labels/y_train.csv').Gender_bin\n",
    "test_labels = pd.read_csv('../Files/labels/y_test.csv').Gender_bin\n",
    "\n",
    "# Encode the labels\n",
    "label_encoder = LabelEncoder()\n",
    "train_labels_encoded = label_encoder.fit_transform(train_labels)\n",
    "test_labels_encoded = label_encoder.transform(test_labels)\n",
    "\n",
    "# Normalize the features\n",
    "scaler = StandardScaler()\n",
    "train_features_normalized = scaler.fit_transform(train_features)\n",
    "test_features_normalized = scaler.transform(test_features)\n",
    "\n",
    "# SVM Classification\n",
    "from sklearn.svm import SVC\n",
    "\n",
    "svm_model = SVC(kernel='linear', C=10.0, gamma='scale', random_state=42)\n",
    "svm_model.fit(train_features, train_labels_encoded)\n",
    "svm_predictions = svm_model.predict(test_features)\n",
    "\n",
    "svm_accuracy = accuracy_score(test_labels_encoded, svm_predictions)\n",
    "print(f\"SVM Accuracy: {svm_accuracy:.4f}\")\n",
    "print(\"SVM Classification Report:\")\n",
    "print(classification_report(test_labels_encoded, svm_predictions))\n",
    "\n",
    "# Function to save confusion matrix\n",
    "def save_confusion_matrix(conf_matrix, labels, model_name, layer_number, folder_name):\n",
    "    os.makedirs(folder_name, exist_ok=True)  # Ensure the folder exists\n",
    "    plt.figure(figsize=(10, 8))\n",
    "    sns.set(font_scale=1.2)\n",
    "    sns.heatmap(conf_matrix, annot=True, fmt='d', cmap='viridis', xticklabels=labels, yticklabels=labels)\n",
    "    plt.title(f'{model_name} Confusion Matrix')\n",
    "    plt.xlabel('Predicted Labels')\n",
    "    plt.ylabel('True Labels')\n",
    "    plt.tight_layout()\n",
    "    save_path = os.path.join(folder_name, f'conf_matrix_layer_{layer_number}.png')\n",
    "    plt.savefig(save_path)\n",
    "    plt.close()\n",
    "    print(f\"Saved confusion matrix for {model_name}: {save_path}\")\n",
    "\n",
    "# SVM Confusion Matrix\n",
    "svm_conf_matrix = confusion_matrix(test_labels_encoded, svm_predictions)\n",
    "save_confusion_matrix(svm_conf_matrix, label_encoder.classes_, \"SVM\", 6, \"../Files/confusion_matrix/balanced_accuracy_gender_hubert/svm_conf_matrix\")\n",
    "\n",
    "# ANN Model\n",
    "ann_model = Sequential([\n",
    "    Dense(512, activation='relu', input_shape=(train_features_normalized.shape[1],)),\n",
    "    Dropout(0.5),\n",
    "    Dense(256, activation='relu'),\n",
    "    Dropout(0.5),\n",
    "    Dense(128, activation='relu'),\n",
    "    Dropout(0.5),\n",
    "    Dense(len(label_encoder.classes_), activation='softmax')\n",
    "])\n",
    "\n",
    "ann_model.compile(optimizer='adam', loss='sparse_categorical_crossentropy', metrics=['accuracy'])\n",
    "\n",
    "# Train the ANN\n",
    "ann_history = ann_model.fit(\n",
    "    train_features_normalized, \n",
    "    train_labels_encoded, \n",
    "    epochs=50, \n",
    "    batch_size=32, \n",
    "    validation_split=0.2,\n",
    "    callbacks=[tf.keras.callbacks.EarlyStopping(patience=5)]\n",
    ")\n",
    "\n",
    "# Evaluate the ANN\n",
    "ann_test_loss, ann_test_accuracy = ann_model.evaluate(test_features_normalized, test_labels_encoded)\n",
    "print(f\"ANN Test Accuracy: {ann_test_accuracy:.4f}\")\n",
    "\n",
    "# ANN Predictions and Classification Report\n",
    "ann_predictions = np.argmax(ann_model.predict(test_features_normalized), axis=1)\n",
    "print(\"ANN Classification Report:\")\n",
    "print(classification_report(test_labels_encoded, ann_predictions))\n",
    "\n",
    "# ANN Confusion Matrix\n",
    "ann_conf_matrix = confusion_matrix(test_labels_encoded, ann_predictions)\n",
    "save_confusion_matrix(ann_conf_matrix, label_encoder.classes_, \"ANN\", 6, \"../Files/confusion_matrix/balanced_accuracy_gender_hubert/ann_conf_matrix\")\n",
    "\n",
    "# Reshape the data for CNN\n",
    "train_features_cnn = np.expand_dims(train_features_normalized, axis=-1)\n",
    "test_features_cnn = np.expand_dims(test_features_normalized, axis=-1)\n",
    "\n",
    "# TensorFlow CNN Model\n",
    "cnn_model = Sequential([\n",
    "    Conv1D(64, kernel_size=5, activation='relu', input_shape=(train_features_cnn.shape[1], 1)),\n",
    "    Conv1D(128, kernel_size=5, activation='relu'),\n",
    "    Conv1D(256, kernel_size=5, activation='relu'),\n",
    "    Flatten(),\n",
    "    Dense(256, activation='relu'),\n",
    "    Dropout(0.5),\n",
    "    Dense(len(label_encoder.classes_), activation='softmax')\n",
    "])\n",
    "\n",
    "cnn_model.compile(optimizer='adam', loss='sparse_categorical_crossentropy', metrics=['accuracy'])\n",
    "\n",
    "# Train the TensorFlow CNN\n",
    "history = cnn_model.fit(\n",
    "    train_features_cnn, \n",
    "    train_labels_encoded, \n",
    "    epochs=50, \n",
    "    batch_size=32, \n",
    "    validation_split=0.2,\n",
    "    callbacks=[tf.keras.callbacks.EarlyStopping(patience=5)]\n",
    ")\n",
    "\n",
    "# Evaluate the TensorFlow CNN\n",
    "cnn_predictions = np.argmax(cnn_model.predict(test_features_cnn), axis=1)\n",
    "cnn_balanced_accuracy = accuracy_score(test_labels_encoded, cnn_predictions)\n",
    "\n",
    "print(f\"TensorFlow CNN Balanced Accuracy Score: {cnn_balanced_accuracy:.4f}\")\n",
    "print(\"TensorFlow CNN Classification Report:\")\n",
    "print(classification_report(test_labels_encoded, cnn_predictions))\n",
    "\n",
    "# CNN Confusion Matrix\n",
    "cnn_conf_matrix = confusion_matrix(test_labels_encoded, cnn_predictions)\n",
    "save_confusion_matrix(cnn_conf_matrix, label_encoder.classes_, \"CNN\", 6, \"../Files/confusion_matrix/balanced_accuracy_gender_hubert/cnn_conf_matrix\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "151ac806",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 7\n",
    "import os\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.preprocessing import LabelEncoder, StandardScaler\n",
    "from sklearn.metrics import accuracy_score, classification_report, confusion_matrix\n",
    "import tensorflow as tf\n",
    "from tensorflow.keras.models import Sequential\n",
    "from tensorflow.keras.layers import Conv1D, Flatten, Dense, Dropout\n",
    "import torch\n",
    "from torch.utils.data import DataLoader, TensorDataset\n",
    "import torch.nn as nn\n",
    "import torch.optim as optim\n",
    "import seaborn as sns\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "# Load the data\n",
    "train_data = np.load('../Files/extracted_features/hubert_large/train_7.npz')\n",
    "test_data = np.load('../Files/extracted_features/hubert_large/test_7.npz')\n",
    "\n",
    "train_features = train_data['features']\n",
    "test_features = test_data['features']\n",
    "\n",
    "train_labels = pd.read_csv('../Files/labels/y_train.csv').Gender_bin\n",
    "test_labels = pd.read_csv('../Files/labels/y_test.csv').Gender_bin\n",
    "\n",
    "# Encode the labels\n",
    "label_encoder = LabelEncoder()\n",
    "train_labels_encoded = label_encoder.fit_transform(train_labels)\n",
    "test_labels_encoded = label_encoder.transform(test_labels)\n",
    "\n",
    "# Normalize the features\n",
    "scaler = StandardScaler()\n",
    "train_features_normalized = scaler.fit_transform(train_features)\n",
    "test_features_normalized = scaler.transform(test_features)\n",
    "\n",
    "# SVM Classification\n",
    "from sklearn.svm import SVC\n",
    "\n",
    "svm_model = SVC(kernel='linear', C=10.0, gamma='scale', random_state=42)\n",
    "svm_model.fit(train_features, train_labels_encoded)\n",
    "svm_predictions = svm_model.predict(test_features)\n",
    "\n",
    "svm_accuracy = accuracy_score(test_labels_encoded, svm_predictions)\n",
    "print(f\"SVM Accuracy: {svm_accuracy:.4f}\")\n",
    "print(\"SVM Classification Report:\")\n",
    "print(classification_report(test_labels_encoded, svm_predictions))\n",
    "\n",
    "# Function to save confusion matrix\n",
    "def save_confusion_matrix(conf_matrix, labels, model_name, layer_number, folder_name):\n",
    "    os.makedirs(folder_name, exist_ok=True)  # Ensure the folder exists\n",
    "    plt.figure(figsize=(10, 8))\n",
    "    sns.set(font_scale=1.2)\n",
    "    sns.heatmap(conf_matrix, annot=True, fmt='d', cmap='viridis', xticklabels=labels, yticklabels=labels)\n",
    "    plt.title(f'{model_name} Confusion Matrix')\n",
    "    plt.xlabel('Predicted Labels')\n",
    "    plt.ylabel('True Labels')\n",
    "    plt.tight_layout()\n",
    "    save_path = os.path.join(folder_name, f'conf_matrix_layer_{layer_number}.png')\n",
    "    plt.savefig(save_path)\n",
    "    plt.close()\n",
    "    print(f\"Saved confusion matrix for {model_name}: {save_path}\")\n",
    "\n",
    "# SVM Confusion Matrix\n",
    "svm_conf_matrix = confusion_matrix(test_labels_encoded, svm_predictions)\n",
    "save_confusion_matrix(svm_conf_matrix, label_encoder.classes_, \"SVM\", 7, \"../Files/confusion_matrix/balanced_accuracy_gender_hubert/svm_conf_matrix\")\n",
    "\n",
    "# ANN Model\n",
    "ann_model = Sequential([\n",
    "    Dense(512, activation='relu', input_shape=(train_features_normalized.shape[1],)),\n",
    "    Dropout(0.5),\n",
    "    Dense(256, activation='relu'),\n",
    "    Dropout(0.5),\n",
    "    Dense(128, activation='relu'),\n",
    "    Dropout(0.5),\n",
    "    Dense(len(label_encoder.classes_), activation='softmax')\n",
    "])\n",
    "\n",
    "ann_model.compile(optimizer='adam', loss='sparse_categorical_crossentropy', metrics=['accuracy'])\n",
    "\n",
    "# Train the ANN\n",
    "ann_history = ann_model.fit(\n",
    "    train_features_normalized, \n",
    "    train_labels_encoded, \n",
    "    epochs=50, \n",
    "    batch_size=32, \n",
    "    validation_split=0.2,\n",
    "    callbacks=[tf.keras.callbacks.EarlyStopping(patience=5)]\n",
    ")\n",
    "\n",
    "# Evaluate the ANN\n",
    "ann_test_loss, ann_test_accuracy = ann_model.evaluate(test_features_normalized, test_labels_encoded)\n",
    "print(f\"ANN Test Accuracy: {ann_test_accuracy:.4f}\")\n",
    "\n",
    "# ANN Predictions and Classification Report\n",
    "ann_predictions = np.argmax(ann_model.predict(test_features_normalized), axis=1)\n",
    "print(\"ANN Classification Report:\")\n",
    "print(classification_report(test_labels_encoded, ann_predictions))\n",
    "\n",
    "# ANN Confusion Matrix\n",
    "ann_conf_matrix = confusion_matrix(test_labels_encoded, ann_predictions)\n",
    "save_confusion_matrix(ann_conf_matrix, label_encoder.classes_, \"ANN\", 7, \"../Files/confusion_matrix/balanced_accuracy_gender_hubert/ann_conf_matrix\")\n",
    "\n",
    "# Reshape the data for CNN\n",
    "train_features_cnn = np.expand_dims(train_features_normalized, axis=-1)\n",
    "test_features_cnn = np.expand_dims(test_features_normalized, axis=-1)\n",
    "\n",
    "# TensorFlow CNN Model\n",
    "cnn_model = Sequential([\n",
    "    Conv1D(64, kernel_size=5, activation='relu', input_shape=(train_features_cnn.shape[1], 1)),\n",
    "    Conv1D(128, kernel_size=5, activation='relu'),\n",
    "    Conv1D(256, kernel_size=5, activation='relu'),\n",
    "    Flatten(),\n",
    "    Dense(256, activation='relu'),\n",
    "    Dropout(0.5),\n",
    "    Dense(len(label_encoder.classes_), activation='softmax')\n",
    "])\n",
    "\n",
    "cnn_model.compile(optimizer='adam', loss='sparse_categorical_crossentropy', metrics=['accuracy'])\n",
    "\n",
    "# Train the TensorFlow CNN\n",
    "history = cnn_model.fit(\n",
    "    train_features_cnn, \n",
    "    train_labels_encoded, \n",
    "    epochs=50, \n",
    "    batch_size=32, \n",
    "    validation_split=0.2,\n",
    "    callbacks=[tf.keras.callbacks.EarlyStopping(patience=5)]\n",
    ")\n",
    "\n",
    "# Evaluate the TensorFlow CNN\n",
    "cnn_predictions = np.argmax(cnn_model.predict(test_features_cnn), axis=1)\n",
    "cnn_balanced_accuracy = accuracy_score(test_labels_encoded, cnn_predictions)\n",
    "\n",
    "print(f\"TensorFlow CNN Balanced Accuracy Score: {cnn_balanced_accuracy:.4f}\")\n",
    "print(\"TensorFlow CNN Classification Report:\")\n",
    "print(classification_report(test_labels_encoded, cnn_predictions))\n",
    "\n",
    "# CNN Confusion Matrix\n",
    "cnn_conf_matrix = confusion_matrix(test_labels_encoded, cnn_predictions)\n",
    "save_confusion_matrix(cnn_conf_matrix, label_encoder.classes_, \"CNN\", 7, \"../Files/confusion_matrix/balanced_accuracy_gender_hubert/cnn_conf_matrix\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2d5e7cd9",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 8\n",
    "import os\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.preprocessing import LabelEncoder, StandardScaler\n",
    "from sklearn.metrics import accuracy_score, classification_report, confusion_matrix\n",
    "import tensorflow as tf\n",
    "from tensorflow.keras.models import Sequential\n",
    "from tensorflow.keras.layers import Conv1D, Flatten, Dense, Dropout\n",
    "import torch\n",
    "from torch.utils.data import DataLoader, TensorDataset\n",
    "import torch.nn as nn\n",
    "import torch.optim as optim\n",
    "import seaborn as sns\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "# Load the data\n",
    "train_data = np.load('../Files/extracted_features/hubert_large/train_8.npz')\n",
    "test_data = np.load('../Files/extracted_features/hubert_large/test_8.npz')\n",
    "\n",
    "train_features = train_data['features']\n",
    "test_features = test_data['features']\n",
    "\n",
    "train_labels = pd.read_csv('../Files/labels/y_train.csv').Gender_bin\n",
    "test_labels = pd.read_csv('../Files/labels/y_test.csv').Gender_bin\n",
    "\n",
    "# Encode the labels\n",
    "label_encoder = LabelEncoder()\n",
    "train_labels_encoded = label_encoder.fit_transform(train_labels)\n",
    "test_labels_encoded = label_encoder.transform(test_labels)\n",
    "\n",
    "# Normalize the features\n",
    "scaler = StandardScaler()\n",
    "train_features_normalized = scaler.fit_transform(train_features)\n",
    "test_features_normalized = scaler.transform(test_features)\n",
    "\n",
    "# SVM Classification\n",
    "from sklearn.svm import SVC\n",
    "\n",
    "svm_model = SVC(kernel='linear', C=10.0, gamma='scale', random_state=42)\n",
    "svm_model.fit(train_features, train_labels_encoded)\n",
    "svm_predictions = svm_model.predict(test_features)\n",
    "\n",
    "svm_accuracy = accuracy_score(test_labels_encoded, svm_predictions)\n",
    "print(f\"SVM Accuracy: {svm_accuracy:.4f}\")\n",
    "print(\"SVM Classification Report:\")\n",
    "print(classification_report(test_labels_encoded, svm_predictions))\n",
    "\n",
    "# Function to save confusion matrix\n",
    "def save_confusion_matrix(conf_matrix, labels, model_name, layer_number, folder_name):\n",
    "    os.makedirs(folder_name, exist_ok=True)  # Ensure the folder exists\n",
    "    plt.figure(figsize=(10, 8))\n",
    "    sns.set(font_scale=1.2)\n",
    "    sns.heatmap(conf_matrix, annot=True, fmt='d', cmap='viridis', xticklabels=labels, yticklabels=labels)\n",
    "    plt.title(f'{model_name} Confusion Matrix')\n",
    "    plt.xlabel('Predicted Labels')\n",
    "    plt.ylabel('True Labels')\n",
    "    plt.tight_layout()\n",
    "    save_path = os.path.join(folder_name, f'conf_matrix_layer_{layer_number}.png')\n",
    "    plt.savefig(save_path)\n",
    "    plt.close()\n",
    "    print(f\"Saved confusion matrix for {model_name}: {save_path}\")\n",
    "\n",
    "# SVM Confusion Matrix\n",
    "svm_conf_matrix = confusion_matrix(test_labels_encoded, svm_predictions)\n",
    "save_confusion_matrix(svm_conf_matrix, label_encoder.classes_, \"SVM\", 8, \"../Files/confusion_matrix/balanced_accuracy_gender_hubert/svm_conf_matrix\")\n",
    "\n",
    "# ANN Model\n",
    "ann_model = Sequential([\n",
    "    Dense(512, activation='relu', input_shape=(train_features_normalized.shape[1],)),\n",
    "    Dropout(0.5),\n",
    "    Dense(256, activation='relu'),\n",
    "    Dropout(0.5),\n",
    "    Dense(128, activation='relu'),\n",
    "    Dropout(0.5),\n",
    "    Dense(len(label_encoder.classes_), activation='softmax')\n",
    "])\n",
    "\n",
    "ann_model.compile(optimizer='adam', loss='sparse_categorical_crossentropy', metrics=['accuracy'])\n",
    "\n",
    "# Train the ANN\n",
    "ann_history = ann_model.fit(\n",
    "    train_features_normalized, \n",
    "    train_labels_encoded, \n",
    "    epochs=50, \n",
    "    batch_size=32, \n",
    "    validation_split=0.2,\n",
    "    callbacks=[tf.keras.callbacks.EarlyStopping(patience=5)]\n",
    ")\n",
    "\n",
    "# Evaluate the ANN\n",
    "ann_test_loss, ann_test_accuracy = ann_model.evaluate(test_features_normalized, test_labels_encoded)\n",
    "print(f\"ANN Test Accuracy: {ann_test_accuracy:.4f}\")\n",
    "\n",
    "# ANN Predictions and Classification Report\n",
    "ann_predictions = np.argmax(ann_model.predict(test_features_normalized), axis=1)\n",
    "print(\"ANN Classification Report:\")\n",
    "print(classification_report(test_labels_encoded, ann_predictions))\n",
    "\n",
    "# ANN Confusion Matrix\n",
    "ann_conf_matrix = confusion_matrix(test_labels_encoded, ann_predictions)\n",
    "save_confusion_matrix(ann_conf_matrix, label_encoder.classes_, \"ANN\", 8, \"../Files/confusion_matrix/balanced_accuracy_gender_hubert/ann_conf_matrix\")\n",
    "\n",
    "# Reshape the data for CNN\n",
    "train_features_cnn = np.expand_dims(train_features_normalized, axis=-1)\n",
    "test_features_cnn = np.expand_dims(test_features_normalized, axis=-1)\n",
    "\n",
    "# TensorFlow CNN Model\n",
    "cnn_model = Sequential([\n",
    "    Conv1D(64, kernel_size=5, activation='relu', input_shape=(train_features_cnn.shape[1], 1)),\n",
    "    Conv1D(128, kernel_size=5, activation='relu'),\n",
    "    Conv1D(256, kernel_size=5, activation='relu'),\n",
    "    Flatten(),\n",
    "    Dense(256, activation='relu'),\n",
    "    Dropout(0.5),\n",
    "    Dense(len(label_encoder.classes_), activation='softmax')\n",
    "])\n",
    "\n",
    "cnn_model.compile(optimizer='adam', loss='sparse_categorical_crossentropy', metrics=['accuracy'])\n",
    "\n",
    "# Train the TensorFlow CNN\n",
    "history = cnn_model.fit(\n",
    "    train_features_cnn, \n",
    "    train_labels_encoded, \n",
    "    epochs=50, \n",
    "    batch_size=32, \n",
    "    validation_split=0.2,\n",
    "    callbacks=[tf.keras.callbacks.EarlyStopping(patience=5)]\n",
    ")\n",
    "\n",
    "# Evaluate the TensorFlow CNN\n",
    "cnn_predictions = np.argmax(cnn_model.predict(test_features_cnn), axis=1)\n",
    "cnn_balanced_accuracy = accuracy_score(test_labels_encoded, cnn_predictions)\n",
    "\n",
    "print(f\"TensorFlow CNN Balanced Accuracy Score: {cnn_balanced_accuracy:.4f}\")\n",
    "print(\"TensorFlow CNN Classification Report:\")\n",
    "print(classification_report(test_labels_encoded, cnn_predictions))\n",
    "\n",
    "# CNN Confusion Matrix\n",
    "cnn_conf_matrix = confusion_matrix(test_labels_encoded, cnn_predictions)\n",
    "save_confusion_matrix(cnn_conf_matrix, label_encoder.classes_, \"CNN\", 8, \"../Files/confusion_matrix/balanced_accuracy_gender_hubert/cnn_conf_matrix\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "255dae30",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 9\n",
    "import os\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.preprocessing import LabelEncoder, StandardScaler\n",
    "from sklearn.metrics import accuracy_score, classification_report, confusion_matrix\n",
    "import tensorflow as tf\n",
    "from tensorflow.keras.models import Sequential\n",
    "from tensorflow.keras.layers import Conv1D, Flatten, Dense, Dropout\n",
    "import torch\n",
    "from torch.utils.data import DataLoader, TensorDataset\n",
    "import torch.nn as nn\n",
    "import torch.optim as optim\n",
    "import seaborn as sns\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "# Load the data\n",
    "train_data = np.load('../Files/extracted_features/hubert_large/train_9.npz')\n",
    "test_data = np.load('../Files/extracted_features/hubert_large/test_9.npz')\n",
    "\n",
    "train_features = train_data['features']\n",
    "test_features = test_data['features']\n",
    "\n",
    "train_labels = pd.read_csv('../Files/labels/y_train.csv').Gender_bin\n",
    "test_labels = pd.read_csv('../Files/labels/y_test.csv').Gender_bin\n",
    "\n",
    "# Encode the labels\n",
    "label_encoder = LabelEncoder()\n",
    "train_labels_encoded = label_encoder.fit_transform(train_labels)\n",
    "test_labels_encoded = label_encoder.transform(test_labels)\n",
    "\n",
    "# Normalize the features\n",
    "scaler = StandardScaler()\n",
    "train_features_normalized = scaler.fit_transform(train_features)\n",
    "test_features_normalized = scaler.transform(test_features)\n",
    "\n",
    "# SVM Classification\n",
    "from sklearn.svm import SVC\n",
    "\n",
    "svm_model = SVC(kernel='linear', C=10.0, gamma='scale', random_state=42)\n",
    "svm_model.fit(train_features, train_labels_encoded)\n",
    "svm_predictions = svm_model.predict(test_features)\n",
    "\n",
    "svm_accuracy = accuracy_score(test_labels_encoded, svm_predictions)\n",
    "print(f\"SVM Accuracy: {svm_accuracy:.4f}\")\n",
    "print(\"SVM Classification Report:\")\n",
    "print(classification_report(test_labels_encoded, svm_predictions))\n",
    "\n",
    "# Function to save confusion matrix\n",
    "def save_confusion_matrix(conf_matrix, labels, model_name, layer_number, folder_name):\n",
    "    os.makedirs(folder_name, exist_ok=True)  # Ensure the folder exists\n",
    "    plt.figure(figsize=(10, 8))\n",
    "    sns.set(font_scale=1.2)\n",
    "    sns.heatmap(conf_matrix, annot=True, fmt='d', cmap='viridis', xticklabels=labels, yticklabels=labels)\n",
    "    plt.title(f'{model_name} Confusion Matrix')\n",
    "    plt.xlabel('Predicted Labels')\n",
    "    plt.ylabel('True Labels')\n",
    "    plt.tight_layout()\n",
    "    save_path = os.path.join(folder_name, f'conf_matrix_layer_{layer_number}.png')\n",
    "    plt.savefig(save_path)\n",
    "    plt.close()\n",
    "    print(f\"Saved confusion matrix for {model_name}: {save_path}\")\n",
    "\n",
    "# SVM Confusion Matrix\n",
    "svm_conf_matrix = confusion_matrix(test_labels_encoded, svm_predictions)\n",
    "save_confusion_matrix(svm_conf_matrix, label_encoder.classes_, \"SVM\", 9, \"../Files/confusion_matrix/balanced_accuracy_gender_hubert/svm_conf_matrix\")\n",
    "\n",
    "# ANN Model\n",
    "ann_model = Sequential([\n",
    "    Dense(512, activation='relu', input_shape=(train_features_normalized.shape[1],)),\n",
    "    Dropout(0.5),\n",
    "    Dense(256, activation='relu'),\n",
    "    Dropout(0.5),\n",
    "    Dense(128, activation='relu'),\n",
    "    Dropout(0.5),\n",
    "    Dense(len(label_encoder.classes_), activation='softmax')\n",
    "])\n",
    "\n",
    "ann_model.compile(optimizer='adam', loss='sparse_categorical_crossentropy', metrics=['accuracy'])\n",
    "\n",
    "# Train the ANN\n",
    "ann_history = ann_model.fit(\n",
    "    train_features_normalized, \n",
    "    train_labels_encoded, \n",
    "    epochs=50, \n",
    "    batch_size=32, \n",
    "    validation_split=0.2,\n",
    "    callbacks=[tf.keras.callbacks.EarlyStopping(patience=5)]\n",
    ")\n",
    "\n",
    "# Evaluate the ANN\n",
    "ann_test_loss, ann_test_accuracy = ann_model.evaluate(test_features_normalized, test_labels_encoded)\n",
    "print(f\"ANN Test Accuracy: {ann_test_accuracy:.4f}\")\n",
    "\n",
    "# ANN Predictions and Classification Report\n",
    "ann_predictions = np.argmax(ann_model.predict(test_features_normalized), axis=1)\n",
    "print(\"ANN Classification Report:\")\n",
    "print(classification_report(test_labels_encoded, ann_predictions))\n",
    "\n",
    "# ANN Confusion Matrix\n",
    "ann_conf_matrix = confusion_matrix(test_labels_encoded, ann_predictions)\n",
    "save_confusion_matrix(ann_conf_matrix, label_encoder.classes_, \"ANN\", 9, \"../Files/confusion_matrix/balanced_accuracy_gender_hubert/ann_conf_matrix\")\n",
    "\n",
    "# Reshape the data for CNN\n",
    "train_features_cnn = np.expand_dims(train_features_normalized, axis=-1)\n",
    "test_features_cnn = np.expand_dims(test_features_normalized, axis=-1)\n",
    "\n",
    "# TensorFlow CNN Model\n",
    "cnn_model = Sequential([\n",
    "    Conv1D(64, kernel_size=5, activation='relu', input_shape=(train_features_cnn.shape[1], 1)),\n",
    "    Conv1D(128, kernel_size=5, activation='relu'),\n",
    "    Conv1D(256, kernel_size=5, activation='relu'),\n",
    "    Flatten(),\n",
    "    Dense(256, activation='relu'),\n",
    "    Dropout(0.5),\n",
    "    Dense(len(label_encoder.classes_), activation='softmax')\n",
    "])\n",
    "\n",
    "cnn_model.compile(optimizer='adam', loss='sparse_categorical_crossentropy', metrics=['accuracy'])\n",
    "\n",
    "# Train the TensorFlow CNN\n",
    "history = cnn_model.fit(\n",
    "    train_features_cnn, \n",
    "    train_labels_encoded, \n",
    "    epochs=50, \n",
    "    batch_size=32, \n",
    "    validation_split=0.2,\n",
    "    callbacks=[tf.keras.callbacks.EarlyStopping(patience=5)]\n",
    ")\n",
    "\n",
    "# Evaluate the TensorFlow CNN\n",
    "cnn_predictions = np.argmax(cnn_model.predict(test_features_cnn), axis=1)\n",
    "cnn_balanced_accuracy = accuracy_score(test_labels_encoded, cnn_predictions)\n",
    "\n",
    "print(f\"TensorFlow CNN Balanced Accuracy Score: {cnn_balanced_accuracy:.4f}\")\n",
    "print(\"TensorFlow CNN Classification Report:\")\n",
    "print(classification_report(test_labels_encoded, cnn_predictions))\n",
    "\n",
    "# CNN Confusion Matrix\n",
    "cnn_conf_matrix = confusion_matrix(test_labels_encoded, cnn_predictions)\n",
    "save_confusion_matrix(cnn_conf_matrix, label_encoder.classes_, \"CNN\", 9, \"../Files/confusion_matrix/balanced_accuracy_gender_hubert/cnn_conf_matrix\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "04520a19",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 10\n",
    "import os\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.preprocessing import LabelEncoder, StandardScaler\n",
    "from sklearn.metrics import accuracy_score, classification_report, confusion_matrix\n",
    "import tensorflow as tf\n",
    "from tensorflow.keras.models import Sequential\n",
    "from tensorflow.keras.layers import Conv1D, Flatten, Dense, Dropout\n",
    "import torch\n",
    "from torch.utils.data import DataLoader, TensorDataset\n",
    "import torch.nn as nn\n",
    "import torch.optim as optim\n",
    "import seaborn as sns\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "# Load the data\n",
    "train_data = np.load('../Files/extracted_features/hubert_large/train_10.npz')\n",
    "test_data = np.load('../Files/extracted_features/hubert_large/test_10.npz')\n",
    "\n",
    "train_features = train_data['features']\n",
    "test_features = test_data['features']\n",
    "\n",
    "train_labels = pd.read_csv('../Files/labels/y_train.csv').Gender_bin\n",
    "test_labels = pd.read_csv('../Files/labels/y_test.csv').Gender_bin\n",
    "\n",
    "# Encode the labels\n",
    "label_encoder = LabelEncoder()\n",
    "train_labels_encoded = label_encoder.fit_transform(train_labels)\n",
    "test_labels_encoded = label_encoder.transform(test_labels)\n",
    "\n",
    "# Normalize the features\n",
    "scaler = StandardScaler()\n",
    "train_features_normalized = scaler.fit_transform(train_features)\n",
    "test_features_normalized = scaler.transform(test_features)\n",
    "\n",
    "# SVM Classification\n",
    "from sklearn.svm import SVC\n",
    "\n",
    "svm_model = SVC(kernel='linear', C=10.0, gamma='scale', random_state=42)\n",
    "svm_model.fit(train_features, train_labels_encoded)\n",
    "svm_predictions = svm_model.predict(test_features)\n",
    "\n",
    "svm_accuracy = accuracy_score(test_labels_encoded, svm_predictions)\n",
    "print(f\"SVM Accuracy: {svm_accuracy:.4f}\")\n",
    "print(\"SVM Classification Report:\")\n",
    "print(classification_report(test_labels_encoded, svm_predictions))\n",
    "\n",
    "# Function to save confusion matrix\n",
    "def save_confusion_matrix(conf_matrix, labels, model_name, layer_number, folder_name):\n",
    "    os.makedirs(folder_name, exist_ok=True)  # Ensure the folder exists\n",
    "    plt.figure(figsize=(10, 8))\n",
    "    sns.set(font_scale=1.2)\n",
    "    sns.heatmap(conf_matrix, annot=True, fmt='d', cmap='viridis', xticklabels=labels, yticklabels=labels)\n",
    "    plt.title(f'{model_name} Confusion Matrix')\n",
    "    plt.xlabel('Predicted Labels')\n",
    "    plt.ylabel('True Labels')\n",
    "    plt.tight_layout()\n",
    "    save_path = os.path.join(folder_name, f'conf_matrix_layer_{layer_number}.png')\n",
    "    plt.savefig(save_path)\n",
    "    plt.close()\n",
    "    print(f\"Saved confusion matrix for {model_name}: {save_path}\")\n",
    "\n",
    "# SVM Confusion Matrix\n",
    "svm_conf_matrix = confusion_matrix(test_labels_encoded, svm_predictions)\n",
    "save_confusion_matrix(svm_conf_matrix, label_encoder.classes_, \"SVM\", 10, \"../Files/confusion_matrix/balanced_accuracy_gender_hubert/svm_conf_matrix\")\n",
    "\n",
    "# ANN Model\n",
    "ann_model = Sequential([\n",
    "    Dense(512, activation='relu', input_shape=(train_features_normalized.shape[1],)),\n",
    "    Dropout(0.5),\n",
    "    Dense(256, activation='relu'),\n",
    "    Dropout(0.5),\n",
    "    Dense(128, activation='relu'),\n",
    "    Dropout(0.5),\n",
    "    Dense(len(label_encoder.classes_), activation='softmax')\n",
    "])\n",
    "\n",
    "ann_model.compile(optimizer='adam', loss='sparse_categorical_crossentropy', metrics=['accuracy'])\n",
    "\n",
    "# Train the ANN\n",
    "ann_history = ann_model.fit(\n",
    "    train_features_normalized, \n",
    "    train_labels_encoded, \n",
    "    epochs=50, \n",
    "    batch_size=32, \n",
    "    validation_split=0.2,\n",
    "    callbacks=[tf.keras.callbacks.EarlyStopping(patience=5)]\n",
    ")\n",
    "\n",
    "# Evaluate the ANN\n",
    "ann_test_loss, ann_test_accuracy = ann_model.evaluate(test_features_normalized, test_labels_encoded)\n",
    "print(f\"ANN Test Accuracy: {ann_test_accuracy:.4f}\")\n",
    "\n",
    "# ANN Predictions and Classification Report\n",
    "ann_predictions = np.argmax(ann_model.predict(test_features_normalized), axis=1)\n",
    "print(\"ANN Classification Report:\")\n",
    "print(classification_report(test_labels_encoded, ann_predictions))\n",
    "\n",
    "# ANN Confusion Matrix\n",
    "ann_conf_matrix = confusion_matrix(test_labels_encoded, ann_predictions)\n",
    "save_confusion_matrix(ann_conf_matrix, label_encoder.classes_, \"ANN\", 10, \"../Files/confusion_matrix/balanced_accuracy_gender_hubert/ann_conf_matrix\")\n",
    "\n",
    "# Reshape the data for CNN\n",
    "train_features_cnn = np.expand_dims(train_features_normalized, axis=-1)\n",
    "test_features_cnn = np.expand_dims(test_features_normalized, axis=-1)\n",
    "\n",
    "# TensorFlow CNN Model\n",
    "cnn_model = Sequential([\n",
    "    Conv1D(64, kernel_size=5, activation='relu', input_shape=(train_features_cnn.shape[1], 1)),\n",
    "    Conv1D(128, kernel_size=5, activation='relu'),\n",
    "    Conv1D(256, kernel_size=5, activation='relu'),\n",
    "    Flatten(),\n",
    "    Dense(256, activation='relu'),\n",
    "    Dropout(0.5),\n",
    "    Dense(len(label_encoder.classes_), activation='softmax')\n",
    "])\n",
    "\n",
    "cnn_model.compile(optimizer='adam', loss='sparse_categorical_crossentropy', metrics=['accuracy'])\n",
    "\n",
    "# Train the TensorFlow CNN\n",
    "history = cnn_model.fit(\n",
    "    train_features_cnn, \n",
    "    train_labels_encoded, \n",
    "    epochs=50, \n",
    "    batch_size=32, \n",
    "    validation_split=0.2,\n",
    "    callbacks=[tf.keras.callbacks.EarlyStopping(patience=5)]\n",
    ")\n",
    "\n",
    "# Evaluate the TensorFlow CNN\n",
    "cnn_predictions = np.argmax(cnn_model.predict(test_features_cnn), axis=1)\n",
    "cnn_balanced_accuracy = accuracy_score(test_labels_encoded, cnn_predictions)\n",
    "\n",
    "print(f\"TensorFlow CNN Balanced Accuracy Score: {cnn_balanced_accuracy:.4f}\")\n",
    "print(\"TensorFlow CNN Classification Report:\")\n",
    "print(classification_report(test_labels_encoded, cnn_predictions))\n",
    "\n",
    "# CNN Confusion Matrix\n",
    "cnn_conf_matrix = confusion_matrix(test_labels_encoded, cnn_predictions)\n",
    "save_confusion_matrix(cnn_conf_matrix, label_encoder.classes_, \"CNN\", 10, \"../Files/confusion_matrix/balanced_accuracy_gender_hubert/cnn_conf_matrix\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e6182a67",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 11\n",
    "import os\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.preprocessing import LabelEncoder, StandardScaler\n",
    "from sklearn.metrics import accuracy_score, classification_report, confusion_matrix\n",
    "import tensorflow as tf\n",
    "from tensorflow.keras.models import Sequential\n",
    "from tensorflow.keras.layers import Conv1D, Flatten, Dense, Dropout\n",
    "import torch\n",
    "from torch.utils.data import DataLoader, TensorDataset\n",
    "import torch.nn as nn\n",
    "import torch.optim as optim\n",
    "import seaborn as sns\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "# Load the data\n",
    "train_data = np.load('../Files/extracted_features/hubert_large/train_11.npz')\n",
    "test_data = np.load('../Files/extracted_features/hubert_large/test_11.npz')\n",
    "\n",
    "train_features = train_data['features']\n",
    "test_features = test_data['features']\n",
    "\n",
    "train_labels = pd.read_csv('../Files/labels/y_train.csv').Gender_bin\n",
    "test_labels = pd.read_csv('../Files/labels/y_test.csv').Gender_bin\n",
    "\n",
    "# Encode the labels\n",
    "label_encoder = LabelEncoder()\n",
    "train_labels_encoded = label_encoder.fit_transform(train_labels)\n",
    "test_labels_encoded = label_encoder.transform(test_labels)\n",
    "\n",
    "# Normalize the features\n",
    "scaler = StandardScaler()\n",
    "train_features_normalized = scaler.fit_transform(train_features)\n",
    "test_features_normalized = scaler.transform(test_features)\n",
    "\n",
    "# SVM Classification\n",
    "from sklearn.svm import SVC\n",
    "\n",
    "svm_model = SVC(kernel='linear', C=10.0, gamma='scale', random_state=42)\n",
    "svm_model.fit(train_features, train_labels_encoded)\n",
    "svm_predictions = svm_model.predict(test_features)\n",
    "\n",
    "svm_accuracy = accuracy_score(test_labels_encoded, svm_predictions)\n",
    "print(f\"SVM Accuracy: {svm_accuracy:.4f}\")\n",
    "print(\"SVM Classification Report:\")\n",
    "print(classification_report(test_labels_encoded, svm_predictions))\n",
    "\n",
    "# Function to save confusion matrix\n",
    "def save_confusion_matrix(conf_matrix, labels, model_name, layer_number, folder_name):\n",
    "    os.makedirs(folder_name, exist_ok=True)  # Ensure the folder exists\n",
    "    plt.figure(figsize=(10, 8))\n",
    "    sns.set(font_scale=1.2)\n",
    "    sns.heatmap(conf_matrix, annot=True, fmt='d', cmap='viridis', xticklabels=labels, yticklabels=labels)\n",
    "    plt.title(f'{model_name} Confusion Matrix')\n",
    "    plt.xlabel('Predicted Labels')\n",
    "    plt.ylabel('True Labels')\n",
    "    plt.tight_layout()\n",
    "    save_path = os.path.join(folder_name, f'conf_matrix_layer_{layer_number}.png')\n",
    "    plt.savefig(save_path)\n",
    "    plt.close()\n",
    "    print(f\"Saved confusion matrix for {model_name}: {save_path}\")\n",
    "\n",
    "# SVM Confusion Matrix\n",
    "svm_conf_matrix = confusion_matrix(test_labels_encoded, svm_predictions)\n",
    "save_confusion_matrix(svm_conf_matrix, label_encoder.classes_, \"SVM\", 11, \"../Files/confusion_matrix/balanced_accuracy_gender_hubert/svm_conf_matrix\")\n",
    "\n",
    "# ANN Model\n",
    "ann_model = Sequential([\n",
    "    Dense(512, activation='relu', input_shape=(train_features_normalized.shape[1],)),\n",
    "    Dropout(0.5),\n",
    "    Dense(256, activation='relu'),\n",
    "    Dropout(0.5),\n",
    "    Dense(128, activation='relu'),\n",
    "    Dropout(0.5),\n",
    "    Dense(len(label_encoder.classes_), activation='softmax')\n",
    "])\n",
    "\n",
    "ann_model.compile(optimizer='adam', loss='sparse_categorical_crossentropy', metrics=['accuracy'])\n",
    "\n",
    "# Train the ANN\n",
    "ann_history = ann_model.fit(\n",
    "    train_features_normalized, \n",
    "    train_labels_encoded, \n",
    "    epochs=50, \n",
    "    batch_size=32, \n",
    "    validation_split=0.2,\n",
    "    callbacks=[tf.keras.callbacks.EarlyStopping(patience=5)]\n",
    ")\n",
    "\n",
    "# Evaluate the ANN\n",
    "ann_test_loss, ann_test_accuracy = ann_model.evaluate(test_features_normalized, test_labels_encoded)\n",
    "print(f\"ANN Test Accuracy: {ann_test_accuracy:.4f}\")\n",
    "\n",
    "# ANN Predictions and Classification Report\n",
    "ann_predictions = np.argmax(ann_model.predict(test_features_normalized), axis=1)\n",
    "print(\"ANN Classification Report:\")\n",
    "print(classification_report(test_labels_encoded, ann_predictions))\n",
    "\n",
    "# ANN Confusion Matrix\n",
    "ann_conf_matrix = confusion_matrix(test_labels_encoded, ann_predictions)\n",
    "save_confusion_matrix(ann_conf_matrix, label_encoder.classes_, \"ANN\", 11, \"../Files/confusion_matrix/balanced_accuracy_gender_hubert/ann_conf_matrix\")\n",
    "\n",
    "# Reshape the data for CNN\n",
    "train_features_cnn = np.expand_dims(train_features_normalized, axis=-1)\n",
    "test_features_cnn = np.expand_dims(test_features_normalized, axis=-1)\n",
    "\n",
    "# TensorFlow CNN Model\n",
    "cnn_model = Sequential([\n",
    "    Conv1D(64, kernel_size=5, activation='relu', input_shape=(train_features_cnn.shape[1], 1)),\n",
    "    Conv1D(128, kernel_size=5, activation='relu'),\n",
    "    Conv1D(256, kernel_size=5, activation='relu'),\n",
    "    Flatten(),\n",
    "    Dense(256, activation='relu'),\n",
    "    Dropout(0.5),\n",
    "    Dense(len(label_encoder.classes_), activation='softmax')\n",
    "])\n",
    "\n",
    "cnn_model.compile(optimizer='adam', loss='sparse_categorical_crossentropy', metrics=['accuracy'])\n",
    "\n",
    "# Train the TensorFlow CNN\n",
    "history = cnn_model.fit(\n",
    "    train_features_cnn, \n",
    "    train_labels_encoded, \n",
    "    epochs=50, \n",
    "    batch_size=32, \n",
    "    validation_split=0.2,\n",
    "    callbacks=[tf.keras.callbacks.EarlyStopping(patience=5)]\n",
    ")\n",
    "\n",
    "# Evaluate the TensorFlow CNN\n",
    "cnn_predictions = np.argmax(cnn_model.predict(test_features_cnn), axis=1)\n",
    "cnn_balanced_accuracy = accuracy_score(test_labels_encoded, cnn_predictions)\n",
    "\n",
    "print(f\"TensorFlow CNN Balanced Accuracy Score: {cnn_balanced_accuracy:.4f}\")\n",
    "print(\"TensorFlow CNN Classification Report:\")\n",
    "print(classification_report(test_labels_encoded, cnn_predictions))\n",
    "\n",
    "# CNN Confusion Matrix\n",
    "cnn_conf_matrix = confusion_matrix(test_labels_encoded, cnn_predictions)\n",
    "save_confusion_matrix(cnn_conf_matrix, label_encoder.classes_, \"CNN\", 11, \"../Files/confusion_matrix/balanced_accuracy_gender_hubert/cnn_conf_matrix\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ad90bfdf",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 12\n",
    "import os\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.preprocessing import LabelEncoder, StandardScaler\n",
    "from sklearn.metrics import accuracy_score, classification_report, confusion_matrix\n",
    "import tensorflow as tf\n",
    "from tensorflow.keras.models import Sequential\n",
    "from tensorflow.keras.layers import Conv1D, Flatten, Dense, Dropout\n",
    "import torch\n",
    "from torch.utils.data import DataLoader, TensorDataset\n",
    "import torch.nn as nn\n",
    "import torch.optim as optim\n",
    "import seaborn as sns\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "# Load the data\n",
    "train_data = np.load('../Files/extracted_features/hubert_large/train_12.npz')\n",
    "test_data = np.load('../Files/extracted_features/hubert_large/test_12.npz')\n",
    "\n",
    "train_features = train_data['features']\n",
    "test_features = test_data['features']\n",
    "\n",
    "train_labels = pd.read_csv('../Files/labels/y_train.csv').Gender_bin\n",
    "test_labels = pd.read_csv('../Files/labels/y_test.csv').Gender_bin\n",
    "\n",
    "# Encode the labels\n",
    "label_encoder = LabelEncoder()\n",
    "train_labels_encoded = label_encoder.fit_transform(train_labels)\n",
    "test_labels_encoded = label_encoder.transform(test_labels)\n",
    "\n",
    "# Normalize the features\n",
    "scaler = StandardScaler()\n",
    "train_features_normalized = scaler.fit_transform(train_features)\n",
    "test_features_normalized = scaler.transform(test_features)\n",
    "\n",
    "# SVM Classification\n",
    "from sklearn.svm import SVC\n",
    "\n",
    "svm_model = SVC(kernel='linear', C=10.0, gamma='scale', random_state=42)\n",
    "svm_model.fit(train_features, train_labels_encoded)\n",
    "svm_predictions = svm_model.predict(test_features)\n",
    "\n",
    "svm_accuracy = accuracy_score(test_labels_encoded, svm_predictions)\n",
    "print(f\"SVM Accuracy: {svm_accuracy:.4f}\")\n",
    "print(\"SVM Classification Report:\")\n",
    "print(classification_report(test_labels_encoded, svm_predictions))\n",
    "\n",
    "# Function to save confusion matrix\n",
    "def save_confusion_matrix(conf_matrix, labels, model_name, layer_number, folder_name):\n",
    "    os.makedirs(folder_name, exist_ok=True)  # Ensure the folder exists\n",
    "    plt.figure(figsize=(10, 8))\n",
    "    sns.set(font_scale=1.2)\n",
    "    sns.heatmap(conf_matrix, annot=True, fmt='d', cmap='viridis', xticklabels=labels, yticklabels=labels)\n",
    "    plt.title(f'{model_name} Confusion Matrix')\n",
    "    plt.xlabel('Predicted Labels')\n",
    "    plt.ylabel('True Labels')\n",
    "    plt.tight_layout()\n",
    "    save_path = os.path.join(folder_name, f'conf_matrix_layer_{layer_number}.png')\n",
    "    plt.savefig(save_path)\n",
    "    plt.close()\n",
    "    print(f\"Saved confusion matrix for {model_name}: {save_path}\")\n",
    "\n",
    "# SVM Confusion Matrix\n",
    "svm_conf_matrix = confusion_matrix(test_labels_encoded, svm_predictions)\n",
    "save_confusion_matrix(svm_conf_matrix, label_encoder.classes_, \"SVM\", 12, \"../Files/confusion_matrix/balanced_accuracy_gender_hubert/svm_conf_matrix\")\n",
    "\n",
    "# ANN Model\n",
    "ann_model = Sequential([\n",
    "    Dense(512, activation='relu', input_shape=(train_features_normalized.shape[1],)),\n",
    "    Dropout(0.5),\n",
    "    Dense(256, activation='relu'),\n",
    "    Dropout(0.5),\n",
    "    Dense(128, activation='relu'),\n",
    "    Dropout(0.5),\n",
    "    Dense(len(label_encoder.classes_), activation='softmax')\n",
    "])\n",
    "\n",
    "ann_model.compile(optimizer='adam', loss='sparse_categorical_crossentropy', metrics=['accuracy'])\n",
    "\n",
    "# Train the ANN\n",
    "ann_history = ann_model.fit(\n",
    "    train_features_normalized, \n",
    "    train_labels_encoded, \n",
    "    epochs=50, \n",
    "    batch_size=32, \n",
    "    validation_split=0.2,\n",
    "    callbacks=[tf.keras.callbacks.EarlyStopping(patience=5)]\n",
    ")\n",
    "\n",
    "# Evaluate the ANN\n",
    "ann_test_loss, ann_test_accuracy = ann_model.evaluate(test_features_normalized, test_labels_encoded)\n",
    "print(f\"ANN Test Accuracy: {ann_test_accuracy:.4f}\")\n",
    "\n",
    "# ANN Predictions and Classification Report\n",
    "ann_predictions = np.argmax(ann_model.predict(test_features_normalized), axis=1)\n",
    "print(\"ANN Classification Report:\")\n",
    "print(classification_report(test_labels_encoded, ann_predictions))\n",
    "\n",
    "# ANN Confusion Matrix\n",
    "ann_conf_matrix = confusion_matrix(test_labels_encoded, ann_predictions)\n",
    "save_confusion_matrix(ann_conf_matrix, label_encoder.classes_, \"ANN\", 12, \"../Files/confusion_matrix/balanced_accuracy_gender_hubert/ann_conf_matrix\")\n",
    "\n",
    "# Reshape the data for CNN\n",
    "train_features_cnn = np.expand_dims(train_features_normalized, axis=-1)\n",
    "test_features_cnn = np.expand_dims(test_features_normalized, axis=-1)\n",
    "\n",
    "# TensorFlow CNN Model\n",
    "cnn_model = Sequential([\n",
    "    Conv1D(64, kernel_size=5, activation='relu', input_shape=(train_features_cnn.shape[1], 1)),\n",
    "    Conv1D(128, kernel_size=5, activation='relu'),\n",
    "    Conv1D(256, kernel_size=5, activation='relu'),\n",
    "    Flatten(),\n",
    "    Dense(256, activation='relu'),\n",
    "    Dropout(0.5),\n",
    "    Dense(len(label_encoder.classes_), activation='softmax')\n",
    "])\n",
    "\n",
    "cnn_model.compile(optimizer='adam', loss='sparse_categorical_crossentropy', metrics=['accuracy'])\n",
    "\n",
    "# Train the TensorFlow CNN\n",
    "history = cnn_model.fit(\n",
    "    train_features_cnn, \n",
    "    train_labels_encoded, \n",
    "    epochs=50, \n",
    "    batch_size=32, \n",
    "    validation_split=0.2,\n",
    "    callbacks=[tf.keras.callbacks.EarlyStopping(patience=5)]\n",
    ")\n",
    "\n",
    "# Evaluate the TensorFlow CNN\n",
    "cnn_predictions = np.argmax(cnn_model.predict(test_features_cnn), axis=1)\n",
    "cnn_balanced_accuracy = accuracy_score(test_labels_encoded, cnn_predictions)\n",
    "\n",
    "print(f\"TensorFlow CNN Balanced Accuracy Score: {cnn_balanced_accuracy:.4f}\")\n",
    "print(\"TensorFlow CNN Classification Report:\")\n",
    "print(classification_report(test_labels_encoded, cnn_predictions))\n",
    "\n",
    "# CNN Confusion Matrix\n",
    "cnn_conf_matrix = confusion_matrix(test_labels_encoded, cnn_predictions)\n",
    "save_confusion_matrix(cnn_conf_matrix, label_encoder.classes_, \"CNN\", 12, \"../Files/confusion_matrix/balanced_accuracy_gender_hubert/cnn_conf_matrix\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "68396bb3",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 13\n",
    "import os\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.preprocessing import LabelEncoder, StandardScaler\n",
    "from sklearn.metrics import accuracy_score, classification_report, confusion_matrix\n",
    "import tensorflow as tf\n",
    "from tensorflow.keras.models import Sequential\n",
    "from tensorflow.keras.layers import Conv1D, Flatten, Dense, Dropout\n",
    "import torch\n",
    "from torch.utils.data import DataLoader, TensorDataset\n",
    "import torch.nn as nn\n",
    "import torch.optim as optim\n",
    "import seaborn as sns\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "# Load the data\n",
    "train_data = np.load('../Files/extracted_features/hubert_large/train_13.npz')\n",
    "test_data = np.load('../Files/extracted_features/hubert_large/test_13.npz')\n",
    "\n",
    "train_features = train_data['features']\n",
    "test_features = test_data['features']\n",
    "\n",
    "train_labels = pd.read_csv('../Files/labels/y_train.csv').Gender_bin\n",
    "test_labels = pd.read_csv('../Files/labels/y_test.csv').Gender_bin\n",
    "\n",
    "# Encode the labels\n",
    "label_encoder = LabelEncoder()\n",
    "train_labels_encoded = label_encoder.fit_transform(train_labels)\n",
    "test_labels_encoded = label_encoder.transform(test_labels)\n",
    "\n",
    "# Normalize the features\n",
    "scaler = StandardScaler()\n",
    "train_features_normalized = scaler.fit_transform(train_features)\n",
    "test_features_normalized = scaler.transform(test_features)\n",
    "\n",
    "# SVM Classification\n",
    "from sklearn.svm import SVC\n",
    "\n",
    "svm_model = SVC(kernel='linear', C=10.0, gamma='scale', random_state=42)\n",
    "svm_model.fit(train_features, train_labels_encoded)\n",
    "svm_predictions = svm_model.predict(test_features)\n",
    "\n",
    "svm_accuracy = accuracy_score(test_labels_encoded, svm_predictions)\n",
    "print(f\"SVM Accuracy: {svm_accuracy:.4f}\")\n",
    "print(\"SVM Classification Report:\")\n",
    "print(classification_report(test_labels_encoded, svm_predictions))\n",
    "\n",
    "# Function to save confusion matrix\n",
    "def save_confusion_matrix(conf_matrix, labels, model_name, layer_number, folder_name):\n",
    "    os.makedirs(folder_name, exist_ok=True)  # Ensure the folder exists\n",
    "    plt.figure(figsize=(10, 8))\n",
    "    sns.set(font_scale=1.2)\n",
    "    sns.heatmap(conf_matrix, annot=True, fmt='d', cmap='viridis', xticklabels=labels, yticklabels=labels)\n",
    "    plt.title(f'{model_name} Confusion Matrix')\n",
    "    plt.xlabel('Predicted Labels')\n",
    "    plt.ylabel('True Labels')\n",
    "    plt.tight_layout()\n",
    "    save_path = os.path.join(folder_name, f'conf_matrix_layer_{layer_number}.png')\n",
    "    plt.savefig(save_path)\n",
    "    plt.close()\n",
    "    print(f\"Saved confusion matrix for {model_name}: {save_path}\")\n",
    "\n",
    "# SVM Confusion Matrix\n",
    "svm_conf_matrix = confusion_matrix(test_labels_encoded, svm_predictions)\n",
    "save_confusion_matrix(svm_conf_matrix, label_encoder.classes_, \"SVM\", 13, \"../Files/confusion_matrix/balanced_accuracy_gender_hubert/svm_conf_matrix\")\n",
    "\n",
    "# ANN Model\n",
    "ann_model = Sequential([\n",
    "    Dense(512, activation='relu', input_shape=(train_features_normalized.shape[1],)),\n",
    "    Dropout(0.5),\n",
    "    Dense(256, activation='relu'),\n",
    "    Dropout(0.5),\n",
    "    Dense(128, activation='relu'),\n",
    "    Dropout(0.5),\n",
    "    Dense(len(label_encoder.classes_), activation='softmax')\n",
    "])\n",
    "\n",
    "ann_model.compile(optimizer='adam', loss='sparse_categorical_crossentropy', metrics=['accuracy'])\n",
    "\n",
    "# Train the ANN\n",
    "ann_history = ann_model.fit(\n",
    "    train_features_normalized, \n",
    "    train_labels_encoded, \n",
    "    epochs=50, \n",
    "    batch_size=32, \n",
    "    validation_split=0.2,\n",
    "    callbacks=[tf.keras.callbacks.EarlyStopping(patience=5)]\n",
    ")\n",
    "\n",
    "# Evaluate the ANN\n",
    "ann_test_loss, ann_test_accuracy = ann_model.evaluate(test_features_normalized, test_labels_encoded)\n",
    "print(f\"ANN Test Accuracy: {ann_test_accuracy:.4f}\")\n",
    "\n",
    "# ANN Predictions and Classification Report\n",
    "ann_predictions = np.argmax(ann_model.predict(test_features_normalized), axis=1)\n",
    "print(\"ANN Classification Report:\")\n",
    "print(classification_report(test_labels_encoded, ann_predictions))\n",
    "\n",
    "# ANN Confusion Matrix\n",
    "ann_conf_matrix = confusion_matrix(test_labels_encoded, ann_predictions)\n",
    "save_confusion_matrix(ann_conf_matrix, label_encoder.classes_, \"ANN\", 13, \"../Files/confusion_matrix/balanced_accuracy_gender_hubert/ann_conf_matrix\")\n",
    "\n",
    "# Reshape the data for CNN\n",
    "train_features_cnn = np.expand_dims(train_features_normalized, axis=-1)\n",
    "test_features_cnn = np.expand_dims(test_features_normalized, axis=-1)\n",
    "\n",
    "# TensorFlow CNN Model\n",
    "cnn_model = Sequential([\n",
    "    Conv1D(64, kernel_size=5, activation='relu', input_shape=(train_features_cnn.shape[1], 1)),\n",
    "    Conv1D(128, kernel_size=5, activation='relu'),\n",
    "    Conv1D(256, kernel_size=5, activation='relu'),\n",
    "    Flatten(),\n",
    "    Dense(256, activation='relu'),\n",
    "    Dropout(0.5),\n",
    "    Dense(len(label_encoder.classes_), activation='softmax')\n",
    "])\n",
    "\n",
    "cnn_model.compile(optimizer='adam', loss='sparse_categorical_crossentropy', metrics=['accuracy'])\n",
    "\n",
    "# Train the TensorFlow CNN\n",
    "history = cnn_model.fit(\n",
    "    train_features_cnn, \n",
    "    train_labels_encoded, \n",
    "    epochs=50, \n",
    "    batch_size=32, \n",
    "    validation_split=0.2,\n",
    "    callbacks=[tf.keras.callbacks.EarlyStopping(patience=5)]\n",
    ")\n",
    "\n",
    "# Evaluate the TensorFlow CNN\n",
    "cnn_predictions = np.argmax(cnn_model.predict(test_features_cnn), axis=1)\n",
    "cnn_balanced_accuracy = accuracy_score(test_labels_encoded, cnn_predictions)\n",
    "\n",
    "print(f\"TensorFlow CNN Balanced Accuracy Score: {cnn_balanced_accuracy:.4f}\")\n",
    "print(\"TensorFlow CNN Classification Report:\")\n",
    "print(classification_report(test_labels_encoded, cnn_predictions))\n",
    "\n",
    "# CNN Confusion Matrix\n",
    "cnn_conf_matrix = confusion_matrix(test_labels_encoded, cnn_predictions)\n",
    "save_confusion_matrix(cnn_conf_matrix, label_encoder.classes_, \"CNN\", 13, \"../Files/confusion_matrix/balanced_accuracy_gender_hubert/cnn_conf_matrix\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "57d0fffa",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 14\n",
    "import os\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.preprocessing import LabelEncoder, StandardScaler\n",
    "from sklearn.metrics import accuracy_score, classification_report, confusion_matrix\n",
    "import tensorflow as tf\n",
    "from tensorflow.keras.models import Sequential\n",
    "from tensorflow.keras.layers import Conv1D, Flatten, Dense, Dropout\n",
    "import torch\n",
    "from torch.utils.data import DataLoader, TensorDataset\n",
    "import torch.nn as nn\n",
    "import torch.optim as optim\n",
    "import seaborn as sns\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "# Load the data\n",
    "train_data = np.load('../Files/extracted_features/hubert_large/train_14.npz')\n",
    "test_data = np.load('../Files/extracted_features/hubert_large/test_14.npz')\n",
    "\n",
    "train_features = train_data['features']\n",
    "test_features = test_data['features']\n",
    "\n",
    "train_labels = pd.read_csv('../Files/labels/y_train.csv').Gender_bin\n",
    "test_labels = pd.read_csv('../Files/labels/y_test.csv').Gender_bin\n",
    "\n",
    "# Encode the labels\n",
    "label_encoder = LabelEncoder()\n",
    "train_labels_encoded = label_encoder.fit_transform(train_labels)\n",
    "test_labels_encoded = label_encoder.transform(test_labels)\n",
    "\n",
    "# Normalize the features\n",
    "scaler = StandardScaler()\n",
    "train_features_normalized = scaler.fit_transform(train_features)\n",
    "test_features_normalized = scaler.transform(test_features)\n",
    "\n",
    "# SVM Classification\n",
    "from sklearn.svm import SVC\n",
    "\n",
    "svm_model = SVC(kernel='linear', C=10.0, gamma='scale', random_state=42)\n",
    "svm_model.fit(train_features, train_labels_encoded)\n",
    "svm_predictions = svm_model.predict(test_features)\n",
    "\n",
    "svm_accuracy = accuracy_score(test_labels_encoded, svm_predictions)\n",
    "print(f\"SVM Accuracy: {svm_accuracy:.4f}\")\n",
    "print(\"SVM Classification Report:\")\n",
    "print(classification_report(test_labels_encoded, svm_predictions))\n",
    "\n",
    "# Function to save confusion matrix\n",
    "def save_confusion_matrix(conf_matrix, labels, model_name, layer_number, folder_name):\n",
    "    os.makedirs(folder_name, exist_ok=True)  # Ensure the folder exists\n",
    "    plt.figure(figsize=(10, 8))\n",
    "    sns.set(font_scale=1.2)\n",
    "    sns.heatmap(conf_matrix, annot=True, fmt='d', cmap='viridis', xticklabels=labels, yticklabels=labels)\n",
    "    plt.title(f'{model_name} Confusion Matrix')\n",
    "    plt.xlabel('Predicted Labels')\n",
    "    plt.ylabel('True Labels')\n",
    "    plt.tight_layout()\n",
    "    save_path = os.path.join(folder_name, f'conf_matrix_layer_{layer_number}.png')\n",
    "    plt.savefig(save_path)\n",
    "    plt.close()\n",
    "    print(f\"Saved confusion matrix for {model_name}: {save_path}\")\n",
    "\n",
    "# SVM Confusion Matrix\n",
    "svm_conf_matrix = confusion_matrix(test_labels_encoded, svm_predictions)\n",
    "save_confusion_matrix(svm_conf_matrix, label_encoder.classes_, \"SVM\", 14, \"../Files/confusion_matrix/balanced_accuracy_gender_hubert/svm_conf_matrix\")\n",
    "\n",
    "# ANN Model\n",
    "ann_model = Sequential([\n",
    "    Dense(512, activation='relu', input_shape=(train_features_normalized.shape[1],)),\n",
    "    Dropout(0.5),\n",
    "    Dense(256, activation='relu'),\n",
    "    Dropout(0.5),\n",
    "    Dense(128, activation='relu'),\n",
    "    Dropout(0.5),\n",
    "    Dense(len(label_encoder.classes_), activation='softmax')\n",
    "])\n",
    "\n",
    "ann_model.compile(optimizer='adam', loss='sparse_categorical_crossentropy', metrics=['accuracy'])\n",
    "\n",
    "# Train the ANN\n",
    "ann_history = ann_model.fit(\n",
    "    train_features_normalized, \n",
    "    train_labels_encoded, \n",
    "    epochs=50, \n",
    "    batch_size=32, \n",
    "    validation_split=0.2,\n",
    "    callbacks=[tf.keras.callbacks.EarlyStopping(patience=5)]\n",
    ")\n",
    "\n",
    "# Evaluate the ANN\n",
    "ann_test_loss, ann_test_accuracy = ann_model.evaluate(test_features_normalized, test_labels_encoded)\n",
    "print(f\"ANN Test Accuracy: {ann_test_accuracy:.4f}\")\n",
    "\n",
    "# ANN Predictions and Classification Report\n",
    "ann_predictions = np.argmax(ann_model.predict(test_features_normalized), axis=1)\n",
    "print(\"ANN Classification Report:\")\n",
    "print(classification_report(test_labels_encoded, ann_predictions))\n",
    "\n",
    "# ANN Confusion Matrix\n",
    "ann_conf_matrix = confusion_matrix(test_labels_encoded, ann_predictions)\n",
    "save_confusion_matrix(ann_conf_matrix, label_encoder.classes_, \"ANN\", 14, \"../Files/confusion_matrix/balanced_accuracy_gender_hubert/ann_conf_matrix\")\n",
    "\n",
    "# Reshape the data for CNN\n",
    "train_features_cnn = np.expand_dims(train_features_normalized, axis=-1)\n",
    "test_features_cnn = np.expand_dims(test_features_normalized, axis=-1)\n",
    "\n",
    "# TensorFlow CNN Model\n",
    "cnn_model = Sequential([\n",
    "    Conv1D(64, kernel_size=5, activation='relu', input_shape=(train_features_cnn.shape[1], 1)),\n",
    "    Conv1D(128, kernel_size=5, activation='relu'),\n",
    "    Conv1D(256, kernel_size=5, activation='relu'),\n",
    "    Flatten(),\n",
    "    Dense(256, activation='relu'),\n",
    "    Dropout(0.5),\n",
    "    Dense(len(label_encoder.classes_), activation='softmax')\n",
    "])\n",
    "\n",
    "cnn_model.compile(optimizer='adam', loss='sparse_categorical_crossentropy', metrics=['accuracy'])\n",
    "\n",
    "# Train the TensorFlow CNN\n",
    "history = cnn_model.fit(\n",
    "    train_features_cnn, \n",
    "    train_labels_encoded, \n",
    "    epochs=50, \n",
    "    batch_size=32, \n",
    "    validation_split=0.2,\n",
    "    callbacks=[tf.keras.callbacks.EarlyStopping(patience=5)]\n",
    ")\n",
    "\n",
    "# Evaluate the TensorFlow CNN\n",
    "cnn_predictions = np.argmax(cnn_model.predict(test_features_cnn), axis=1)\n",
    "cnn_balanced_accuracy = accuracy_score(test_labels_encoded, cnn_predictions)\n",
    "\n",
    "print(f\"TensorFlow CNN Balanced Accuracy Score: {cnn_balanced_accuracy:.4f}\")\n",
    "print(\"TensorFlow CNN Classification Report:\")\n",
    "print(classification_report(test_labels_encoded, cnn_predictions))\n",
    "\n",
    "# CNN Confusion Matrix\n",
    "cnn_conf_matrix = confusion_matrix(test_labels_encoded, cnn_predictions)\n",
    "save_confusion_matrix(cnn_conf_matrix, label_encoder.classes_, \"CNN\", 14, \"../Files/confusion_matrix/balanced_accuracy_gender_hubert/cnn_conf_matrix\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5fb7c937",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 15\n",
    "import os\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.preprocessing import LabelEncoder, StandardScaler\n",
    "from sklearn.metrics import accuracy_score, classification_report, confusion_matrix\n",
    "import tensorflow as tf\n",
    "from tensorflow.keras.models import Sequential\n",
    "from tensorflow.keras.layers import Conv1D, Flatten, Dense, Dropout\n",
    "import torch\n",
    "from torch.utils.data import DataLoader, TensorDataset\n",
    "import torch.nn as nn\n",
    "import torch.optim as optim\n",
    "import seaborn as sns\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "# Load the data\n",
    "train_data = np.load('../Files/extracted_features/hubert_large/train_15.npz')\n",
    "test_data = np.load('../Files/extracted_features/hubert_large/test_15.npz')\n",
    "\n",
    "train_features = train_data['features']\n",
    "test_features = test_data['features']\n",
    "\n",
    "train_labels = pd.read_csv('../Files/labels/y_train.csv').Gender_bin\n",
    "test_labels = pd.read_csv('../Files/labels/y_test.csv').Gender_bin\n",
    "\n",
    "# Encode the labels\n",
    "label_encoder = LabelEncoder()\n",
    "train_labels_encoded = label_encoder.fit_transform(train_labels)\n",
    "test_labels_encoded = label_encoder.transform(test_labels)\n",
    "\n",
    "# Normalize the features\n",
    "scaler = StandardScaler()\n",
    "train_features_normalized = scaler.fit_transform(train_features)\n",
    "test_features_normalized = scaler.transform(test_features)\n",
    "\n",
    "# SVM Classification\n",
    "from sklearn.svm import SVC\n",
    "\n",
    "svm_model = SVC(kernel='linear', C=10.0, gamma='scale', random_state=42)\n",
    "svm_model.fit(train_features, train_labels_encoded)\n",
    "svm_predictions = svm_model.predict(test_features)\n",
    "\n",
    "svm_accuracy = accuracy_score(test_labels_encoded, svm_predictions)\n",
    "print(f\"SVM Accuracy: {svm_accuracy:.4f}\")\n",
    "print(\"SVM Classification Report:\")\n",
    "print(classification_report(test_labels_encoded, svm_predictions))\n",
    "\n",
    "# Function to save confusion matrix\n",
    "def save_confusion_matrix(conf_matrix, labels, model_name, layer_number, folder_name):\n",
    "    os.makedirs(folder_name, exist_ok=True)  # Ensure the folder exists\n",
    "    plt.figure(figsize=(10, 8))\n",
    "    sns.set(font_scale=1.2)\n",
    "    sns.heatmap(conf_matrix, annot=True, fmt='d', cmap='viridis', xticklabels=labels, yticklabels=labels)\n",
    "    plt.title(f'{model_name} Confusion Matrix')\n",
    "    plt.xlabel('Predicted Labels')\n",
    "    plt.ylabel('True Labels')\n",
    "    plt.tight_layout()\n",
    "    save_path = os.path.join(folder_name, f'conf_matrix_layer_{layer_number}.png')\n",
    "    plt.savefig(save_path)\n",
    "    plt.close()\n",
    "    print(f\"Saved confusion matrix for {model_name}: {save_path}\")\n",
    "\n",
    "# SVM Confusion Matrix\n",
    "svm_conf_matrix = confusion_matrix(test_labels_encoded, svm_predictions)\n",
    "save_confusion_matrix(svm_conf_matrix, label_encoder.classes_, \"SVM\", 15, \"../Files/confusion_matrix/balanced_accuracy_gender_hubert/svm_conf_matrix\")\n",
    "\n",
    "# ANN Model\n",
    "ann_model = Sequential([\n",
    "    Dense(512, activation='relu', input_shape=(train_features_normalized.shape[1],)),\n",
    "    Dropout(0.5),\n",
    "    Dense(256, activation='relu'),\n",
    "    Dropout(0.5),\n",
    "    Dense(128, activation='relu'),\n",
    "    Dropout(0.5),\n",
    "    Dense(len(label_encoder.classes_), activation='softmax')\n",
    "])\n",
    "\n",
    "ann_model.compile(optimizer='adam', loss='sparse_categorical_crossentropy', metrics=['accuracy'])\n",
    "\n",
    "# Train the ANN\n",
    "ann_history = ann_model.fit(\n",
    "    train_features_normalized, \n",
    "    train_labels_encoded, \n",
    "    epochs=50, \n",
    "    batch_size=32, \n",
    "    validation_split=0.2,\n",
    "    callbacks=[tf.keras.callbacks.EarlyStopping(patience=5)]\n",
    ")\n",
    "\n",
    "# Evaluate the ANN\n",
    "ann_test_loss, ann_test_accuracy = ann_model.evaluate(test_features_normalized, test_labels_encoded)\n",
    "print(f\"ANN Test Accuracy: {ann_test_accuracy:.4f}\")\n",
    "\n",
    "# ANN Predictions and Classification Report\n",
    "ann_predictions = np.argmax(ann_model.predict(test_features_normalized), axis=1)\n",
    "print(\"ANN Classification Report:\")\n",
    "print(classification_report(test_labels_encoded, ann_predictions))\n",
    "\n",
    "# ANN Confusion Matrix\n",
    "ann_conf_matrix = confusion_matrix(test_labels_encoded, ann_predictions)\n",
    "save_confusion_matrix(ann_conf_matrix, label_encoder.classes_, \"ANN\", 15, \"../Files/confusion_matrix/balanced_accuracy_gender_hubert/ann_conf_matrix\")\n",
    "\n",
    "# Reshape the data for CNN\n",
    "train_features_cnn = np.expand_dims(train_features_normalized, axis=-1)\n",
    "test_features_cnn = np.expand_dims(test_features_normalized, axis=-1)\n",
    "\n",
    "# TensorFlow CNN Model\n",
    "cnn_model = Sequential([\n",
    "    Conv1D(64, kernel_size=5, activation='relu', input_shape=(train_features_cnn.shape[1], 1)),\n",
    "    Conv1D(128, kernel_size=5, activation='relu'),\n",
    "    Conv1D(256, kernel_size=5, activation='relu'),\n",
    "    Flatten(),\n",
    "    Dense(256, activation='relu'),\n",
    "    Dropout(0.5),\n",
    "    Dense(len(label_encoder.classes_), activation='softmax')\n",
    "])\n",
    "\n",
    "cnn_model.compile(optimizer='adam', loss='sparse_categorical_crossentropy', metrics=['accuracy'])\n",
    "\n",
    "# Train the TensorFlow CNN\n",
    "history = cnn_model.fit(\n",
    "    train_features_cnn, \n",
    "    train_labels_encoded, \n",
    "    epochs=50, \n",
    "    batch_size=32, \n",
    "    validation_split=0.2,\n",
    "    callbacks=[tf.keras.callbacks.EarlyStopping(patience=5)]\n",
    ")\n",
    "\n",
    "# Evaluate the TensorFlow CNN\n",
    "cnn_predictions = np.argmax(cnn_model.predict(test_features_cnn), axis=1)\n",
    "cnn_balanced_accuracy = accuracy_score(test_labels_encoded, cnn_predictions)\n",
    "\n",
    "print(f\"TensorFlow CNN Balanced Accuracy Score: {cnn_balanced_accuracy:.4f}\")\n",
    "print(\"TensorFlow CNN Classification Report:\")\n",
    "print(classification_report(test_labels_encoded, cnn_predictions))\n",
    "\n",
    "# CNN Confusion Matrix\n",
    "cnn_conf_matrix = confusion_matrix(test_labels_encoded, cnn_predictions)\n",
    "save_confusion_matrix(cnn_conf_matrix, label_encoder.classes_, \"CNN\", 15, \"../Files/confusion_matrix/balanced_accuracy_gender_hubert/cnn_conf_matrix\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "42dbc604",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 16\n",
    "import os\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.preprocessing import LabelEncoder, StandardScaler\n",
    "from sklearn.metrics import accuracy_score, classification_report, confusion_matrix\n",
    "import tensorflow as tf\n",
    "from tensorflow.keras.models import Sequential\n",
    "from tensorflow.keras.layers import Conv1D, Flatten, Dense, Dropout\n",
    "import torch\n",
    "from torch.utils.data import DataLoader, TensorDataset\n",
    "import torch.nn as nn\n",
    "import torch.optim as optim\n",
    "import seaborn as sns\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "# Load the data\n",
    "train_data = np.load('../Files/extracted_features/hubert_large/train_16.npz')\n",
    "test_data = np.load('../Files/extracted_features/hubert_large/test_16.npz')\n",
    "\n",
    "train_features = train_data['features']\n",
    "test_features = test_data['features']\n",
    "\n",
    "train_labels = pd.read_csv('../Files/labels/y_train.csv').Gender_bin\n",
    "test_labels = pd.read_csv('../Files/labels/y_test.csv').Gender_bin\n",
    "\n",
    "# Encode the labels\n",
    "label_encoder = LabelEncoder()\n",
    "train_labels_encoded = label_encoder.fit_transform(train_labels)\n",
    "test_labels_encoded = label_encoder.transform(test_labels)\n",
    "\n",
    "# Normalize the features\n",
    "scaler = StandardScaler()\n",
    "train_features_normalized = scaler.fit_transform(train_features)\n",
    "test_features_normalized = scaler.transform(test_features)\n",
    "\n",
    "# SVM Classification\n",
    "from sklearn.svm import SVC\n",
    "\n",
    "svm_model = SVC(kernel='linear', C=10.0, gamma='scale', random_state=42)\n",
    "svm_model.fit(train_features, train_labels_encoded)\n",
    "svm_predictions = svm_model.predict(test_features)\n",
    "\n",
    "svm_accuracy = accuracy_score(test_labels_encoded, svm_predictions)\n",
    "print(f\"SVM Accuracy: {svm_accuracy:.4f}\")\n",
    "print(\"SVM Classification Report:\")\n",
    "print(classification_report(test_labels_encoded, svm_predictions))\n",
    "\n",
    "# Function to save confusion matrix\n",
    "def save_confusion_matrix(conf_matrix, labels, model_name, layer_number, folder_name):\n",
    "    os.makedirs(folder_name, exist_ok=True)  # Ensure the folder exists\n",
    "    plt.figure(figsize=(10, 8))\n",
    "    sns.set(font_scale=1.2)\n",
    "    sns.heatmap(conf_matrix, annot=True, fmt='d', cmap='viridis', xticklabels=labels, yticklabels=labels)\n",
    "    plt.title(f'{model_name} Confusion Matrix')\n",
    "    plt.xlabel('Predicted Labels')\n",
    "    plt.ylabel('True Labels')\n",
    "    plt.tight_layout()\n",
    "    save_path = os.path.join(folder_name, f'conf_matrix_layer_{layer_number}.png')\n",
    "    plt.savefig(save_path)\n",
    "    plt.close()\n",
    "    print(f\"Saved confusion matrix for {model_name}: {save_path}\")\n",
    "\n",
    "# SVM Confusion Matrix\n",
    "svm_conf_matrix = confusion_matrix(test_labels_encoded, svm_predictions)\n",
    "save_confusion_matrix(svm_conf_matrix, label_encoder.classes_, \"SVM\", 16, \"../Files/confusion_matrix/balanced_accuracy_gender_hubert/svm_conf_matrix\")\n",
    "\n",
    "# ANN Model\n",
    "ann_model = Sequential([\n",
    "    Dense(512, activation='relu', input_shape=(train_features_normalized.shape[1],)),\n",
    "    Dropout(0.5),\n",
    "    Dense(256, activation='relu'),\n",
    "    Dropout(0.5),\n",
    "    Dense(128, activation='relu'),\n",
    "    Dropout(0.5),\n",
    "    Dense(len(label_encoder.classes_), activation='softmax')\n",
    "])\n",
    "\n",
    "ann_model.compile(optimizer='adam', loss='sparse_categorical_crossentropy', metrics=['accuracy'])\n",
    "\n",
    "# Train the ANN\n",
    "ann_history = ann_model.fit(\n",
    "    train_features_normalized, \n",
    "    train_labels_encoded, \n",
    "    epochs=50, \n",
    "    batch_size=32, \n",
    "    validation_split=0.2,\n",
    "    callbacks=[tf.keras.callbacks.EarlyStopping(patience=5)]\n",
    ")\n",
    "\n",
    "# Evaluate the ANN\n",
    "ann_test_loss, ann_test_accuracy = ann_model.evaluate(test_features_normalized, test_labels_encoded)\n",
    "print(f\"ANN Test Accuracy: {ann_test_accuracy:.4f}\")\n",
    "\n",
    "# ANN Predictions and Classification Report\n",
    "ann_predictions = np.argmax(ann_model.predict(test_features_normalized), axis=1)\n",
    "print(\"ANN Classification Report:\")\n",
    "print(classification_report(test_labels_encoded, ann_predictions))\n",
    "\n",
    "# ANN Confusion Matrix\n",
    "ann_conf_matrix = confusion_matrix(test_labels_encoded, ann_predictions)\n",
    "save_confusion_matrix(ann_conf_matrix, label_encoder.classes_, \"ANN\", 16, \"../Files/confusion_matrix/balanced_accuracy_gender_hubert/ann_conf_matrix\")\n",
    "\n",
    "# Reshape the data for CNN\n",
    "train_features_cnn = np.expand_dims(train_features_normalized, axis=-1)\n",
    "test_features_cnn = np.expand_dims(test_features_normalized, axis=-1)\n",
    "\n",
    "# TensorFlow CNN Model\n",
    "cnn_model = Sequential([\n",
    "    Conv1D(64, kernel_size=5, activation='relu', input_shape=(train_features_cnn.shape[1], 1)),\n",
    "    Conv1D(128, kernel_size=5, activation='relu'),\n",
    "    Conv1D(256, kernel_size=5, activation='relu'),\n",
    "    Flatten(),\n",
    "    Dense(256, activation='relu'),\n",
    "    Dropout(0.5),\n",
    "    Dense(len(label_encoder.classes_), activation='softmax')\n",
    "])\n",
    "\n",
    "cnn_model.compile(optimizer='adam', loss='sparse_categorical_crossentropy', metrics=['accuracy'])\n",
    "\n",
    "# Train the TensorFlow CNN\n",
    "history = cnn_model.fit(\n",
    "    train_features_cnn, \n",
    "    train_labels_encoded, \n",
    "    epochs=50, \n",
    "    batch_size=32, \n",
    "    validation_split=0.2,\n",
    "    callbacks=[tf.keras.callbacks.EarlyStopping(patience=5)]\n",
    ")\n",
    "\n",
    "# Evaluate the TensorFlow CNN\n",
    "cnn_predictions = np.argmax(cnn_model.predict(test_features_cnn), axis=1)\n",
    "cnn_balanced_accuracy = accuracy_score(test_labels_encoded, cnn_predictions)\n",
    "\n",
    "print(f\"TensorFlow CNN Balanced Accuracy Score: {cnn_balanced_accuracy:.4f}\")\n",
    "print(\"TensorFlow CNN Classification Report:\")\n",
    "print(classification_report(test_labels_encoded, cnn_predictions))\n",
    "\n",
    "# CNN Confusion Matrix\n",
    "cnn_conf_matrix = confusion_matrix(test_labels_encoded, cnn_predictions)\n",
    "save_confusion_matrix(cnn_conf_matrix, label_encoder.classes_, \"CNN\", 16, \"../Files/confusion_matrix/balanced_accuracy_gender_hubert/cnn_conf_matrix\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c27d1a58",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 17\n",
    "import os\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.preprocessing import LabelEncoder, StandardScaler\n",
    "from sklearn.metrics import accuracy_score, classification_report, confusion_matrix\n",
    "import tensorflow as tf\n",
    "from tensorflow.keras.models import Sequential\n",
    "from tensorflow.keras.layers import Conv1D, Flatten, Dense, Dropout\n",
    "import torch\n",
    "from torch.utils.data import DataLoader, TensorDataset\n",
    "import torch.nn as nn\n",
    "import torch.optim as optim\n",
    "import seaborn as sns\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "# Load the data\n",
    "train_data = np.load('../Files/extracted_features/hubert_large/train_17.npz')\n",
    "test_data = np.load('../Files/extracted_features/hubert_large/test_17.npz')\n",
    "\n",
    "train_features = train_data['features']\n",
    "test_features = test_data['features']\n",
    "\n",
    "train_labels = pd.read_csv('../Files/labels/y_train.csv').Gender_bin\n",
    "test_labels = pd.read_csv('../Files/labels/y_test.csv').Gender_bin\n",
    "\n",
    "# Encode the labels\n",
    "label_encoder = LabelEncoder()\n",
    "train_labels_encoded = label_encoder.fit_transform(train_labels)\n",
    "test_labels_encoded = label_encoder.transform(test_labels)\n",
    "\n",
    "# Normalize the features\n",
    "scaler = StandardScaler()\n",
    "train_features_normalized = scaler.fit_transform(train_features)\n",
    "test_features_normalized = scaler.transform(test_features)\n",
    "\n",
    "# SVM Classification\n",
    "from sklearn.svm import SVC\n",
    "\n",
    "svm_model = SVC(kernel='linear', C=10.0, gamma='scale', random_state=42)\n",
    "svm_model.fit(train_features, train_labels_encoded)\n",
    "svm_predictions = svm_model.predict(test_features)\n",
    "\n",
    "svm_accuracy = accuracy_score(test_labels_encoded, svm_predictions)\n",
    "print(f\"SVM Accuracy: {svm_accuracy:.4f}\")\n",
    "print(\"SVM Classification Report:\")\n",
    "print(classification_report(test_labels_encoded, svm_predictions))\n",
    "\n",
    "# Function to save confusion matrix\n",
    "def save_confusion_matrix(conf_matrix, labels, model_name, layer_number, folder_name):\n",
    "    os.makedirs(folder_name, exist_ok=True)  # Ensure the folder exists\n",
    "    plt.figure(figsize=(10, 8))\n",
    "    sns.set(font_scale=1.2)\n",
    "    sns.heatmap(conf_matrix, annot=True, fmt='d', cmap='viridis', xticklabels=labels, yticklabels=labels)\n",
    "    plt.title(f'{model_name} Confusion Matrix')\n",
    "    plt.xlabel('Predicted Labels')\n",
    "    plt.ylabel('True Labels')\n",
    "    plt.tight_layout()\n",
    "    save_path = os.path.join(folder_name, f'conf_matrix_layer_{layer_number}.png')\n",
    "    plt.savefig(save_path)\n",
    "    plt.close()\n",
    "    print(f\"Saved confusion matrix for {model_name}: {save_path}\")\n",
    "\n",
    "# SVM Confusion Matrix\n",
    "svm_conf_matrix = confusion_matrix(test_labels_encoded, svm_predictions)\n",
    "save_confusion_matrix(svm_conf_matrix, label_encoder.classes_, \"SVM\", 17, \"../Files/confusion_matrix/balanced_accuracy_gender_hubert/svm_conf_matrix\")\n",
    "\n",
    "# ANN Model\n",
    "ann_model = Sequential([\n",
    "    Dense(512, activation='relu', input_shape=(train_features_normalized.shape[1],)),\n",
    "    Dropout(0.5),\n",
    "    Dense(256, activation='relu'),\n",
    "    Dropout(0.5),\n",
    "    Dense(128, activation='relu'),\n",
    "    Dropout(0.5),\n",
    "    Dense(len(label_encoder.classes_), activation='softmax')\n",
    "])\n",
    "\n",
    "ann_model.compile(optimizer='adam', loss='sparse_categorical_crossentropy', metrics=['accuracy'])\n",
    "\n",
    "# Train the ANN\n",
    "ann_history = ann_model.fit(\n",
    "    train_features_normalized, \n",
    "    train_labels_encoded, \n",
    "    epochs=50, \n",
    "    batch_size=32, \n",
    "    validation_split=0.2,\n",
    "    callbacks=[tf.keras.callbacks.EarlyStopping(patience=5)]\n",
    ")\n",
    "\n",
    "# Evaluate the ANN\n",
    "ann_test_loss, ann_test_accuracy = ann_model.evaluate(test_features_normalized, test_labels_encoded)\n",
    "print(f\"ANN Test Accuracy: {ann_test_accuracy:.4f}\")\n",
    "\n",
    "# ANN Predictions and Classification Report\n",
    "ann_predictions = np.argmax(ann_model.predict(test_features_normalized), axis=1)\n",
    "print(\"ANN Classification Report:\")\n",
    "print(classification_report(test_labels_encoded, ann_predictions))\n",
    "\n",
    "# ANN Confusion Matrix\n",
    "ann_conf_matrix = confusion_matrix(test_labels_encoded, ann_predictions)\n",
    "save_confusion_matrix(ann_conf_matrix, label_encoder.classes_, \"ANN\", 17, \"../Files/confusion_matrix/balanced_accuracy_gender_hubert/ann_conf_matrix\")\n",
    "\n",
    "# Reshape the data for CNN\n",
    "train_features_cnn = np.expand_dims(train_features_normalized, axis=-1)\n",
    "test_features_cnn = np.expand_dims(test_features_normalized, axis=-1)\n",
    "\n",
    "# TensorFlow CNN Model\n",
    "cnn_model = Sequential([\n",
    "    Conv1D(64, kernel_size=5, activation='relu', input_shape=(train_features_cnn.shape[1], 1)),\n",
    "    Conv1D(128, kernel_size=5, activation='relu'),\n",
    "    Conv1D(256, kernel_size=5, activation='relu'),\n",
    "    Flatten(),\n",
    "    Dense(256, activation='relu'),\n",
    "    Dropout(0.5),\n",
    "    Dense(len(label_encoder.classes_), activation='softmax')\n",
    "])\n",
    "\n",
    "cnn_model.compile(optimizer='adam', loss='sparse_categorical_crossentropy', metrics=['accuracy'])\n",
    "\n",
    "# Train the TensorFlow CNN\n",
    "history = cnn_model.fit(\n",
    "    train_features_cnn, \n",
    "    train_labels_encoded, \n",
    "    epochs=50, \n",
    "    batch_size=32, \n",
    "    validation_split=0.2,\n",
    "    callbacks=[tf.keras.callbacks.EarlyStopping(patience=5)]\n",
    ")\n",
    "\n",
    "# Evaluate the TensorFlow CNN\n",
    "cnn_predictions = np.argmax(cnn_model.predict(test_features_cnn), axis=1)\n",
    "cnn_balanced_accuracy = accuracy_score(test_labels_encoded, cnn_predictions)\n",
    "\n",
    "print(f\"TensorFlow CNN Balanced Accuracy Score: {cnn_balanced_accuracy:.4f}\")\n",
    "print(\"TensorFlow CNN Classification Report:\")\n",
    "print(classification_report(test_labels_encoded, cnn_predictions))\n",
    "\n",
    "# CNN Confusion Matrix\n",
    "cnn_conf_matrix = confusion_matrix(test_labels_encoded, cnn_predictions)\n",
    "save_confusion_matrix(cnn_conf_matrix, label_encoder.classes_, \"CNN\", 17, \"../Files/confusion_matrix/balanced_accuracy_gender_hubert/cnn_conf_matrix\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8e3925e1",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 18\n",
    "import os\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.preprocessing import LabelEncoder, StandardScaler\n",
    "from sklearn.metrics import accuracy_score, classification_report, confusion_matrix\n",
    "import tensorflow as tf\n",
    "from tensorflow.keras.models import Sequential\n",
    "from tensorflow.keras.layers import Conv1D, Flatten, Dense, Dropout\n",
    "import torch\n",
    "from torch.utils.data import DataLoader, TensorDataset\n",
    "import torch.nn as nn\n",
    "import torch.optim as optim\n",
    "import seaborn as sns\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "# Load the data\n",
    "train_data = np.load('../Files/extracted_features/hubert_large/train_18.npz')\n",
    "test_data = np.load('../Files/extracted_features/hubert_large/test_18.npz')\n",
    "\n",
    "train_features = train_data['features']\n",
    "test_features = test_data['features']\n",
    "\n",
    "train_labels = pd.read_csv('../Files/labels/y_train.csv').Gender_bin\n",
    "test_labels = pd.read_csv('../Files/labels/y_test.csv').Gender_bin\n",
    "\n",
    "# Encode the labels\n",
    "label_encoder = LabelEncoder()\n",
    "train_labels_encoded = label_encoder.fit_transform(train_labels)\n",
    "test_labels_encoded = label_encoder.transform(test_labels)\n",
    "\n",
    "# Normalize the features\n",
    "scaler = StandardScaler()\n",
    "train_features_normalized = scaler.fit_transform(train_features)\n",
    "test_features_normalized = scaler.transform(test_features)\n",
    "\n",
    "# SVM Classification\n",
    "from sklearn.svm import SVC\n",
    "\n",
    "svm_model = SVC(kernel='linear', C=10.0, gamma='scale', random_state=42)\n",
    "svm_model.fit(train_features, train_labels_encoded)\n",
    "svm_predictions = svm_model.predict(test_features)\n",
    "\n",
    "svm_accuracy = accuracy_score(test_labels_encoded, svm_predictions)\n",
    "print(f\"SVM Accuracy: {svm_accuracy:.4f}\")\n",
    "print(\"SVM Classification Report:\")\n",
    "print(classification_report(test_labels_encoded, svm_predictions))\n",
    "\n",
    "# Function to save confusion matrix\n",
    "def save_confusion_matrix(conf_matrix, labels, model_name, layer_number, folder_name):\n",
    "    os.makedirs(folder_name, exist_ok=True)  # Ensure the folder exists\n",
    "    plt.figure(figsize=(10, 8))\n",
    "    sns.set(font_scale=1.2)\n",
    "    sns.heatmap(conf_matrix, annot=True, fmt='d', cmap='viridis', xticklabels=labels, yticklabels=labels)\n",
    "    plt.title(f'{model_name} Confusion Matrix')\n",
    "    plt.xlabel('Predicted Labels')\n",
    "    plt.ylabel('True Labels')\n",
    "    plt.tight_layout()\n",
    "    save_path = os.path.join(folder_name, f'conf_matrix_layer_{layer_number}.png')\n",
    "    plt.savefig(save_path)\n",
    "    plt.close()\n",
    "    print(f\"Saved confusion matrix for {model_name}: {save_path}\")\n",
    "\n",
    "# SVM Confusion Matrix\n",
    "svm_conf_matrix = confusion_matrix(test_labels_encoded, svm_predictions)\n",
    "save_confusion_matrix(svm_conf_matrix, label_encoder.classes_, \"SVM\", 18, \"../Files/confusion_matrix/balanced_accuracy_gender_hubert/svm_conf_matrix\")\n",
    "\n",
    "# ANN Model\n",
    "ann_model = Sequential([\n",
    "    Dense(512, activation='relu', input_shape=(train_features_normalized.shape[1],)),\n",
    "    Dropout(0.5),\n",
    "    Dense(256, activation='relu'),\n",
    "    Dropout(0.5),\n",
    "    Dense(128, activation='relu'),\n",
    "    Dropout(0.5),\n",
    "    Dense(len(label_encoder.classes_), activation='softmax')\n",
    "])\n",
    "\n",
    "ann_model.compile(optimizer='adam', loss='sparse_categorical_crossentropy', metrics=['accuracy'])\n",
    "\n",
    "# Train the ANN\n",
    "ann_history = ann_model.fit(\n",
    "    train_features_normalized, \n",
    "    train_labels_encoded, \n",
    "    epochs=50, \n",
    "    batch_size=32, \n",
    "    validation_split=0.2,\n",
    "    callbacks=[tf.keras.callbacks.EarlyStopping(patience=5)]\n",
    ")\n",
    "\n",
    "# Evaluate the ANN\n",
    "ann_test_loss, ann_test_accuracy = ann_model.evaluate(test_features_normalized, test_labels_encoded)\n",
    "print(f\"ANN Test Accuracy: {ann_test_accuracy:.4f}\")\n",
    "\n",
    "# ANN Predictions and Classification Report\n",
    "ann_predictions = np.argmax(ann_model.predict(test_features_normalized), axis=1)\n",
    "print(\"ANN Classification Report:\")\n",
    "print(classification_report(test_labels_encoded, ann_predictions))\n",
    "\n",
    "# ANN Confusion Matrix\n",
    "ann_conf_matrix = confusion_matrix(test_labels_encoded, ann_predictions)\n",
    "save_confusion_matrix(ann_conf_matrix, label_encoder.classes_, \"ANN\", 18, \"../Files/confusion_matrix/balanced_accuracy_gender_hubert/ann_conf_matrix\")\n",
    "\n",
    "# Reshape the data for CNN\n",
    "train_features_cnn = np.expand_dims(train_features_normalized, axis=-1)\n",
    "test_features_cnn = np.expand_dims(test_features_normalized, axis=-1)\n",
    "\n",
    "# TensorFlow CNN Model\n",
    "cnn_model = Sequential([\n",
    "    Conv1D(64, kernel_size=5, activation='relu', input_shape=(train_features_cnn.shape[1], 1)),\n",
    "    Conv1D(128, kernel_size=5, activation='relu'),\n",
    "    Conv1D(256, kernel_size=5, activation='relu'),\n",
    "    Flatten(),\n",
    "    Dense(256, activation='relu'),\n",
    "    Dropout(0.5),\n",
    "    Dense(len(label_encoder.classes_), activation='softmax')\n",
    "])\n",
    "\n",
    "cnn_model.compile(optimizer='adam', loss='sparse_categorical_crossentropy', metrics=['accuracy'])\n",
    "\n",
    "# Train the TensorFlow CNN\n",
    "history = cnn_model.fit(\n",
    "    train_features_cnn, \n",
    "    train_labels_encoded, \n",
    "    epochs=50, \n",
    "    batch_size=32, \n",
    "    validation_split=0.2,\n",
    "    callbacks=[tf.keras.callbacks.EarlyStopping(patience=5)]\n",
    ")\n",
    "\n",
    "# Evaluate the TensorFlow CNN\n",
    "cnn_predictions = np.argmax(cnn_model.predict(test_features_cnn), axis=1)\n",
    "cnn_balanced_accuracy = accuracy_score(test_labels_encoded, cnn_predictions)\n",
    "\n",
    "print(f\"TensorFlow CNN Balanced Accuracy Score: {cnn_balanced_accuracy:.4f}\")\n",
    "print(\"TensorFlow CNN Classification Report:\")\n",
    "print(classification_report(test_labels_encoded, cnn_predictions))\n",
    "\n",
    "# CNN Confusion Matrix\n",
    "cnn_conf_matrix = confusion_matrix(test_labels_encoded, cnn_predictions)\n",
    "save_confusion_matrix(cnn_conf_matrix, label_encoder.classes_, \"CNN\", 18, \"../Files/confusion_matrix/balanced_accuracy_gender_hubert/cnn_conf_matrix\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a9ced419",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 19\n",
    "import os\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.preprocessing import LabelEncoder, StandardScaler\n",
    "from sklearn.metrics import accuracy_score, classification_report, confusion_matrix\n",
    "import tensorflow as tf\n",
    "from tensorflow.keras.models import Sequential\n",
    "from tensorflow.keras.layers import Conv1D, Flatten, Dense, Dropout\n",
    "import torch\n",
    "from torch.utils.data import DataLoader, TensorDataset\n",
    "import torch.nn as nn\n",
    "import torch.optim as optim\n",
    "import seaborn as sns\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "# Load the data\n",
    "train_data = np.load('../Files/extracted_features/hubert_large/train_19.npz')\n",
    "test_data = np.load('../Files/extracted_features/hubert_large/test_19.npz')\n",
    "\n",
    "train_features = train_data['features']\n",
    "test_features = test_data['features']\n",
    "\n",
    "train_labels = pd.read_csv('../Files/labels/y_train.csv').Gender_bin\n",
    "test_labels = pd.read_csv('../Files/labels/y_test.csv').Gender_bin\n",
    "\n",
    "# Encode the labels\n",
    "label_encoder = LabelEncoder()\n",
    "train_labels_encoded = label_encoder.fit_transform(train_labels)\n",
    "test_labels_encoded = label_encoder.transform(test_labels)\n",
    "\n",
    "# Normalize the features\n",
    "scaler = StandardScaler()\n",
    "train_features_normalized = scaler.fit_transform(train_features)\n",
    "test_features_normalized = scaler.transform(test_features)\n",
    "\n",
    "# SVM Classification\n",
    "from sklearn.svm import SVC\n",
    "\n",
    "svm_model = SVC(kernel='linear', C=10.0, gamma='scale', random_state=42)\n",
    "svm_model.fit(train_features, train_labels_encoded)\n",
    "svm_predictions = svm_model.predict(test_features)\n",
    "\n",
    "svm_accuracy = accuracy_score(test_labels_encoded, svm_predictions)\n",
    "print(f\"SVM Accuracy: {svm_accuracy:.4f}\")\n",
    "print(\"SVM Classification Report:\")\n",
    "print(classification_report(test_labels_encoded, svm_predictions))\n",
    "\n",
    "# Function to save confusion matrix\n",
    "def save_confusion_matrix(conf_matrix, labels, model_name, layer_number, folder_name):\n",
    "    os.makedirs(folder_name, exist_ok=True)  # Ensure the folder exists\n",
    "    plt.figure(figsize=(10, 8))\n",
    "    sns.set(font_scale=1.2)\n",
    "    sns.heatmap(conf_matrix, annot=True, fmt='d', cmap='viridis', xticklabels=labels, yticklabels=labels)\n",
    "    plt.title(f'{model_name} Confusion Matrix')\n",
    "    plt.xlabel('Predicted Labels')\n",
    "    plt.ylabel('True Labels')\n",
    "    plt.tight_layout()\n",
    "    save_path = os.path.join(folder_name, f'conf_matrix_layer_{layer_number}.png')\n",
    "    plt.savefig(save_path)\n",
    "    plt.close()\n",
    "    print(f\"Saved confusion matrix for {model_name}: {save_path}\")\n",
    "\n",
    "# SVM Confusion Matrix\n",
    "svm_conf_matrix = confusion_matrix(test_labels_encoded, svm_predictions)\n",
    "save_confusion_matrix(svm_conf_matrix, label_encoder.classes_, \"SVM\", 19, \"../Files/confusion_matrix/balanced_accuracy_gender_hubert/svm_conf_matrix\")\n",
    "\n",
    "# ANN Model\n",
    "ann_model = Sequential([\n",
    "    Dense(512, activation='relu', input_shape=(train_features_normalized.shape[1],)),\n",
    "    Dropout(0.5),\n",
    "    Dense(256, activation='relu'),\n",
    "    Dropout(0.5),\n",
    "    Dense(128, activation='relu'),\n",
    "    Dropout(0.5),\n",
    "    Dense(len(label_encoder.classes_), activation='softmax')\n",
    "])\n",
    "\n",
    "ann_model.compile(optimizer='adam', loss='sparse_categorical_crossentropy', metrics=['accuracy'])\n",
    "\n",
    "# Train the ANN\n",
    "ann_history = ann_model.fit(\n",
    "    train_features_normalized, \n",
    "    train_labels_encoded, \n",
    "    epochs=50, \n",
    "    batch_size=32, \n",
    "    validation_split=0.2,\n",
    "    callbacks=[tf.keras.callbacks.EarlyStopping(patience=5)]\n",
    ")\n",
    "\n",
    "# Evaluate the ANN\n",
    "ann_test_loss, ann_test_accuracy = ann_model.evaluate(test_features_normalized, test_labels_encoded)\n",
    "print(f\"ANN Test Accuracy: {ann_test_accuracy:.4f}\")\n",
    "\n",
    "# ANN Predictions and Classification Report\n",
    "ann_predictions = np.argmax(ann_model.predict(test_features_normalized), axis=1)\n",
    "print(\"ANN Classification Report:\")\n",
    "print(classification_report(test_labels_encoded, ann_predictions))\n",
    "\n",
    "# ANN Confusion Matrix\n",
    "ann_conf_matrix = confusion_matrix(test_labels_encoded, ann_predictions)\n",
    "save_confusion_matrix(ann_conf_matrix, label_encoder.classes_, \"ANN\", 19, \"../Files/confusion_matrix/balanced_accuracy_gender_hubert/ann_conf_matrix\")\n",
    "\n",
    "# Reshape the data for CNN\n",
    "train_features_cnn = np.expand_dims(train_features_normalized, axis=-1)\n",
    "test_features_cnn = np.expand_dims(test_features_normalized, axis=-1)\n",
    "\n",
    "# TensorFlow CNN Model\n",
    "cnn_model = Sequential([\n",
    "    Conv1D(64, kernel_size=5, activation='relu', input_shape=(train_features_cnn.shape[1], 1)),\n",
    "    Conv1D(128, kernel_size=5, activation='relu'),\n",
    "    Conv1D(256, kernel_size=5, activation='relu'),\n",
    "    Flatten(),\n",
    "    Dense(256, activation='relu'),\n",
    "    Dropout(0.5),\n",
    "    Dense(len(label_encoder.classes_), activation='softmax')\n",
    "])\n",
    "\n",
    "cnn_model.compile(optimizer='adam', loss='sparse_categorical_crossentropy', metrics=['accuracy'])\n",
    "\n",
    "# Train the TensorFlow CNN\n",
    "history = cnn_model.fit(\n",
    "    train_features_cnn, \n",
    "    train_labels_encoded, \n",
    "    epochs=50, \n",
    "    batch_size=32, \n",
    "    validation_split=0.2,\n",
    "    callbacks=[tf.keras.callbacks.EarlyStopping(patience=5)]\n",
    ")\n",
    "\n",
    "# Evaluate the TensorFlow CNN\n",
    "cnn_predictions = np.argmax(cnn_model.predict(test_features_cnn), axis=1)\n",
    "cnn_balanced_accuracy = accuracy_score(test_labels_encoded, cnn_predictions)\n",
    "\n",
    "print(f\"TensorFlow CNN Balanced Accuracy Score: {cnn_balanced_accuracy:.4f}\")\n",
    "print(\"TensorFlow CNN Classification Report:\")\n",
    "print(classification_report(test_labels_encoded, cnn_predictions))\n",
    "\n",
    "# CNN Confusion Matrix\n",
    "cnn_conf_matrix = confusion_matrix(test_labels_encoded, cnn_predictions)\n",
    "save_confusion_matrix(cnn_conf_matrix, label_encoder.classes_, \"CNN\", 19, \"../Files/confusion_matrix/balanced_accuracy_gender_hubert/cnn_conf_matrix\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ce7d19b2",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 20\n",
    "import os\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.preprocessing import LabelEncoder, StandardScaler\n",
    "from sklearn.metrics import accuracy_score, classification_report, confusion_matrix\n",
    "import tensorflow as tf\n",
    "from tensorflow.keras.models import Sequential\n",
    "from tensorflow.keras.layers import Conv1D, Flatten, Dense, Dropout\n",
    "import torch\n",
    "from torch.utils.data import DataLoader, TensorDataset\n",
    "import torch.nn as nn\n",
    "import torch.optim as optim\n",
    "import seaborn as sns\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "# Load the data\n",
    "train_data = np.load('../Files/extracted_features/hubert_large/train_20.npz')\n",
    "test_data = np.load('../Files/extracted_features/hubert_large/test_20.npz')\n",
    "\n",
    "train_features = train_data['features']\n",
    "test_features = test_data['features']\n",
    "\n",
    "train_labels = pd.read_csv('../Files/labels/y_train.csv').Gender_bin\n",
    "test_labels = pd.read_csv('../Files/labels/y_test.csv').Gender_bin\n",
    "\n",
    "# Encode the labels\n",
    "label_encoder = LabelEncoder()\n",
    "train_labels_encoded = label_encoder.fit_transform(train_labels)\n",
    "test_labels_encoded = label_encoder.transform(test_labels)\n",
    "\n",
    "# Normalize the features\n",
    "scaler = StandardScaler()\n",
    "train_features_normalized = scaler.fit_transform(train_features)\n",
    "test_features_normalized = scaler.transform(test_features)\n",
    "\n",
    "# SVM Classification\n",
    "from sklearn.svm import SVC\n",
    "\n",
    "svm_model = SVC(kernel='linear', C=10.0, gamma='scale', random_state=42)\n",
    "svm_model.fit(train_features, train_labels_encoded)\n",
    "svm_predictions = svm_model.predict(test_features)\n",
    "\n",
    "svm_accuracy = accuracy_score(test_labels_encoded, svm_predictions)\n",
    "print(f\"SVM Accuracy: {svm_accuracy:.4f}\")\n",
    "print(\"SVM Classification Report:\")\n",
    "print(classification_report(test_labels_encoded, svm_predictions))\n",
    "\n",
    "# Function to save confusion matrix\n",
    "def save_confusion_matrix(conf_matrix, labels, model_name, layer_number, folder_name):\n",
    "    os.makedirs(folder_name, exist_ok=True)  # Ensure the folder exists\n",
    "    plt.figure(figsize=(10, 8))\n",
    "    sns.set(font_scale=1.2)\n",
    "    sns.heatmap(conf_matrix, annot=True, fmt='d', cmap='viridis', xticklabels=labels, yticklabels=labels)\n",
    "    plt.title(f'{model_name} Confusion Matrix')\n",
    "    plt.xlabel('Predicted Labels')\n",
    "    plt.ylabel('True Labels')\n",
    "    plt.tight_layout()\n",
    "    save_path = os.path.join(folder_name, f'conf_matrix_layer_{layer_number}.png')\n",
    "    plt.savefig(save_path)\n",
    "    plt.close()\n",
    "    print(f\"Saved confusion matrix for {model_name}: {save_path}\")\n",
    "\n",
    "# SVM Confusion Matrix\n",
    "svm_conf_matrix = confusion_matrix(test_labels_encoded, svm_predictions)\n",
    "save_confusion_matrix(svm_conf_matrix, label_encoder.classes_, \"SVM\", 20, \"../Files/confusion_matrix/balanced_accuracy_gender_hubert/svm_conf_matrix\")\n",
    "\n",
    "# ANN Model\n",
    "ann_model = Sequential([\n",
    "    Dense(512, activation='relu', input_shape=(train_features_normalized.shape[1],)),\n",
    "    Dropout(0.5),\n",
    "    Dense(256, activation='relu'),\n",
    "    Dropout(0.5),\n",
    "    Dense(128, activation='relu'),\n",
    "    Dropout(0.5),\n",
    "    Dense(len(label_encoder.classes_), activation='softmax')\n",
    "])\n",
    "\n",
    "ann_model.compile(optimizer='adam', loss='sparse_categorical_crossentropy', metrics=['accuracy'])\n",
    "\n",
    "# Train the ANN\n",
    "ann_history = ann_model.fit(\n",
    "    train_features_normalized, \n",
    "    train_labels_encoded, \n",
    "    epochs=50, \n",
    "    batch_size=32, \n",
    "    validation_split=0.2,\n",
    "    callbacks=[tf.keras.callbacks.EarlyStopping(patience=5)]\n",
    ")\n",
    "\n",
    "# Evaluate the ANN\n",
    "ann_test_loss, ann_test_accuracy = ann_model.evaluate(test_features_normalized, test_labels_encoded)\n",
    "print(f\"ANN Test Accuracy: {ann_test_accuracy:.4f}\")\n",
    "\n",
    "# ANN Predictions and Classification Report\n",
    "ann_predictions = np.argmax(ann_model.predict(test_features_normalized), axis=1)\n",
    "print(\"ANN Classification Report:\")\n",
    "print(classification_report(test_labels_encoded, ann_predictions))\n",
    "\n",
    "# ANN Confusion Matrix\n",
    "ann_conf_matrix = confusion_matrix(test_labels_encoded, ann_predictions)\n",
    "save_confusion_matrix(ann_conf_matrix, label_encoder.classes_, \"ANN\", 20, \"../Files/confusion_matrix/balanced_accuracy_gender_hubert/ann_conf_matrix\")\n",
    "\n",
    "# Reshape the data for CNN\n",
    "train_features_cnn = np.expand_dims(train_features_normalized, axis=-1)\n",
    "test_features_cnn = np.expand_dims(test_features_normalized, axis=-1)\n",
    "\n",
    "# TensorFlow CNN Model\n",
    "cnn_model = Sequential([\n",
    "    Conv1D(64, kernel_size=5, activation='relu', input_shape=(train_features_cnn.shape[1], 1)),\n",
    "    Conv1D(128, kernel_size=5, activation='relu'),\n",
    "    Conv1D(256, kernel_size=5, activation='relu'),\n",
    "    Flatten(),\n",
    "    Dense(256, activation='relu'),\n",
    "    Dropout(0.5),\n",
    "    Dense(len(label_encoder.classes_), activation='softmax')\n",
    "])\n",
    "\n",
    "cnn_model.compile(optimizer='adam', loss='sparse_categorical_crossentropy', metrics=['accuracy'])\n",
    "\n",
    "# Train the TensorFlow CNN\n",
    "history = cnn_model.fit(\n",
    "    train_features_cnn, \n",
    "    train_labels_encoded, \n",
    "    epochs=50, \n",
    "    batch_size=32, \n",
    "    validation_split=0.2,\n",
    "    callbacks=[tf.keras.callbacks.EarlyStopping(patience=5)]\n",
    ")\n",
    "\n",
    "# Evaluate the TensorFlow CNN\n",
    "cnn_predictions = np.argmax(cnn_model.predict(test_features_cnn), axis=1)\n",
    "cnn_balanced_accuracy = accuracy_score(test_labels_encoded, cnn_predictions)\n",
    "\n",
    "print(f\"TensorFlow CNN Balanced Accuracy Score: {cnn_balanced_accuracy:.4f}\")\n",
    "print(\"TensorFlow CNN Classification Report:\")\n",
    "print(classification_report(test_labels_encoded, cnn_predictions))\n",
    "\n",
    "# CNN Confusion Matrix\n",
    "cnn_conf_matrix = confusion_matrix(test_labels_encoded, cnn_predictions)\n",
    "save_confusion_matrix(cnn_conf_matrix, label_encoder.classes_, \"CNN\", 20, \"../Files/confusion_matrix/balanced_accuracy_gender_hubert/cnn_conf_matrix\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e39fbb26",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 21\n",
    "import os\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.preprocessing import LabelEncoder, StandardScaler\n",
    "from sklearn.metrics import accuracy_score, classification_report, confusion_matrix\n",
    "import tensorflow as tf\n",
    "from tensorflow.keras.models import Sequential\n",
    "from tensorflow.keras.layers import Conv1D, Flatten, Dense, Dropout\n",
    "import torch\n",
    "from torch.utils.data import DataLoader, TensorDataset\n",
    "import torch.nn as nn\n",
    "import torch.optim as optim\n",
    "import seaborn as sns\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "# Load the data\n",
    "train_data = np.load('../Files/extracted_features/hubert_large/train_21.npz')\n",
    "test_data = np.load('../Files/extracted_features/hubert_large/test_21.npz')\n",
    "\n",
    "train_features = train_data['features']\n",
    "test_features = test_data['features']\n",
    "\n",
    "train_labels = pd.read_csv('../Files/labels/y_train.csv').Gender_bin\n",
    "test_labels = pd.read_csv('../Files/labels/y_test.csv').Gender_bin\n",
    "\n",
    "# Encode the labels\n",
    "label_encoder = LabelEncoder()\n",
    "train_labels_encoded = label_encoder.fit_transform(train_labels)\n",
    "test_labels_encoded = label_encoder.transform(test_labels)\n",
    "\n",
    "# Normalize the features\n",
    "scaler = StandardScaler()\n",
    "train_features_normalized = scaler.fit_transform(train_features)\n",
    "test_features_normalized = scaler.transform(test_features)\n",
    "\n",
    "# SVM Classification\n",
    "from sklearn.svm import SVC\n",
    "\n",
    "svm_model = SVC(kernel='linear', C=10.0, gamma='scale', random_state=42)\n",
    "svm_model.fit(train_features, train_labels_encoded)\n",
    "svm_predictions = svm_model.predict(test_features)\n",
    "\n",
    "svm_accuracy = accuracy_score(test_labels_encoded, svm_predictions)\n",
    "print(f\"SVM Accuracy: {svm_accuracy:.4f}\")\n",
    "print(\"SVM Classification Report:\")\n",
    "print(classification_report(test_labels_encoded, svm_predictions))\n",
    "\n",
    "# Function to save confusion matrix\n",
    "def save_confusion_matrix(conf_matrix, labels, model_name, layer_number, folder_name):\n",
    "    os.makedirs(folder_name, exist_ok=True)  # Ensure the folder exists\n",
    "    plt.figure(figsize=(10, 8))\n",
    "    sns.set(font_scale=1.2)\n",
    "    sns.heatmap(conf_matrix, annot=True, fmt='d', cmap='viridis', xticklabels=labels, yticklabels=labels)\n",
    "    plt.title(f'{model_name} Confusion Matrix')\n",
    "    plt.xlabel('Predicted Labels')\n",
    "    plt.ylabel('True Labels')\n",
    "    plt.tight_layout()\n",
    "    save_path = os.path.join(folder_name, f'conf_matrix_layer_{layer_number}.png')\n",
    "    plt.savefig(save_path)\n",
    "    plt.close()\n",
    "    print(f\"Saved confusion matrix for {model_name}: {save_path}\")\n",
    "\n",
    "# SVM Confusion Matrix\n",
    "svm_conf_matrix = confusion_matrix(test_labels_encoded, svm_predictions)\n",
    "save_confusion_matrix(svm_conf_matrix, label_encoder.classes_, \"SVM\", 21, \"../Files/confusion_matrix/balanced_accuracy_gender_hubert/svm_conf_matrix\")\n",
    "\n",
    "# ANN Model\n",
    "ann_model = Sequential([\n",
    "    Dense(512, activation='relu', input_shape=(train_features_normalized.shape[1],)),\n",
    "    Dropout(0.5),\n",
    "    Dense(256, activation='relu'),\n",
    "    Dropout(0.5),\n",
    "    Dense(128, activation='relu'),\n",
    "    Dropout(0.5),\n",
    "    Dense(len(label_encoder.classes_), activation='softmax')\n",
    "])\n",
    "\n",
    "ann_model.compile(optimizer='adam', loss='sparse_categorical_crossentropy', metrics=['accuracy'])\n",
    "\n",
    "# Train the ANN\n",
    "ann_history = ann_model.fit(\n",
    "    train_features_normalized, \n",
    "    train_labels_encoded, \n",
    "    epochs=50, \n",
    "    batch_size=32, \n",
    "    validation_split=0.2,\n",
    "    callbacks=[tf.keras.callbacks.EarlyStopping(patience=5)]\n",
    ")\n",
    "\n",
    "# Evaluate the ANN\n",
    "ann_test_loss, ann_test_accuracy = ann_model.evaluate(test_features_normalized, test_labels_encoded)\n",
    "print(f\"ANN Test Accuracy: {ann_test_accuracy:.4f}\")\n",
    "\n",
    "# ANN Predictions and Classification Report\n",
    "ann_predictions = np.argmax(ann_model.predict(test_features_normalized), axis=1)\n",
    "print(\"ANN Classification Report:\")\n",
    "print(classification_report(test_labels_encoded, ann_predictions))\n",
    "\n",
    "# ANN Confusion Matrix\n",
    "ann_conf_matrix = confusion_matrix(test_labels_encoded, ann_predictions)\n",
    "save_confusion_matrix(ann_conf_matrix, label_encoder.classes_, \"ANN\", 21, \"../Files/confusion_matrix/balanced_accuracy_gender_hubert/ann_conf_matrix\")\n",
    "\n",
    "# Reshape the data for CNN\n",
    "train_features_cnn = np.expand_dims(train_features_normalized, axis=-1)\n",
    "test_features_cnn = np.expand_dims(test_features_normalized, axis=-1)\n",
    "\n",
    "# TensorFlow CNN Model\n",
    "cnn_model = Sequential([\n",
    "    Conv1D(64, kernel_size=5, activation='relu', input_shape=(train_features_cnn.shape[1], 1)),\n",
    "    Conv1D(128, kernel_size=5, activation='relu'),\n",
    "    Conv1D(256, kernel_size=5, activation='relu'),\n",
    "    Flatten(),\n",
    "    Dense(256, activation='relu'),\n",
    "    Dropout(0.5),\n",
    "    Dense(len(label_encoder.classes_), activation='softmax')\n",
    "])\n",
    "\n",
    "cnn_model.compile(optimizer='adam', loss='sparse_categorical_crossentropy', metrics=['accuracy'])\n",
    "\n",
    "# Train the TensorFlow CNN\n",
    "history = cnn_model.fit(\n",
    "    train_features_cnn, \n",
    "    train_labels_encoded, \n",
    "    epochs=50, \n",
    "    batch_size=32, \n",
    "    validation_split=0.2,\n",
    "    callbacks=[tf.keras.callbacks.EarlyStopping(patience=5)]\n",
    ")\n",
    "\n",
    "# Evaluate the TensorFlow CNN\n",
    "cnn_predictions = np.argmax(cnn_model.predict(test_features_cnn), axis=1)\n",
    "cnn_balanced_accuracy = accuracy_score(test_labels_encoded, cnn_predictions)\n",
    "\n",
    "print(f\"TensorFlow CNN Balanced Accuracy Score: {cnn_balanced_accuracy:.4f}\")\n",
    "print(\"TensorFlow CNN Classification Report:\")\n",
    "print(classification_report(test_labels_encoded, cnn_predictions))\n",
    "\n",
    "# CNN Confusion Matrix\n",
    "cnn_conf_matrix = confusion_matrix(test_labels_encoded, cnn_predictions)\n",
    "save_confusion_matrix(cnn_conf_matrix, label_encoder.classes_, \"CNN\", 21, \"../Files/confusion_matrix/balanced_accuracy_gender_hubert/cnn_conf_matrix\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b7638966",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 22\n",
    "import os\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.preprocessing import LabelEncoder, StandardScaler\n",
    "from sklearn.metrics import accuracy_score, classification_report, confusion_matrix\n",
    "import tensorflow as tf\n",
    "from tensorflow.keras.models import Sequential\n",
    "from tensorflow.keras.layers import Conv1D, Flatten, Dense, Dropout\n",
    "import torch\n",
    "from torch.utils.data import DataLoader, TensorDataset\n",
    "import torch.nn as nn\n",
    "import torch.optim as optim\n",
    "import seaborn as sns\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "# Load the data\n",
    "train_data = np.load('../Files/extracted_features/hubert_large/train_22.npz')\n",
    "test_data = np.load('../Files/extracted_features/hubert_large/test_22.npz')\n",
    "\n",
    "train_features = train_data['features']\n",
    "test_features = test_data['features']\n",
    "\n",
    "train_labels = pd.read_csv('../Files/labels/y_train.csv').Gender_bin\n",
    "test_labels = pd.read_csv('../Files/labels/y_test.csv').Gender_bin\n",
    "\n",
    "# Encode the labels\n",
    "label_encoder = LabelEncoder()\n",
    "train_labels_encoded = label_encoder.fit_transform(train_labels)\n",
    "test_labels_encoded = label_encoder.transform(test_labels)\n",
    "\n",
    "# Normalize the features\n",
    "scaler = StandardScaler()\n",
    "train_features_normalized = scaler.fit_transform(train_features)\n",
    "test_features_normalized = scaler.transform(test_features)\n",
    "\n",
    "# SVM Classification\n",
    "from sklearn.svm import SVC\n",
    "\n",
    "svm_model = SVC(kernel='linear', C=10.0, gamma='scale', random_state=42)\n",
    "svm_model.fit(train_features, train_labels_encoded)\n",
    "svm_predictions = svm_model.predict(test_features)\n",
    "\n",
    "svm_accuracy = accuracy_score(test_labels_encoded, svm_predictions)\n",
    "print(f\"SVM Accuracy: {svm_accuracy:.4f}\")\n",
    "print(\"SVM Classification Report:\")\n",
    "print(classification_report(test_labels_encoded, svm_predictions))\n",
    "\n",
    "# Function to save confusion matrix\n",
    "def save_confusion_matrix(conf_matrix, labels, model_name, layer_number, folder_name):\n",
    "    os.makedirs(folder_name, exist_ok=True)  # Ensure the folder exists\n",
    "    plt.figure(figsize=(10, 8))\n",
    "    sns.set(font_scale=1.2)\n",
    "    sns.heatmap(conf_matrix, annot=True, fmt='d', cmap='viridis', xticklabels=labels, yticklabels=labels)\n",
    "    plt.title(f'{model_name} Confusion Matrix')\n",
    "    plt.xlabel('Predicted Labels')\n",
    "    plt.ylabel('True Labels')\n",
    "    plt.tight_layout()\n",
    "    save_path = os.path.join(folder_name, f'conf_matrix_layer_{layer_number}.png')\n",
    "    plt.savefig(save_path)\n",
    "    plt.close()\n",
    "    print(f\"Saved confusion matrix for {model_name}: {save_path}\")\n",
    "\n",
    "# SVM Confusion Matrix\n",
    "svm_conf_matrix = confusion_matrix(test_labels_encoded, svm_predictions)\n",
    "save_confusion_matrix(svm_conf_matrix, label_encoder.classes_, \"SVM\", 22, \"../Files/confusion_matrix/balanced_accuracy_gender_hubert/svm_conf_matrix\")\n",
    "\n",
    "# ANN Model\n",
    "ann_model = Sequential([\n",
    "    Dense(512, activation='relu', input_shape=(train_features_normalized.shape[1],)),\n",
    "    Dropout(0.5),\n",
    "    Dense(256, activation='relu'),\n",
    "    Dropout(0.5),\n",
    "    Dense(128, activation='relu'),\n",
    "    Dropout(0.5),\n",
    "    Dense(len(label_encoder.classes_), activation='softmax')\n",
    "])\n",
    "\n",
    "ann_model.compile(optimizer='adam', loss='sparse_categorical_crossentropy', metrics=['accuracy'])\n",
    "\n",
    "# Train the ANN\n",
    "ann_history = ann_model.fit(\n",
    "    train_features_normalized, \n",
    "    train_labels_encoded, \n",
    "    epochs=50, \n",
    "    batch_size=32, \n",
    "    validation_split=0.2,\n",
    "    callbacks=[tf.keras.callbacks.EarlyStopping(patience=5)]\n",
    ")\n",
    "\n",
    "# Evaluate the ANN\n",
    "ann_test_loss, ann_test_accuracy = ann_model.evaluate(test_features_normalized, test_labels_encoded)\n",
    "print(f\"ANN Test Accuracy: {ann_test_accuracy:.4f}\")\n",
    "\n",
    "# ANN Predictions and Classification Report\n",
    "ann_predictions = np.argmax(ann_model.predict(test_features_normalized), axis=1)\n",
    "print(\"ANN Classification Report:\")\n",
    "print(classification_report(test_labels_encoded, ann_predictions))\n",
    "\n",
    "# ANN Confusion Matrix\n",
    "ann_conf_matrix = confusion_matrix(test_labels_encoded, ann_predictions)\n",
    "save_confusion_matrix(ann_conf_matrix, label_encoder.classes_, \"ANN\", 22, \"../Files/confusion_matrix/balanced_accuracy_gender_hubert/ann_conf_matrix\")\n",
    "\n",
    "# Reshape the data for CNN\n",
    "train_features_cnn = np.expand_dims(train_features_normalized, axis=-1)\n",
    "test_features_cnn = np.expand_dims(test_features_normalized, axis=-1)\n",
    "\n",
    "# TensorFlow CNN Model\n",
    "cnn_model = Sequential([\n",
    "    Conv1D(64, kernel_size=5, activation='relu', input_shape=(train_features_cnn.shape[1], 1)),\n",
    "    Conv1D(128, kernel_size=5, activation='relu'),\n",
    "    Conv1D(256, kernel_size=5, activation='relu'),\n",
    "    Flatten(),\n",
    "    Dense(256, activation='relu'),\n",
    "    Dropout(0.5),\n",
    "    Dense(len(label_encoder.classes_), activation='softmax')\n",
    "])\n",
    "\n",
    "cnn_model.compile(optimizer='adam', loss='sparse_categorical_crossentropy', metrics=['accuracy'])\n",
    "\n",
    "# Train the TensorFlow CNN\n",
    "history = cnn_model.fit(\n",
    "    train_features_cnn, \n",
    "    train_labels_encoded, \n",
    "    epochs=50, \n",
    "    batch_size=32, \n",
    "    validation_split=0.2,\n",
    "    callbacks=[tf.keras.callbacks.EarlyStopping(patience=5)]\n",
    ")\n",
    "\n",
    "# Evaluate the TensorFlow CNN\n",
    "cnn_predictions = np.argmax(cnn_model.predict(test_features_cnn), axis=1)\n",
    "cnn_balanced_accuracy = accuracy_score(test_labels_encoded, cnn_predictions)\n",
    "\n",
    "print(f\"TensorFlow CNN Balanced Accuracy Score: {cnn_balanced_accuracy:.4f}\")\n",
    "print(\"TensorFlow CNN Classification Report:\")\n",
    "print(classification_report(test_labels_encoded, cnn_predictions))\n",
    "\n",
    "# CNN Confusion Matrix\n",
    "cnn_conf_matrix = confusion_matrix(test_labels_encoded, cnn_predictions)\n",
    "save_confusion_matrix(cnn_conf_matrix, label_encoder.classes_, \"CNN\", 22, \"../Files/confusion_matrix/balanced_accuracy_gender_hubert/cnn_conf_matrix\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0b0d7865",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 23\n",
    "import os\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.preprocessing import LabelEncoder, StandardScaler\n",
    "from sklearn.metrics import accuracy_score, classification_report, confusion_matrix\n",
    "import tensorflow as tf\n",
    "from tensorflow.keras.models import Sequential\n",
    "from tensorflow.keras.layers import Conv1D, Flatten, Dense, Dropout\n",
    "import torch\n",
    "from torch.utils.data import DataLoader, TensorDataset\n",
    "import torch.nn as nn\n",
    "import torch.optim as optim\n",
    "import seaborn as sns\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "# Load the data\n",
    "train_data = np.load('../Files/extracted_features/hubert_large/train_23.npz')\n",
    "test_data = np.load('../Files/extracted_features/hubert_large/test_23.npz')\n",
    "\n",
    "train_features = train_data['features']\n",
    "test_features = test_data['features']\n",
    "\n",
    "train_labels = pd.read_csv('../Files/labels/y_train.csv').Gender_bin\n",
    "test_labels = pd.read_csv('../Files/labels/y_test.csv').Gender_bin\n",
    "\n",
    "# Encode the labels\n",
    "label_encoder = LabelEncoder()\n",
    "train_labels_encoded = label_encoder.fit_transform(train_labels)\n",
    "test_labels_encoded = label_encoder.transform(test_labels)\n",
    "\n",
    "# Normalize the features\n",
    "scaler = StandardScaler()\n",
    "train_features_normalized = scaler.fit_transform(train_features)\n",
    "test_features_normalized = scaler.transform(test_features)\n",
    "\n",
    "# SVM Classification\n",
    "from sklearn.svm import SVC\n",
    "\n",
    "svm_model = SVC(kernel='linear', C=10.0, gamma='scale', random_state=42)\n",
    "svm_model.fit(train_features, train_labels_encoded)\n",
    "svm_predictions = svm_model.predict(test_features)\n",
    "\n",
    "svm_accuracy = accuracy_score(test_labels_encoded, svm_predictions)\n",
    "print(f\"SVM Accuracy: {svm_accuracy:.4f}\")\n",
    "print(\"SVM Classification Report:\")\n",
    "print(classification_report(test_labels_encoded, svm_predictions))\n",
    "\n",
    "# Function to save confusion matrix\n",
    "def save_confusion_matrix(conf_matrix, labels, model_name, layer_number, folder_name):\n",
    "    os.makedirs(folder_name, exist_ok=True)  # Ensure the folder exists\n",
    "    plt.figure(figsize=(10, 8))\n",
    "    sns.set(font_scale=1.2)\n",
    "    sns.heatmap(conf_matrix, annot=True, fmt='d', cmap='viridis', xticklabels=labels, yticklabels=labels)\n",
    "    plt.title(f'{model_name} Confusion Matrix')\n",
    "    plt.xlabel('Predicted Labels')\n",
    "    plt.ylabel('True Labels')\n",
    "    plt.tight_layout()\n",
    "    save_path = os.path.join(folder_name, f'conf_matrix_layer_{layer_number}.png')\n",
    "    plt.savefig(save_path)\n",
    "    plt.close()\n",
    "    print(f\"Saved confusion matrix for {model_name}: {save_path}\")\n",
    "\n",
    "# SVM Confusion Matrix\n",
    "svm_conf_matrix = confusion_matrix(test_labels_encoded, svm_predictions)\n",
    "save_confusion_matrix(svm_conf_matrix, label_encoder.classes_, \"SVM\", 23, \"../Files/confusion_matrix/balanced_accuracy_gender_hubert/svm_conf_matrix\")\n",
    "\n",
    "# ANN Model\n",
    "ann_model = Sequential([\n",
    "    Dense(512, activation='relu', input_shape=(train_features_normalized.shape[1],)),\n",
    "    Dropout(0.5),\n",
    "    Dense(256, activation='relu'),\n",
    "    Dropout(0.5),\n",
    "    Dense(128, activation='relu'),\n",
    "    Dropout(0.5),\n",
    "    Dense(len(label_encoder.classes_), activation='softmax')\n",
    "])\n",
    "\n",
    "ann_model.compile(optimizer='adam', loss='sparse_categorical_crossentropy', metrics=['accuracy'])\n",
    "\n",
    "# Train the ANN\n",
    "ann_history = ann_model.fit(\n",
    "    train_features_normalized, \n",
    "    train_labels_encoded, \n",
    "    epochs=50, \n",
    "    batch_size=32, \n",
    "    validation_split=0.2,\n",
    "    callbacks=[tf.keras.callbacks.EarlyStopping(patience=5)]\n",
    ")\n",
    "\n",
    "# Evaluate the ANN\n",
    "ann_test_loss, ann_test_accuracy = ann_model.evaluate(test_features_normalized, test_labels_encoded)\n",
    "print(f\"ANN Test Accuracy: {ann_test_accuracy:.4f}\")\n",
    "\n",
    "# ANN Predictions and Classification Report\n",
    "ann_predictions = np.argmax(ann_model.predict(test_features_normalized), axis=1)\n",
    "print(\"ANN Classification Report:\")\n",
    "print(classification_report(test_labels_encoded, ann_predictions))\n",
    "\n",
    "# ANN Confusion Matrix\n",
    "ann_conf_matrix = confusion_matrix(test_labels_encoded, ann_predictions)\n",
    "save_confusion_matrix(ann_conf_matrix, label_encoder.classes_, \"ANN\", 23, \"../Files/confusion_matrix/balanced_accuracy_gender_hubert/ann_conf_matrix\")\n",
    "\n",
    "# Reshape the data for CNN\n",
    "train_features_cnn = np.expand_dims(train_features_normalized, axis=-1)\n",
    "test_features_cnn = np.expand_dims(test_features_normalized, axis=-1)\n",
    "\n",
    "# TensorFlow CNN Model\n",
    "cnn_model = Sequential([\n",
    "    Conv1D(64, kernel_size=5, activation='relu', input_shape=(train_features_cnn.shape[1], 1)),\n",
    "    Conv1D(128, kernel_size=5, activation='relu'),\n",
    "    Conv1D(256, kernel_size=5, activation='relu'),\n",
    "    Flatten(),\n",
    "    Dense(256, activation='relu'),\n",
    "    Dropout(0.5),\n",
    "    Dense(len(label_encoder.classes_), activation='softmax')\n",
    "])\n",
    "\n",
    "cnn_model.compile(optimizer='adam', loss='sparse_categorical_crossentropy', metrics=['accuracy'])\n",
    "\n",
    "# Train the TensorFlow CNN\n",
    "history = cnn_model.fit(\n",
    "    train_features_cnn, \n",
    "    train_labels_encoded, \n",
    "    epochs=50, \n",
    "    batch_size=32, \n",
    "    validation_split=0.2,\n",
    "    callbacks=[tf.keras.callbacks.EarlyStopping(patience=5)]\n",
    ")\n",
    "\n",
    "# Evaluate the TensorFlow CNN\n",
    "cnn_predictions = np.argmax(cnn_model.predict(test_features_cnn), axis=1)\n",
    "cnn_balanced_accuracy = accuracy_score(test_labels_encoded, cnn_predictions)\n",
    "\n",
    "print(f\"TensorFlow CNN Balanced Accuracy Score: {cnn_balanced_accuracy:.4f}\")\n",
    "print(\"TensorFlow CNN Classification Report:\")\n",
    "print(classification_report(test_labels_encoded, cnn_predictions))\n",
    "\n",
    "# CNN Confusion Matrix\n",
    "cnn_conf_matrix = confusion_matrix(test_labels_encoded, cnn_predictions)\n",
    "save_confusion_matrix(cnn_conf_matrix, label_encoder.classes_, \"CNN\", 23, \"../Files/confusion_matrix/balanced_accuracy_gender_hubert/cnn_conf_matrix\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "38615140",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 24\n",
    "import os\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.preprocessing import LabelEncoder, StandardScaler\n",
    "from sklearn.metrics import accuracy_score, classification_report, confusion_matrix\n",
    "import tensorflow as tf\n",
    "from tensorflow.keras.models import Sequential\n",
    "from tensorflow.keras.layers import Conv1D, Flatten, Dense, Dropout\n",
    "import torch\n",
    "from torch.utils.data import DataLoader, TensorDataset\n",
    "import torch.nn as nn\n",
    "import torch.optim as optim\n",
    "import seaborn as sns\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "# Load the data\n",
    "train_data = np.load('../Files/extracted_features/hubert_large/train_24.npz')\n",
    "test_data = np.load('../Files/extracted_features/hubert_large/test_24.npz')\n",
    "\n",
    "train_features = train_data['features']\n",
    "test_features = test_data['features']\n",
    "\n",
    "train_labels = pd.read_csv('../Files/labels/y_train.csv').Gender_bin\n",
    "test_labels = pd.read_csv('../Files/labels/y_test.csv').Gender_bin\n",
    "\n",
    "# Encode the labels\n",
    "label_encoder = LabelEncoder()\n",
    "train_labels_encoded = label_encoder.fit_transform(train_labels)\n",
    "test_labels_encoded = label_encoder.transform(test_labels)\n",
    "\n",
    "# Normalize the features\n",
    "scaler = StandardScaler()\n",
    "train_features_normalized = scaler.fit_transform(train_features)\n",
    "test_features_normalized = scaler.transform(test_features)\n",
    "\n",
    "# SVM Classification\n",
    "from sklearn.svm import SVC\n",
    "\n",
    "svm_model = SVC(kernel='linear', C=10.0, gamma='scale', random_state=42)\n",
    "svm_model.fit(train_features, train_labels_encoded)\n",
    "svm_predictions = svm_model.predict(test_features)\n",
    "\n",
    "svm_accuracy = accuracy_score(test_labels_encoded, svm_predictions)\n",
    "print(f\"SVM Accuracy: {svm_accuracy:.4f}\")\n",
    "print(\"SVM Classification Report:\")\n",
    "print(classification_report(test_labels_encoded, svm_predictions))\n",
    "\n",
    "# Function to save confusion matrix\n",
    "def save_confusion_matrix(conf_matrix, labels, model_name, layer_number, folder_name):\n",
    "    os.makedirs(folder_name, exist_ok=True)  # Ensure the folder exists\n",
    "    plt.figure(figsize=(10, 8))\n",
    "    sns.set(font_scale=1.2)\n",
    "    sns.heatmap(conf_matrix, annot=True, fmt='d', cmap='viridis', xticklabels=labels, yticklabels=labels)\n",
    "    plt.title(f'{model_name} Confusion Matrix')\n",
    "    plt.xlabel('Predicted Labels')\n",
    "    plt.ylabel('True Labels')\n",
    "    plt.tight_layout()\n",
    "    save_path = os.path.join(folder_name, f'conf_matrix_layer_{layer_number}.png')\n",
    "    plt.savefig(save_path)\n",
    "    plt.close()\n",
    "    print(f\"Saved confusion matrix for {model_name}: {save_path}\")\n",
    "\n",
    "# SVM Confusion Matrix\n",
    "svm_conf_matrix = confusion_matrix(test_labels_encoded, svm_predictions)\n",
    "save_confusion_matrix(svm_conf_matrix, label_encoder.classes_, \"SVM\", 24, \"../Files/confusion_matrix/balanced_accuracy_gender_hubert/svm_conf_matrix\")\n",
    "\n",
    "# ANN Model\n",
    "ann_model = Sequential([\n",
    "    Dense(512, activation='relu', input_shape=(train_features_normalized.shape[1],)),\n",
    "    Dropout(0.5),\n",
    "    Dense(256, activation='relu'),\n",
    "    Dropout(0.5),\n",
    "    Dense(128, activation='relu'),\n",
    "    Dropout(0.5),\n",
    "    Dense(len(label_encoder.classes_), activation='softmax')\n",
    "])\n",
    "\n",
    "ann_model.compile(optimizer='adam', loss='sparse_categorical_crossentropy', metrics=['accuracy'])\n",
    "\n",
    "# Train the ANN\n",
    "ann_history = ann_model.fit(\n",
    "    train_features_normalized, \n",
    "    train_labels_encoded, \n",
    "    epochs=50, \n",
    "    batch_size=32, \n",
    "    validation_split=0.2,\n",
    "    callbacks=[tf.keras.callbacks.EarlyStopping(patience=5)]\n",
    ")\n",
    "\n",
    "# Evaluate the ANN\n",
    "ann_test_loss, ann_test_accuracy = ann_model.evaluate(test_features_normalized, test_labels_encoded)\n",
    "print(f\"ANN Test Accuracy: {ann_test_accuracy:.4f}\")\n",
    "\n",
    "# ANN Predictions and Classification Report\n",
    "ann_predictions = np.argmax(ann_model.predict(test_features_normalized), axis=1)\n",
    "print(\"ANN Classification Report:\")\n",
    "print(classification_report(test_labels_encoded, ann_predictions))\n",
    "\n",
    "# ANN Confusion Matrix\n",
    "ann_conf_matrix = confusion_matrix(test_labels_encoded, ann_predictions)\n",
    "save_confusion_matrix(ann_conf_matrix, label_encoder.classes_, \"ANN\", 24, \"../Files/confusion_matrix/balanced_accuracy_gender_hubert/ann_conf_matrix\")\n",
    "\n",
    "# Reshape the data for CNN\n",
    "train_features_cnn = np.expand_dims(train_features_normalized, axis=-1)\n",
    "test_features_cnn = np.expand_dims(test_features_normalized, axis=-1)\n",
    "\n",
    "# TensorFlow CNN Model\n",
    "cnn_model = Sequential([\n",
    "    Conv1D(64, kernel_size=5, activation='relu', input_shape=(train_features_cnn.shape[1], 1)),\n",
    "    Conv1D(128, kernel_size=5, activation='relu'),\n",
    "    Conv1D(256, kernel_size=5, activation='relu'),\n",
    "    Flatten(),\n",
    "    Dense(256, activation='relu'),\n",
    "    Dropout(0.5),\n",
    "    Dense(len(label_encoder.classes_), activation='softmax')\n",
    "])\n",
    "\n",
    "cnn_model.compile(optimizer='adam', loss='sparse_categorical_crossentropy', metrics=['accuracy'])\n",
    "\n",
    "# Train the TensorFlow CNN\n",
    "history = cnn_model.fit(\n",
    "    train_features_cnn, \n",
    "    train_labels_encoded, \n",
    "    epochs=50, \n",
    "    batch_size=32, \n",
    "    validation_split=0.2,\n",
    "    callbacks=[tf.keras.callbacks.EarlyStopping(patience=5)]\n",
    ")\n",
    "\n",
    "# Evaluate the TensorFlow CNN\n",
    "cnn_predictions = np.argmax(cnn_model.predict(test_features_cnn), axis=1)\n",
    "cnn_balanced_accuracy = accuracy_score(test_labels_encoded, cnn_predictions)\n",
    "\n",
    "print(f\"TensorFlow CNN Balanced Accuracy Score: {cnn_balanced_accuracy:.4f}\")\n",
    "print(\"TensorFlow CNN Classification Report:\")\n",
    "print(classification_report(test_labels_encoded, cnn_predictions))\n",
    "\n",
    "# CNN Confusion Matrix\n",
    "cnn_conf_matrix = confusion_matrix(test_labels_encoded, cnn_predictions)\n",
    "save_confusion_matrix(cnn_conf_matrix, label_encoder.classes_, \"CNN\", 24, \"../Files/confusion_matrix/balanced_accuracy_gender_hubert/cnn_conf_matrix\")\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e2948592",
   "metadata": {},
   "outputs": [],
   "source": [
    "# wavlm"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
