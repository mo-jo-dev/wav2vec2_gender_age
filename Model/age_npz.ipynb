{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/lib/python3/dist-packages/sklearn/metrics/_classification.py:2458: UserWarning: y_pred contains classes not in y_true\n",
      "  warnings.warn(\"y_pred contains classes not in y_true\")\n",
      "/usr/lib/python3/dist-packages/sklearn/metrics/_classification.py:1509: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", len(result))\n",
      "/usr/lib/python3/dist-packages/sklearn/metrics/_classification.py:1509: UndefinedMetricWarning: Recall is ill-defined and being set to 0.0 in labels with no true samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", len(result))\n",
      "/usr/lib/python3/dist-packages/sklearn/metrics/_classification.py:1509: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", len(result))\n",
      "/usr/lib/python3/dist-packages/sklearn/metrics/_classification.py:1509: UndefinedMetricWarning: Recall is ill-defined and being set to 0.0 in labels with no true samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", len(result))\n",
      "/usr/lib/python3/dist-packages/sklearn/metrics/_classification.py:1509: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", len(result))\n",
      "/usr/lib/python3/dist-packages/sklearn/metrics/_classification.py:1509: UndefinedMetricWarning: Recall is ill-defined and being set to 0.0 in labels with no true samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", len(result))\n",
      "/home/mojo/.local/lib/python3.12/site-packages/keras/src/layers/convolutional/base_conv.py:107: UserWarning: Do not pass an `input_shape`/`input_dim` argument to a layer. When using Sequential models, prefer using an `Input(shape)` object as the first layer in the model instead.\n",
      "  super().__init__(activity_regularizer=activity_regularizer, **kwargs)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "SVM Accuracy: 0.3102\n",
      "SVM Classification Report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           1       0.43      0.50      0.46        12\n",
      "           2       0.13      0.25      0.17         8\n",
      "           3       0.51      0.54      0.53        39\n",
      "           4       0.25      0.33      0.29         6\n",
      "           5       0.61      0.55      0.57        42\n",
      "           6       0.56      0.31      0.40        16\n",
      "           7       0.00      0.00      0.00         2\n",
      "           8       0.00      0.00      0.00         2\n",
      "           9       0.00      0.00      0.00         0\n",
      "\n",
      "    accuracy                           0.46       127\n",
      "   macro avg       0.28      0.28      0.27       127\n",
      "weighted avg       0.49      0.46      0.47       127\n",
      "\n",
      "Epoch 1/50\n",
      "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m13s\u001b[0m 528ms/step - accuracy: 0.2493 - loss: 5.3310 - val_accuracy: 0.0465 - val_loss: 2.4517\n",
      "Epoch 2/50\n",
      "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m11s\u001b[0m 504ms/step - accuracy: 0.3814 - loss: 1.8972 - val_accuracy: 0.0407 - val_loss: 2.5036\n",
      "Epoch 3/50\n",
      "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m11s\u001b[0m 505ms/step - accuracy: 0.4705 - loss: 1.6525 - val_accuracy: 0.0407 - val_loss: 3.1460\n",
      "Epoch 4/50\n",
      "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m11s\u001b[0m 505ms/step - accuracy: 0.5046 - loss: 1.4481 - val_accuracy: 0.0640 - val_loss: 2.5693\n",
      "Epoch 5/50\n",
      "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m11s\u001b[0m 521ms/step - accuracy: 0.6280 - loss: 1.0910 - val_accuracy: 0.1221 - val_loss: 2.5300\n",
      "Epoch 6/50\n",
      "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m11s\u001b[0m 505ms/step - accuracy: 0.7153 - loss: 0.8570 - val_accuracy: 0.1395 - val_loss: 3.1170\n",
      "Epoch 7/50\n",
      "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m11s\u001b[0m 499ms/step - accuracy: 0.7645 - loss: 0.6472 - val_accuracy: 0.0814 - val_loss: 3.7316\n",
      "Epoch 8/50\n",
      "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m11s\u001b[0m 494ms/step - accuracy: 0.8760 - loss: 0.4119 - val_accuracy: 0.2267 - val_loss: 3.1972\n",
      "Epoch 9/50\n",
      "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m11s\u001b[0m 500ms/step - accuracy: 0.8945 - loss: 0.3391 - val_accuracy: 0.1860 - val_loss: 3.2010\n",
      "Epoch 10/50\n",
      "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m11s\u001b[0m 494ms/step - accuracy: 0.9265 - loss: 0.2408 - val_accuracy: 0.1163 - val_loss: 4.8976\n",
      "Epoch 11/50\n",
      "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m11s\u001b[0m 510ms/step - accuracy: 0.9276 - loss: 0.2088 - val_accuracy: 0.1512 - val_loss: 4.9350\n",
      "Epoch 12/50\n",
      "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m11s\u001b[0m 496ms/step - accuracy: 0.9408 - loss: 0.1714 - val_accuracy: 0.1337 - val_loss: 5.5241\n",
      "Epoch 13/50\n",
      "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m11s\u001b[0m 504ms/step - accuracy: 0.9653 - loss: 0.1261 - val_accuracy: 0.1686 - val_loss: 4.7957\n",
      "Epoch 14/50\n",
      "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m11s\u001b[0m 510ms/step - accuracy: 0.9720 - loss: 0.0874 - val_accuracy: 0.1279 - val_loss: 5.8062\n",
      "Epoch 15/50\n",
      "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m11s\u001b[0m 507ms/step - accuracy: 0.9699 - loss: 0.1325 - val_accuracy: 0.1047 - val_loss: 6.5905\n",
      "Epoch 16/50\n",
      "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m11s\u001b[0m 499ms/step - accuracy: 0.9752 - loss: 0.1105 - val_accuracy: 0.1628 - val_loss: 5.0578\n",
      "Epoch 17/50\n",
      "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m11s\u001b[0m 508ms/step - accuracy: 0.9584 - loss: 0.1071 - val_accuracy: 0.1221 - val_loss: 6.7295\n",
      "Epoch 18/50\n",
      "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m11s\u001b[0m 495ms/step - accuracy: 0.9838 - loss: 0.0561 - val_accuracy: 0.0872 - val_loss: 7.6868\n",
      "Epoch 19/50\n",
      "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m11s\u001b[0m 503ms/step - accuracy: 0.9863 - loss: 0.0474 - val_accuracy: 0.0756 - val_loss: 8.8400\n",
      "Epoch 20/50\n",
      "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m11s\u001b[0m 504ms/step - accuracy: 0.9777 - loss: 0.0555 - val_accuracy: 0.1453 - val_loss: 6.8619\n",
      "Epoch 21/50\n",
      "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m11s\u001b[0m 499ms/step - accuracy: 0.9824 - loss: 0.0691 - val_accuracy: 0.1047 - val_loss: 7.4378\n",
      "Epoch 22/50\n",
      "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m11s\u001b[0m 507ms/step - accuracy: 0.9902 - loss: 0.0456 - val_accuracy: 0.1453 - val_loss: 6.9885\n",
      "Epoch 23/50\n",
      "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m11s\u001b[0m 506ms/step - accuracy: 0.9883 - loss: 0.0469 - val_accuracy: 0.1221 - val_loss: 7.0140\n",
      "Epoch 24/50\n",
      "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m12s\u001b[0m 528ms/step - accuracy: 0.9817 - loss: 0.0528 - val_accuracy: 0.1279 - val_loss: 7.0327\n",
      "Epoch 25/50\n",
      "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m12s\u001b[0m 529ms/step - accuracy: 0.9814 - loss: 0.0453 - val_accuracy: 0.1279 - val_loss: 7.6430\n",
      "Epoch 26/50\n",
      "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m11s\u001b[0m 522ms/step - accuracy: 0.9852 - loss: 0.0384 - val_accuracy: 0.1163 - val_loss: 8.4025\n",
      "Epoch 27/50\n",
      "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m11s\u001b[0m 501ms/step - accuracy: 0.9791 - loss: 0.0520 - val_accuracy: 0.1105 - val_loss: 8.1512\n",
      "Epoch 28/50\n",
      "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m11s\u001b[0m 493ms/step - accuracy: 0.9894 - loss: 0.0275 - val_accuracy: 0.1163 - val_loss: 9.5113\n",
      "Epoch 29/50\n",
      "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m11s\u001b[0m 494ms/step - accuracy: 0.9957 - loss: 0.0164 - val_accuracy: 0.1163 - val_loss: 10.4131\n",
      "Epoch 30/50\n",
      "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m11s\u001b[0m 491ms/step - accuracy: 0.9870 - loss: 0.0351 - val_accuracy: 0.2093 - val_loss: 6.9718\n",
      "Epoch 31/50\n",
      "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m11s\u001b[0m 494ms/step - accuracy: 0.9882 - loss: 0.0431 - val_accuracy: 0.1744 - val_loss: 7.3746\n",
      "Epoch 32/50\n",
      "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m11s\u001b[0m 484ms/step - accuracy: 0.9882 - loss: 0.0215 - val_accuracy: 0.1512 - val_loss: 7.3327\n",
      "Epoch 33/50\n",
      "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m11s\u001b[0m 492ms/step - accuracy: 0.9847 - loss: 0.0282 - val_accuracy: 0.1163 - val_loss: 8.9609\n",
      "Epoch 34/50\n",
      "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m11s\u001b[0m 493ms/step - accuracy: 0.9879 - loss: 0.0428 - val_accuracy: 0.1047 - val_loss: 9.7578\n",
      "Epoch 35/50\n",
      "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m11s\u001b[0m 498ms/step - accuracy: 0.9869 - loss: 0.0453 - val_accuracy: 0.1570 - val_loss: 6.8839\n",
      "Epoch 36/50\n",
      "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m11s\u001b[0m 494ms/step - accuracy: 0.9883 - loss: 0.0287 - val_accuracy: 0.1395 - val_loss: 8.0083\n",
      "Epoch 37/50\n",
      "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m11s\u001b[0m 489ms/step - accuracy: 0.9986 - loss: 0.0120 - val_accuracy: 0.1453 - val_loss: 9.0862\n",
      "Epoch 38/50\n",
      "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m11s\u001b[0m 488ms/step - accuracy: 0.9895 - loss: 0.0335 - val_accuracy: 0.1395 - val_loss: 8.4067\n",
      "Epoch 39/50\n",
      "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m11s\u001b[0m 498ms/step - accuracy: 0.9957 - loss: 0.0142 - val_accuracy: 0.1512 - val_loss: 9.7127\n",
      "Epoch 40/50\n",
      "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m11s\u001b[0m 497ms/step - accuracy: 0.9864 - loss: 0.0294 - val_accuracy: 0.1628 - val_loss: 8.9020\n",
      "Epoch 41/50\n",
      "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m11s\u001b[0m 501ms/step - accuracy: 0.9981 - loss: 0.0161 - val_accuracy: 0.1337 - val_loss: 10.0091\n",
      "Epoch 42/50\n",
      "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m11s\u001b[0m 498ms/step - accuracy: 0.9948 - loss: 0.0148 - val_accuracy: 0.1453 - val_loss: 9.9306\n",
      "Epoch 43/50\n",
      "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m11s\u001b[0m 511ms/step - accuracy: 0.9946 - loss: 0.0180 - val_accuracy: 0.1570 - val_loss: 9.0947\n",
      "Epoch 44/50\n",
      "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m11s\u001b[0m 504ms/step - accuracy: 0.9943 - loss: 0.0228 - val_accuracy: 0.1570 - val_loss: 9.4155\n",
      "Epoch 45/50\n",
      "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m11s\u001b[0m 503ms/step - accuracy: 0.9871 - loss: 0.0231 - val_accuracy: 0.1802 - val_loss: 8.0435\n",
      "Epoch 46/50\n",
      "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m11s\u001b[0m 506ms/step - accuracy: 0.9927 - loss: 0.0295 - val_accuracy: 0.1628 - val_loss: 8.6126\n",
      "Epoch 47/50\n",
      "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m11s\u001b[0m 508ms/step - accuracy: 0.9928 - loss: 0.0138 - val_accuracy: 0.1337 - val_loss: 10.1665\n",
      "Epoch 48/50\n",
      "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m11s\u001b[0m 504ms/step - accuracy: 0.9977 - loss: 0.0119 - val_accuracy: 0.1163 - val_loss: 11.5745\n",
      "Epoch 49/50\n",
      "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m11s\u001b[0m 514ms/step - accuracy: 0.9947 - loss: 0.0199 - val_accuracy: 0.1628 - val_loss: 8.4348\n",
      "Epoch 50/50\n",
      "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m11s\u001b[0m 503ms/step - accuracy: 0.9924 - loss: 0.0229 - val_accuracy: 0.1744 - val_loss: 9.3192\n",
      "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 59ms/step\n",
      "CNN Accuracy: 0.2383\n",
      "CNN Classification Report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           1       0.24      0.33      0.28        12\n",
      "           2       0.18      0.38      0.24         8\n",
      "           3       0.50      0.10      0.17        39\n",
      "           4       0.17      0.33      0.22         6\n",
      "           5       0.47      0.76      0.58        42\n",
      "           6       0.00      0.00      0.00        16\n",
      "           7       0.00      0.00      0.00         2\n",
      "           8       0.00      0.00      0.00         2\n",
      "           9       0.00      0.00      0.00         0\n",
      "\n",
      "    accuracy                           0.35       127\n",
      "   macro avg       0.17      0.21      0.17       127\n",
      "weighted avg       0.35      0.35      0.30       127\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/lib/python3/dist-packages/sklearn/metrics/_classification.py:2458: UserWarning: y_pred contains classes not in y_true\n",
      "  warnings.warn(\"y_pred contains classes not in y_true\")\n",
      "/usr/lib/python3/dist-packages/sklearn/metrics/_classification.py:1509: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", len(result))\n",
      "/usr/lib/python3/dist-packages/sklearn/metrics/_classification.py:1509: UndefinedMetricWarning: Recall is ill-defined and being set to 0.0 in labels with no true samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", len(result))\n",
      "/usr/lib/python3/dist-packages/sklearn/metrics/_classification.py:1509: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", len(result))\n",
      "/usr/lib/python3/dist-packages/sklearn/metrics/_classification.py:1509: UndefinedMetricWarning: Recall is ill-defined and being set to 0.0 in labels with no true samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", len(result))\n",
      "/usr/lib/python3/dist-packages/sklearn/metrics/_classification.py:1509: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", len(result))\n",
      "/usr/lib/python3/dist-packages/sklearn/metrics/_classification.py:1509: UndefinedMetricWarning: Recall is ill-defined and being set to 0.0 in labels with no true samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", len(result))\n",
      "/home/mojo/.local/lib/python3.12/site-packages/keras/src/layers/core/dense.py:87: UserWarning: Do not pass an `input_shape`/`input_dim` argument to a layer. When using Sequential models, prefer using an `Input(shape)` object as the first layer in the model instead.\n",
      "  super().__init__(activity_regularizer=activity_regularizer, **kwargs)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Confusion matrix saved at: ../Files/confusion_matrix/balanced_acc_wav2vec2/cnn_confusion_matrix_layer_9.png\n",
      "Epoch 1/50\n",
      "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 8ms/step - accuracy: 0.1964 - loss: 3.1574 - val_accuracy: 0.0407 - val_loss: 2.3359\n",
      "Epoch 2/50\n",
      "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - accuracy: 0.3598 - loss: 2.2051 - val_accuracy: 0.0349 - val_loss: 2.4032\n",
      "Epoch 3/50\n",
      "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.3508 - loss: 1.8921 - val_accuracy: 0.0349 - val_loss: 2.3149\n",
      "Epoch 4/50\n",
      "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.3994 - loss: 1.8900 - val_accuracy: 0.0349 - val_loss: 2.3491\n",
      "Epoch 5/50\n",
      "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.4315 - loss: 1.8057 - val_accuracy: 0.0349 - val_loss: 2.3353\n",
      "Epoch 6/50\n",
      "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.4718 - loss: 1.5984 - val_accuracy: 0.0465 - val_loss: 2.3495\n",
      "Epoch 7/50\n",
      "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.4467 - loss: 1.6413 - val_accuracy: 0.0523 - val_loss: 2.2911\n",
      "Epoch 8/50\n",
      "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.4840 - loss: 1.5064 - val_accuracy: 0.0523 - val_loss: 2.2858\n",
      "Epoch 9/50\n",
      "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.4760 - loss: 1.5433 - val_accuracy: 0.0465 - val_loss: 2.3797\n",
      "Epoch 10/50\n",
      "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - accuracy: 0.5151 - loss: 1.4351 - val_accuracy: 0.0756 - val_loss: 2.3419\n",
      "Epoch 11/50\n",
      "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - accuracy: 0.5305 - loss: 1.4373 - val_accuracy: 0.1221 - val_loss: 2.1495\n",
      "Epoch 12/50\n",
      "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - accuracy: 0.5571 - loss: 1.2902 - val_accuracy: 0.1047 - val_loss: 2.4145\n",
      "Epoch 13/50\n",
      "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.5758 - loss: 1.2373 - val_accuracy: 0.1279 - val_loss: 2.2570\n",
      "Epoch 14/50\n",
      "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.6013 - loss: 1.1463 - val_accuracy: 0.1686 - val_loss: 2.0958\n",
      "Epoch 15/50\n",
      "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.6418 - loss: 1.0850 - val_accuracy: 0.1453 - val_loss: 2.3212\n",
      "Epoch 16/50\n",
      "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.6731 - loss: 1.0589 - val_accuracy: 0.1570 - val_loss: 2.2997\n",
      "Epoch 17/50\n",
      "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.6327 - loss: 1.0488 - val_accuracy: 0.1163 - val_loss: 2.5611\n",
      "Epoch 18/50\n",
      "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.7055 - loss: 0.8652 - val_accuracy: 0.1570 - val_loss: 2.4110\n",
      "Epoch 19/50\n",
      "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.7522 - loss: 0.7900 - val_accuracy: 0.1744 - val_loss: 2.6365\n",
      "Epoch 20/50\n",
      "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.7070 - loss: 0.8027 - val_accuracy: 0.1744 - val_loss: 2.7435\n",
      "Epoch 21/50\n",
      "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.7467 - loss: 0.7930 - val_accuracy: 0.1570 - val_loss: 2.4491\n",
      "Epoch 22/50\n",
      "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.7596 - loss: 0.7400 - val_accuracy: 0.1802 - val_loss: 2.7311\n",
      "Epoch 23/50\n",
      "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - accuracy: 0.7447 - loss: 0.7343 - val_accuracy: 0.1453 - val_loss: 2.9327\n",
      "Epoch 24/50\n",
      "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - accuracy: 0.8001 - loss: 0.6246 - val_accuracy: 0.1802 - val_loss: 2.8448\n",
      "Epoch 25/50\n",
      "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.7995 - loss: 0.6419 - val_accuracy: 0.1512 - val_loss: 2.9960\n",
      "Epoch 26/50\n",
      "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.8217 - loss: 0.5550 - val_accuracy: 0.1919 - val_loss: 2.8948\n",
      "Epoch 27/50\n",
      "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.8482 - loss: 0.5285 - val_accuracy: 0.1919 - val_loss: 3.1003\n",
      "Epoch 28/50\n",
      "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.8669 - loss: 0.4292 - val_accuracy: 0.1860 - val_loss: 3.5423\n",
      "Epoch 29/50\n",
      "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.8402 - loss: 0.4606 - val_accuracy: 0.2093 - val_loss: 3.3345\n",
      "Epoch 30/50\n",
      "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - accuracy: 0.8398 - loss: 0.4865 - val_accuracy: 0.1977 - val_loss: 3.2603\n",
      "Epoch 31/50\n",
      "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - accuracy: 0.8650 - loss: 0.4460 - val_accuracy: 0.1628 - val_loss: 3.4102\n",
      "Epoch 32/50\n",
      "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.8616 - loss: 0.4186 - val_accuracy: 0.1919 - val_loss: 3.5031\n",
      "Epoch 33/50\n",
      "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.9075 - loss: 0.3113 - val_accuracy: 0.2093 - val_loss: 3.4797\n",
      "Epoch 34/50\n",
      "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - accuracy: 0.8637 - loss: 0.4146 - val_accuracy: 0.2093 - val_loss: 3.6982\n",
      "Epoch 35/50\n",
      "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.8745 - loss: 0.3818 - val_accuracy: 0.2209 - val_loss: 3.6577\n",
      "Epoch 36/50\n",
      "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.9005 - loss: 0.2971 - val_accuracy: 0.2209 - val_loss: 3.5278\n",
      "Epoch 37/50\n",
      "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.8845 - loss: 0.3687 - val_accuracy: 0.2326 - val_loss: 3.4927\n",
      "Epoch 38/50\n",
      "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.8970 - loss: 0.3592 - val_accuracy: 0.1628 - val_loss: 3.8968\n",
      "Epoch 39/50\n",
      "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.8986 - loss: 0.3551 - val_accuracy: 0.1860 - val_loss: 3.8395\n",
      "Epoch 40/50\n",
      "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.8971 - loss: 0.3151 - val_accuracy: 0.1919 - val_loss: 3.8495\n",
      "Epoch 41/50\n",
      "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.9184 - loss: 0.2970 - val_accuracy: 0.1628 - val_loss: 4.1383\n",
      "Epoch 42/50\n",
      "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - accuracy: 0.9157 - loss: 0.2848 - val_accuracy: 0.1744 - val_loss: 4.8413\n",
      "Epoch 43/50\n",
      "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.8880 - loss: 0.2783 - val_accuracy: 0.2093 - val_loss: 4.3683\n",
      "Epoch 44/50\n",
      "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.9171 - loss: 0.2148 - val_accuracy: 0.1744 - val_loss: 4.8145\n",
      "Epoch 45/50\n",
      "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.9177 - loss: 0.2367 - val_accuracy: 0.1570 - val_loss: 5.0547\n",
      "Epoch 46/50\n",
      "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.9445 - loss: 0.1780 - val_accuracy: 0.1686 - val_loss: 5.0870\n",
      "Epoch 47/50\n",
      "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.9049 - loss: 0.3029 - val_accuracy: 0.1802 - val_loss: 4.9055\n",
      "Epoch 48/50\n",
      "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.9283 - loss: 0.2651 - val_accuracy: 0.1977 - val_loss: 4.5203\n",
      "Epoch 49/50\n",
      "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.9233 - loss: 0.2315 - val_accuracy: 0.2209 - val_loss: 4.4105\n",
      "Epoch 50/50\n",
      "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.9425 - loss: 0.1662 - val_accuracy: 0.1744 - val_loss: 5.2923\n",
      "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 8ms/step \n",
      "ANN Accuracy: 0.4029\n",
      "ANN Classification Report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           1       0.30      0.50      0.38        12\n",
      "           2       0.08      0.12      0.10         8\n",
      "           3       0.76      0.33      0.46        39\n",
      "           4       0.13      0.33      0.19         6\n",
      "           5       0.54      0.62      0.58        42\n",
      "           6       0.56      0.31      0.40        16\n",
      "           7       1.00      0.50      0.67         2\n",
      "           8       0.25      0.50      0.33         2\n",
      "           9       0.00      0.00      0.00         0\n",
      "\n",
      "    accuracy                           0.43       127\n",
      "   macro avg       0.40      0.36      0.35       127\n",
      "weighted avg       0.54      0.43      0.45       127\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/lib/python3/dist-packages/sklearn/metrics/_classification.py:2458: UserWarning: y_pred contains classes not in y_true\n",
      "  warnings.warn(\"y_pred contains classes not in y_true\")\n",
      "/usr/lib/python3/dist-packages/sklearn/metrics/_classification.py:1509: UndefinedMetricWarning: Recall is ill-defined and being set to 0.0 in labels with no true samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", len(result))\n",
      "/usr/lib/python3/dist-packages/sklearn/metrics/_classification.py:1509: UndefinedMetricWarning: Recall is ill-defined and being set to 0.0 in labels with no true samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", len(result))\n",
      "/usr/lib/python3/dist-packages/sklearn/metrics/_classification.py:1509: UndefinedMetricWarning: Recall is ill-defined and being set to 0.0 in labels with no true samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", len(result))\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "from sklearn.preprocessing import LabelEncoder\n",
    "from sklearn.svm import SVC\n",
    "from sklearn.metrics import balanced_accuracy_score, classification_report, confusion_matrix\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "\n",
    "# Load the data\n",
    "train_data = np.load('../Files/extracted_features/layer_features_lv60_self/train_9.npz')\n",
    "test_data = np.load('../Files/extracted_features/layer_features_lv60_self/test_9.npz')\n",
    "\n",
    "train_features = train_data['features']  # Ensure these have 1024 features\n",
    "test_features = test_data['features']    # Ensure these have 1024 features\n",
    "\n",
    "# Read Age labels instead of Gender\n",
    "train_labels = pd.read_csv('../Files/labels/y_train.csv').Age\n",
    "test_labels = pd.read_csv('../Files/labels/y_test.csv').Age\n",
    "\n",
    "# Encode the labels\n",
    "label_encoder = LabelEncoder()\n",
    "train_labels_encoded = label_encoder.fit_transform(train_labels)\n",
    "\n",
    "# Handle unseen labels in test set by filtering out labels not present in train set\n",
    "test_labels_filtered = test_labels[test_labels.isin(train_labels.unique())]\n",
    "test_features_filtered = test_features[test_labels.isin(train_labels.unique())]\n",
    "test_labels_encoded = label_encoder.transform(test_labels_filtered)\n",
    "\n",
    "# Standardize features\n",
    "scaler = StandardScaler()\n",
    "train_features_normalized = scaler.fit_transform(train_features)\n",
    "test_features_normalized = scaler.transform(test_features_filtered)\n",
    "\n",
    "# SVM model\n",
    "svm_model = SVC(kernel='linear', C=10.0, gamma='scale', random_state=42)\n",
    "svm_model.fit(train_features_normalized, train_labels_encoded)\n",
    "\n",
    "# SVM Prediction and Evaluation\n",
    "svm_predictions = svm_model.predict(test_features_normalized)\n",
    "svm_accuracy = balanced_accuracy_score(test_labels_encoded, svm_predictions)\n",
    "print(f\"SVM Accuracy: {svm_accuracy:.4f}\")\n",
    "print(\"SVM Classification Report:\")\n",
    "print(classification_report(test_labels_encoded, svm_predictions))\n",
    "\n",
    "# CNN model (TensorFlow)\n",
    "import tensorflow as tf\n",
    "from tensorflow.keras.models import Sequential\n",
    "from tensorflow.keras.layers import Conv1D, Flatten, Dense, Dropout\n",
    "\n",
    "train_features_cnn = np.expand_dims(train_features_normalized, axis=-1)  # Shape: (num_samples, 1024, 1)\n",
    "test_features_cnn = np.expand_dims(test_features_normalized, axis=-1)    # Shape: (num_samples, 1024, 1)\n",
    "\n",
    "cnn_model = Sequential([\n",
    "    Conv1D(64, kernel_size=5, activation='relu', input_shape=(1024, 1)),  # Updated input shape to 1024\n",
    "    Conv1D(128, kernel_size=5, activation='relu'),\n",
    "    Conv1D(256, kernel_size=5, activation='relu'),\n",
    "    Flatten(),\n",
    "    Dense(256, activation='relu'),\n",
    "    Dropout(0.5),\n",
    "    Dense(len(label_encoder.classes_), activation='softmax')\n",
    "])\n",
    "\n",
    "cnn_model.compile(optimizer='adam', loss='sparse_categorical_crossentropy', metrics=['accuracy'])\n",
    "\n",
    "cnn_model.fit(train_features_cnn, train_labels_encoded, epochs=50, batch_size=32, validation_split=0.2)\n",
    "\n",
    "# CNN Prediction and Evaluation\n",
    "cnn_predictions = np.argmax(cnn_model.predict(test_features_cnn), axis=-1)\n",
    "cnn_accuracy = balanced_accuracy_score(test_labels_encoded, cnn_predictions)\n",
    "print(f\"CNN Accuracy: {cnn_accuracy:.4f}\")\n",
    "print(\"CNN Classification Report:\")\n",
    "print(classification_report(test_labels_encoded, cnn_predictions))\n",
    "\n",
    "# Confusion Matrix\n",
    "cm = confusion_matrix(test_labels_encoded, cnn_predictions)\n",
    "classes = label_encoder.classes_\n",
    "\n",
    "# Create folder for saving confusion matrix\n",
    "output_folder = \"../Files/confusion_matrix/balanced_acc_wav2vec2\"\n",
    "os.makedirs(output_folder, exist_ok=True)\n",
    "\n",
    "# Plot and save confusion matrix\n",
    "plt.figure(figsize=(10, 8))\n",
    "sns.heatmap(cm, annot=True, fmt='d', cmap='Blues', xticklabels=classes, yticklabels=classes)\n",
    "plt.xlabel('Predicted Labels')\n",
    "plt.ylabel('True Labels')\n",
    "plt.title('Confusion Matrix for CNN Model')\n",
    "\n",
    "# Save the confusion matrix\n",
    "confusion_matrix_path = os.path.join(output_folder, \"cnn_confusion_matrix_layer_9.png\")\n",
    "plt.savefig(confusion_matrix_path)\n",
    "plt.close()\n",
    "\n",
    "print(f\"Confusion matrix saved at: {confusion_matrix_path}\")\n",
    "\n",
    "# ANN model (TensorFlow)\n",
    "ann_model = Sequential([\n",
    "    Dense(512, activation='relu', input_shape=(1024,)),  # Updated input shape to 1024\n",
    "    Dropout(0.5),\n",
    "    Dense(256, activation='relu'),\n",
    "    Dropout(0.5),\n",
    "    Dense(128, activation='relu'),\n",
    "    Dropout(0.5),\n",
    "    Dense(len(label_encoder.classes_), activation='softmax')\n",
    "])\n",
    "\n",
    "ann_model.compile(optimizer='adam', loss='sparse_categorical_crossentropy', metrics=['accuracy'])\n",
    "\n",
    "ann_model.fit(train_features_normalized, train_labels_encoded, epochs=50, batch_size=32, validation_split=0.2)\n",
    "\n",
    "# ANN Prediction and Evaluation\n",
    "ann_predictions = np.argmax(ann_model.predict(test_features_normalized), axis=-1)\n",
    "ann_accuracy = balanced_accuracy_score(test_labels_encoded, ann_predictions)\n",
    "print(f\"ANN Accuracy: {ann_accuracy:.4f}\")\n",
    "print(\"ANN Classification Report:\")\n",
    "print(classification_report(test_labels_encoded, ann_predictions))\n",
    "\n",
    "# PyTorch CNN Model\n",
    "import torch\n",
    "from torch.utils.data import DataLoader, TensorDataset\n",
    "\n",
    "X_train_tensor = torch.tensor(train_features_cnn, dtype=torch.float32).permute(0, 2, 1)  # Shape: (num_samples, 1, 1024)\n",
    "y_train_tensor = torch.tensor(train_labels_encoded, dtype=torch.long)\n",
    "X_test_tensor = torch.tensor(test_features_cnn, dtype=torch.float32).permute(0, 2, 1)    # Shape: (num_samples, 1, 1024)\n",
    "y_test_tensor = torch.tensor(test_labels_encoded, dtype=torch.long)\n",
    "\n",
    "train_dataset = TensorDataset(X_train_tensor, y_train_tensor)\n",
    "test_dataset = TensorDataset(X_test_tensor, y_test_tensor)\n",
    "\n",
    "train_loader = DataLoader(train_dataset, batch_size=64, shuffle=True)\n",
    "test_loader = DataLoader(test_dataset, batch_size=64, shuffle=False)\n",
    "\n",
    "import torch.nn as nn\n",
    "import torch.optim as optim\n",
    "\n",
    "class CNN1DModel(nn.Module):\n",
    "    def __init__(self, input_channels, num_classes):\n",
    "        super(CNN1DModel, self).__init__()\n",
    "        self.conv1 = nn.Conv1d(input_channels, 32, kernel_size=5, stride=1, padding=2)\n",
    "        self.bn1 = nn.BatchNorm1d(32)\n",
    "        self.relu = nn.ReLU()\n",
    "        self.conv2 = nn.Conv1d(32, 64, kernel_size=5, stride=1, padding=2)\n",
    "        self.bn2 = nn.BatchNorm1d(64)\n",
    "        self.conv3 = nn.Conv1d(64, 128, kernel_size=5, stride=1, padding=2)\n",
    "        self.bn3 = nn.BatchNorm1d(128)\n",
    "        self.flatten = nn.Flatten()\n",
    "        self.fc1 = nn.Linear(128 * 1024, 512)  # Updated to 1024 features\n",
    "        self.fc2 = nn.Linear(512, num_classes)\n",
    "        self.dropout = nn.Dropout(0.5)\n",
    "    \n",
    "    def forward(self, x):\n",
    "        x = self.relu(self.bn1(self.conv1(x)))\n",
    "        x = self.relu(self.bn2(self.conv2(x)))\n",
    "        x = self.relu(self.bn3(self.conv3(x)))\n",
    "        x = self.flatten(x)\n",
    "        x = self.dropout(self.relu(self.fc1(x)))\n",
    "        x = self.fc2(x)\n",
    "        return x\n",
    "\n",
    "input_channels = 1\n",
    "num_classes = len(label_encoder.classes_)\n",
    "model = CNN1DModel(input_channels, num_classes)\n",
    "criterion = nn.CrossEntropyLoss()\n",
    "optimizer = optim.Adam(model.parameters(), lr=0.001)\n",
    "\n",
    "# Training loop and evaluation (not shown)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "SVM Accuracy: 0.7199\n",
      "SVM Classification Report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.85      0.76      0.80        62\n",
      "           1       0.67      0.57      0.62        14\n",
      "           2       0.71      0.83      0.77        53\n",
      "\n",
      "    accuracy                           0.77       129\n",
      "   macro avg       0.74      0.72      0.73       129\n",
      "weighted avg       0.77      0.77      0.77       129\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/mojo/.local/lib/python3.12/site-packages/keras/src/layers/convolutional/base_conv.py:107: UserWarning: Do not pass an `input_shape`/`input_dim` argument to a layer. When using Sequential models, prefer using an `Input(shape)` object as the first layer in the model instead.\n",
      "  super().__init__(activity_regularizer=activity_regularizer, **kwargs)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/50\n",
      "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m12s\u001b[0m 503ms/step - accuracy: 0.5689 - loss: 3.6927 - val_accuracy: 0.6105 - val_loss: 0.8763\n",
      "Epoch 2/50\n",
      "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m11s\u001b[0m 515ms/step - accuracy: 0.7590 - loss: 0.5869 - val_accuracy: 0.4535 - val_loss: 1.0587\n",
      "Epoch 3/50\n",
      "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m11s\u001b[0m 507ms/step - accuracy: 0.8403 - loss: 0.4187 - val_accuracy: 0.5174 - val_loss: 1.0753\n",
      "Epoch 4/50\n",
      "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m11s\u001b[0m 507ms/step - accuracy: 0.8894 - loss: 0.2715 - val_accuracy: 0.6221 - val_loss: 0.8370\n",
      "Epoch 5/50\n",
      "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m11s\u001b[0m 507ms/step - accuracy: 0.9613 - loss: 0.1341 - val_accuracy: 0.4419 - val_loss: 1.6828\n",
      "Epoch 6/50\n",
      "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m11s\u001b[0m 509ms/step - accuracy: 0.9860 - loss: 0.0767 - val_accuracy: 0.6105 - val_loss: 1.3180\n",
      "Epoch 7/50\n",
      "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m11s\u001b[0m 505ms/step - accuracy: 0.9788 - loss: 0.0453 - val_accuracy: 0.5640 - val_loss: 1.3363\n",
      "Epoch 8/50\n",
      "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m11s\u001b[0m 505ms/step - accuracy: 0.9939 - loss: 0.0419 - val_accuracy: 0.5872 - val_loss: 1.4646\n",
      "Epoch 9/50\n",
      "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m11s\u001b[0m 501ms/step - accuracy: 0.9825 - loss: 0.0416 - val_accuracy: 0.6163 - val_loss: 1.2409\n",
      "Epoch 10/50\n",
      "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m11s\u001b[0m 496ms/step - accuracy: 0.9941 - loss: 0.0284 - val_accuracy: 0.5581 - val_loss: 2.0379\n",
      "Epoch 11/50\n",
      "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m11s\u001b[0m 491ms/step - accuracy: 0.9976 - loss: 0.0101 - val_accuracy: 0.4709 - val_loss: 2.7244\n",
      "Epoch 12/50\n",
      "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m11s\u001b[0m 493ms/step - accuracy: 0.9842 - loss: 0.0483 - val_accuracy: 0.5291 - val_loss: 1.2571\n",
      "Epoch 13/50\n",
      "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m11s\u001b[0m 494ms/step - accuracy: 0.9990 - loss: 0.0146 - val_accuracy: 0.5116 - val_loss: 2.5160\n",
      "Epoch 14/50\n",
      "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m11s\u001b[0m 482ms/step - accuracy: 0.9939 - loss: 0.0128 - val_accuracy: 0.5814 - val_loss: 1.5928\n",
      "Epoch 15/50\n",
      "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m11s\u001b[0m 481ms/step - accuracy: 0.9971 - loss: 0.0137 - val_accuracy: 0.5000 - val_loss: 2.4432\n",
      "Epoch 16/50\n",
      "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m11s\u001b[0m 482ms/step - accuracy: 0.9962 - loss: 0.0094 - val_accuracy: 0.5349 - val_loss: 2.0770\n",
      "Epoch 17/50\n",
      "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m11s\u001b[0m 485ms/step - accuracy: 0.9957 - loss: 0.0236 - val_accuracy: 0.5640 - val_loss: 1.6447\n",
      "Epoch 18/50\n",
      "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m11s\u001b[0m 479ms/step - accuracy: 0.9960 - loss: 0.0110 - val_accuracy: 0.5349 - val_loss: 2.0667\n",
      "Epoch 19/50\n",
      "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m11s\u001b[0m 486ms/step - accuracy: 0.9974 - loss: 0.0243 - val_accuracy: 0.4884 - val_loss: 1.9002\n",
      "Epoch 20/50\n",
      "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m11s\u001b[0m 485ms/step - accuracy: 0.9993 - loss: 0.0060 - val_accuracy: 0.6047 - val_loss: 1.5672\n",
      "Epoch 21/50\n",
      "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m11s\u001b[0m 480ms/step - accuracy: 0.9973 - loss: 0.0152 - val_accuracy: 0.5756 - val_loss: 1.8582\n",
      "Epoch 22/50\n",
      "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m11s\u001b[0m 482ms/step - accuracy: 0.9980 - loss: 0.0067 - val_accuracy: 0.5756 - val_loss: 1.9651\n",
      "Epoch 23/50\n",
      "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m11s\u001b[0m 481ms/step - accuracy: 0.9980 - loss: 0.0037 - val_accuracy: 0.5581 - val_loss: 2.0555\n",
      "Epoch 24/50\n",
      "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m11s\u001b[0m 481ms/step - accuracy: 0.9990 - loss: 0.0038 - val_accuracy: 0.5872 - val_loss: 1.9543\n",
      "Epoch 25/50\n",
      "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m11s\u001b[0m 492ms/step - accuracy: 1.0000 - loss: 0.0013 - val_accuracy: 0.5872 - val_loss: 2.0342\n",
      "Epoch 26/50\n",
      "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m11s\u001b[0m 506ms/step - accuracy: 1.0000 - loss: 0.0010 - val_accuracy: 0.5872 - val_loss: 2.2044\n",
      "Epoch 27/50\n",
      "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m11s\u001b[0m 499ms/step - accuracy: 1.0000 - loss: 7.1457e-04 - val_accuracy: 0.5930 - val_loss: 2.3735\n",
      "Epoch 28/50\n",
      "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m11s\u001b[0m 490ms/step - accuracy: 0.9991 - loss: 0.0021 - val_accuracy: 0.5756 - val_loss: 2.1999\n",
      "Epoch 29/50\n",
      "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m11s\u001b[0m 495ms/step - accuracy: 1.0000 - loss: 0.0022 - val_accuracy: 0.6395 - val_loss: 1.7933\n",
      "Epoch 30/50\n",
      "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m11s\u001b[0m 497ms/step - accuracy: 0.9993 - loss: 0.0027 - val_accuracy: 0.5698 - val_loss: 2.2191\n",
      "Epoch 31/50\n",
      "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m11s\u001b[0m 492ms/step - accuracy: 1.0000 - loss: 0.0015 - val_accuracy: 0.5465 - val_loss: 2.6292\n",
      "Epoch 32/50\n",
      "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m11s\u001b[0m 499ms/step - accuracy: 1.0000 - loss: 0.0011 - val_accuracy: 0.5640 - val_loss: 2.4255\n",
      "Epoch 33/50\n",
      "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m11s\u001b[0m 496ms/step - accuracy: 1.0000 - loss: 4.7178e-04 - val_accuracy: 0.5465 - val_loss: 2.8104\n",
      "Epoch 34/50\n",
      "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m11s\u001b[0m 506ms/step - accuracy: 1.0000 - loss: 4.5097e-04 - val_accuracy: 0.5233 - val_loss: 3.2360\n",
      "Epoch 35/50\n",
      "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m11s\u001b[0m 511ms/step - accuracy: 0.9993 - loss: 0.0047 - val_accuracy: 0.4826 - val_loss: 3.4345\n",
      "Epoch 36/50\n",
      "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m12s\u001b[0m 527ms/step - accuracy: 1.0000 - loss: 0.0040 - val_accuracy: 0.6977 - val_loss: 1.2552\n",
      "Epoch 37/50\n",
      "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m11s\u001b[0m 506ms/step - accuracy: 0.9997 - loss: 0.0012 - val_accuracy: 0.5930 - val_loss: 2.4075\n",
      "Epoch 38/50\n",
      "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m11s\u001b[0m 511ms/step - accuracy: 0.9940 - loss: 0.0128 - val_accuracy: 0.5988 - val_loss: 1.6556\n",
      "Epoch 39/50\n",
      "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m11s\u001b[0m 503ms/step - accuracy: 1.0000 - loss: 0.0021 - val_accuracy: 0.5872 - val_loss: 2.4607\n",
      "Epoch 40/50\n",
      "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m11s\u001b[0m 506ms/step - accuracy: 0.9995 - loss: 0.0014 - val_accuracy: 0.6105 - val_loss: 2.1768\n",
      "Epoch 41/50\n",
      "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m11s\u001b[0m 509ms/step - accuracy: 1.0000 - loss: 0.0017 - val_accuracy: 0.5058 - val_loss: 3.0018\n",
      "Epoch 42/50\n",
      "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m11s\u001b[0m 515ms/step - accuracy: 1.0000 - loss: 0.0014 - val_accuracy: 0.5407 - val_loss: 3.0016\n",
      "Epoch 43/50\n",
      "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m11s\u001b[0m 515ms/step - accuracy: 1.0000 - loss: 2.3939e-04 - val_accuracy: 0.6105 - val_loss: 2.3188\n",
      "Epoch 44/50\n",
      "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m11s\u001b[0m 505ms/step - accuracy: 0.9998 - loss: 0.0016 - val_accuracy: 0.6163 - val_loss: 2.2128\n",
      "Epoch 45/50\n",
      "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m11s\u001b[0m 512ms/step - accuracy: 0.9992 - loss: 0.0031 - val_accuracy: 0.5814 - val_loss: 2.4315\n",
      "Epoch 46/50\n",
      "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m11s\u001b[0m 511ms/step - accuracy: 1.0000 - loss: 0.0012 - val_accuracy: 0.5581 - val_loss: 3.0138\n",
      "Epoch 47/50\n",
      "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m11s\u001b[0m 517ms/step - accuracy: 1.0000 - loss: 0.0011 - val_accuracy: 0.5523 - val_loss: 3.0971\n",
      "Epoch 48/50\n",
      "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m11s\u001b[0m 507ms/step - accuracy: 0.9982 - loss: 0.0037 - val_accuracy: 0.5407 - val_loss: 3.2144\n",
      "Epoch 49/50\n",
      "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m11s\u001b[0m 512ms/step - accuracy: 0.9993 - loss: 0.0020 - val_accuracy: 0.5465 - val_loss: 2.5636\n",
      "Epoch 50/50\n",
      "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m11s\u001b[0m 521ms/step - accuracy: 0.9967 - loss: 0.0085 - val_accuracy: 0.5988 - val_loss: 2.2096\n",
      "\u001b[1m5/5\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 49ms/step\n",
      "CNN Accuracy: 0.6825\n",
      "CNN Classification Report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.79      0.89      0.83        62\n",
      "           1       0.50      0.50      0.50        14\n",
      "           2       0.78      0.66      0.71        53\n",
      "\n",
      "    accuracy                           0.75       129\n",
      "   macro avg       0.69      0.68      0.68       129\n",
      "weighted avg       0.75      0.75      0.75       129\n",
      "\n",
      "Epoch 1/50\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/mojo/.local/lib/python3.12/site-packages/keras/src/layers/core/dense.py:87: UserWarning: Do not pass an `input_shape`/`input_dim` argument to a layer. When using Sequential models, prefer using an `Input(shape)` object as the first layer in the model instead.\n",
      "  super().__init__(activity_regularizer=activity_regularizer, **kwargs)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 9ms/step - accuracy: 0.4964 - loss: 1.7184 - val_accuracy: 0.7093 - val_loss: 0.6020\n",
      "Epoch 2/50\n",
      "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - accuracy: 0.5873 - loss: 1.2132 - val_accuracy: 0.5465 - val_loss: 0.9705\n",
      "Epoch 3/50\n",
      "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - accuracy: 0.6080 - loss: 1.0647 - val_accuracy: 0.6279 - val_loss: 0.8344\n",
      "Epoch 4/50\n",
      "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - accuracy: 0.7198 - loss: 0.6969 - val_accuracy: 0.6628 - val_loss: 0.8125\n",
      "Epoch 5/50\n",
      "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - accuracy: 0.7111 - loss: 0.7702 - val_accuracy: 0.5930 - val_loss: 0.8665\n",
      "Epoch 6/50\n",
      "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - accuracy: 0.7259 - loss: 0.6767 - val_accuracy: 0.5465 - val_loss: 0.9573\n",
      "Epoch 7/50\n",
      "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.7279 - loss: 0.6745 - val_accuracy: 0.5581 - val_loss: 0.9035\n",
      "Epoch 8/50\n",
      "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.7419 - loss: 0.6101 - val_accuracy: 0.5174 - val_loss: 0.9712\n",
      "Epoch 9/50\n",
      "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.7968 - loss: 0.5472 - val_accuracy: 0.6163 - val_loss: 0.7944\n",
      "Epoch 10/50\n",
      "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.7869 - loss: 0.5256 - val_accuracy: 0.5349 - val_loss: 0.9292\n",
      "Epoch 11/50\n",
      "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - accuracy: 0.7837 - loss: 0.5005 - val_accuracy: 0.5174 - val_loss: 0.9929\n",
      "Epoch 12/50\n",
      "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - accuracy: 0.7960 - loss: 0.5078 - val_accuracy: 0.5349 - val_loss: 0.9693\n",
      "Epoch 13/50\n",
      "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - accuracy: 0.8542 - loss: 0.3961 - val_accuracy: 0.5349 - val_loss: 1.0111\n",
      "Epoch 14/50\n",
      "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - accuracy: 0.8561 - loss: 0.3794 - val_accuracy: 0.4826 - val_loss: 1.1399\n",
      "Epoch 15/50\n",
      "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - accuracy: 0.8428 - loss: 0.4001 - val_accuracy: 0.5349 - val_loss: 1.0408\n",
      "Epoch 16/50\n",
      "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - accuracy: 0.8768 - loss: 0.2975 - val_accuracy: 0.5233 - val_loss: 1.0499\n",
      "Epoch 17/50\n",
      "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.8819 - loss: 0.3181 - val_accuracy: 0.6047 - val_loss: 0.9280\n",
      "Epoch 18/50\n",
      "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - accuracy: 0.8618 - loss: 0.3773 - val_accuracy: 0.5174 - val_loss: 1.1619\n",
      "Epoch 19/50\n",
      "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - accuracy: 0.8757 - loss: 0.3120 - val_accuracy: 0.5814 - val_loss: 0.8710\n",
      "Epoch 20/50\n",
      "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - accuracy: 0.9000 - loss: 0.2661 - val_accuracy: 0.5523 - val_loss: 1.1070\n",
      "Epoch 21/50\n",
      "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.8873 - loss: 0.2963 - val_accuracy: 0.5174 - val_loss: 1.3005\n",
      "Epoch 22/50\n",
      "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - accuracy: 0.9042 - loss: 0.2648 - val_accuracy: 0.5523 - val_loss: 1.2109\n",
      "Epoch 23/50\n",
      "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - accuracy: 0.9056 - loss: 0.2443 - val_accuracy: 0.4884 - val_loss: 1.4537\n",
      "Epoch 24/50\n",
      "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - accuracy: 0.8884 - loss: 0.2623 - val_accuracy: 0.5465 - val_loss: 1.3137\n",
      "Epoch 25/50\n",
      "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.9186 - loss: 0.2542 - val_accuracy: 0.5523 - val_loss: 1.3057\n",
      "Epoch 26/50\n",
      "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - accuracy: 0.9277 - loss: 0.1980 - val_accuracy: 0.6221 - val_loss: 1.3079\n",
      "Epoch 27/50\n",
      "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.9346 - loss: 0.2088 - val_accuracy: 0.5349 - val_loss: 1.6619\n",
      "Epoch 28/50\n",
      "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.9369 - loss: 0.1793 - val_accuracy: 0.5581 - val_loss: 1.5381\n",
      "Epoch 29/50\n",
      "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - accuracy: 0.9316 - loss: 0.1554 - val_accuracy: 0.5814 - val_loss: 1.4522\n",
      "Epoch 30/50\n",
      "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.9513 - loss: 0.1467 - val_accuracy: 0.5814 - val_loss: 1.4269\n",
      "Epoch 31/50\n",
      "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - accuracy: 0.9408 - loss: 0.1905 - val_accuracy: 0.5523 - val_loss: 1.5465\n",
      "Epoch 32/50\n",
      "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - accuracy: 0.9447 - loss: 0.1869 - val_accuracy: 0.5756 - val_loss: 1.3785\n",
      "Epoch 33/50\n",
      "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - accuracy: 0.9556 - loss: 0.1495 - val_accuracy: 0.4942 - val_loss: 1.9325\n",
      "Epoch 34/50\n",
      "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - accuracy: 0.9248 - loss: 0.2336 - val_accuracy: 0.5058 - val_loss: 1.7002\n",
      "Epoch 35/50\n",
      "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.9620 - loss: 0.1097 - val_accuracy: 0.5640 - val_loss: 2.0562\n",
      "Epoch 36/50\n",
      "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.9478 - loss: 0.1511 - val_accuracy: 0.5349 - val_loss: 1.8554\n",
      "Epoch 37/50\n",
      "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - accuracy: 0.9494 - loss: 0.1771 - val_accuracy: 0.5523 - val_loss: 1.5152\n",
      "Epoch 38/50\n",
      "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.9425 - loss: 0.1921 - val_accuracy: 0.4767 - val_loss: 1.9193\n",
      "Epoch 39/50\n",
      "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.9606 - loss: 0.1281 - val_accuracy: 0.5698 - val_loss: 1.5816\n",
      "Epoch 40/50\n",
      "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.9484 - loss: 0.1507 - val_accuracy: 0.5116 - val_loss: 1.7136\n",
      "Epoch 41/50\n",
      "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.9460 - loss: 0.1284 - val_accuracy: 0.5233 - val_loss: 2.1630\n",
      "Epoch 42/50\n",
      "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - accuracy: 0.9494 - loss: 0.1248 - val_accuracy: 0.5814 - val_loss: 1.6167\n",
      "Epoch 43/50\n",
      "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - accuracy: 0.9532 - loss: 0.1245 - val_accuracy: 0.5640 - val_loss: 1.6406\n",
      "Epoch 44/50\n",
      "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.9470 - loss: 0.1434 - val_accuracy: 0.5349 - val_loss: 1.9048\n",
      "Epoch 45/50\n",
      "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.9676 - loss: 0.1106 - val_accuracy: 0.6105 - val_loss: 1.6700\n",
      "Epoch 46/50\n",
      "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - accuracy: 0.9552 - loss: 0.1121 - val_accuracy: 0.4942 - val_loss: 2.3152\n",
      "Epoch 47/50\n",
      "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - accuracy: 0.9572 - loss: 0.1306 - val_accuracy: 0.4826 - val_loss: 2.1802\n",
      "Epoch 48/50\n",
      "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - accuracy: 0.9545 - loss: 0.1123 - val_accuracy: 0.5523 - val_loss: 1.7189\n",
      "Epoch 49/50\n",
      "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - accuracy: 0.9511 - loss: 0.1269 - val_accuracy: 0.5523 - val_loss: 1.8209\n",
      "Epoch 50/50\n",
      "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.9547 - loss: 0.1315 - val_accuracy: 0.6047 - val_loss: 1.6724\n",
      "\u001b[1m5/5\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step \n",
      "ANN Accuracy: 0.6565\n",
      "ANN Classification Report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.82      0.79      0.80        62\n",
      "           1       0.47      0.50      0.48        14\n",
      "           2       0.67      0.68      0.67        53\n",
      "\n",
      "    accuracy                           0.71       129\n",
      "   macro avg       0.65      0.66      0.65       129\n",
      "weighted avg       0.72      0.71      0.71       129\n",
      "\n"
     ]
    },
    {
     "ename": "",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31mThe Kernel crashed while executing code in the current cell or a previous cell. \n",
      "\u001b[1;31mPlease review the code in the cell(s) to identify a possible cause of the failure. \n",
      "\u001b[1;31mClick <a href='https://aka.ms/vscodeJupyterKernelCrash'>here</a> for more info. \n",
      "\u001b[1;31mView Jupyter <a href='command:jupyter.viewOutput'>log</a> for further details."
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "from sklearn.preprocessing import LabelEncoder\n",
    "from sklearn.svm import SVC\n",
    "from sklearn.metrics import balanced_accuracy_score, classification_report\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "\n",
    "# Load the data\n",
    "train_data = np.load('../Files/extracted_features/layer_features_lv60_self/train_0.npz')\n",
    "test_data = np.load('../Files/extracted_features/layer_features_lv60_self/test_0.npz')\n",
    "\n",
    "train_features = train_data['features']  # Ensure these have 1024 features\n",
    "test_features = test_data['features']    # Ensure these have 1024 features\n",
    "\n",
    "# Read Age labels instead of Gender\n",
    "train_labels = pd.read_csv('../Files/labels/y_train.csv').Age_Group\n",
    "test_labels = pd.read_csv('../Files/labels/y_test.csv').Age_Group\n",
    "\n",
    "# Encode the labels\n",
    "label_encoder = LabelEncoder()\n",
    "train_labels_encoded = label_encoder.fit_transform(train_labels)\n",
    "\n",
    "# Handle unseen labels in test set by filtering out labels not present in train set\n",
    "test_labels_filtered = test_labels[test_labels.isin(train_labels.unique())]\n",
    "test_features_filtered = test_features[test_labels.isin(train_labels.unique())]\n",
    "test_labels_encoded = label_encoder.transform(test_labels_filtered)\n",
    "\n",
    "# Standardize features\n",
    "scaler = StandardScaler()\n",
    "train_features_normalized = scaler.fit_transform(train_features)\n",
    "test_features_normalized = scaler.transform(test_features_filtered)\n",
    "\n",
    "# SVM model\n",
    "svm_model = SVC(kernel='linear', C=10.0, gamma='scale', random_state=42)\n",
    "svm_model.fit(train_features_normalized, train_labels_encoded)\n",
    "\n",
    "# SVM Prediction and Evaluation\n",
    "svm_predictions = svm_model.predict(test_features_normalized)\n",
    "svm_accuracy = balanced_accuracy_score(test_labels_encoded, svm_predictions)\n",
    "print(f\"SVM Accuracy: {svm_accuracy:.4f}\")\n",
    "print(\"SVM Classification Report:\")\n",
    "print(classification_report(test_labels_encoded, svm_predictions))\n",
    "\n",
    "# CNN model (TensorFlow)\n",
    "import tensorflow as tf\n",
    "from tensorflow.keras.models import Sequential\n",
    "from tensorflow.keras.layers import Conv1D, Flatten, Dense, Dropout\n",
    "\n",
    "train_features_cnn = np.expand_dims(train_features_normalized, axis=-1)  # Shape: (num_samples, 1024, 1)\n",
    "test_features_cnn = np.expand_dims(test_features_normalized, axis=-1)    # Shape: (num_samples, 1024, 1)\n",
    "\n",
    "cnn_model = Sequential([\n",
    "    Conv1D(64, kernel_size=5, activation='relu', input_shape=(1024, 1)),  # Updated input shape to 1024\n",
    "    Conv1D(128, kernel_size=5, activation='relu'),\n",
    "    Conv1D(256, kernel_size=5, activation='relu'),\n",
    "    Flatten(),\n",
    "    Dense(256, activation='relu'),\n",
    "    Dropout(0.5),\n",
    "    Dense(len(label_encoder.classes_), activation='softmax')\n",
    "])\n",
    "\n",
    "cnn_model.compile(optimizer='adam', loss='sparse_categorical_crossentropy', metrics=['accuracy'])\n",
    "\n",
    "cnn_model.fit(train_features_cnn, train_labels_encoded, epochs=50, batch_size=32, validation_split=0.2)\n",
    "\n",
    "# CNN Prediction and Evaluation\n",
    "cnn_predictions = np.argmax(cnn_model.predict(test_features_cnn), axis=-1)\n",
    "cnn_accuracy = balanced_accuracy_score(test_labels_encoded, cnn_predictions)\n",
    "print(f\"CNN Accuracy: {cnn_accuracy:.4f}\")\n",
    "print(\"CNN Classification Report:\")\n",
    "print(classification_report(test_labels_encoded, cnn_predictions))\n",
    "\n",
    "# ANN model (TensorFlow)\n",
    "ann_model = Sequential([\n",
    "    Dense(512, activation='relu', input_shape=(1024,)),  # Updated input shape to 1024\n",
    "    Dropout(0.5),\n",
    "    Dense(256, activation='relu'),\n",
    "    Dropout(0.5),\n",
    "    Dense(128, activation='relu'),\n",
    "    Dropout(0.5),\n",
    "    Dense(len(label_encoder.classes_), activation='softmax')\n",
    "])\n",
    "\n",
    "ann_model.compile(optimizer='adam', loss='sparse_categorical_crossentropy', metrics=['accuracy'])\n",
    "\n",
    "ann_model.fit(train_features_normalized, train_labels_encoded, epochs=50, batch_size=32, validation_split=0.2)\n",
    "\n",
    "# ANN Prediction and Evaluation\n",
    "ann_predictions = np.argmax(ann_model.predict(test_features_normalized), axis=-1)\n",
    "ann_accuracy = balanced_accuracy_score(test_labels_encoded, ann_predictions)\n",
    "print(f\"ANN Accuracy: {ann_accuracy:.4f}\")\n",
    "print(\"ANN Classification Report:\")\n",
    "print(classification_report(test_labels_encoded, ann_predictions))\n",
    "\n",
    "# PyTorch CNN Model\n",
    "import torch\n",
    "from torch.utils.data import DataLoader, TensorDataset\n",
    "\n",
    "X_train_tensor = torch.tensor(train_features_cnn, dtype=torch.float32).permute(0, 2, 1)  # Shape: (num_samples, 1, 1024)\n",
    "y_train_tensor = torch.tensor(train_labels_encoded, dtype=torch.long)\n",
    "X_test_tensor = torch.tensor(test_features_cnn, dtype=torch.float32).permute(0, 2, 1)    # Shape: (num_samples, 1, 1024)\n",
    "y_test_tensor = torch.tensor(test_labels_encoded, dtype=torch.long)\n",
    "\n",
    "train_dataset = TensorDataset(X_train_tensor, y_train_tensor)\n",
    "test_dataset = TensorDataset(X_test_tensor, y_test_tensor)\n",
    "\n",
    "train_loader = DataLoader(train_dataset, batch_size=64, shuffle=True)\n",
    "test_loader = DataLoader(test_dataset, batch_size=64, shuffle=False)\n",
    "\n",
    "import torch.nn as nn\n",
    "import torch.optim as optim\n",
    "\n",
    "class CNN1DModel(nn.Module):\n",
    "    def __init__(self, input_channels, num_classes):\n",
    "        super(CNN1DModel, self).__init__()\n",
    "        self.conv1 = nn.Conv1d(input_channels, 32, kernel_size=5, stride=1, padding=2)\n",
    "        self.bn1 = nn.BatchNorm1d(32)\n",
    "        self.relu = nn.ReLU()\n",
    "        self.conv2 = nn.Conv1d(32, 64, kernel_size=5, stride=1, padding=2)\n",
    "        self.bn2 = nn.BatchNorm1d(64)\n",
    "        self.conv3 = nn.Conv1d(64, 128, kernel_size=5, stride=1, padding=2)\n",
    "        self.bn3 = nn.BatchNorm1d(128)\n",
    "        self.flatten = nn.Flatten()\n",
    "        self.fc1 = nn.Linear(128 * 1024, 512)  # Updated to 1024 features\n",
    "        self.fc2 = nn.Linear(512, num_classes)\n",
    "        self.dropout = nn.Dropout(0.5)\n",
    "    \n",
    "    def forward(self, x):\n",
    "        x = self.relu(self.bn1(self.conv1(x)))\n",
    "        x = self.relu(self.bn2(self.conv2(x)))\n",
    "        x = self.relu(self.bn3(self.conv3(x)))\n",
    "        x = self.flatten(x)\n",
    "        x = self.dropout(self.relu(self.fc1(x)))\n",
    "        x = self.fc2(x)\n",
    "        return x\n",
    "\n",
    "input_channels = 1\n",
    "num_classes = len(label_encoder.classes_)\n",
    "model = CNN1DModel(input_channels, num_classes)\n",
    "criterion = nn.CrossEntropyLoss()\n",
    "optimizer = optim.Adam(model.parameters(), lr=0.001)\n",
    "\n",
    "# Training loop and evaluation (not shown)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "SVM Accuracy: 0.9080\n",
      "SVM Classification Report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.96      0.87      0.92        62\n",
      "           1       0.81      0.93      0.87        14\n",
      "           2       0.86      0.92      0.89        53\n",
      "\n",
      "    accuracy                           0.90       129\n",
      "   macro avg       0.88      0.91      0.89       129\n",
      "weighted avg       0.90      0.90      0.90       129\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2024-12-11 16:01:17.546098: E external/local_xla/xla/stream_executor/cuda/cuda_fft.cc:485] Unable to register cuFFT factory: Attempting to register factory for plugin cuFFT when one has already been registered\n",
      "2024-12-11 16:01:17.595990: E external/local_xla/xla/stream_executor/cuda/cuda_dnn.cc:8454] Unable to register cuDNN factory: Attempting to register factory for plugin cuDNN when one has already been registered\n",
      "2024-12-11 16:01:17.610997: E external/local_xla/xla/stream_executor/cuda/cuda_blas.cc:1452] Unable to register cuBLAS factory: Attempting to register factory for plugin cuBLAS when one has already been registered\n",
      "2024-12-11 16:01:17.711038: I tensorflow/core/platform/cpu_feature_guard.cc:210] This TensorFlow binary is optimized to use available CPU instructions in performance-critical operations.\n",
      "To enable the following instructions: AVX2 FMA, in other operations, rebuild TensorFlow with the appropriate compiler flags.\n",
      "2024-12-11 16:01:18.751442: W tensorflow/compiler/tf2tensorrt/utils/py_utils.cc:38] TF-TRT Warning: Could not find TensorRT\n",
      "/home/mojo/.local/lib/python3.12/site-packages/keras/src/layers/convolutional/base_conv.py:107: UserWarning: Do not pass an `input_shape`/`input_dim` argument to a layer. When using Sequential models, prefer using an `Input(shape)` object as the first layer in the model instead.\n",
      "  super().__init__(activity_regularizer=activity_regularizer, **kwargs)\n",
      "WARNING: All log messages before absl::InitializeLog() is called are written to STDERR\n",
      "I0000 00:00:1733913079.817547  124089 cuda_executor.cc:1015] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero. See more at https://github.com/torvalds/linux/blob/v6.0/Documentation/ABI/testing/sysfs-bus-pci#L344-L355\n",
      "2024-12-11 16:01:19.959155: W tensorflow/core/common_runtime/gpu/gpu_device.cc:2343] Cannot dlopen some GPU libraries. Please make sure the missing libraries mentioned above are installed properly if you would like to use GPU. Follow the guide at https://www.tensorflow.org/install/gpu for how to download and setup the required libraries for your platform.\n",
      "Skipping registering GPU devices...\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/50\n",
      "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m12s\u001b[0m 479ms/step - accuracy: 0.5873 - loss: 3.4197 - val_accuracy: 0.4709 - val_loss: 0.9372\n",
      "Epoch 2/50\n",
      "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m10s\u001b[0m 471ms/step - accuracy: 0.9039 - loss: 0.2833 - val_accuracy: 0.6105 - val_loss: 1.0422\n",
      "Epoch 3/50\n",
      "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m10s\u001b[0m 472ms/step - accuracy: 0.9720 - loss: 0.0928 - val_accuracy: 0.7209 - val_loss: 0.8996\n",
      "Epoch 4/50\n",
      "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m10s\u001b[0m 476ms/step - accuracy: 0.9934 - loss: 0.0257 - val_accuracy: 0.8023 - val_loss: 0.6168\n",
      "Epoch 5/50\n",
      "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m10s\u001b[0m 476ms/step - accuracy: 0.9972 - loss: 0.0122 - val_accuracy: 0.6163 - val_loss: 1.7603\n",
      "Epoch 6/50\n",
      "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m11s\u001b[0m 479ms/step - accuracy: 0.9991 - loss: 0.0077 - val_accuracy: 0.8198 - val_loss: 0.6447\n",
      "Epoch 7/50\n",
      "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m10s\u001b[0m 476ms/step - accuracy: 0.9929 - loss: 0.0116 - val_accuracy: 0.7558 - val_loss: 1.0651\n",
      "Epoch 8/50\n",
      "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m11s\u001b[0m 478ms/step - accuracy: 0.9969 - loss: 0.0173 - val_accuracy: 0.7733 - val_loss: 0.8165\n",
      "Epoch 9/50\n",
      "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m11s\u001b[0m 484ms/step - accuracy: 1.0000 - loss: 0.0028 - val_accuracy: 0.7674 - val_loss: 0.8892\n",
      "Epoch 10/50\n",
      "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m11s\u001b[0m 494ms/step - accuracy: 0.9988 - loss: 0.0036 - val_accuracy: 0.7849 - val_loss: 0.7083\n",
      "Epoch 11/50\n",
      "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m11s\u001b[0m 494ms/step - accuracy: 0.9982 - loss: 0.0148 - val_accuracy: 0.7791 - val_loss: 0.7237\n",
      "Epoch 12/50\n",
      "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m11s\u001b[0m 481ms/step - accuracy: 1.0000 - loss: 0.0024 - val_accuracy: 0.7616 - val_loss: 0.9923\n",
      "Epoch 13/50\n",
      "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m11s\u001b[0m 483ms/step - accuracy: 1.0000 - loss: 5.2123e-04 - val_accuracy: 0.7616 - val_loss: 1.0782\n",
      "Epoch 14/50\n",
      "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m11s\u001b[0m 482ms/step - accuracy: 1.0000 - loss: 6.0805e-04 - val_accuracy: 0.7558 - val_loss: 1.4129\n",
      "Epoch 15/50\n",
      "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m11s\u001b[0m 485ms/step - accuracy: 1.0000 - loss: 2.1140e-04 - val_accuracy: 0.7674 - val_loss: 1.2248\n",
      "Epoch 16/50\n",
      "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m11s\u001b[0m 493ms/step - accuracy: 1.0000 - loss: 1.3486e-04 - val_accuracy: 0.7674 - val_loss: 1.0937\n",
      "Epoch 17/50\n",
      "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m11s\u001b[0m 485ms/step - accuracy: 1.0000 - loss: 2.0703e-04 - val_accuracy: 0.7616 - val_loss: 1.2548\n",
      "Epoch 18/50\n",
      "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m11s\u001b[0m 478ms/step - accuracy: 0.9990 - loss: 0.0010 - val_accuracy: 0.7267 - val_loss: 1.3927\n",
      "Epoch 19/50\n",
      "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m11s\u001b[0m 490ms/step - accuracy: 0.9970 - loss: 0.0115 - val_accuracy: 0.7151 - val_loss: 1.2795\n",
      "Epoch 20/50\n",
      "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m11s\u001b[0m 484ms/step - accuracy: 0.9989 - loss: 0.0029 - val_accuracy: 0.7849 - val_loss: 0.9829\n",
      "Epoch 21/50\n",
      "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m11s\u001b[0m 484ms/step - accuracy: 0.9860 - loss: 0.0443 - val_accuracy: 0.7791 - val_loss: 1.0174\n",
      "Epoch 22/50\n",
      "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m11s\u001b[0m 487ms/step - accuracy: 0.9954 - loss: 0.0084 - val_accuracy: 0.7674 - val_loss: 1.0458\n",
      "Epoch 23/50\n",
      "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m11s\u001b[0m 490ms/step - accuracy: 0.9931 - loss: 0.0095 - val_accuracy: 0.7384 - val_loss: 1.2269\n",
      "Epoch 24/50\n",
      "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m11s\u001b[0m 497ms/step - accuracy: 1.0000 - loss: 0.0025 - val_accuracy: 0.7965 - val_loss: 0.9472\n",
      "Epoch 25/50\n",
      "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m11s\u001b[0m 479ms/step - accuracy: 1.0000 - loss: 5.0275e-04 - val_accuracy: 0.8023 - val_loss: 1.0235\n",
      "Epoch 26/50\n",
      "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m11s\u001b[0m 491ms/step - accuracy: 1.0000 - loss: 4.2306e-04 - val_accuracy: 0.8314 - val_loss: 0.7486\n",
      "Epoch 27/50\n",
      "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m11s\u001b[0m 485ms/step - accuracy: 1.0000 - loss: 8.7015e-04 - val_accuracy: 0.7267 - val_loss: 1.5627\n",
      "Epoch 28/50\n",
      "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m11s\u001b[0m 488ms/step - accuracy: 0.9986 - loss: 0.0025 - val_accuracy: 0.7965 - val_loss: 0.9434\n",
      "Epoch 29/50\n",
      "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m11s\u001b[0m 495ms/step - accuracy: 1.0000 - loss: 2.0030e-04 - val_accuracy: 0.7849 - val_loss: 1.0261\n",
      "Epoch 30/50\n",
      "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m11s\u001b[0m 489ms/step - accuracy: 1.0000 - loss: 6.5345e-04 - val_accuracy: 0.7442 - val_loss: 1.4491\n",
      "Epoch 31/50\n",
      "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m11s\u001b[0m 479ms/step - accuracy: 1.0000 - loss: 4.8014e-04 - val_accuracy: 0.7674 - val_loss: 1.3306\n",
      "Epoch 32/50\n",
      "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m11s\u001b[0m 485ms/step - accuracy: 1.0000 - loss: 2.4338e-04 - val_accuracy: 0.7791 - val_loss: 1.2011\n",
      "Epoch 33/50\n",
      "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m11s\u001b[0m 482ms/step - accuracy: 1.0000 - loss: 1.1637e-04 - val_accuracy: 0.7907 - val_loss: 1.1428\n",
      "Epoch 34/50\n",
      "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m11s\u001b[0m 491ms/step - accuracy: 1.0000 - loss: 1.1303e-04 - val_accuracy: 0.7849 - val_loss: 1.2404\n",
      "Epoch 35/50\n",
      "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m11s\u001b[0m 483ms/step - accuracy: 1.0000 - loss: 6.9305e-05 - val_accuracy: 0.7849 - val_loss: 1.3137\n",
      "Epoch 36/50\n",
      "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m11s\u001b[0m 485ms/step - accuracy: 1.0000 - loss: 1.4492e-04 - val_accuracy: 0.7791 - val_loss: 1.3428\n",
      "Epoch 37/50\n",
      "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m11s\u001b[0m 488ms/step - accuracy: 1.0000 - loss: 1.1628e-04 - val_accuracy: 0.7849 - val_loss: 1.1865\n",
      "Epoch 38/50\n",
      "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m11s\u001b[0m 490ms/step - accuracy: 1.0000 - loss: 1.4704e-04 - val_accuracy: 0.7907 - val_loss: 1.0853\n",
      "Epoch 39/50\n",
      "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m11s\u001b[0m 494ms/step - accuracy: 1.0000 - loss: 3.8799e-05 - val_accuracy: 0.7907 - val_loss: 1.1276\n",
      "Epoch 40/50\n",
      "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m11s\u001b[0m 501ms/step - accuracy: 1.0000 - loss: 1.0798e-04 - val_accuracy: 0.7907 - val_loss: 1.1827\n",
      "Epoch 41/50\n",
      "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m11s\u001b[0m 496ms/step - accuracy: 1.0000 - loss: 4.6667e-05 - val_accuracy: 0.7907 - val_loss: 1.2363\n",
      "Epoch 42/50\n",
      "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m11s\u001b[0m 502ms/step - accuracy: 1.0000 - loss: 3.1392e-05 - val_accuracy: 0.7849 - val_loss: 1.2700\n",
      "Epoch 43/50\n",
      "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m11s\u001b[0m 498ms/step - accuracy: 1.0000 - loss: 7.3294e-05 - val_accuracy: 0.7849 - val_loss: 1.3362\n",
      "Epoch 44/50\n",
      "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m11s\u001b[0m 494ms/step - accuracy: 1.0000 - loss: 1.6407e-05 - val_accuracy: 0.7733 - val_loss: 1.4010\n",
      "Epoch 45/50\n",
      "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m11s\u001b[0m 493ms/step - accuracy: 1.0000 - loss: 3.1023e-05 - val_accuracy: 0.7733 - val_loss: 1.4294\n",
      "Epoch 46/50\n",
      "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m11s\u001b[0m 494ms/step - accuracy: 1.0000 - loss: 1.1260e-05 - val_accuracy: 0.7791 - val_loss: 1.4297\n",
      "Epoch 47/50\n",
      "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m11s\u001b[0m 486ms/step - accuracy: 1.0000 - loss: 3.1100e-05 - val_accuracy: 0.7849 - val_loss: 1.4136\n",
      "Epoch 48/50\n",
      "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m11s\u001b[0m 487ms/step - accuracy: 1.0000 - loss: 1.3413e-05 - val_accuracy: 0.7849 - val_loss: 1.4103\n",
      "Epoch 49/50\n",
      "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m11s\u001b[0m 481ms/step - accuracy: 1.0000 - loss: 4.0494e-05 - val_accuracy: 0.7965 - val_loss: 1.3026\n",
      "Epoch 50/50\n",
      "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m11s\u001b[0m 485ms/step - accuracy: 1.0000 - loss: 1.3311e-04 - val_accuracy: 0.8140 - val_loss: 1.0063\n",
      "\u001b[1m5/5\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 45ms/step\n",
      "CNN Accuracy: 0.9004\n",
      "CNN Classification Report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.98      0.87      0.92        62\n",
      "           1       0.64      1.00      0.78        14\n",
      "           2       0.85      0.83      0.84        53\n",
      "\n",
      "    accuracy                           0.87       129\n",
      "   macro avg       0.82      0.90      0.85       129\n",
      "weighted avg       0.89      0.87      0.87       129\n",
      "\n",
      "Epoch 1/50\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/mojo/.local/lib/python3.12/site-packages/keras/src/layers/core/dense.py:87: UserWarning: Do not pass an `input_shape`/`input_dim` argument to a layer. When using Sequential models, prefer using an `Input(shape)` object as the first layer in the model instead.\n",
      "  super().__init__(activity_regularizer=activity_regularizer, **kwargs)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 8ms/step - accuracy: 0.5969 - loss: 1.2085 - val_accuracy: 0.8372 - val_loss: 0.4724\n",
      "Epoch 2/50\n",
      "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.7771 - loss: 0.7810 - val_accuracy: 0.7442 - val_loss: 0.6254\n",
      "Epoch 3/50\n",
      "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.7787 - loss: 0.6993 - val_accuracy: 0.7616 - val_loss: 0.5746\n",
      "Epoch 4/50\n",
      "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.8793 - loss: 0.3944 - val_accuracy: 0.7616 - val_loss: 0.6163\n",
      "Epoch 5/50\n",
      "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.8981 - loss: 0.2509 - val_accuracy: 0.7674 - val_loss: 0.7213\n",
      "Epoch 6/50\n",
      "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.9123 - loss: 0.2324 - val_accuracy: 0.7674 - val_loss: 0.9579\n",
      "Epoch 7/50\n",
      "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.9136 - loss: 0.2449 - val_accuracy: 0.7791 - val_loss: 0.8050\n",
      "Epoch 8/50\n",
      "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.9293 - loss: 0.2464 - val_accuracy: 0.7500 - val_loss: 0.8355\n",
      "Epoch 9/50\n",
      "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.9655 - loss: 0.1241 - val_accuracy: 0.7442 - val_loss: 0.9453\n",
      "Epoch 10/50\n",
      "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.9546 - loss: 0.1342 - val_accuracy: 0.6860 - val_loss: 1.5396\n",
      "Epoch 11/50\n",
      "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.9829 - loss: 0.0946 - val_accuracy: 0.7907 - val_loss: 1.1114\n",
      "Epoch 12/50\n",
      "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.9786 - loss: 0.0642 - val_accuracy: 0.7442 - val_loss: 1.2034\n",
      "Epoch 13/50\n",
      "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.9746 - loss: 0.1060 - val_accuracy: 0.7151 - val_loss: 1.5972\n",
      "Epoch 14/50\n",
      "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - accuracy: 0.9718 - loss: 0.0959 - val_accuracy: 0.7035 - val_loss: 1.7898\n",
      "Epoch 15/50\n",
      "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.9787 - loss: 0.0457 - val_accuracy: 0.7209 - val_loss: 1.6614\n",
      "Epoch 16/50\n",
      "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.9793 - loss: 0.0632 - val_accuracy: 0.7326 - val_loss: 1.3493\n",
      "Epoch 17/50\n",
      "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - accuracy: 0.9837 - loss: 0.0647 - val_accuracy: 0.7500 - val_loss: 0.9782\n",
      "Epoch 18/50\n",
      "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - accuracy: 0.9932 - loss: 0.0237 - val_accuracy: 0.7500 - val_loss: 1.0522\n",
      "Epoch 19/50\n",
      "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.9851 - loss: 0.0321 - val_accuracy: 0.7500 - val_loss: 1.1142\n",
      "Epoch 20/50\n",
      "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - accuracy: 0.9920 - loss: 0.0482 - val_accuracy: 0.7616 - val_loss: 1.3374\n",
      "Epoch 21/50\n",
      "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.9691 - loss: 0.0511 - val_accuracy: 0.7035 - val_loss: 1.6750\n",
      "Epoch 22/50\n",
      "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - accuracy: 0.9944 - loss: 0.0248 - val_accuracy: 0.7442 - val_loss: 1.5701\n",
      "Epoch 23/50\n",
      "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.9933 - loss: 0.0252 - val_accuracy: 0.7616 - val_loss: 1.5181\n",
      "Epoch 24/50\n",
      "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.9934 - loss: 0.0190 - val_accuracy: 0.7442 - val_loss: 1.4742\n",
      "Epoch 25/50\n",
      "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - accuracy: 0.9954 - loss: 0.0172 - val_accuracy: 0.7093 - val_loss: 1.7919\n",
      "Epoch 26/50\n",
      "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.9899 - loss: 0.0395 - val_accuracy: 0.6802 - val_loss: 1.9804\n",
      "Epoch 27/50\n",
      "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.9883 - loss: 0.0307 - val_accuracy: 0.7035 - val_loss: 1.6250\n",
      "Epoch 28/50\n",
      "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - accuracy: 0.9866 - loss: 0.0236 - val_accuracy: 0.7209 - val_loss: 2.0231\n",
      "Epoch 29/50\n",
      "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - accuracy: 0.9902 - loss: 0.0297 - val_accuracy: 0.7616 - val_loss: 1.6038\n",
      "Epoch 30/50\n",
      "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.9868 - loss: 0.0806 - val_accuracy: 0.7500 - val_loss: 1.7383\n",
      "Epoch 31/50\n",
      "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - accuracy: 0.9866 - loss: 0.0694 - val_accuracy: 0.7384 - val_loss: 1.7328\n",
      "Epoch 32/50\n",
      "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.9805 - loss: 0.1533 - val_accuracy: 0.7849 - val_loss: 1.4729\n",
      "Epoch 33/50\n",
      "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - accuracy: 0.9797 - loss: 0.1536 - val_accuracy: 0.7442 - val_loss: 2.0137\n",
      "Epoch 34/50\n",
      "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.9921 - loss: 0.0197 - val_accuracy: 0.7616 - val_loss: 1.8863\n",
      "Epoch 35/50\n",
      "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - accuracy: 0.9862 - loss: 0.0386 - val_accuracy: 0.6453 - val_loss: 2.2603\n",
      "Epoch 36/50\n",
      "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - accuracy: 0.9925 - loss: 0.0253 - val_accuracy: 0.6686 - val_loss: 1.9858\n",
      "Epoch 37/50\n",
      "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - accuracy: 0.9944 - loss: 0.0181 - val_accuracy: 0.7616 - val_loss: 1.4592\n",
      "Epoch 38/50\n",
      "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - accuracy: 0.9957 - loss: 0.0156 - val_accuracy: 0.7151 - val_loss: 2.2588\n",
      "Epoch 39/50\n",
      "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - accuracy: 0.9863 - loss: 0.0519 - val_accuracy: 0.6570 - val_loss: 2.4828\n",
      "Epoch 40/50\n",
      "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - accuracy: 0.9888 - loss: 0.0296 - val_accuracy: 0.7733 - val_loss: 1.9862\n",
      "Epoch 41/50\n",
      "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - accuracy: 0.9958 - loss: 0.0240 - val_accuracy: 0.6977 - val_loss: 2.4943\n",
      "Epoch 42/50\n",
      "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.9870 - loss: 0.0323 - val_accuracy: 0.7209 - val_loss: 2.3832\n",
      "Epoch 43/50\n",
      "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.9986 - loss: 0.0053 - val_accuracy: 0.7326 - val_loss: 2.6279\n",
      "Epoch 44/50\n",
      "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.9968 - loss: 0.0106 - val_accuracy: 0.7093 - val_loss: 2.9655\n",
      "Epoch 45/50\n",
      "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - accuracy: 0.9993 - loss: 0.0026 - val_accuracy: 0.6919 - val_loss: 3.6384\n",
      "Epoch 46/50\n",
      "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - accuracy: 0.9873 - loss: 0.0354 - val_accuracy: 0.7151 - val_loss: 2.4546\n",
      "Epoch 47/50\n",
      "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - accuracy: 0.9964 - loss: 0.0129 - val_accuracy: 0.7733 - val_loss: 2.1618\n",
      "Epoch 48/50\n",
      "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.9983 - loss: 0.0129 - val_accuracy: 0.7558 - val_loss: 2.2747\n",
      "Epoch 49/50\n",
      "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.9900 - loss: 0.0262 - val_accuracy: 0.6977 - val_loss: 2.7893\n",
      "Epoch 50/50\n",
      "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - accuracy: 0.9973 - loss: 0.0189 - val_accuracy: 0.6802 - val_loss: 2.8987\n",
      "\u001b[1m5/5\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 10ms/step\n",
      "ANN Accuracy: 0.8941\n",
      "ANN Classification Report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       1.00      0.87      0.93        62\n",
      "           1       0.58      1.00      0.74        14\n",
      "           2       0.84      0.81      0.83        53\n",
      "\n",
      "    accuracy                           0.86       129\n",
      "   macro avg       0.81      0.89      0.83       129\n",
      "weighted avg       0.89      0.86      0.87       129\n",
      "\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "from sklearn.preprocessing import LabelEncoder\n",
    "from sklearn.svm import SVC\n",
    "from sklearn.metrics import balanced_accuracy_score, classification_report\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "\n",
    "# Load the data\n",
    "train_data = np.load('../Files/extracted_features/layer_features_lv60_self/train_1.npz')\n",
    "test_data = np.load('../Files/extracted_features/layer_features_lv60_self/test_1.npz')\n",
    "\n",
    "train_features = train_data['features']  # Ensure these have 1024 features\n",
    "test_features = test_data['features']    # Ensure these have 1024 features\n",
    "\n",
    "# Read Age labels instead of Gender\n",
    "train_labels = pd.read_csv('../Files/labels/y_train.csv').Age_Group\n",
    "test_labels = pd.read_csv('../Files/labels/y_test.csv').Age_Group\n",
    "\n",
    "# Encode the labels\n",
    "label_encoder = LabelEncoder()\n",
    "train_labels_encoded = label_encoder.fit_transform(train_labels)\n",
    "\n",
    "# Handle unseen labels in test set by filtering out labels not present in train set\n",
    "test_labels_filtered = test_labels[test_labels.isin(train_labels.unique())]\n",
    "test_features_filtered = test_features[test_labels.isin(train_labels.unique())]\n",
    "test_labels_encoded = label_encoder.transform(test_labels_filtered)\n",
    "\n",
    "# Standardize features\n",
    "scaler = StandardScaler()\n",
    "train_features_normalized = scaler.fit_transform(train_features)\n",
    "test_features_normalized = scaler.transform(test_features_filtered)\n",
    "\n",
    "# SVM model\n",
    "svm_model = SVC(kernel='linear', C=10.0, gamma='scale', random_state=42)\n",
    "svm_model.fit(train_features_normalized, train_labels_encoded)\n",
    "\n",
    "# SVM Prediction and Evaluation\n",
    "svm_predictions = svm_model.predict(test_features_normalized)\n",
    "svm_accuracy = balanced_accuracy_score(test_labels_encoded, svm_predictions)\n",
    "print(f\"SVM Accuracy: {svm_accuracy:.4f}\")\n",
    "print(\"SVM Classification Report:\")\n",
    "print(classification_report(test_labels_encoded, svm_predictions))\n",
    "\n",
    "# CNN model (TensorFlow)\n",
    "import tensorflow as tf\n",
    "from tensorflow.keras.models import Sequential\n",
    "from tensorflow.keras.layers import Conv1D, Flatten, Dense, Dropout\n",
    "\n",
    "train_features_cnn = np.expand_dims(train_features_normalized, axis=-1)  # Shape: (num_samples, 1024, 1)\n",
    "test_features_cnn = np.expand_dims(test_features_normalized, axis=-1)    # Shape: (num_samples, 1024, 1)\n",
    "\n",
    "cnn_model = Sequential([\n",
    "    Conv1D(64, kernel_size=5, activation='relu', input_shape=(1024, 1)),  # Updated input shape to 1024\n",
    "    Conv1D(128, kernel_size=5, activation='relu'),\n",
    "    Conv1D(256, kernel_size=5, activation='relu'),\n",
    "    Flatten(),\n",
    "    Dense(256, activation='relu'),\n",
    "    Dropout(0.5),\n",
    "    Dense(len(label_encoder.classes_), activation='softmax')\n",
    "])\n",
    "\n",
    "cnn_model.compile(optimizer='adam', loss='sparse_categorical_crossentropy', metrics=['accuracy'])\n",
    "\n",
    "cnn_model.fit(train_features_cnn, train_labels_encoded, epochs=50, batch_size=32, validation_split=0.2)\n",
    "\n",
    "# CNN Prediction and Evaluation\n",
    "cnn_predictions = np.argmax(cnn_model.predict(test_features_cnn), axis=-1)\n",
    "cnn_accuracy = balanced_accuracy_score(test_labels_encoded, cnn_predictions)\n",
    "print(f\"CNN Accuracy: {cnn_accuracy:.4f}\")\n",
    "print(\"CNN Classification Report:\")\n",
    "print(classification_report(test_labels_encoded, cnn_predictions))\n",
    "\n",
    "# ANN model (TensorFlow)\n",
    "ann_model = Sequential([\n",
    "    Dense(512, activation='relu', input_shape=(1024,)),  # Updated input shape to 1024\n",
    "    Dropout(0.5),\n",
    "    Dense(256, activation='relu'),\n",
    "    Dropout(0.5),\n",
    "    Dense(128, activation='relu'),\n",
    "    Dropout(0.5),\n",
    "    Dense(len(label_encoder.classes_), activation='softmax')\n",
    "])\n",
    "\n",
    "ann_model.compile(optimizer='adam', loss='sparse_categorical_crossentropy', metrics=['accuracy'])\n",
    "\n",
    "ann_model.fit(train_features_normalized, train_labels_encoded, epochs=50, batch_size=32, validation_split=0.2)\n",
    "\n",
    "# ANN Prediction and Evaluation\n",
    "ann_predictions = np.argmax(ann_model.predict(test_features_normalized), axis=-1)\n",
    "ann_accuracy = balanced_accuracy_score(test_labels_encoded, ann_predictions)\n",
    "print(f\"ANN Accuracy: {ann_accuracy:.4f}\")\n",
    "print(\"ANN Classification Report:\")\n",
    "print(classification_report(test_labels_encoded, ann_predictions))\n",
    "\n",
    "# PyTorch CNN Model\n",
    "import torch\n",
    "from torch.utils.data import DataLoader, TensorDataset\n",
    "\n",
    "X_train_tensor = torch.tensor(train_features_cnn, dtype=torch.float32).permute(0, 2, 1)  # Shape: (num_samples, 1, 1024)\n",
    "y_train_tensor = torch.tensor(train_labels_encoded, dtype=torch.long)\n",
    "X_test_tensor = torch.tensor(test_features_cnn, dtype=torch.float32).permute(0, 2, 1)    # Shape: (num_samples, 1, 1024)\n",
    "y_test_tensor = torch.tensor(test_labels_encoded, dtype=torch.long)\n",
    "\n",
    "train_dataset = TensorDataset(X_train_tensor, y_train_tensor)\n",
    "test_dataset = TensorDataset(X_test_tensor, y_test_tensor)\n",
    "\n",
    "train_loader = DataLoader(train_dataset, batch_size=64, shuffle=True)\n",
    "test_loader = DataLoader(test_dataset, batch_size=64, shuffle=False)\n",
    "\n",
    "import torch.nn as nn\n",
    "import torch.optim as optim\n",
    "\n",
    "class CNN1DModel(nn.Module):\n",
    "    def __init__(self, input_channels, num_classes):\n",
    "        super(CNN1DModel, self).__init__()\n",
    "        self.conv1 = nn.Conv1d(input_channels, 32, kernel_size=5, stride=1, padding=2)\n",
    "        self.bn1 = nn.BatchNorm1d(32)\n",
    "        self.relu = nn.ReLU()\n",
    "        self.conv2 = nn.Conv1d(32, 64, kernel_size=5, stride=1, padding=2)\n",
    "        self.bn2 = nn.BatchNorm1d(64)\n",
    "        self.conv3 = nn.Conv1d(64, 128, kernel_size=5, stride=1, padding=2)\n",
    "        self.bn3 = nn.BatchNorm1d(128)\n",
    "        self.flatten = nn.Flatten()\n",
    "        self.fc1 = nn.Linear(128 * 1024, 512)  # Updated to 1024 features\n",
    "        self.fc2 = nn.Linear(512, num_classes)\n",
    "        self.dropout = nn.Dropout(0.5)\n",
    "    \n",
    "    def forward(self, x):\n",
    "        x = self.relu(self.bn1(self.conv1(x)))\n",
    "        x = self.relu(self.bn2(self.conv2(x)))\n",
    "        x = self.relu(self.bn3(self.conv3(x)))\n",
    "        x = self.flatten(x)\n",
    "        x = self.dropout(self.relu(self.fc1(x)))\n",
    "        x = self.fc2(x)\n",
    "        return x\n",
    "\n",
    "input_channels = 1\n",
    "num_classes = len(label_encoder.classes_)\n",
    "model = CNN1DModel(input_channels, num_classes)\n",
    "criterion = nn.CrossEntropyLoss()\n",
    "optimizer = optim.Adam(model.parameters(), lr=0.001)\n",
    "\n",
    "# Training loop and evaluation (not shown)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "SVM Accuracy: 0.6686\n",
      "SVM Classification Report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.81      0.82      0.82        62\n",
      "           1       0.50      0.43      0.46        14\n",
      "           2       0.74      0.75      0.75        53\n",
      "\n",
      "    accuracy                           0.75       129\n",
      "   macro avg       0.68      0.67      0.68       129\n",
      "weighted avg       0.75      0.75      0.75       129\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2024-12-11 16:11:07.097076: E external/local_xla/xla/stream_executor/cuda/cuda_fft.cc:485] Unable to register cuFFT factory: Attempting to register factory for plugin cuFFT when one has already been registered\n",
      "2024-12-11 16:11:07.108425: E external/local_xla/xla/stream_executor/cuda/cuda_dnn.cc:8454] Unable to register cuDNN factory: Attempting to register factory for plugin cuDNN when one has already been registered\n",
      "2024-12-11 16:11:07.112317: E external/local_xla/xla/stream_executor/cuda/cuda_blas.cc:1452] Unable to register cuBLAS factory: Attempting to register factory for plugin cuBLAS when one has already been registered\n",
      "2024-12-11 16:11:07.123605: I tensorflow/core/platform/cpu_feature_guard.cc:210] This TensorFlow binary is optimized to use available CPU instructions in performance-critical operations.\n",
      "To enable the following instructions: AVX2 FMA, in other operations, rebuild TensorFlow with the appropriate compiler flags.\n",
      "2024-12-11 16:11:08.018862: W tensorflow/compiler/tf2tensorrt/utils/py_utils.cc:38] TF-TRT Warning: Could not find TensorRT\n",
      "/home/mojo/.local/lib/python3.12/site-packages/keras/src/layers/convolutional/base_conv.py:107: UserWarning: Do not pass an `input_shape`/`input_dim` argument to a layer. When using Sequential models, prefer using an `Input(shape)` object as the first layer in the model instead.\n",
      "  super().__init__(activity_regularizer=activity_regularizer, **kwargs)\n",
      "WARNING: All log messages before absl::InitializeLog() is called are written to STDERR\n",
      "I0000 00:00:1733913668.682948  131573 cuda_executor.cc:1015] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero. See more at https://github.com/torvalds/linux/blob/v6.0/Documentation/ABI/testing/sysfs-bus-pci#L344-L355\n",
      "2024-12-11 16:11:08.726174: W tensorflow/core/common_runtime/gpu/gpu_device.cc:2343] Cannot dlopen some GPU libraries. Please make sure the missing libraries mentioned above are installed properly if you would like to use GPU. Follow the guide at https://www.tensorflow.org/install/gpu for how to download and setup the required libraries for your platform.\n",
      "Skipping registering GPU devices...\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/50\n",
      "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m12s\u001b[0m 502ms/step - accuracy: 0.4721 - loss: 2.6341 - val_accuracy: 0.7151 - val_loss: 0.6579\n",
      "Epoch 2/50\n",
      "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m10s\u001b[0m 462ms/step - accuracy: 0.7406 - loss: 0.6152 - val_accuracy: 0.6163 - val_loss: 0.8038\n",
      "Epoch 3/50\n",
      "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m10s\u001b[0m 462ms/step - accuracy: 0.8641 - loss: 0.3671 - val_accuracy: 0.5523 - val_loss: 0.9670\n",
      "Epoch 4/50\n",
      "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m10s\u001b[0m 455ms/step - accuracy: 0.9383 - loss: 0.1923 - val_accuracy: 0.6686 - val_loss: 0.6695\n",
      "Epoch 5/50\n",
      "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m10s\u001b[0m 464ms/step - accuracy: 0.9794 - loss: 0.0865 - val_accuracy: 0.6047 - val_loss: 1.4726\n",
      "Epoch 6/50\n",
      "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m10s\u001b[0m 457ms/step - accuracy: 0.9941 - loss: 0.0208 - val_accuracy: 0.6919 - val_loss: 0.9997\n",
      "Epoch 7/50\n",
      "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m10s\u001b[0m 461ms/step - accuracy: 0.9937 - loss: 0.0239 - val_accuracy: 0.4884 - val_loss: 1.9691\n",
      "Epoch 8/50\n",
      "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m10s\u001b[0m 463ms/step - accuracy: 0.9969 - loss: 0.0171 - val_accuracy: 0.5233 - val_loss: 1.8945\n",
      "Epoch 9/50\n",
      "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m10s\u001b[0m 471ms/step - accuracy: 0.9908 - loss: 0.0231 - val_accuracy: 0.6337 - val_loss: 1.2501\n",
      "Epoch 10/50\n",
      "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m10s\u001b[0m 455ms/step - accuracy: 0.9962 - loss: 0.0139 - val_accuracy: 0.5465 - val_loss: 1.8695\n",
      "Epoch 11/50\n",
      "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m10s\u001b[0m 465ms/step - accuracy: 1.0000 - loss: 0.0049 - val_accuracy: 0.5000 - val_loss: 2.2159\n",
      "Epoch 12/50\n",
      "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m11s\u001b[0m 480ms/step - accuracy: 0.9986 - loss: 0.0066 - val_accuracy: 0.4360 - val_loss: 2.8800\n",
      "Epoch 13/50\n",
      "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m11s\u001b[0m 482ms/step - accuracy: 1.0000 - loss: 0.0029 - val_accuracy: 0.5465 - val_loss: 2.6463\n",
      "Epoch 14/50\n",
      "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m11s\u001b[0m 482ms/step - accuracy: 0.9984 - loss: 0.0027 - val_accuracy: 0.5756 - val_loss: 2.1928\n",
      "Epoch 15/50\n",
      "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m10s\u001b[0m 468ms/step - accuracy: 1.0000 - loss: 0.0017 - val_accuracy: 0.4709 - val_loss: 3.0392\n",
      "Epoch 16/50\n",
      "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m10s\u001b[0m 464ms/step - accuracy: 1.0000 - loss: 0.0010 - val_accuracy: 0.5640 - val_loss: 2.6371\n",
      "Epoch 17/50\n",
      "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m11s\u001b[0m 491ms/step - accuracy: 1.0000 - loss: 5.4500e-04 - val_accuracy: 0.5523 - val_loss: 2.8450\n",
      "Epoch 18/50\n",
      "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m11s\u001b[0m 492ms/step - accuracy: 1.0000 - loss: 0.0013 - val_accuracy: 0.6279 - val_loss: 2.3822\n",
      "Epoch 19/50\n",
      "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m11s\u001b[0m 488ms/step - accuracy: 1.0000 - loss: 0.0010 - val_accuracy: 0.5756 - val_loss: 2.7984\n",
      "Epoch 20/50\n",
      "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m11s\u001b[0m 485ms/step - accuracy: 1.0000 - loss: 4.1994e-04 - val_accuracy: 0.5988 - val_loss: 2.5630\n",
      "Epoch 21/50\n",
      "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m11s\u001b[0m 487ms/step - accuracy: 1.0000 - loss: 0.0010 - val_accuracy: 0.5291 - val_loss: 3.1987\n",
      "Epoch 22/50\n",
      "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m11s\u001b[0m 481ms/step - accuracy: 1.0000 - loss: 6.3749e-04 - val_accuracy: 0.5756 - val_loss: 2.7892\n",
      "Epoch 23/50\n",
      "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m11s\u001b[0m 478ms/step - accuracy: 1.0000 - loss: 3.6676e-04 - val_accuracy: 0.5640 - val_loss: 2.9678\n",
      "Epoch 24/50\n",
      "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m11s\u001b[0m 480ms/step - accuracy: 1.0000 - loss: 1.8055e-04 - val_accuracy: 0.5465 - val_loss: 3.0678\n",
      "Epoch 25/50\n",
      "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m11s\u001b[0m 478ms/step - accuracy: 1.0000 - loss: 1.3813e-04 - val_accuracy: 0.5872 - val_loss: 2.9371\n",
      "Epoch 26/50\n",
      "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m11s\u001b[0m 482ms/step - accuracy: 1.0000 - loss: 2.3948e-04 - val_accuracy: 0.5581 - val_loss: 2.9897\n",
      "Epoch 27/50\n",
      "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m11s\u001b[0m 483ms/step - accuracy: 1.0000 - loss: 2.2435e-04 - val_accuracy: 0.5581 - val_loss: 3.0431\n",
      "Epoch 28/50\n",
      "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m11s\u001b[0m 480ms/step - accuracy: 1.0000 - loss: 2.1506e-04 - val_accuracy: 0.5233 - val_loss: 3.5673\n",
      "Epoch 29/50\n",
      "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m11s\u001b[0m 479ms/step - accuracy: 1.0000 - loss: 1.3743e-04 - val_accuracy: 0.5465 - val_loss: 3.4865\n",
      "Epoch 30/50\n",
      "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m11s\u001b[0m 480ms/step - accuracy: 1.0000 - loss: 1.4650e-04 - val_accuracy: 0.5581 - val_loss: 3.3906\n",
      "Epoch 31/50\n",
      "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m11s\u001b[0m 479ms/step - accuracy: 1.0000 - loss: 8.7029e-05 - val_accuracy: 0.5698 - val_loss: 3.2076\n",
      "Epoch 32/50\n",
      "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m11s\u001b[0m 481ms/step - accuracy: 1.0000 - loss: 9.6772e-05 - val_accuracy: 0.5698 - val_loss: 3.2502\n",
      "Epoch 33/50\n",
      "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m11s\u001b[0m 484ms/step - accuracy: 1.0000 - loss: 6.1392e-05 - val_accuracy: 0.5523 - val_loss: 3.4763\n",
      "Epoch 34/50\n",
      "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m11s\u001b[0m 481ms/step - accuracy: 1.0000 - loss: 6.5950e-05 - val_accuracy: 0.5116 - val_loss: 3.9922\n",
      "Epoch 35/50\n",
      "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m11s\u001b[0m 480ms/step - accuracy: 1.0000 - loss: 2.6288e-04 - val_accuracy: 0.6047 - val_loss: 3.1469\n",
      "Epoch 36/50\n",
      "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m11s\u001b[0m 480ms/step - accuracy: 1.0000 - loss: 2.0170e-04 - val_accuracy: 0.5058 - val_loss: 4.0005\n",
      "Epoch 37/50\n",
      "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m11s\u001b[0m 483ms/step - accuracy: 1.0000 - loss: 6.2759e-04 - val_accuracy: 0.6628 - val_loss: 2.6398\n",
      "Epoch 38/50\n",
      "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m11s\u001b[0m 483ms/step - accuracy: 0.9981 - loss: 0.0033 - val_accuracy: 0.7209 - val_loss: 1.1326\n",
      "Epoch 39/50\n",
      "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m11s\u001b[0m 486ms/step - accuracy: 0.9851 - loss: 0.0369 - val_accuracy: 0.6105 - val_loss: 2.1205\n",
      "Epoch 40/50\n",
      "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m11s\u001b[0m 483ms/step - accuracy: 0.9913 - loss: 0.0311 - val_accuracy: 0.5988 - val_loss: 1.6143\n",
      "Epoch 41/50\n",
      "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m11s\u001b[0m 483ms/step - accuracy: 0.9912 - loss: 0.0244 - val_accuracy: 0.4767 - val_loss: 3.2300\n",
      "Epoch 42/50\n",
      "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m11s\u001b[0m 482ms/step - accuracy: 0.9858 - loss: 0.0389 - val_accuracy: 0.5640 - val_loss: 2.3810\n",
      "Epoch 43/50\n",
      "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m11s\u001b[0m 485ms/step - accuracy: 0.9902 - loss: 0.0278 - val_accuracy: 0.6512 - val_loss: 2.3235\n",
      "Epoch 44/50\n",
      "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m11s\u001b[0m 488ms/step - accuracy: 0.9901 - loss: 0.0472 - val_accuracy: 0.4942 - val_loss: 2.1678\n",
      "Epoch 45/50\n",
      "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m11s\u001b[0m 488ms/step - accuracy: 0.9992 - loss: 0.0077 - val_accuracy: 0.4244 - val_loss: 3.5092\n",
      "Epoch 46/50\n",
      "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m11s\u001b[0m 488ms/step - accuracy: 0.9986 - loss: 0.0046 - val_accuracy: 0.4884 - val_loss: 3.7577\n",
      "Epoch 47/50\n",
      "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m11s\u001b[0m 486ms/step - accuracy: 0.9942 - loss: 0.0370 - val_accuracy: 0.4942 - val_loss: 1.9831\n",
      "Epoch 48/50\n",
      "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m11s\u001b[0m 487ms/step - accuracy: 1.0000 - loss: 0.0056 - val_accuracy: 0.4651 - val_loss: 3.0776\n",
      "Epoch 49/50\n",
      "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m11s\u001b[0m 487ms/step - accuracy: 1.0000 - loss: 0.0014 - val_accuracy: 0.5174 - val_loss: 3.1801\n",
      "Epoch 50/50\n",
      "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m11s\u001b[0m 486ms/step - accuracy: 1.0000 - loss: 6.9800e-04 - val_accuracy: 0.5291 - val_loss: 3.1457\n",
      "\u001b[1m5/5\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 46ms/step\n",
      "CNN Accuracy: 0.6596\n",
      "CNN Classification Report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.78      0.87      0.82        62\n",
      "           1       0.55      0.43      0.48        14\n",
      "           2       0.73      0.68      0.71        53\n",
      "\n",
      "    accuracy                           0.74       129\n",
      "   macro avg       0.69      0.66      0.67       129\n",
      "weighted avg       0.74      0.74      0.74       129\n",
      "\n",
      "Epoch 1/50\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/mojo/.local/lib/python3.12/site-packages/keras/src/layers/core/dense.py:87: UserWarning: Do not pass an `input_shape`/`input_dim` argument to a layer. When using Sequential models, prefer using an `Input(shape)` object as the first layer in the model instead.\n",
      "  super().__init__(activity_regularizer=activity_regularizer, **kwargs)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 7ms/step - accuracy: 0.4544 - loss: 1.6087 - val_accuracy: 0.6105 - val_loss: 0.7750\n",
      "Epoch 2/50\n",
      "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.6122 - loss: 1.0183 - val_accuracy: 0.5640 - val_loss: 0.8872\n",
      "Epoch 3/50\n",
      "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.6988 - loss: 0.7528 - val_accuracy: 0.6395 - val_loss: 0.8139\n",
      "Epoch 4/50\n",
      "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.7316 - loss: 0.6555 - val_accuracy: 0.5756 - val_loss: 0.8399\n",
      "Epoch 5/50\n",
      "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.8020 - loss: 0.5179 - val_accuracy: 0.5756 - val_loss: 0.8835\n",
      "Epoch 6/50\n",
      "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.8083 - loss: 0.4928 - val_accuracy: 0.6279 - val_loss: 0.7783\n",
      "Epoch 7/50\n",
      "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.8159 - loss: 0.4708 - val_accuracy: 0.6105 - val_loss: 0.8532\n",
      "Epoch 8/50\n",
      "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.8545 - loss: 0.3458 - val_accuracy: 0.6105 - val_loss: 0.8085\n",
      "Epoch 9/50\n",
      "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.8376 - loss: 0.3827 - val_accuracy: 0.6337 - val_loss: 0.7604\n",
      "Epoch 10/50\n",
      "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.8820 - loss: 0.3305 - val_accuracy: 0.6337 - val_loss: 0.8501\n",
      "Epoch 11/50\n",
      "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.9128 - loss: 0.2371 - val_accuracy: 0.5116 - val_loss: 1.3683\n",
      "Epoch 12/50\n",
      "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.9071 - loss: 0.2410 - val_accuracy: 0.7209 - val_loss: 0.7189\n",
      "Epoch 13/50\n",
      "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.9233 - loss: 0.1742 - val_accuracy: 0.6337 - val_loss: 1.1229\n",
      "Epoch 14/50\n",
      "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.9333 - loss: 0.2058 - val_accuracy: 0.5523 - val_loss: 1.5374\n",
      "Epoch 15/50\n",
      "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.9174 - loss: 0.2451 - val_accuracy: 0.5116 - val_loss: 1.6954\n",
      "Epoch 16/50\n",
      "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.9449 - loss: 0.1339 - val_accuracy: 0.5174 - val_loss: 1.7222\n",
      "Epoch 17/50\n",
      "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.9751 - loss: 0.1183 - val_accuracy: 0.4767 - val_loss: 2.4190\n",
      "Epoch 18/50\n",
      "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.9565 - loss: 0.1122 - val_accuracy: 0.5698 - val_loss: 1.8184\n",
      "Epoch 19/50\n",
      "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.9618 - loss: 0.1356 - val_accuracy: 0.5349 - val_loss: 2.2181\n",
      "Epoch 20/50\n",
      "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.9672 - loss: 0.0874 - val_accuracy: 0.5930 - val_loss: 1.8540\n",
      "Epoch 21/50\n",
      "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.9565 - loss: 0.0966 - val_accuracy: 0.5000 - val_loss: 3.1859\n",
      "Epoch 22/50\n",
      "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.9622 - loss: 0.0811 - val_accuracy: 0.5116 - val_loss: 2.6614\n",
      "Epoch 23/50\n",
      "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.9868 - loss: 0.0558 - val_accuracy: 0.5291 - val_loss: 3.0124\n",
      "Epoch 24/50\n",
      "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.9760 - loss: 0.0550 - val_accuracy: 0.5174 - val_loss: 3.3136\n",
      "Epoch 25/50\n",
      "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.9813 - loss: 0.0460 - val_accuracy: 0.5465 - val_loss: 2.9421\n",
      "Epoch 26/50\n",
      "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.9866 - loss: 0.0511 - val_accuracy: 0.5640 - val_loss: 2.8023\n",
      "Epoch 27/50\n",
      "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.9743 - loss: 0.0568 - val_accuracy: 0.6105 - val_loss: 2.5298\n",
      "Epoch 28/50\n",
      "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.9859 - loss: 0.0510 - val_accuracy: 0.5640 - val_loss: 3.0173\n",
      "Epoch 29/50\n",
      "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.9840 - loss: 0.0477 - val_accuracy: 0.5581 - val_loss: 3.0978\n",
      "Epoch 30/50\n",
      "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.9795 - loss: 0.0835 - val_accuracy: 0.5872 - val_loss: 2.7423\n",
      "Epoch 31/50\n",
      "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.9764 - loss: 0.0681 - val_accuracy: 0.4419 - val_loss: 3.8670\n",
      "Epoch 32/50\n",
      "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.9683 - loss: 0.0853 - val_accuracy: 0.5291 - val_loss: 3.2506\n",
      "Epoch 33/50\n",
      "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.9811 - loss: 0.0596 - val_accuracy: 0.4884 - val_loss: 3.9225\n",
      "Epoch 34/50\n",
      "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.9843 - loss: 0.0570 - val_accuracy: 0.5000 - val_loss: 4.1163\n",
      "Epoch 35/50\n",
      "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.9885 - loss: 0.0304 - val_accuracy: 0.5407 - val_loss: 3.2080\n",
      "Epoch 36/50\n",
      "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.9790 - loss: 0.0568 - val_accuracy: 0.5930 - val_loss: 2.8172\n",
      "Epoch 37/50\n",
      "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.9783 - loss: 0.0550 - val_accuracy: 0.5233 - val_loss: 3.4195\n",
      "Epoch 38/50\n",
      "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.9776 - loss: 0.0653 - val_accuracy: 0.5291 - val_loss: 3.5142\n",
      "Epoch 39/50\n",
      "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.9806 - loss: 0.0740 - val_accuracy: 0.4884 - val_loss: 3.9996\n",
      "Epoch 40/50\n",
      "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.9812 - loss: 0.0515 - val_accuracy: 0.5407 - val_loss: 3.3640\n",
      "Epoch 41/50\n",
      "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.9940 - loss: 0.0237 - val_accuracy: 0.5116 - val_loss: 3.7800\n",
      "Epoch 42/50\n",
      "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.9893 - loss: 0.0452 - val_accuracy: 0.5581 - val_loss: 3.3816\n",
      "Epoch 43/50\n",
      "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.9892 - loss: 0.0430 - val_accuracy: 0.5174 - val_loss: 3.8461\n",
      "Epoch 44/50\n",
      "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.9881 - loss: 0.0236 - val_accuracy: 0.4884 - val_loss: 4.6084\n",
      "Epoch 45/50\n",
      "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.9852 - loss: 0.0307 - val_accuracy: 0.5407 - val_loss: 4.4121\n",
      "Epoch 46/50\n",
      "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.9905 - loss: 0.0255 - val_accuracy: 0.5174 - val_loss: 4.3212\n",
      "Epoch 47/50\n",
      "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.9837 - loss: 0.0312 - val_accuracy: 0.5407 - val_loss: 3.7943\n",
      "Epoch 48/50\n",
      "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.9787 - loss: 0.1094 - val_accuracy: 0.5174 - val_loss: 4.2405\n",
      "Epoch 49/50\n",
      "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.9810 - loss: 0.0481 - val_accuracy: 0.5233 - val_loss: 4.3573\n",
      "Epoch 50/50\n",
      "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.9834 - loss: 0.0411 - val_accuracy: 0.5116 - val_loss: 4.5134\n",
      "\u001b[1m5/5\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step \n",
      "ANN Accuracy: 0.6246\n",
      "ANN Classification Report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.77      0.87      0.82        62\n",
      "           1       0.67      0.29      0.40        14\n",
      "           2       0.72      0.72      0.72        53\n",
      "\n",
      "    accuracy                           0.74       129\n",
      "   macro avg       0.72      0.62      0.65       129\n",
      "weighted avg       0.74      0.74      0.73       129\n",
      "\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "from sklearn.preprocessing import LabelEncoder\n",
    "from sklearn.svm import SVC\n",
    "from sklearn.metrics import balanced_accuracy_score, classification_report\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "\n",
    "# Load the data\n",
    "train_data = np.load('../Files/extracted_features/layer_features_lv60_self/train_2.npz')\n",
    "test_data = np.load('../Files/extracted_features/layer_features_lv60_self/test_2.npz')\n",
    "\n",
    "train_features = train_data['features']  # Ensure these have 1024 features\n",
    "test_features = test_data['features']    # Ensure these have 1024 features\n",
    "\n",
    "# Read Age labels instead of Gender\n",
    "train_labels = pd.read_csv('../Files/labels/y_train.csv').Age_Group\n",
    "test_labels = pd.read_csv('../Files/labels/y_test.csv').Age_Group\n",
    "\n",
    "# Encode the labels\n",
    "label_encoder = LabelEncoder()\n",
    "train_labels_encoded = label_encoder.fit_transform(train_labels)\n",
    "\n",
    "# Handle unseen labels in test set by filtering out labels not present in train set\n",
    "test_labels_filtered = test_labels[test_labels.isin(train_labels.unique())]\n",
    "test_features_filtered = test_features[test_labels.isin(train_labels.unique())]\n",
    "test_labels_encoded = label_encoder.transform(test_labels_filtered)\n",
    "\n",
    "# Standardize features\n",
    "scaler = StandardScaler()\n",
    "train_features_normalized = scaler.fit_transform(train_features)\n",
    "test_features_normalized = scaler.transform(test_features_filtered)\n",
    "\n",
    "# SVM model\n",
    "svm_model = SVC(kernel='linear', C=10.0, gamma='scale', random_state=42)\n",
    "svm_model.fit(train_features_normalized, train_labels_encoded)\n",
    "\n",
    "# SVM Prediction and Evaluation\n",
    "svm_predictions = svm_model.predict(test_features_normalized)\n",
    "svm_accuracy = balanced_accuracy_score(test_labels_encoded, svm_predictions)\n",
    "print(f\"SVM Accuracy: {svm_accuracy:.4f}\")\n",
    "print(\"SVM Classification Report:\")\n",
    "print(classification_report(test_labels_encoded, svm_predictions))\n",
    "\n",
    "# CNN model (TensorFlow)\n",
    "import tensorflow as tf\n",
    "from tensorflow.keras.models import Sequential\n",
    "from tensorflow.keras.layers import Conv1D, Flatten, Dense, Dropout\n",
    "\n",
    "train_features_cnn = np.expand_dims(train_features_normalized, axis=-1)  # Shape: (num_samples, 1024, 1)\n",
    "test_features_cnn = np.expand_dims(test_features_normalized, axis=-1)    # Shape: (num_samples, 1024, 1)\n",
    "\n",
    "cnn_model = Sequential([\n",
    "    Conv1D(64, kernel_size=5, activation='relu', input_shape=(1024, 1)),  # Updated input shape to 1024\n",
    "    Conv1D(128, kernel_size=5, activation='relu'),\n",
    "    Conv1D(256, kernel_size=5, activation='relu'),\n",
    "    Flatten(),\n",
    "    Dense(256, activation='relu'),\n",
    "    Dropout(0.5),\n",
    "    Dense(len(label_encoder.classes_), activation='softmax')\n",
    "])\n",
    "\n",
    "cnn_model.compile(optimizer='adam', loss='sparse_categorical_crossentropy', metrics=['accuracy'])\n",
    "\n",
    "cnn_model.fit(train_features_cnn, train_labels_encoded, epochs=50, batch_size=32, validation_split=0.2)\n",
    "\n",
    "# CNN Prediction and Evaluation\n",
    "cnn_predictions = np.argmax(cnn_model.predict(test_features_cnn), axis=-1)\n",
    "cnn_accuracy = balanced_accuracy_score(test_labels_encoded, cnn_predictions)\n",
    "print(f\"CNN Accuracy: {cnn_accuracy:.4f}\")\n",
    "print(\"CNN Classification Report:\")\n",
    "print(classification_report(test_labels_encoded, cnn_predictions))\n",
    "\n",
    "# ANN model (TensorFlow)\n",
    "ann_model = Sequential([\n",
    "    Dense(512, activation='relu', input_shape=(1024,)),  # Updated input shape to 1024\n",
    "    Dropout(0.5),\n",
    "    Dense(256, activation='relu'),\n",
    "    Dropout(0.5),\n",
    "    Dense(128, activation='relu'),\n",
    "    Dropout(0.5),\n",
    "    Dense(len(label_encoder.classes_), activation='softmax')\n",
    "])\n",
    "\n",
    "ann_model.compile(optimizer='adam', loss='sparse_categorical_crossentropy', metrics=['accuracy'])\n",
    "\n",
    "ann_model.fit(train_features_normalized, train_labels_encoded, epochs=50, batch_size=32, validation_split=0.2)\n",
    "\n",
    "# ANN Prediction and Evaluation\n",
    "ann_predictions = np.argmax(ann_model.predict(test_features_normalized), axis=-1)\n",
    "ann_accuracy = balanced_accuracy_score(test_labels_encoded, ann_predictions)\n",
    "print(f\"ANN Accuracy: {ann_accuracy:.4f}\")\n",
    "print(\"ANN Classification Report:\")\n",
    "print(classification_report(test_labels_encoded, ann_predictions))\n",
    "\n",
    "# PyTorch CNN Model\n",
    "import torch\n",
    "from torch.utils.data import DataLoader, TensorDataset\n",
    "\n",
    "X_train_tensor = torch.tensor(train_features_cnn, dtype=torch.float32).permute(0, 2, 1)  # Shape: (num_samples, 1, 1024)\n",
    "y_train_tensor = torch.tensor(train_labels_encoded, dtype=torch.long)\n",
    "X_test_tensor = torch.tensor(test_features_cnn, dtype=torch.float32).permute(0, 2, 1)    # Shape: (num_samples, 1, 1024)\n",
    "y_test_tensor = torch.tensor(test_labels_encoded, dtype=torch.long)\n",
    "\n",
    "train_dataset = TensorDataset(X_train_tensor, y_train_tensor)\n",
    "test_dataset = TensorDataset(X_test_tensor, y_test_tensor)\n",
    "\n",
    "train_loader = DataLoader(train_dataset, batch_size=64, shuffle=True)\n",
    "test_loader = DataLoader(test_dataset, batch_size=64, shuffle=False)\n",
    "\n",
    "import torch.nn as nn\n",
    "import torch.optim as optim\n",
    "\n",
    "class CNN1DModel(nn.Module):\n",
    "    def __init__(self, input_channels, num_classes):\n",
    "        super(CNN1DModel, self).__init__()\n",
    "        self.conv1 = nn.Conv1d(input_channels, 32, kernel_size=5, stride=1, padding=2)\n",
    "        self.bn1 = nn.BatchNorm1d(32)\n",
    "        self.relu = nn.ReLU()\n",
    "        self.conv2 = nn.Conv1d(32, 64, kernel_size=5, stride=1, padding=2)\n",
    "        self.bn2 = nn.BatchNorm1d(64)\n",
    "        self.conv3 = nn.Conv1d(64, 128, kernel_size=5, stride=1, padding=2)\n",
    "        self.bn3 = nn.BatchNorm1d(128)\n",
    "        self.flatten = nn.Flatten()\n",
    "        self.fc1 = nn.Linear(128 * 1024, 512)  # Updated to 1024 features\n",
    "        self.fc2 = nn.Linear(512, num_classes)\n",
    "        self.dropout = nn.Dropout(0.5)\n",
    "    \n",
    "    def forward(self, x):\n",
    "        x = self.relu(self.bn1(self.conv1(x)))\n",
    "        x = self.relu(self.bn2(self.conv2(x)))\n",
    "        x = self.relu(self.bn3(self.conv3(x)))\n",
    "        x = self.flatten(x)\n",
    "        x = self.dropout(self.relu(self.fc1(x)))\n",
    "        x = self.fc2(x)\n",
    "        return x\n",
    "\n",
    "input_channels = 1\n",
    "num_classes = len(label_encoder.classes_)\n",
    "model = CNN1DModel(input_channels, num_classes)\n",
    "criterion = nn.CrossEntropyLoss()\n",
    "optimizer = optim.Adam(model.parameters(), lr=0.001)\n",
    "\n",
    "# Training loop and evaluation (not shown)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "SVM Accuracy: 0.6256\n",
      "SVM Classification Report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.87      0.74      0.80        62\n",
      "           1       0.50      0.29      0.36        14\n",
      "           2       0.66      0.85      0.74        53\n",
      "\n",
      "    accuracy                           0.74       129\n",
      "   macro avg       0.68      0.63      0.64       129\n",
      "weighted avg       0.74      0.74      0.73       129\n",
      "\n",
      "Epoch 1/50\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/mojo/.local/lib/python3.12/site-packages/keras/src/layers/convolutional/base_conv.py:107: UserWarning: Do not pass an `input_shape`/`input_dim` argument to a layer. When using Sequential models, prefer using an `Input(shape)` object as the first layer in the model instead.\n",
      "  super().__init__(activity_regularizer=activity_regularizer, **kwargs)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m12s\u001b[0m 477ms/step - accuracy: 0.4798 - loss: 3.4872 - val_accuracy: 0.5116 - val_loss: 0.8841\n",
      "Epoch 2/50\n",
      "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m10s\u001b[0m 468ms/step - accuracy: 0.7554 - loss: 0.5816 - val_accuracy: 0.6337 - val_loss: 0.7523\n",
      "Epoch 3/50\n",
      "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m10s\u001b[0m 472ms/step - accuracy: 0.8347 - loss: 0.3960 - val_accuracy: 0.7965 - val_loss: 0.4682\n",
      "Epoch 4/50\n",
      "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m10s\u001b[0m 470ms/step - accuracy: 0.9248 - loss: 0.2408 - val_accuracy: 0.4477 - val_loss: 1.3842\n",
      "Epoch 5/50\n",
      "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m10s\u001b[0m 469ms/step - accuracy: 0.9596 - loss: 0.1189 - val_accuracy: 0.6512 - val_loss: 0.8876\n",
      "Epoch 6/50\n",
      "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m10s\u001b[0m 471ms/step - accuracy: 0.9889 - loss: 0.0558 - val_accuracy: 0.6744 - val_loss: 0.9633\n",
      "Epoch 7/50\n",
      "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m10s\u001b[0m 471ms/step - accuracy: 0.9869 - loss: 0.0381 - val_accuracy: 0.4884 - val_loss: 1.8345\n",
      "Epoch 8/50\n",
      "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m10s\u001b[0m 472ms/step - accuracy: 0.9977 - loss: 0.0154 - val_accuracy: 0.5523 - val_loss: 1.8193\n",
      "Epoch 9/50\n",
      "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m10s\u001b[0m 472ms/step - accuracy: 1.0000 - loss: 0.0043 - val_accuracy: 0.6047 - val_loss: 1.6494\n",
      "Epoch 10/50\n",
      "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m10s\u001b[0m 469ms/step - accuracy: 0.9947 - loss: 0.0132 - val_accuracy: 0.6047 - val_loss: 1.3131\n",
      "Epoch 11/50\n",
      "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m10s\u001b[0m 474ms/step - accuracy: 0.9973 - loss: 0.0149 - val_accuracy: 0.5233 - val_loss: 1.8665\n",
      "Epoch 12/50\n",
      "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m10s\u001b[0m 470ms/step - accuracy: 0.9979 - loss: 0.0128 - val_accuracy: 0.5872 - val_loss: 1.7519\n",
      "Epoch 13/50\n",
      "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m10s\u001b[0m 470ms/step - accuracy: 1.0000 - loss: 0.0058 - val_accuracy: 0.6105 - val_loss: 1.7043\n",
      "Epoch 14/50\n",
      "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m10s\u001b[0m 473ms/step - accuracy: 1.0000 - loss: 0.0024 - val_accuracy: 0.6453 - val_loss: 1.8095\n",
      "Epoch 15/50\n",
      "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m10s\u001b[0m 471ms/step - accuracy: 1.0000 - loss: 0.0021 - val_accuracy: 0.6570 - val_loss: 1.7677\n",
      "Epoch 16/50\n",
      "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m10s\u001b[0m 471ms/step - accuracy: 0.9930 - loss: 0.0124 - val_accuracy: 0.5581 - val_loss: 2.4536\n",
      "Epoch 17/50\n",
      "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m10s\u001b[0m 471ms/step - accuracy: 0.9985 - loss: 0.0041 - val_accuracy: 0.5291 - val_loss: 2.0545\n",
      "Epoch 18/50\n",
      "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m10s\u001b[0m 472ms/step - accuracy: 0.9943 - loss: 0.0179 - val_accuracy: 0.6686 - val_loss: 1.5190\n",
      "Epoch 19/50\n",
      "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m10s\u001b[0m 473ms/step - accuracy: 0.9974 - loss: 0.0068 - val_accuracy: 0.5058 - val_loss: 2.9422\n",
      "Epoch 20/50\n",
      "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m10s\u001b[0m 471ms/step - accuracy: 1.0000 - loss: 8.3689e-04 - val_accuracy: 0.6163 - val_loss: 2.1229\n",
      "Epoch 21/50\n",
      "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m10s\u001b[0m 475ms/step - accuracy: 1.0000 - loss: 0.0015 - val_accuracy: 0.5814 - val_loss: 2.7866\n",
      "Epoch 22/50\n",
      "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m10s\u001b[0m 476ms/step - accuracy: 1.0000 - loss: 0.0022 - val_accuracy: 0.5640 - val_loss: 2.8546\n",
      "Epoch 23/50\n",
      "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m10s\u001b[0m 472ms/step - accuracy: 1.0000 - loss: 7.7541e-04 - val_accuracy: 0.5291 - val_loss: 3.3161\n",
      "Epoch 24/50\n",
      "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m10s\u001b[0m 473ms/step - accuracy: 1.0000 - loss: 8.7373e-04 - val_accuracy: 0.5523 - val_loss: 3.0915\n",
      "Epoch 25/50\n",
      "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m10s\u001b[0m 470ms/step - accuracy: 1.0000 - loss: 6.1739e-04 - val_accuracy: 0.5814 - val_loss: 2.5603\n",
      "Epoch 26/50\n",
      "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m10s\u001b[0m 474ms/step - accuracy: 1.0000 - loss: 4.1295e-04 - val_accuracy: 0.5523 - val_loss: 3.0935\n",
      "Epoch 27/50\n",
      "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m10s\u001b[0m 472ms/step - accuracy: 1.0000 - loss: 1.0038e-04 - val_accuracy: 0.5465 - val_loss: 3.1822\n",
      "Epoch 28/50\n",
      "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m10s\u001b[0m 476ms/step - accuracy: 1.0000 - loss: 1.8747e-04 - val_accuracy: 0.5640 - val_loss: 3.0209\n",
      "Epoch 29/50\n",
      "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m11s\u001b[0m 485ms/step - accuracy: 1.0000 - loss: 1.3773e-04 - val_accuracy: 0.5698 - val_loss: 3.0595\n",
      "Epoch 30/50\n",
      "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m11s\u001b[0m 482ms/step - accuracy: 1.0000 - loss: 2.5328e-04 - val_accuracy: 0.5930 - val_loss: 2.7834\n",
      "Epoch 31/50\n",
      "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m11s\u001b[0m 502ms/step - accuracy: 1.0000 - loss: 2.4205e-04 - val_accuracy: 0.6279 - val_loss: 2.6281\n",
      "Epoch 32/50\n",
      "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m11s\u001b[0m 502ms/step - accuracy: 1.0000 - loss: 1.5011e-04 - val_accuracy: 0.6105 - val_loss: 2.8008\n",
      "Epoch 33/50\n",
      "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m11s\u001b[0m 497ms/step - accuracy: 1.0000 - loss: 6.3123e-04 - val_accuracy: 0.5174 - val_loss: 3.5929\n",
      "Epoch 34/50\n",
      "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m11s\u001b[0m 498ms/step - accuracy: 1.0000 - loss: 3.0481e-04 - val_accuracy: 0.5465 - val_loss: 3.2632\n",
      "Epoch 35/50\n",
      "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m11s\u001b[0m 499ms/step - accuracy: 1.0000 - loss: 2.2090e-04 - val_accuracy: 0.5116 - val_loss: 3.5506\n",
      "Epoch 36/50\n",
      "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m11s\u001b[0m 494ms/step - accuracy: 1.0000 - loss: 4.9412e-04 - val_accuracy: 0.5756 - val_loss: 2.6454\n",
      "Epoch 37/50\n",
      "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m11s\u001b[0m 496ms/step - accuracy: 0.9992 - loss: 0.0046 - val_accuracy: 0.5930 - val_loss: 2.2873\n",
      "Epoch 38/50\n",
      "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m11s\u001b[0m 496ms/step - accuracy: 0.9981 - loss: 0.0059 - val_accuracy: 0.5872 - val_loss: 1.9379\n",
      "Epoch 39/50\n",
      "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m11s\u001b[0m 495ms/step - accuracy: 0.9962 - loss: 0.0103 - val_accuracy: 0.5174 - val_loss: 2.8965\n",
      "Epoch 40/50\n",
      "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m11s\u001b[0m 478ms/step - accuracy: 0.9980 - loss: 0.0109 - val_accuracy: 0.5407 - val_loss: 2.4574\n",
      "Epoch 41/50\n",
      "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m11s\u001b[0m 479ms/step - accuracy: 0.9926 - loss: 0.0236 - val_accuracy: 0.6860 - val_loss: 1.4016\n",
      "Epoch 42/50\n",
      "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m10s\u001b[0m 475ms/step - accuracy: 0.9963 - loss: 0.0082 - val_accuracy: 0.6105 - val_loss: 2.0804\n",
      "Epoch 43/50\n",
      "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m10s\u001b[0m 475ms/step - accuracy: 0.9999 - loss: 0.0028 - val_accuracy: 0.6570 - val_loss: 2.0860\n",
      "Epoch 44/50\n",
      "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m10s\u001b[0m 477ms/step - accuracy: 0.9890 - loss: 0.0361 - val_accuracy: 0.6221 - val_loss: 1.3736\n",
      "Epoch 45/50\n",
      "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m11s\u001b[0m 478ms/step - accuracy: 0.9974 - loss: 0.0106 - val_accuracy: 0.6279 - val_loss: 2.0968\n",
      "Epoch 46/50\n",
      "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m11s\u001b[0m 478ms/step - accuracy: 0.9997 - loss: 0.0057 - val_accuracy: 0.5814 - val_loss: 2.5068\n",
      "Epoch 47/50\n",
      "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m11s\u001b[0m 479ms/step - accuracy: 0.9993 - loss: 0.0015 - val_accuracy: 0.6279 - val_loss: 2.4447\n",
      "Epoch 48/50\n",
      "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m11s\u001b[0m 478ms/step - accuracy: 1.0000 - loss: 0.0019 - val_accuracy: 0.5640 - val_loss: 3.2987\n",
      "Epoch 49/50\n",
      "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m10s\u001b[0m 476ms/step - accuracy: 1.0000 - loss: 4.2574e-04 - val_accuracy: 0.6453 - val_loss: 2.5677\n",
      "Epoch 50/50\n",
      "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m10s\u001b[0m 475ms/step - accuracy: 0.9960 - loss: 0.0054 - val_accuracy: 0.4186 - val_loss: 4.3842\n",
      "WARNING:tensorflow:5 out of the last 11 calls to <function TensorFlowTrainer.make_predict_function.<locals>.one_step_on_data_distributed at 0x779db6d7f420> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has reduce_retracing=True option that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/guide/function#controlling_retracing and https://www.tensorflow.org/api_docs/python/tf/function for  more details.\n",
      "\u001b[1m3/5\u001b[0m \u001b[32m━━━━━━━━━━━━\u001b[0m\u001b[37m━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 46ms/stepWARNING:tensorflow:5 out of the last 11 calls to <function TensorFlowTrainer.make_predict_function.<locals>.one_step_on_data_distributed at 0x779db6d7f420> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has reduce_retracing=True option that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/guide/function#controlling_retracing and https://www.tensorflow.org/api_docs/python/tf/function for  more details.\n",
      "\u001b[1m5/5\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 56ms/step\n",
      "CNN Accuracy: 0.5639\n",
      "CNN Classification Report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.70      0.92      0.79        62\n",
      "           1       0.36      0.36      0.36        14\n",
      "           2       0.67      0.42      0.51        53\n",
      "\n",
      "    accuracy                           0.65       129\n",
      "   macro avg       0.57      0.56      0.55       129\n",
      "weighted avg       0.65      0.65      0.63       129\n",
      "\n",
      "Epoch 1/50\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/mojo/.local/lib/python3.12/site-packages/keras/src/layers/core/dense.py:87: UserWarning: Do not pass an `input_shape`/`input_dim` argument to a layer. When using Sequential models, prefer using an `Input(shape)` object as the first layer in the model instead.\n",
      "  super().__init__(activity_regularizer=activity_regularizer, **kwargs)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 7ms/step - accuracy: 0.5122 - loss: 1.5799 - val_accuracy: 0.6047 - val_loss: 0.8302\n",
      "Epoch 2/50\n",
      "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.6710 - loss: 0.9304 - val_accuracy: 0.6512 - val_loss: 0.7897\n",
      "Epoch 3/50\n",
      "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.7008 - loss: 0.7813 - val_accuracy: 0.6453 - val_loss: 0.7955\n",
      "Epoch 4/50\n",
      "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.6946 - loss: 0.7603 - val_accuracy: 0.5988 - val_loss: 0.8921\n",
      "Epoch 5/50\n",
      "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.7592 - loss: 0.6704 - val_accuracy: 0.5814 - val_loss: 0.9152\n",
      "Epoch 6/50\n",
      "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.7759 - loss: 0.5246 - val_accuracy: 0.6453 - val_loss: 0.8228\n",
      "Epoch 7/50\n",
      "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.8169 - loss: 0.4367 - val_accuracy: 0.6047 - val_loss: 1.0628\n",
      "Epoch 8/50\n",
      "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.8358 - loss: 0.3771 - val_accuracy: 0.6395 - val_loss: 0.8743\n",
      "Epoch 9/50\n",
      "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.8310 - loss: 0.4385 - val_accuracy: 0.6512 - val_loss: 0.9329\n",
      "Epoch 10/50\n",
      "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.8941 - loss: 0.2993 - val_accuracy: 0.5930 - val_loss: 1.1780\n",
      "Epoch 11/50\n",
      "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.9076 - loss: 0.2457 - val_accuracy: 0.6163 - val_loss: 1.2098\n",
      "Epoch 12/50\n",
      "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.9224 - loss: 0.1998 - val_accuracy: 0.6570 - val_loss: 1.1627\n",
      "Epoch 13/50\n",
      "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.9228 - loss: 0.2199 - val_accuracy: 0.5756 - val_loss: 1.5630\n",
      "Epoch 14/50\n",
      "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.9400 - loss: 0.1913 - val_accuracy: 0.6163 - val_loss: 1.4774\n",
      "Epoch 15/50\n",
      "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.9482 - loss: 0.1500 - val_accuracy: 0.5930 - val_loss: 1.5805\n",
      "Epoch 16/50\n",
      "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.9515 - loss: 0.1227 - val_accuracy: 0.6279 - val_loss: 1.5220\n",
      "Epoch 17/50\n",
      "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.9475 - loss: 0.1555 - val_accuracy: 0.5814 - val_loss: 2.0590\n",
      "Epoch 18/50\n",
      "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.9708 - loss: 0.0977 - val_accuracy: 0.5523 - val_loss: 1.8330\n",
      "Epoch 19/50\n",
      "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.9512 - loss: 0.1456 - val_accuracy: 0.6105 - val_loss: 1.8250\n",
      "Epoch 20/50\n",
      "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.9503 - loss: 0.1582 - val_accuracy: 0.5523 - val_loss: 2.4369\n",
      "Epoch 21/50\n",
      "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.9741 - loss: 0.0877 - val_accuracy: 0.6337 - val_loss: 1.8446\n",
      "Epoch 22/50\n",
      "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.9664 - loss: 0.0912 - val_accuracy: 0.5756 - val_loss: 1.9866\n",
      "Epoch 23/50\n",
      "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.9741 - loss: 0.0842 - val_accuracy: 0.5756 - val_loss: 1.9816\n",
      "Epoch 24/50\n",
      "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.9651 - loss: 0.1404 - val_accuracy: 0.6337 - val_loss: 1.7097\n",
      "Epoch 25/50\n",
      "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.9868 - loss: 0.0585 - val_accuracy: 0.5814 - val_loss: 2.0216\n",
      "Epoch 26/50\n",
      "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.9751 - loss: 0.0597 - val_accuracy: 0.6221 - val_loss: 1.8239\n",
      "Epoch 27/50\n",
      "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.9874 - loss: 0.0414 - val_accuracy: 0.6163 - val_loss: 1.8799\n",
      "Epoch 28/50\n",
      "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.9835 - loss: 0.0533 - val_accuracy: 0.6453 - val_loss: 1.9997\n",
      "Epoch 29/50\n",
      "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.9755 - loss: 0.0674 - val_accuracy: 0.5930 - val_loss: 2.4445\n",
      "Epoch 30/50\n",
      "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.9799 - loss: 0.0651 - val_accuracy: 0.5640 - val_loss: 2.4935\n",
      "Epoch 31/50\n",
      "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.9834 - loss: 0.0604 - val_accuracy: 0.5581 - val_loss: 2.3333\n",
      "Epoch 32/50\n",
      "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.9805 - loss: 0.0666 - val_accuracy: 0.5407 - val_loss: 2.7419\n",
      "Epoch 33/50\n",
      "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.9850 - loss: 0.0376 - val_accuracy: 0.6221 - val_loss: 2.5302\n",
      "Epoch 34/50\n",
      "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - accuracy: 0.9898 - loss: 0.0256 - val_accuracy: 0.6105 - val_loss: 2.1531\n",
      "Epoch 35/50\n",
      "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.9798 - loss: 0.0539 - val_accuracy: 0.5581 - val_loss: 2.9848\n",
      "Epoch 36/50\n",
      "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.9875 - loss: 0.0335 - val_accuracy: 0.5988 - val_loss: 2.8956\n",
      "Epoch 37/50\n",
      "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.9898 - loss: 0.0516 - val_accuracy: 0.6512 - val_loss: 2.5505\n",
      "Epoch 38/50\n",
      "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.9816 - loss: 0.0387 - val_accuracy: 0.6453 - val_loss: 2.6360\n",
      "Epoch 39/50\n",
      "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.9917 - loss: 0.0281 - val_accuracy: 0.6570 - val_loss: 2.1600\n",
      "Epoch 40/50\n",
      "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.9831 - loss: 0.0395 - val_accuracy: 0.6686 - val_loss: 2.4686\n",
      "Epoch 41/50\n",
      "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.9784 - loss: 0.0459 - val_accuracy: 0.6047 - val_loss: 3.1757\n",
      "Epoch 42/50\n",
      "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.9844 - loss: 0.0347 - val_accuracy: 0.5698 - val_loss: 3.8820\n",
      "Epoch 43/50\n",
      "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.9965 - loss: 0.0099 - val_accuracy: 0.6105 - val_loss: 3.1284\n",
      "Epoch 44/50\n",
      "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.9941 - loss: 0.0243 - val_accuracy: 0.6047 - val_loss: 3.1900\n",
      "Epoch 45/50\n",
      "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.9933 - loss: 0.0638 - val_accuracy: 0.5814 - val_loss: 3.2524\n",
      "Epoch 46/50\n",
      "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.9955 - loss: 0.0156 - val_accuracy: 0.6163 - val_loss: 3.0172\n",
      "Epoch 47/50\n",
      "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.9864 - loss: 0.0468 - val_accuracy: 0.6105 - val_loss: 2.9972\n",
      "Epoch 48/50\n",
      "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.9923 - loss: 0.0284 - val_accuracy: 0.5872 - val_loss: 3.1194\n",
      "Epoch 49/50\n",
      "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.9868 - loss: 0.0400 - val_accuracy: 0.5291 - val_loss: 3.7755\n",
      "Epoch 50/50\n",
      "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.9862 - loss: 0.0237 - val_accuracy: 0.5698 - val_loss: 3.5925\n",
      "\u001b[1m5/5\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 8ms/step \n",
      "ANN Accuracy: 0.7005\n",
      "ANN Classification Report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.89      0.79      0.84        62\n",
      "           1       0.50      0.50      0.50        14\n",
      "           2       0.72      0.81      0.76        53\n",
      "\n",
      "    accuracy                           0.77       129\n",
      "   macro avg       0.70      0.70      0.70       129\n",
      "weighted avg       0.78      0.77      0.77       129\n",
      "\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "from sklearn.preprocessing import LabelEncoder\n",
    "from sklearn.svm import SVC\n",
    "from sklearn.metrics import balanced_accuracy_score, classification_report\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "\n",
    "# Load the data\n",
    "train_data = np.load('../Files/extracted_features/layer_features_lv60_self/train_3.npz')\n",
    "test_data = np.load('../Files/extracted_features/layer_features_lv60_self/test_3.npz')\n",
    "\n",
    "train_features = train_data['features']  # Ensure these have 1024 features\n",
    "test_features = test_data['features']    # Ensure these have 1024 features\n",
    "\n",
    "# Read Age labels instead of Gender\n",
    "train_labels = pd.read_csv('../Files/labels/y_train.csv').Age_Group\n",
    "test_labels = pd.read_csv('../Files/labels/y_test.csv').Age_Group\n",
    "\n",
    "# Encode the labels\n",
    "label_encoder = LabelEncoder()\n",
    "train_labels_encoded = label_encoder.fit_transform(train_labels)\n",
    "\n",
    "# Handle unseen labels in test set by filtering out labels not present in train set\n",
    "test_labels_filtered = test_labels[test_labels.isin(train_labels.unique())]\n",
    "test_features_filtered = test_features[test_labels.isin(train_labels.unique())]\n",
    "test_labels_encoded = label_encoder.transform(test_labels_filtered)\n",
    "\n",
    "# Standardize features\n",
    "scaler = StandardScaler()\n",
    "train_features_normalized = scaler.fit_transform(train_features)\n",
    "test_features_normalized = scaler.transform(test_features_filtered)\n",
    "\n",
    "# SVM model\n",
    "svm_model = SVC(kernel='linear', C=10.0, gamma='scale', random_state=42)\n",
    "svm_model.fit(train_features_normalized, train_labels_encoded)\n",
    "\n",
    "# SVM Prediction and Evaluation\n",
    "svm_predictions = svm_model.predict(test_features_normalized)\n",
    "svm_accuracy = balanced_accuracy_score(test_labels_encoded, svm_predictions)\n",
    "print(f\"SVM Accuracy: {svm_accuracy:.4f}\")\n",
    "print(\"SVM Classification Report:\")\n",
    "print(classification_report(test_labels_encoded, svm_predictions))\n",
    "\n",
    "# CNN model (TensorFlow)\n",
    "import tensorflow as tf\n",
    "from tensorflow.keras.models import Sequential\n",
    "from tensorflow.keras.layers import Conv1D, Flatten, Dense, Dropout\n",
    "\n",
    "train_features_cnn = np.expand_dims(train_features_normalized, axis=-1)  # Shape: (num_samples, 1024, 1)\n",
    "test_features_cnn = np.expand_dims(test_features_normalized, axis=-1)    # Shape: (num_samples, 1024, 1)\n",
    "\n",
    "cnn_model = Sequential([\n",
    "    Conv1D(64, kernel_size=5, activation='relu', input_shape=(1024, 1)),  # Updated input shape to 1024\n",
    "    Conv1D(128, kernel_size=5, activation='relu'),\n",
    "    Conv1D(256, kernel_size=5, activation='relu'),\n",
    "    Flatten(),\n",
    "    Dense(256, activation='relu'),\n",
    "    Dropout(0.5),\n",
    "    Dense(len(label_encoder.classes_), activation='softmax')\n",
    "])\n",
    "\n",
    "cnn_model.compile(optimizer='adam', loss='sparse_categorical_crossentropy', metrics=['accuracy'])\n",
    "\n",
    "cnn_model.fit(train_features_cnn, train_labels_encoded, epochs=50, batch_size=32, validation_split=0.2)\n",
    "\n",
    "# CNN Prediction and Evaluation\n",
    "cnn_predictions = np.argmax(cnn_model.predict(test_features_cnn), axis=-1)\n",
    "cnn_accuracy = balanced_accuracy_score(test_labels_encoded, cnn_predictions)\n",
    "print(f\"CNN Accuracy: {cnn_accuracy:.4f}\")\n",
    "print(\"CNN Classification Report:\")\n",
    "print(classification_report(test_labels_encoded, cnn_predictions))\n",
    "\n",
    "# ANN model (TensorFlow)\n",
    "ann_model = Sequential([\n",
    "    Dense(512, activation='relu', input_shape=(1024,)),  # Updated input shape to 1024\n",
    "    Dropout(0.5),\n",
    "    Dense(256, activation='relu'),\n",
    "    Dropout(0.5),\n",
    "    Dense(128, activation='relu'),\n",
    "    Dropout(0.5),\n",
    "    Dense(len(label_encoder.classes_), activation='softmax')\n",
    "])\n",
    "\n",
    "ann_model.compile(optimizer='adam', loss='sparse_categorical_crossentropy', metrics=['accuracy'])\n",
    "\n",
    "ann_model.fit(train_features_normalized, train_labels_encoded, epochs=50, batch_size=32, validation_split=0.2)\n",
    "\n",
    "# ANN Prediction and Evaluation\n",
    "ann_predictions = np.argmax(ann_model.predict(test_features_normalized), axis=-1)\n",
    "ann_accuracy = balanced_accuracy_score(test_labels_encoded, ann_predictions)\n",
    "print(f\"ANN Accuracy: {ann_accuracy:.4f}\")\n",
    "print(\"ANN Classification Report:\")\n",
    "print(classification_report(test_labels_encoded, ann_predictions))\n",
    "\n",
    "# PyTorch CNN Model\n",
    "import torch\n",
    "from torch.utils.data import DataLoader, TensorDataset\n",
    "\n",
    "X_train_tensor = torch.tensor(train_features_cnn, dtype=torch.float32).permute(0, 2, 1)  # Shape: (num_samples, 1, 1024)\n",
    "y_train_tensor = torch.tensor(train_labels_encoded, dtype=torch.long)\n",
    "X_test_tensor = torch.tensor(test_features_cnn, dtype=torch.float32).permute(0, 2, 1)    # Shape: (num_samples, 1, 1024)\n",
    "y_test_tensor = torch.tensor(test_labels_encoded, dtype=torch.long)\n",
    "\n",
    "train_dataset = TensorDataset(X_train_tensor, y_train_tensor)\n",
    "test_dataset = TensorDataset(X_test_tensor, y_test_tensor)\n",
    "\n",
    "train_loader = DataLoader(train_dataset, batch_size=64, shuffle=True)\n",
    "test_loader = DataLoader(test_dataset, batch_size=64, shuffle=False)\n",
    "\n",
    "import torch.nn as nn\n",
    "import torch.optim as optim\n",
    "\n",
    "class CNN1DModel(nn.Module):\n",
    "    def __init__(self, input_channels, num_classes):\n",
    "        super(CNN1DModel, self).__init__()\n",
    "        self.conv1 = nn.Conv1d(input_channels, 32, kernel_size=5, stride=1, padding=2)\n",
    "        self.bn1 = nn.BatchNorm1d(32)\n",
    "        self.relu = nn.ReLU()\n",
    "        self.conv2 = nn.Conv1d(32, 64, kernel_size=5, stride=1, padding=2)\n",
    "        self.bn2 = nn.BatchNorm1d(64)\n",
    "        self.conv3 = nn.Conv1d(64, 128, kernel_size=5, stride=1, padding=2)\n",
    "        self.bn3 = nn.BatchNorm1d(128)\n",
    "        self.flatten = nn.Flatten()\n",
    "        self.fc1 = nn.Linear(128 * 1024, 512)  # Updated to 1024 features\n",
    "        self.fc2 = nn.Linear(512, num_classes)\n",
    "        self.dropout = nn.Dropout(0.5)\n",
    "    \n",
    "    def forward(self, x):\n",
    "        x = self.relu(self.bn1(self.conv1(x)))\n",
    "        x = self.relu(self.bn2(self.conv2(x)))\n",
    "        x = self.relu(self.bn3(self.conv3(x)))\n",
    "        x = self.flatten(x)\n",
    "        x = self.dropout(self.relu(self.fc1(x)))\n",
    "        x = self.fc2(x)\n",
    "        return x\n",
    "\n",
    "input_channels = 1\n",
    "num_classes = len(label_encoder.classes_)\n",
    "model = CNN1DModel(input_channels, num_classes)\n",
    "criterion = nn.CrossEntropyLoss()\n",
    "optimizer = optim.Adam(model.parameters(), lr=0.001)\n",
    "\n",
    "# Training loop and evaluation (not shown)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "SVM Accuracy: 0.6786\n",
      "SVM Classification Report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.87      0.76      0.81        62\n",
      "           1       0.60      0.43      0.50        14\n",
      "           2       0.69      0.85      0.76        53\n",
      "\n",
      "    accuracy                           0.76       129\n",
      "   macro avg       0.72      0.68      0.69       129\n",
      "weighted avg       0.77      0.76      0.76       129\n",
      "\n",
      "Epoch 1/50\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/mojo/.local/lib/python3.12/site-packages/keras/src/layers/convolutional/base_conv.py:107: UserWarning: Do not pass an `input_shape`/`input_dim` argument to a layer. When using Sequential models, prefer using an `Input(shape)` object as the first layer in the model instead.\n",
      "  super().__init__(activity_regularizer=activity_regularizer, **kwargs)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m12s\u001b[0m 485ms/step - accuracy: 0.5365 - loss: 2.9517 - val_accuracy: 0.4012 - val_loss: 1.0800\n",
      "Epoch 2/50\n",
      "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m10s\u001b[0m 463ms/step - accuracy: 0.7269 - loss: 0.6049 - val_accuracy: 0.4244 - val_loss: 1.1173\n",
      "Epoch 3/50\n",
      "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m10s\u001b[0m 466ms/step - accuracy: 0.8382 - loss: 0.4018 - val_accuracy: 0.5930 - val_loss: 0.8022\n",
      "Epoch 4/50\n",
      "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m10s\u001b[0m 473ms/step - accuracy: 0.9175 - loss: 0.2166 - val_accuracy: 0.5291 - val_loss: 1.1255\n",
      "Epoch 5/50\n",
      "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m10s\u001b[0m 467ms/step - accuracy: 0.9568 - loss: 0.1342 - val_accuracy: 0.6512 - val_loss: 0.9097\n",
      "Epoch 6/50\n",
      "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m10s\u001b[0m 466ms/step - accuracy: 0.9627 - loss: 0.0988 - val_accuracy: 0.5814 - val_loss: 1.3785\n",
      "Epoch 7/50\n",
      "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m10s\u001b[0m 466ms/step - accuracy: 0.9936 - loss: 0.0289 - val_accuracy: 0.5640 - val_loss: 1.7681\n",
      "Epoch 8/50\n",
      "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m10s\u001b[0m 463ms/step - accuracy: 0.9952 - loss: 0.0251 - val_accuracy: 0.4942 - val_loss: 1.9304\n",
      "Epoch 9/50\n",
      "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m10s\u001b[0m 463ms/step - accuracy: 0.9906 - loss: 0.0249 - val_accuracy: 0.5698 - val_loss: 1.6662\n",
      "Epoch 10/50\n",
      "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m10s\u001b[0m 469ms/step - accuracy: 0.9983 - loss: 0.0120 - val_accuracy: 0.6047 - val_loss: 1.5503\n",
      "Epoch 11/50\n",
      "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m10s\u001b[0m 473ms/step - accuracy: 0.9978 - loss: 0.0119 - val_accuracy: 0.6744 - val_loss: 1.1652\n",
      "Epoch 12/50\n",
      "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m10s\u001b[0m 472ms/step - accuracy: 0.9938 - loss: 0.0274 - val_accuracy: 0.6628 - val_loss: 1.0753\n",
      "Epoch 13/50\n",
      "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m10s\u001b[0m 466ms/step - accuracy: 0.9998 - loss: 0.0134 - val_accuracy: 0.5988 - val_loss: 1.9194\n",
      "Epoch 14/50\n",
      "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m10s\u001b[0m 467ms/step - accuracy: 0.9975 - loss: 0.0075 - val_accuracy: 0.6047 - val_loss: 1.8400\n",
      "Epoch 15/50\n",
      "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m10s\u001b[0m 467ms/step - accuracy: 0.9972 - loss: 0.0143 - val_accuracy: 0.6395 - val_loss: 1.3566\n",
      "Epoch 16/50\n",
      "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m10s\u001b[0m 463ms/step - accuracy: 0.9963 - loss: 0.0191 - val_accuracy: 0.6221 - val_loss: 1.8838\n",
      "Epoch 17/50\n",
      "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m10s\u001b[0m 468ms/step - accuracy: 0.9995 - loss: 0.0045 - val_accuracy: 0.6744 - val_loss: 1.5417\n",
      "Epoch 18/50\n",
      "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m10s\u001b[0m 470ms/step - accuracy: 1.0000 - loss: 0.0038 - val_accuracy: 0.5872 - val_loss: 2.4240\n",
      "Epoch 19/50\n",
      "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m10s\u001b[0m 466ms/step - accuracy: 1.0000 - loss: 0.0017 - val_accuracy: 0.6105 - val_loss: 2.3424\n",
      "Epoch 20/50\n",
      "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m10s\u001b[0m 463ms/step - accuracy: 0.9976 - loss: 0.0081 - val_accuracy: 0.5349 - val_loss: 2.7505\n",
      "Epoch 21/50\n",
      "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m10s\u001b[0m 462ms/step - accuracy: 0.9973 - loss: 0.0058 - val_accuracy: 0.7442 - val_loss: 0.9437\n",
      "Epoch 22/50\n",
      "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m10s\u001b[0m 465ms/step - accuracy: 0.9970 - loss: 0.0082 - val_accuracy: 0.6047 - val_loss: 2.0930\n",
      "Epoch 23/50\n",
      "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m10s\u001b[0m 467ms/step - accuracy: 1.0000 - loss: 0.0016 - val_accuracy: 0.6163 - val_loss: 2.1560\n",
      "Epoch 24/50\n",
      "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m10s\u001b[0m 469ms/step - accuracy: 0.9956 - loss: 0.0118 - val_accuracy: 0.5058 - val_loss: 3.1630\n",
      "Epoch 25/50\n",
      "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m10s\u001b[0m 473ms/step - accuracy: 0.9923 - loss: 0.0437 - val_accuracy: 0.5698 - val_loss: 1.7402\n",
      "Epoch 26/50\n",
      "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m10s\u001b[0m 470ms/step - accuracy: 1.0000 - loss: 0.0039 - val_accuracy: 0.6802 - val_loss: 1.5459\n",
      "Epoch 27/50\n",
      "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m10s\u001b[0m 464ms/step - accuracy: 0.9972 - loss: 0.0053 - val_accuracy: 0.5872 - val_loss: 2.2563\n",
      "Epoch 28/50\n",
      "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m10s\u001b[0m 463ms/step - accuracy: 0.9978 - loss: 0.0041 - val_accuracy: 0.6163 - val_loss: 1.8801\n",
      "Epoch 29/50\n",
      "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m10s\u001b[0m 462ms/step - accuracy: 0.9940 - loss: 0.0197 - val_accuracy: 0.6105 - val_loss: 1.6557\n",
      "Epoch 30/50\n",
      "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m10s\u001b[0m 465ms/step - accuracy: 0.9964 - loss: 0.0073 - val_accuracy: 0.6686 - val_loss: 1.6172\n",
      "Epoch 31/50\n",
      "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m10s\u001b[0m 470ms/step - accuracy: 1.0000 - loss: 0.0012 - val_accuracy: 0.6279 - val_loss: 2.0210\n",
      "Epoch 32/50\n",
      "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m10s\u001b[0m 470ms/step - accuracy: 1.0000 - loss: 8.8167e-04 - val_accuracy: 0.5640 - val_loss: 2.6895\n",
      "Epoch 33/50\n",
      "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m10s\u001b[0m 466ms/step - accuracy: 1.0000 - loss: 6.6378e-04 - val_accuracy: 0.5581 - val_loss: 2.9768\n",
      "Epoch 34/50\n",
      "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m10s\u001b[0m 466ms/step - accuracy: 1.0000 - loss: 0.0016 - val_accuracy: 0.5872 - val_loss: 2.5177\n",
      "Epoch 35/50\n",
      "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m11s\u001b[0m 484ms/step - accuracy: 0.9991 - loss: 0.0011 - val_accuracy: 0.5756 - val_loss: 2.6316\n",
      "Epoch 36/50\n",
      "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m10s\u001b[0m 468ms/step - accuracy: 1.0000 - loss: 4.7720e-04 - val_accuracy: 0.6512 - val_loss: 2.2466\n",
      "Epoch 37/50\n",
      "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m10s\u001b[0m 473ms/step - accuracy: 1.0000 - loss: 0.0034 - val_accuracy: 0.5581 - val_loss: 2.6100\n",
      "Epoch 38/50\n",
      "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m11s\u001b[0m 483ms/step - accuracy: 0.9986 - loss: 0.0030 - val_accuracy: 0.6686 - val_loss: 2.0022\n",
      "Epoch 39/50\n",
      "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m11s\u001b[0m 484ms/step - accuracy: 1.0000 - loss: 0.0011 - val_accuracy: 0.7209 - val_loss: 1.5346\n",
      "Epoch 40/50\n",
      "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m11s\u001b[0m 493ms/step - accuracy: 1.0000 - loss: 2.6781e-04 - val_accuracy: 0.6686 - val_loss: 1.8679\n",
      "Epoch 41/50\n",
      "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m11s\u001b[0m 480ms/step - accuracy: 0.9979 - loss: 0.0048 - val_accuracy: 0.5814 - val_loss: 2.2822\n",
      "Epoch 42/50\n",
      "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m10s\u001b[0m 468ms/step - accuracy: 0.9984 - loss: 0.0027 - val_accuracy: 0.6744 - val_loss: 1.5583\n",
      "Epoch 43/50\n",
      "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m10s\u001b[0m 468ms/step - accuracy: 1.0000 - loss: 0.0015 - val_accuracy: 0.5233 - val_loss: 2.8872\n",
      "Epoch 44/50\n",
      "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m10s\u001b[0m 472ms/step - accuracy: 1.0000 - loss: 0.0012 - val_accuracy: 0.5930 - val_loss: 2.4268\n",
      "Epoch 45/50\n",
      "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m10s\u001b[0m 468ms/step - accuracy: 1.0000 - loss: 1.8705e-04 - val_accuracy: 0.6047 - val_loss: 2.4244\n",
      "Epoch 46/50\n",
      "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m10s\u001b[0m 466ms/step - accuracy: 1.0000 - loss: 2.8428e-04 - val_accuracy: 0.5756 - val_loss: 2.6822\n",
      "Epoch 47/50\n",
      "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m10s\u001b[0m 465ms/step - accuracy: 1.0000 - loss: 6.1210e-04 - val_accuracy: 0.5872 - val_loss: 2.7942\n",
      "Epoch 48/50\n",
      "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m11s\u001b[0m 479ms/step - accuracy: 1.0000 - loss: 4.5455e-04 - val_accuracy: 0.5640 - val_loss: 3.0571\n",
      "Epoch 49/50\n",
      "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m11s\u001b[0m 479ms/step - accuracy: 1.0000 - loss: 2.0075e-04 - val_accuracy: 0.5930 - val_loss: 2.7965\n",
      "Epoch 50/50\n",
      "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m11s\u001b[0m 480ms/step - accuracy: 1.0000 - loss: 2.3189e-04 - val_accuracy: 0.6279 - val_loss: 2.7669\n",
      "\u001b[1m5/5\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 46ms/step\n",
      "CNN Accuracy: 0.6525\n",
      "CNN Classification Report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.81      0.77      0.79        62\n",
      "           1       0.55      0.43      0.48        14\n",
      "           2       0.68      0.75      0.71        53\n",
      "\n",
      "    accuracy                           0.73       129\n",
      "   macro avg       0.68      0.65      0.66       129\n",
      "weighted avg       0.73      0.73      0.73       129\n",
      "\n",
      "Epoch 1/50\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/mojo/.local/lib/python3.12/site-packages/keras/src/layers/core/dense.py:87: UserWarning: Do not pass an `input_shape`/`input_dim` argument to a layer. When using Sequential models, prefer using an `Input(shape)` object as the first layer in the model instead.\n",
      "  super().__init__(activity_regularizer=activity_regularizer, **kwargs)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 9ms/step - accuracy: 0.4476 - loss: 1.7114 - val_accuracy: 0.3837 - val_loss: 1.1014\n",
      "Epoch 2/50\n",
      "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.6368 - loss: 0.9967 - val_accuracy: 0.4186 - val_loss: 1.0920\n",
      "Epoch 3/50\n",
      "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.6922 - loss: 0.7880 - val_accuracy: 0.4419 - val_loss: 0.9981\n",
      "Epoch 4/50\n",
      "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.7174 - loss: 0.6506 - val_accuracy: 0.5814 - val_loss: 0.8484\n",
      "Epoch 5/50\n",
      "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.7622 - loss: 0.5875 - val_accuracy: 0.4360 - val_loss: 1.1170\n",
      "Epoch 6/50\n",
      "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.7560 - loss: 0.5696 - val_accuracy: 0.5988 - val_loss: 0.8123\n",
      "Epoch 7/50\n",
      "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.8271 - loss: 0.4218 - val_accuracy: 0.5058 - val_loss: 0.9950\n",
      "Epoch 8/50\n",
      "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.8465 - loss: 0.4369 - val_accuracy: 0.5698 - val_loss: 0.8695\n",
      "Epoch 9/50\n",
      "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - accuracy: 0.8503 - loss: 0.3718 - val_accuracy: 0.5930 - val_loss: 0.8387\n",
      "Epoch 10/50\n",
      "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.8696 - loss: 0.2972 - val_accuracy: 0.5349 - val_loss: 1.0330\n",
      "Epoch 11/50\n",
      "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.8979 - loss: 0.2597 - val_accuracy: 0.5988 - val_loss: 0.9102\n",
      "Epoch 12/50\n",
      "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.9132 - loss: 0.2430 - val_accuracy: 0.5640 - val_loss: 1.0490\n",
      "Epoch 13/50\n",
      "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.9169 - loss: 0.2206 - val_accuracy: 0.6163 - val_loss: 0.9423\n",
      "Epoch 14/50\n",
      "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.9052 - loss: 0.2937 - val_accuracy: 0.5291 - val_loss: 1.1678\n",
      "Epoch 15/50\n",
      "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.9348 - loss: 0.1875 - val_accuracy: 0.5523 - val_loss: 1.1619\n",
      "Epoch 16/50\n",
      "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.9517 - loss: 0.1245 - val_accuracy: 0.5349 - val_loss: 1.3867\n",
      "Epoch 17/50\n",
      "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.9382 - loss: 0.1467 - val_accuracy: 0.5814 - val_loss: 1.2161\n",
      "Epoch 18/50\n",
      "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.9734 - loss: 0.0912 - val_accuracy: 0.6105 - val_loss: 1.2942\n",
      "Epoch 19/50\n",
      "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.9613 - loss: 0.1071 - val_accuracy: 0.5698 - val_loss: 1.5222\n",
      "Epoch 20/50\n",
      "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.9503 - loss: 0.1323 - val_accuracy: 0.5465 - val_loss: 1.6759\n",
      "Epoch 21/50\n",
      "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.9659 - loss: 0.1032 - val_accuracy: 0.5349 - val_loss: 1.8027\n",
      "Epoch 22/50\n",
      "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.9566 - loss: 0.1114 - val_accuracy: 0.6047 - val_loss: 1.5070\n",
      "Epoch 23/50\n",
      "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.9682 - loss: 0.0843 - val_accuracy: 0.5291 - val_loss: 1.8861\n",
      "Epoch 24/50\n",
      "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.9779 - loss: 0.0642 - val_accuracy: 0.5640 - val_loss: 1.7589\n",
      "Epoch 25/50\n",
      "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - accuracy: 0.9620 - loss: 0.1399 - val_accuracy: 0.5698 - val_loss: 1.5897\n",
      "Epoch 26/50\n",
      "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.9751 - loss: 0.0743 - val_accuracy: 0.5407 - val_loss: 1.9486\n",
      "Epoch 27/50\n",
      "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.9654 - loss: 0.0819 - val_accuracy: 0.5872 - val_loss: 1.6046\n",
      "Epoch 28/50\n",
      "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.9492 - loss: 0.1187 - val_accuracy: 0.5116 - val_loss: 2.1047\n",
      "Epoch 29/50\n",
      "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.9866 - loss: 0.0377 - val_accuracy: 0.5872 - val_loss: 1.7052\n",
      "Epoch 30/50\n",
      "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.9673 - loss: 0.0620 - val_accuracy: 0.6163 - val_loss: 1.5610\n",
      "Epoch 31/50\n",
      "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.9907 - loss: 0.0294 - val_accuracy: 0.5930 - val_loss: 1.9962\n",
      "Epoch 32/50\n",
      "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.9847 - loss: 0.0568 - val_accuracy: 0.5756 - val_loss: 2.1842\n",
      "Epoch 33/50\n",
      "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.9818 - loss: 0.0420 - val_accuracy: 0.5523 - val_loss: 2.4890\n",
      "Epoch 34/50\n",
      "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.9861 - loss: 0.0464 - val_accuracy: 0.6105 - val_loss: 2.0655\n",
      "Epoch 35/50\n",
      "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.9881 - loss: 0.0285 - val_accuracy: 0.5640 - val_loss: 2.8465\n",
      "Epoch 36/50\n",
      "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.9840 - loss: 0.0400 - val_accuracy: 0.5116 - val_loss: 3.4760\n",
      "Epoch 37/50\n",
      "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.9781 - loss: 0.0698 - val_accuracy: 0.5407 - val_loss: 2.9186\n",
      "Epoch 38/50\n",
      "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.9881 - loss: 0.0407 - val_accuracy: 0.5523 - val_loss: 3.0198\n",
      "Epoch 39/50\n",
      "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.9859 - loss: 0.0517 - val_accuracy: 0.5349 - val_loss: 3.3043\n",
      "Epoch 40/50\n",
      "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.9948 - loss: 0.0201 - val_accuracy: 0.5116 - val_loss: 3.5933\n",
      "Epoch 41/50\n",
      "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.9891 - loss: 0.0192 - val_accuracy: 0.6047 - val_loss: 2.6826\n",
      "Epoch 42/50\n",
      "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.9818 - loss: 0.0505 - val_accuracy: 0.5698 - val_loss: 3.0530\n",
      "Epoch 43/50\n",
      "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.9874 - loss: 0.0295 - val_accuracy: 0.4767 - val_loss: 4.3323\n",
      "Epoch 44/50\n",
      "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.9803 - loss: 0.0704 - val_accuracy: 0.4651 - val_loss: 4.4803\n",
      "Epoch 45/50\n",
      "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.9851 - loss: 0.0496 - val_accuracy: 0.5581 - val_loss: 2.8292\n",
      "Epoch 46/50\n",
      "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.9843 - loss: 0.0323 - val_accuracy: 0.5233 - val_loss: 3.4017\n",
      "Epoch 47/50\n",
      "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.9909 - loss: 0.0182 - val_accuracy: 0.5814 - val_loss: 3.1327\n",
      "Epoch 48/50\n",
      "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.9888 - loss: 0.0486 - val_accuracy: 0.5698 - val_loss: 3.3370\n",
      "Epoch 49/50\n",
      "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.9792 - loss: 0.0589 - val_accuracy: 0.4767 - val_loss: 4.4718\n",
      "Epoch 50/50\n",
      "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - accuracy: 0.9848 - loss: 0.0861 - val_accuracy: 0.6337 - val_loss: 2.7128\n",
      "\u001b[1m5/5\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step \n",
      "ANN Accuracy: 0.6812\n",
      "ANN Classification Report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.88      0.82      0.85        62\n",
      "           1       0.55      0.43      0.48        14\n",
      "           2       0.70      0.79      0.74        53\n",
      "\n",
      "    accuracy                           0.77       129\n",
      "   macro avg       0.71      0.68      0.69       129\n",
      "weighted avg       0.77      0.77      0.77       129\n",
      "\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "from sklearn.preprocessing import LabelEncoder\n",
    "from sklearn.svm import SVC\n",
    "from sklearn.metrics import balanced_accuracy_score, classification_report\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "\n",
    "# Load the data\n",
    "train_data = np.load('../Files/extracted_features/layer_features_lv60_self/train_4.npz')\n",
    "test_data = np.load('../Files/extracted_features/layer_features_lv60_self/test_4.npz')\n",
    "\n",
    "train_features = train_data['features']  # Ensure these have 1024 features\n",
    "test_features = test_data['features']    # Ensure these have 1024 features\n",
    "\n",
    "# Read Age labels instead of Gender\n",
    "train_labels = pd.read_csv('../Files/labels/y_train.csv').Age_Group\n",
    "test_labels = pd.read_csv('../Files/labels/y_test.csv').Age_Group\n",
    "\n",
    "# Encode the labels\n",
    "label_encoder = LabelEncoder()\n",
    "train_labels_encoded = label_encoder.fit_transform(train_labels)\n",
    "\n",
    "# Handle unseen labels in test set by filtering out labels not present in train set\n",
    "test_labels_filtered = test_labels[test_labels.isin(train_labels.unique())]\n",
    "test_features_filtered = test_features[test_labels.isin(train_labels.unique())]\n",
    "test_labels_encoded = label_encoder.transform(test_labels_filtered)\n",
    "\n",
    "# Standardize features\n",
    "scaler = StandardScaler()\n",
    "train_features_normalized = scaler.fit_transform(train_features)\n",
    "test_features_normalized = scaler.transform(test_features_filtered)\n",
    "\n",
    "# SVM model\n",
    "svm_model = SVC(kernel='linear', C=10.0, gamma='scale', random_state=42)\n",
    "svm_model.fit(train_features_normalized, train_labels_encoded)\n",
    "\n",
    "# SVM Prediction and Evaluation\n",
    "svm_predictions = svm_model.predict(test_features_normalized)\n",
    "svm_accuracy = balanced_accuracy_score(test_labels_encoded, svm_predictions)\n",
    "print(f\"SVM Accuracy: {svm_accuracy:.4f}\")\n",
    "print(\"SVM Classification Report:\")\n",
    "print(classification_report(test_labels_encoded, svm_predictions))\n",
    "\n",
    "# CNN model (TensorFlow)\n",
    "import tensorflow as tf\n",
    "from tensorflow.keras.models import Sequential\n",
    "from tensorflow.keras.layers import Conv1D, Flatten, Dense, Dropout\n",
    "\n",
    "train_features_cnn = np.expand_dims(train_features_normalized, axis=-1)  # Shape: (num_samples, 1024, 1)\n",
    "test_features_cnn = np.expand_dims(test_features_normalized, axis=-1)    # Shape: (num_samples, 1024, 1)\n",
    "\n",
    "cnn_model = Sequential([\n",
    "    Conv1D(64, kernel_size=5, activation='relu', input_shape=(1024, 1)),  # Updated input shape to 1024\n",
    "    Conv1D(128, kernel_size=5, activation='relu'),\n",
    "    Conv1D(256, kernel_size=5, activation='relu'),\n",
    "    Flatten(),\n",
    "    Dense(256, activation='relu'),\n",
    "    Dropout(0.5),\n",
    "    Dense(len(label_encoder.classes_), activation='softmax')\n",
    "])\n",
    "\n",
    "cnn_model.compile(optimizer='adam', loss='sparse_categorical_crossentropy', metrics=['accuracy'])\n",
    "\n",
    "cnn_model.fit(train_features_cnn, train_labels_encoded, epochs=50, batch_size=32, validation_split=0.2)\n",
    "\n",
    "# CNN Prediction and Evaluation\n",
    "cnn_predictions = np.argmax(cnn_model.predict(test_features_cnn), axis=-1)\n",
    "cnn_accuracy = balanced_accuracy_score(test_labels_encoded, cnn_predictions)\n",
    "print(f\"CNN Accuracy: {cnn_accuracy:.4f}\")\n",
    "print(\"CNN Classification Report:\")\n",
    "print(classification_report(test_labels_encoded, cnn_predictions))\n",
    "\n",
    "# ANN model (TensorFlow)\n",
    "ann_model = Sequential([\n",
    "    Dense(512, activation='relu', input_shape=(1024,)),  # Updated input shape to 1024\n",
    "    Dropout(0.5),\n",
    "    Dense(256, activation='relu'),\n",
    "    Dropout(0.5),\n",
    "    Dense(128, activation='relu'),\n",
    "    Dropout(0.5),\n",
    "    Dense(len(label_encoder.classes_), activation='softmax')\n",
    "])\n",
    "\n",
    "ann_model.compile(optimizer='adam', loss='sparse_categorical_crossentropy', metrics=['accuracy'])\n",
    "\n",
    "ann_model.fit(train_features_normalized, train_labels_encoded, epochs=50, batch_size=32, validation_split=0.2)\n",
    "\n",
    "# ANN Prediction and Evaluation\n",
    "ann_predictions = np.argmax(ann_model.predict(test_features_normalized), axis=-1)\n",
    "ann_accuracy = balanced_accuracy_score(test_labels_encoded, ann_predictions)\n",
    "print(f\"ANN Accuracy: {ann_accuracy:.4f}\")\n",
    "print(\"ANN Classification Report:\")\n",
    "print(classification_report(test_labels_encoded, ann_predictions))\n",
    "\n",
    "# PyTorch CNN Model\n",
    "import torch\n",
    "from torch.utils.data import DataLoader, TensorDataset\n",
    "\n",
    "X_train_tensor = torch.tensor(train_features_cnn, dtype=torch.float32).permute(0, 2, 1)  # Shape: (num_samples, 1, 1024)\n",
    "y_train_tensor = torch.tensor(train_labels_encoded, dtype=torch.long)\n",
    "X_test_tensor = torch.tensor(test_features_cnn, dtype=torch.float32).permute(0, 2, 1)    # Shape: (num_samples, 1, 1024)\n",
    "y_test_tensor = torch.tensor(test_labels_encoded, dtype=torch.long)\n",
    "\n",
    "train_dataset = TensorDataset(X_train_tensor, y_train_tensor)\n",
    "test_dataset = TensorDataset(X_test_tensor, y_test_tensor)\n",
    "\n",
    "train_loader = DataLoader(train_dataset, batch_size=64, shuffle=True)\n",
    "test_loader = DataLoader(test_dataset, batch_size=64, shuffle=False)\n",
    "\n",
    "import torch.nn as nn\n",
    "import torch.optim as optim\n",
    "\n",
    "class CNN1DModel(nn.Module):\n",
    "    def __init__(self, input_channels, num_classes):\n",
    "        super(CNN1DModel, self).__init__()\n",
    "        self.conv1 = nn.Conv1d(input_channels, 32, kernel_size=5, stride=1, padding=2)\n",
    "        self.bn1 = nn.BatchNorm1d(32)\n",
    "        self.relu = nn.ReLU()\n",
    "        self.conv2 = nn.Conv1d(32, 64, kernel_size=5, stride=1, padding=2)\n",
    "        self.bn2 = nn.BatchNorm1d(64)\n",
    "        self.conv3 = nn.Conv1d(64, 128, kernel_size=5, stride=1, padding=2)\n",
    "        self.bn3 = nn.BatchNorm1d(128)\n",
    "        self.flatten = nn.Flatten()\n",
    "        self.fc1 = nn.Linear(128 * 1024, 512)  # Updated to 1024 features\n",
    "        self.fc2 = nn.Linear(512, num_classes)\n",
    "        self.dropout = nn.Dropout(0.5)\n",
    "    \n",
    "    def forward(self, x):\n",
    "        x = self.relu(self.bn1(self.conv1(x)))\n",
    "        x = self.relu(self.bn2(self.conv2(x)))\n",
    "        x = self.relu(self.bn3(self.conv3(x)))\n",
    "        x = self.flatten(x)\n",
    "        x = self.dropout(self.relu(self.fc1(x)))\n",
    "        x = self.fc2(x)\n",
    "        return x\n",
    "\n",
    "input_channels = 1\n",
    "num_classes = len(label_encoder.classes_)\n",
    "model = CNN1DModel(input_channels, num_classes)\n",
    "criterion = nn.CrossEntropyLoss()\n",
    "optimizer = optim.Adam(model.parameters(), lr=0.001)\n",
    "\n",
    "# Training loop and evaluation (not shown)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "SVM Accuracy: 0.6642\n",
      "SVM Classification Report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.86      0.79      0.82        62\n",
      "           1       0.46      0.43      0.44        14\n",
      "           2       0.69      0.77      0.73        53\n",
      "\n",
      "    accuracy                           0.74       129\n",
      "   macro avg       0.67      0.66      0.67       129\n",
      "weighted avg       0.75      0.74      0.74       129\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2024-12-11 16:37:52.780650: E external/local_xla/xla/stream_executor/cuda/cuda_fft.cc:485] Unable to register cuFFT factory: Attempting to register factory for plugin cuFFT when one has already been registered\n",
      "2024-12-11 16:37:52.791694: E external/local_xla/xla/stream_executor/cuda/cuda_dnn.cc:8454] Unable to register cuDNN factory: Attempting to register factory for plugin cuDNN when one has already been registered\n",
      "2024-12-11 16:37:52.795819: E external/local_xla/xla/stream_executor/cuda/cuda_blas.cc:1452] Unable to register cuBLAS factory: Attempting to register factory for plugin cuBLAS when one has already been registered\n",
      "2024-12-11 16:37:52.807392: I tensorflow/core/platform/cpu_feature_guard.cc:210] This TensorFlow binary is optimized to use available CPU instructions in performance-critical operations.\n",
      "To enable the following instructions: AVX2 FMA, in other operations, rebuild TensorFlow with the appropriate compiler flags.\n",
      "2024-12-11 16:37:53.630635: W tensorflow/compiler/tf2tensorrt/utils/py_utils.cc:38] TF-TRT Warning: Could not find TensorRT\n",
      "/home/mojo/.local/lib/python3.12/site-packages/keras/src/layers/convolutional/base_conv.py:107: UserWarning: Do not pass an `input_shape`/`input_dim` argument to a layer. When using Sequential models, prefer using an `Input(shape)` object as the first layer in the model instead.\n",
      "  super().__init__(activity_regularizer=activity_regularizer, **kwargs)\n",
      "WARNING: All log messages before absl::InitializeLog() is called are written to STDERR\n",
      "I0000 00:00:1733915274.244163  154515 cuda_executor.cc:1015] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero. See more at https://github.com/torvalds/linux/blob/v6.0/Documentation/ABI/testing/sysfs-bus-pci#L344-L355\n",
      "2024-12-11 16:37:54.282562: W tensorflow/core/common_runtime/gpu/gpu_device.cc:2343] Cannot dlopen some GPU libraries. Please make sure the missing libraries mentioned above are installed properly if you would like to use GPU. Follow the guide at https://www.tensorflow.org/install/gpu for how to download and setup the required libraries for your platform.\n",
      "Skipping registering GPU devices...\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/50\n",
      "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m12s\u001b[0m 493ms/step - accuracy: 0.5305 - loss: 3.0938 - val_accuracy: 0.2965 - val_loss: 1.1180\n",
      "Epoch 2/50\n",
      "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m11s\u001b[0m 488ms/step - accuracy: 0.7435 - loss: 0.6159 - val_accuracy: 0.5814 - val_loss: 0.7501\n",
      "Epoch 3/50\n",
      "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m11s\u001b[0m 487ms/step - accuracy: 0.7924 - loss: 0.5071 - val_accuracy: 0.5872 - val_loss: 0.7746\n",
      "Epoch 4/50\n",
      "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m11s\u001b[0m 491ms/step - accuracy: 0.8734 - loss: 0.3640 - val_accuracy: 0.5233 - val_loss: 1.0512\n",
      "Epoch 5/50\n",
      "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m11s\u001b[0m 489ms/step - accuracy: 0.9167 - loss: 0.2222 - val_accuracy: 0.6047 - val_loss: 0.9965\n",
      "Epoch 6/50\n",
      "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m11s\u001b[0m 495ms/step - accuracy: 0.9529 - loss: 0.1367 - val_accuracy: 0.6686 - val_loss: 0.8259\n",
      "Epoch 7/50\n",
      "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m11s\u001b[0m 491ms/step - accuracy: 0.9752 - loss: 0.0910 - val_accuracy: 0.6395 - val_loss: 1.2264\n",
      "Epoch 8/50\n",
      "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m11s\u001b[0m 494ms/step - accuracy: 0.9906 - loss: 0.0423 - val_accuracy: 0.5349 - val_loss: 1.7493\n",
      "Epoch 9/50\n",
      "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m11s\u001b[0m 483ms/step - accuracy: 0.9909 - loss: 0.0341 - val_accuracy: 0.5581 - val_loss: 1.6032\n",
      "Epoch 10/50\n",
      "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m11s\u001b[0m 482ms/step - accuracy: 0.9959 - loss: 0.0188 - val_accuracy: 0.5756 - val_loss: 1.7651\n",
      "Epoch 11/50\n",
      "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m11s\u001b[0m 485ms/step - accuracy: 0.9925 - loss: 0.0190 - val_accuracy: 0.5988 - val_loss: 1.5215\n",
      "Epoch 12/50\n",
      "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m11s\u001b[0m 487ms/step - accuracy: 0.9977 - loss: 0.0087 - val_accuracy: 0.5988 - val_loss: 1.6725\n",
      "Epoch 13/50\n",
      "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m10s\u001b[0m 476ms/step - accuracy: 0.9989 - loss: 0.0084 - val_accuracy: 0.6105 - val_loss: 1.7270\n",
      "Epoch 14/50\n",
      "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m11s\u001b[0m 478ms/step - accuracy: 1.0000 - loss: 0.0128 - val_accuracy: 0.6337 - val_loss: 1.6562\n",
      "Epoch 15/50\n",
      "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m10s\u001b[0m 474ms/step - accuracy: 0.9997 - loss: 0.0069 - val_accuracy: 0.7209 - val_loss: 1.2813\n",
      "Epoch 16/50\n",
      "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m10s\u001b[0m 474ms/step - accuracy: 0.9949 - loss: 0.0086 - val_accuracy: 0.5814 - val_loss: 2.2131\n",
      "Epoch 17/50\n",
      "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m10s\u001b[0m 477ms/step - accuracy: 1.0000 - loss: 0.0031 - val_accuracy: 0.6453 - val_loss: 1.8453\n",
      "Epoch 18/50\n",
      "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m10s\u001b[0m 476ms/step - accuracy: 0.9951 - loss: 0.0107 - val_accuracy: 0.4186 - val_loss: 3.1948\n",
      "Epoch 19/50\n",
      "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m10s\u001b[0m 475ms/step - accuracy: 1.0000 - loss: 0.0072 - val_accuracy: 0.6628 - val_loss: 1.5468\n",
      "Epoch 20/50\n",
      "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m11s\u001b[0m 481ms/step - accuracy: 1.0000 - loss: 0.0066 - val_accuracy: 0.5988 - val_loss: 2.3906\n",
      "Epoch 21/50\n",
      "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m10s\u001b[0m 474ms/step - accuracy: 1.0000 - loss: 0.0033 - val_accuracy: 0.5407 - val_loss: 3.4482\n",
      "Epoch 22/50\n",
      "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m10s\u001b[0m 473ms/step - accuracy: 0.9934 - loss: 0.0138 - val_accuracy: 0.7151 - val_loss: 1.3065\n",
      "Epoch 23/50\n",
      "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m10s\u001b[0m 474ms/step - accuracy: 0.9974 - loss: 0.0088 - val_accuracy: 0.6628 - val_loss: 1.6280\n",
      "Epoch 24/50\n",
      "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m10s\u001b[0m 474ms/step - accuracy: 0.9974 - loss: 0.0129 - val_accuracy: 0.5698 - val_loss: 2.9615\n",
      "Epoch 25/50\n",
      "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m10s\u001b[0m 476ms/step - accuracy: 0.9980 - loss: 0.0102 - val_accuracy: 0.5930 - val_loss: 2.4768\n",
      "Epoch 26/50\n",
      "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m10s\u001b[0m 475ms/step - accuracy: 0.9989 - loss: 0.0046 - val_accuracy: 0.5407 - val_loss: 3.0136\n",
      "Epoch 27/50\n",
      "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m10s\u001b[0m 477ms/step - accuracy: 0.9998 - loss: 0.0051 - val_accuracy: 0.6628 - val_loss: 1.6786\n",
      "Epoch 28/50\n",
      "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m10s\u001b[0m 475ms/step - accuracy: 0.9957 - loss: 0.0113 - val_accuracy: 0.6512 - val_loss: 1.4807\n",
      "Epoch 29/50\n",
      "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m10s\u001b[0m 474ms/step - accuracy: 1.0000 - loss: 0.0059 - val_accuracy: 0.5988 - val_loss: 2.5190\n",
      "Epoch 30/50\n",
      "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m10s\u001b[0m 475ms/step - accuracy: 0.9978 - loss: 0.0126 - val_accuracy: 0.6047 - val_loss: 1.7444\n",
      "Epoch 31/50\n",
      "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m10s\u001b[0m 477ms/step - accuracy: 1.0000 - loss: 0.0017 - val_accuracy: 0.6221 - val_loss: 1.9047\n",
      "Epoch 32/50\n",
      "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m11s\u001b[0m 478ms/step - accuracy: 1.0000 - loss: 0.0017 - val_accuracy: 0.5930 - val_loss: 2.5901\n",
      "Epoch 33/50\n",
      "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m10s\u001b[0m 477ms/step - accuracy: 1.0000 - loss: 0.0024 - val_accuracy: 0.6047 - val_loss: 3.0790\n",
      "Epoch 34/50\n",
      "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m10s\u001b[0m 475ms/step - accuracy: 0.9997 - loss: 0.0019 - val_accuracy: 0.6221 - val_loss: 2.6716\n",
      "Epoch 35/50\n",
      "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m10s\u001b[0m 475ms/step - accuracy: 0.9973 - loss: 0.0130 - val_accuracy: 0.6512 - val_loss: 1.4970\n",
      "Epoch 36/50\n",
      "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m10s\u001b[0m 473ms/step - accuracy: 0.9969 - loss: 0.0077 - val_accuracy: 0.5988 - val_loss: 1.8473\n",
      "Epoch 37/50\n",
      "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m10s\u001b[0m 474ms/step - accuracy: 0.9936 - loss: 0.0153 - val_accuracy: 0.6105 - val_loss: 1.7653\n",
      "Epoch 38/50\n",
      "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m11s\u001b[0m 480ms/step - accuracy: 1.0000 - loss: 0.0016 - val_accuracy: 0.5814 - val_loss: 2.6913\n",
      "Epoch 39/50\n",
      "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m11s\u001b[0m 479ms/step - accuracy: 0.9970 - loss: 0.0120 - val_accuracy: 0.5872 - val_loss: 2.2396\n",
      "Epoch 40/50\n",
      "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m11s\u001b[0m 478ms/step - accuracy: 0.9963 - loss: 0.0044 - val_accuracy: 0.5291 - val_loss: 3.3906\n",
      "Epoch 41/50\n",
      "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m11s\u001b[0m 484ms/step - accuracy: 0.9965 - loss: 0.0112 - val_accuracy: 0.5581 - val_loss: 2.6373\n",
      "Epoch 42/50\n",
      "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m20s\u001b[0m 478ms/step - accuracy: 0.9974 - loss: 0.0069 - val_accuracy: 0.5349 - val_loss: 3.0991\n",
      "Epoch 43/50\n",
      "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m11s\u001b[0m 478ms/step - accuracy: 1.0000 - loss: 3.6112e-04 - val_accuracy: 0.5698 - val_loss: 2.8535\n",
      "Epoch 44/50\n",
      "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m11s\u001b[0m 480ms/step - accuracy: 1.0000 - loss: 9.3167e-04 - val_accuracy: 0.5640 - val_loss: 3.1467\n",
      "Epoch 45/50\n",
      "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m11s\u001b[0m 482ms/step - accuracy: 1.0000 - loss: 8.2122e-05 - val_accuracy: 0.5640 - val_loss: 3.1961\n",
      "Epoch 46/50\n",
      "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m11s\u001b[0m 478ms/step - accuracy: 1.0000 - loss: 0.0014 - val_accuracy: 0.5581 - val_loss: 3.4452\n",
      "Epoch 47/50\n",
      "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m11s\u001b[0m 477ms/step - accuracy: 1.0000 - loss: 8.8916e-04 - val_accuracy: 0.6047 - val_loss: 3.0337\n",
      "Epoch 48/50\n",
      "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m11s\u001b[0m 478ms/step - accuracy: 1.0000 - loss: 7.4251e-04 - val_accuracy: 0.6570 - val_loss: 2.5085\n",
      "Epoch 49/50\n",
      "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m11s\u001b[0m 479ms/step - accuracy: 0.9978 - loss: 0.0019 - val_accuracy: 0.5233 - val_loss: 4.3983\n",
      "Epoch 50/50\n",
      "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m11s\u001b[0m 478ms/step - accuracy: 0.9999 - loss: 0.0011 - val_accuracy: 0.6047 - val_loss: 3.0197\n",
      "\u001b[1m5/5\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 44ms/step\n",
      "CNN Accuracy: 0.5855\n",
      "CNN Classification Report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.78      0.81      0.79        62\n",
      "           1       0.50      0.21      0.30        14\n",
      "           2       0.66      0.74      0.70        53\n",
      "\n",
      "    accuracy                           0.71       129\n",
      "   macro avg       0.65      0.59      0.60       129\n",
      "weighted avg       0.70      0.71      0.70       129\n",
      "\n",
      "Epoch 1/50\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/mojo/.local/lib/python3.12/site-packages/keras/src/layers/core/dense.py:87: UserWarning: Do not pass an `input_shape`/`input_dim` argument to a layer. When using Sequential models, prefer using an `Input(shape)` object as the first layer in the model instead.\n",
      "  super().__init__(activity_regularizer=activity_regularizer, **kwargs)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 7ms/step - accuracy: 0.4810 - loss: 1.5820 - val_accuracy: 0.5291 - val_loss: 0.8465\n",
      "Epoch 2/50\n",
      "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.6376 - loss: 0.9499 - val_accuracy: 0.4244 - val_loss: 1.0865\n",
      "Epoch 3/50\n",
      "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.7029 - loss: 0.7516 - val_accuracy: 0.4826 - val_loss: 0.9366\n",
      "Epoch 4/50\n",
      "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.7235 - loss: 0.7160 - val_accuracy: 0.6395 - val_loss: 0.7286\n",
      "Epoch 5/50\n",
      "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.7182 - loss: 0.6732 - val_accuracy: 0.5116 - val_loss: 1.0353\n",
      "Epoch 6/50\n",
      "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.8062 - loss: 0.4884 - val_accuracy: 0.6221 - val_loss: 0.8246\n",
      "Epoch 7/50\n",
      "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.8402 - loss: 0.4231 - val_accuracy: 0.5407 - val_loss: 1.0274\n",
      "Epoch 8/50\n",
      "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.8271 - loss: 0.4009 - val_accuracy: 0.5640 - val_loss: 0.9825\n",
      "Epoch 9/50\n",
      "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.8759 - loss: 0.3051 - val_accuracy: 0.5581 - val_loss: 1.0037\n",
      "Epoch 10/50\n",
      "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.8597 - loss: 0.3521 - val_accuracy: 0.6047 - val_loss: 0.9908\n",
      "Epoch 11/50\n",
      "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.8961 - loss: 0.2675 - val_accuracy: 0.5988 - val_loss: 1.0540\n",
      "Epoch 12/50\n",
      "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.9013 - loss: 0.3093 - val_accuracy: 0.5407 - val_loss: 1.1966\n",
      "Epoch 13/50\n",
      "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.8878 - loss: 0.3288 - val_accuracy: 0.6395 - val_loss: 1.0315\n",
      "Epoch 14/50\n",
      "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.9182 - loss: 0.2269 - val_accuracy: 0.6453 - val_loss: 0.9710\n",
      "Epoch 15/50\n",
      "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.9425 - loss: 0.1460 - val_accuracy: 0.6453 - val_loss: 0.9993\n",
      "Epoch 16/50\n",
      "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.9415 - loss: 0.1580 - val_accuracy: 0.5698 - val_loss: 1.3102\n",
      "Epoch 17/50\n",
      "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.9386 - loss: 0.1797 - val_accuracy: 0.5349 - val_loss: 1.5302\n",
      "Epoch 18/50\n",
      "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.9580 - loss: 0.0967 - val_accuracy: 0.6163 - val_loss: 1.5100\n",
      "Epoch 19/50\n",
      "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.9512 - loss: 0.1338 - val_accuracy: 0.5756 - val_loss: 1.6216\n",
      "Epoch 20/50\n",
      "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.9450 - loss: 0.1345 - val_accuracy: 0.5814 - val_loss: 1.6649\n",
      "Epoch 21/50\n",
      "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.9475 - loss: 0.1280 - val_accuracy: 0.5581 - val_loss: 1.7224\n",
      "Epoch 22/50\n",
      "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.9755 - loss: 0.0735 - val_accuracy: 0.5814 - val_loss: 1.9041\n",
      "Epoch 23/50\n",
      "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.9614 - loss: 0.1126 - val_accuracy: 0.5581 - val_loss: 1.9632\n",
      "Epoch 24/50\n",
      "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.9686 - loss: 0.1218 - val_accuracy: 0.5640 - val_loss: 2.0480\n",
      "Epoch 25/50\n",
      "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.9701 - loss: 0.0798 - val_accuracy: 0.5349 - val_loss: 2.1908\n",
      "Epoch 26/50\n",
      "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.9705 - loss: 0.0776 - val_accuracy: 0.6512 - val_loss: 1.3734\n",
      "Epoch 27/50\n",
      "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.9774 - loss: 0.0668 - val_accuracy: 0.6221 - val_loss: 1.9715\n",
      "Epoch 28/50\n",
      "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.9822 - loss: 0.0504 - val_accuracy: 0.5988 - val_loss: 2.1668\n",
      "Epoch 29/50\n",
      "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.9717 - loss: 0.0865 - val_accuracy: 0.6279 - val_loss: 1.8596\n",
      "Epoch 30/50\n",
      "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.9816 - loss: 0.0612 - val_accuracy: 0.5756 - val_loss: 2.0884\n",
      "Epoch 31/50\n",
      "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.9782 - loss: 0.0802 - val_accuracy: 0.5640 - val_loss: 2.2394\n",
      "Epoch 32/50\n",
      "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.9830 - loss: 0.0467 - val_accuracy: 0.6221 - val_loss: 2.1950\n",
      "Epoch 33/50\n",
      "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.9699 - loss: 0.1083 - val_accuracy: 0.5058 - val_loss: 3.1148\n",
      "Epoch 34/50\n",
      "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.9769 - loss: 0.0698 - val_accuracy: 0.5523 - val_loss: 2.6089\n",
      "Epoch 35/50\n",
      "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.9744 - loss: 0.0739 - val_accuracy: 0.5407 - val_loss: 2.6978\n",
      "Epoch 36/50\n",
      "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.9876 - loss: 0.0364 - val_accuracy: 0.5116 - val_loss: 3.3288\n",
      "Epoch 37/50\n",
      "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.9876 - loss: 0.0414 - val_accuracy: 0.5116 - val_loss: 3.2589\n",
      "Epoch 38/50\n",
      "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.9865 - loss: 0.0490 - val_accuracy: 0.5581 - val_loss: 3.2072\n",
      "Epoch 39/50\n",
      "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.9859 - loss: 0.0498 - val_accuracy: 0.5988 - val_loss: 2.7114\n",
      "Epoch 40/50\n",
      "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.9911 - loss: 0.0279 - val_accuracy: 0.6047 - val_loss: 2.7774\n",
      "Epoch 41/50\n",
      "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.9973 - loss: 0.0161 - val_accuracy: 0.5756 - val_loss: 3.0574\n",
      "Epoch 42/50\n",
      "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.9905 - loss: 0.0174 - val_accuracy: 0.5756 - val_loss: 2.9951\n",
      "Epoch 43/50\n",
      "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.9893 - loss: 0.0524 - val_accuracy: 0.5581 - val_loss: 3.8932\n",
      "Epoch 44/50\n",
      "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.9944 - loss: 0.0276 - val_accuracy: 0.5291 - val_loss: 3.4628\n",
      "Epoch 45/50\n",
      "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.9784 - loss: 0.0631 - val_accuracy: 0.5988 - val_loss: 2.7803\n",
      "Epoch 46/50\n",
      "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.9826 - loss: 0.0566 - val_accuracy: 0.5465 - val_loss: 3.5818\n",
      "Epoch 47/50\n",
      "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.9793 - loss: 0.0449 - val_accuracy: 0.5640 - val_loss: 2.7411\n",
      "Epoch 48/50\n",
      "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.9819 - loss: 0.0988 - val_accuracy: 0.5233 - val_loss: 3.4180\n",
      "Epoch 49/50\n",
      "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.9780 - loss: 0.0638 - val_accuracy: 0.6163 - val_loss: 2.3281\n",
      "Epoch 50/50\n",
      "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.9881 - loss: 0.0343 - val_accuracy: 0.6163 - val_loss: 2.4360\n",
      "\u001b[1m5/5\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step \n",
      "ANN Accuracy: 0.5900\n",
      "ANN Classification Report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.80      0.84      0.82        62\n",
      "           1       0.30      0.21      0.25        14\n",
      "           2       0.70      0.72      0.71        53\n",
      "\n",
      "    accuracy                           0.72       129\n",
      "   macro avg       0.60      0.59      0.59       129\n",
      "weighted avg       0.71      0.72      0.71       129\n",
      "\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "from sklearn.preprocessing import LabelEncoder\n",
    "from sklearn.svm import SVC\n",
    "from sklearn.metrics import balanced_accuracy_score, classification_report\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "\n",
    "# Load the data\n",
    "train_data = np.load('../Files/extracted_features/layer_features_lv60_self/train_5.npz')\n",
    "test_data = np.load('../Files/extracted_features/layer_features_lv60_self/test_5.npz')\n",
    "\n",
    "train_features = train_data['features']  # Ensure these have 1024 features\n",
    "test_features = test_data['features']    # Ensure these have 1024 features\n",
    "\n",
    "# Read Age labels instead of Gender\n",
    "train_labels = pd.read_csv('../Files/labels/y_train.csv').Age_Group\n",
    "test_labels = pd.read_csv('../Files/labels/y_test.csv').Age_Group\n",
    "\n",
    "# Encode the labels\n",
    "label_encoder = LabelEncoder()\n",
    "train_labels_encoded = label_encoder.fit_transform(train_labels)\n",
    "\n",
    "# Handle unseen labels in test set by filtering out labels not present in train set\n",
    "test_labels_filtered = test_labels[test_labels.isin(train_labels.unique())]\n",
    "test_features_filtered = test_features[test_labels.isin(train_labels.unique())]\n",
    "test_labels_encoded = label_encoder.transform(test_labels_filtered)\n",
    "\n",
    "# Standardize features\n",
    "scaler = StandardScaler()\n",
    "train_features_normalized = scaler.fit_transform(train_features)\n",
    "test_features_normalized = scaler.transform(test_features_filtered)\n",
    "\n",
    "# SVM model\n",
    "svm_model = SVC(kernel='linear', C=10.0, gamma='scale', random_state=42)\n",
    "svm_model.fit(train_features_normalized, train_labels_encoded)\n",
    "\n",
    "# SVM Prediction and Evaluation\n",
    "svm_predictions = svm_model.predict(test_features_normalized)\n",
    "svm_accuracy = balanced_accuracy_score(test_labels_encoded, svm_predictions)\n",
    "print(f\"SVM Accuracy: {svm_accuracy:.4f}\")\n",
    "print(\"SVM Classification Report:\")\n",
    "print(classification_report(test_labels_encoded, svm_predictions))\n",
    "\n",
    "# CNN model (TensorFlow)\n",
    "import tensorflow as tf\n",
    "from tensorflow.keras.models import Sequential\n",
    "from tensorflow.keras.layers import Conv1D, Flatten, Dense, Dropout\n",
    "\n",
    "train_features_cnn = np.expand_dims(train_features_normalized, axis=-1)  # Shape: (num_samples, 1024, 1)\n",
    "test_features_cnn = np.expand_dims(test_features_normalized, axis=-1)    # Shape: (num_samples, 1024, 1)\n",
    "\n",
    "cnn_model = Sequential([\n",
    "    Conv1D(64, kernel_size=5, activation='relu', input_shape=(1024, 1)),  # Updated input shape to 1024\n",
    "    Conv1D(128, kernel_size=5, activation='relu'),\n",
    "    Conv1D(256, kernel_size=5, activation='relu'),\n",
    "    Flatten(),\n",
    "    Dense(256, activation='relu'),\n",
    "    Dropout(0.5),\n",
    "    Dense(len(label_encoder.classes_), activation='softmax')\n",
    "])\n",
    "\n",
    "cnn_model.compile(optimizer='adam', loss='sparse_categorical_crossentropy', metrics=['accuracy'])\n",
    "\n",
    "cnn_model.fit(train_features_cnn, train_labels_encoded, epochs=50, batch_size=32, validation_split=0.2)\n",
    "\n",
    "# CNN Prediction and Evaluation\n",
    "cnn_predictions = np.argmax(cnn_model.predict(test_features_cnn), axis=-1)\n",
    "cnn_accuracy = balanced_accuracy_score(test_labels_encoded, cnn_predictions)\n",
    "print(f\"CNN Accuracy: {cnn_accuracy:.4f}\")\n",
    "print(\"CNN Classification Report:\")\n",
    "print(classification_report(test_labels_encoded, cnn_predictions))\n",
    "\n",
    "# ANN model (TensorFlow)\n",
    "ann_model = Sequential([\n",
    "    Dense(512, activation='relu', input_shape=(1024,)),  # Updated input shape to 1024\n",
    "    Dropout(0.5),\n",
    "    Dense(256, activation='relu'),\n",
    "    Dropout(0.5),\n",
    "    Dense(128, activation='relu'),\n",
    "    Dropout(0.5),\n",
    "    Dense(len(label_encoder.classes_), activation='softmax')\n",
    "])\n",
    "\n",
    "ann_model.compile(optimizer='adam', loss='sparse_categorical_crossentropy', metrics=['accuracy'])\n",
    "\n",
    "ann_model.fit(train_features_normalized, train_labels_encoded, epochs=50, batch_size=32, validation_split=0.2)\n",
    "\n",
    "# ANN Prediction and Evaluation\n",
    "ann_predictions = np.argmax(ann_model.predict(test_features_normalized), axis=-1)\n",
    "ann_accuracy = balanced_accuracy_score(test_labels_encoded, ann_predictions)\n",
    "print(f\"ANN Accuracy: {ann_accuracy:.4f}\")\n",
    "print(\"ANN Classification Report:\")\n",
    "print(classification_report(test_labels_encoded, ann_predictions))\n",
    "\n",
    "# PyTorch CNN Model\n",
    "import torch\n",
    "from torch.utils.data import DataLoader, TensorDataset\n",
    "\n",
    "X_train_tensor = torch.tensor(train_features_cnn, dtype=torch.float32).permute(0, 2, 1)  # Shape: (num_samples, 1, 1024)\n",
    "y_train_tensor = torch.tensor(train_labels_encoded, dtype=torch.long)\n",
    "X_test_tensor = torch.tensor(test_features_cnn, dtype=torch.float32).permute(0, 2, 1)    # Shape: (num_samples, 1, 1024)\n",
    "y_test_tensor = torch.tensor(test_labels_encoded, dtype=torch.long)\n",
    "\n",
    "train_dataset = TensorDataset(X_train_tensor, y_train_tensor)\n",
    "test_dataset = TensorDataset(X_test_tensor, y_test_tensor)\n",
    "\n",
    "train_loader = DataLoader(train_dataset, batch_size=64, shuffle=True)\n",
    "test_loader = DataLoader(test_dataset, batch_size=64, shuffle=False)\n",
    "\n",
    "import torch.nn as nn\n",
    "import torch.optim as optim\n",
    "\n",
    "class CNN1DModel(nn.Module):\n",
    "    def __init__(self, input_channels, num_classes):\n",
    "        super(CNN1DModel, self).__init__()\n",
    "        self.conv1 = nn.Conv1d(input_channels, 32, kernel_size=5, stride=1, padding=2)\n",
    "        self.bn1 = nn.BatchNorm1d(32)\n",
    "        self.relu = nn.ReLU()\n",
    "        self.conv2 = nn.Conv1d(32, 64, kernel_size=5, stride=1, padding=2)\n",
    "        self.bn2 = nn.BatchNorm1d(64)\n",
    "        self.conv3 = nn.Conv1d(64, 128, kernel_size=5, stride=1, padding=2)\n",
    "        self.bn3 = nn.BatchNorm1d(128)\n",
    "        self.flatten = nn.Flatten()\n",
    "        self.fc1 = nn.Linear(128 * 1024, 512)  # Updated to 1024 features\n",
    "        self.fc2 = nn.Linear(512, num_classes)\n",
    "        self.dropout = nn.Dropout(0.5)\n",
    "    \n",
    "    def forward(self, x):\n",
    "        x = self.relu(self.bn1(self.conv1(x)))\n",
    "        x = self.relu(self.bn2(self.conv2(x)))\n",
    "        x = self.relu(self.bn3(self.conv3(x)))\n",
    "        x = self.flatten(x)\n",
    "        x = self.dropout(self.relu(self.fc1(x)))\n",
    "        x = self.fc2(x)\n",
    "        return x\n",
    "\n",
    "input_channels = 1\n",
    "num_classes = len(label_encoder.classes_)\n",
    "model = CNN1DModel(input_channels, num_classes)\n",
    "criterion = nn.CrossEntropyLoss()\n",
    "optimizer = optim.Adam(model.parameters(), lr=0.001)\n",
    "\n",
    "# Training loop and evaluation (not shown)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "SVM Accuracy: 0.6520\n",
      "SVM Classification Report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.85      0.81      0.83        62\n",
      "           1       0.50      0.36      0.42        14\n",
      "           2       0.70      0.79      0.74        53\n",
      "\n",
      "    accuracy                           0.75       129\n",
      "   macro avg       0.68      0.65      0.66       129\n",
      "weighted avg       0.75      0.75      0.75       129\n",
      "\n",
      "Epoch 1/50\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/mojo/.local/lib/python3.12/site-packages/keras/src/layers/convolutional/base_conv.py:107: UserWarning: Do not pass an `input_shape`/`input_dim` argument to a layer. When using Sequential models, prefer using an `Input(shape)` object as the first layer in the model instead.\n",
      "  super().__init__(activity_regularizer=activity_regularizer, **kwargs)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m11s\u001b[0m 466ms/step - accuracy: 0.5247 - loss: 3.7367 - val_accuracy: 0.2674 - val_loss: 1.1971\n",
      "Epoch 2/50\n",
      "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m10s\u001b[0m 457ms/step - accuracy: 0.7225 - loss: 0.6533 - val_accuracy: 0.6221 - val_loss: 0.7529\n",
      "Epoch 3/50\n",
      "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m10s\u001b[0m 461ms/step - accuracy: 0.8496 - loss: 0.3824 - val_accuracy: 0.5174 - val_loss: 1.0610\n",
      "Epoch 4/50\n",
      "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m10s\u001b[0m 458ms/step - accuracy: 0.9226 - loss: 0.2304 - val_accuracy: 0.6919 - val_loss: 0.7016\n",
      "Epoch 5/50\n",
      "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m10s\u001b[0m 460ms/step - accuracy: 0.9681 - loss: 0.1171 - val_accuracy: 0.6395 - val_loss: 0.8071\n",
      "Epoch 6/50\n",
      "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m10s\u001b[0m 459ms/step - accuracy: 0.9848 - loss: 0.0631 - val_accuracy: 0.4767 - val_loss: 1.5727\n",
      "Epoch 7/50\n",
      "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m10s\u001b[0m 458ms/step - accuracy: 0.9944 - loss: 0.0433 - val_accuracy: 0.6628 - val_loss: 1.1199\n",
      "Epoch 8/50\n",
      "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m10s\u001b[0m 457ms/step - accuracy: 0.9872 - loss: 0.0370 - val_accuracy: 0.7267 - val_loss: 0.7841\n",
      "Epoch 9/50\n",
      "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m10s\u001b[0m 458ms/step - accuracy: 0.9976 - loss: 0.0239 - val_accuracy: 0.6163 - val_loss: 1.2953\n",
      "Epoch 10/50\n",
      "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m10s\u001b[0m 457ms/step - accuracy: 0.9943 - loss: 0.0183 - val_accuracy: 0.5640 - val_loss: 1.6700\n",
      "Epoch 11/50\n",
      "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m10s\u001b[0m 459ms/step - accuracy: 0.9974 - loss: 0.0095 - val_accuracy: 0.6163 - val_loss: 1.5528\n",
      "Epoch 12/50\n",
      "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m10s\u001b[0m 462ms/step - accuracy: 0.9982 - loss: 0.0076 - val_accuracy: 0.6395 - val_loss: 1.4580\n",
      "Epoch 13/50\n",
      "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m10s\u001b[0m 462ms/step - accuracy: 0.9994 - loss: 0.0061 - val_accuracy: 0.6395 - val_loss: 1.5634\n",
      "Epoch 14/50\n",
      "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m10s\u001b[0m 463ms/step - accuracy: 0.9975 - loss: 0.0063 - val_accuracy: 0.5233 - val_loss: 2.2327\n",
      "Epoch 15/50\n",
      "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m10s\u001b[0m 464ms/step - accuracy: 0.9996 - loss: 0.0089 - val_accuracy: 0.6744 - val_loss: 1.4720\n",
      "Epoch 16/50\n",
      "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m10s\u001b[0m 462ms/step - accuracy: 0.9984 - loss: 0.0037 - val_accuracy: 0.6453 - val_loss: 1.4876\n",
      "Epoch 17/50\n",
      "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m10s\u001b[0m 463ms/step - accuracy: 1.0000 - loss: 0.0051 - val_accuracy: 0.6512 - val_loss: 1.4604\n",
      "Epoch 18/50\n",
      "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m10s\u001b[0m 461ms/step - accuracy: 1.0000 - loss: 0.0040 - val_accuracy: 0.5872 - val_loss: 1.8244\n",
      "Epoch 19/50\n",
      "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m10s\u001b[0m 460ms/step - accuracy: 0.9978 - loss: 0.0044 - val_accuracy: 0.6395 - val_loss: 1.6376\n",
      "Epoch 20/50\n",
      "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m10s\u001b[0m 462ms/step - accuracy: 0.9997 - loss: 0.0016 - val_accuracy: 0.5988 - val_loss: 1.9726\n",
      "Epoch 21/50\n",
      "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m10s\u001b[0m 462ms/step - accuracy: 0.9989 - loss: 0.0052 - val_accuracy: 0.6686 - val_loss: 1.5183\n",
      "Epoch 22/50\n",
      "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m10s\u001b[0m 463ms/step - accuracy: 1.0000 - loss: 0.0021 - val_accuracy: 0.6628 - val_loss: 1.7693\n",
      "Epoch 23/50\n",
      "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m10s\u001b[0m 461ms/step - accuracy: 1.0000 - loss: 7.3343e-04 - val_accuracy: 0.6512 - val_loss: 1.9579\n",
      "Epoch 24/50\n",
      "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m10s\u001b[0m 463ms/step - accuracy: 1.0000 - loss: 5.9964e-04 - val_accuracy: 0.6860 - val_loss: 1.6407\n",
      "Epoch 25/50\n",
      "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m10s\u001b[0m 460ms/step - accuracy: 1.0000 - loss: 0.0018 - val_accuracy: 0.6686 - val_loss: 1.5650\n",
      "Epoch 26/50\n",
      "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m10s\u001b[0m 458ms/step - accuracy: 1.0000 - loss: 0.0013 - val_accuracy: 0.6279 - val_loss: 1.9245\n",
      "Epoch 27/50\n",
      "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m10s\u001b[0m 460ms/step - accuracy: 1.0000 - loss: 0.0013 - val_accuracy: 0.5233 - val_loss: 2.8589\n",
      "Epoch 28/50\n",
      "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m10s\u001b[0m 461ms/step - accuracy: 1.0000 - loss: 0.0012 - val_accuracy: 0.6105 - val_loss: 2.2460\n",
      "Epoch 29/50\n",
      "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m10s\u001b[0m 464ms/step - accuracy: 1.0000 - loss: 0.0011 - val_accuracy: 0.6221 - val_loss: 2.3798\n",
      "Epoch 30/50\n",
      "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m10s\u001b[0m 463ms/step - accuracy: 1.0000 - loss: 1.7523e-04 - val_accuracy: 0.6163 - val_loss: 2.4451\n",
      "Epoch 31/50\n",
      "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m10s\u001b[0m 462ms/step - accuracy: 1.0000 - loss: 2.7682e-04 - val_accuracy: 0.5872 - val_loss: 2.6237\n",
      "Epoch 32/50\n",
      "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m10s\u001b[0m 461ms/step - accuracy: 1.0000 - loss: 6.2031e-04 - val_accuracy: 0.5872 - val_loss: 2.5342\n",
      "Epoch 33/50\n",
      "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m10s\u001b[0m 461ms/step - accuracy: 1.0000 - loss: 8.6664e-04 - val_accuracy: 0.5756 - val_loss: 2.6319\n",
      "Epoch 34/50\n",
      "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m10s\u001b[0m 464ms/step - accuracy: 0.9997 - loss: 0.0011 - val_accuracy: 0.5291 - val_loss: 2.9952\n",
      "Epoch 35/50\n",
      "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m10s\u001b[0m 464ms/step - accuracy: 1.0000 - loss: 0.0017 - val_accuracy: 0.6744 - val_loss: 1.5316\n",
      "Epoch 36/50\n",
      "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m10s\u001b[0m 463ms/step - accuracy: 1.0000 - loss: 6.5641e-04 - val_accuracy: 0.5872 - val_loss: 2.3245\n",
      "Epoch 37/50\n",
      "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m10s\u001b[0m 467ms/step - accuracy: 1.0000 - loss: 1.6865e-04 - val_accuracy: 0.5698 - val_loss: 2.5432\n",
      "Epoch 38/50\n",
      "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m10s\u001b[0m 466ms/step - accuracy: 1.0000 - loss: 3.9458e-04 - val_accuracy: 0.5988 - val_loss: 2.4904\n",
      "Epoch 39/50\n",
      "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m10s\u001b[0m 463ms/step - accuracy: 1.0000 - loss: 8.2473e-05 - val_accuracy: 0.6047 - val_loss: 2.5095\n",
      "Epoch 40/50\n",
      "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m10s\u001b[0m 465ms/step - accuracy: 1.0000 - loss: 4.6482e-05 - val_accuracy: 0.5930 - val_loss: 2.5696\n",
      "Epoch 41/50\n",
      "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m10s\u001b[0m 465ms/step - accuracy: 1.0000 - loss: 9.2494e-05 - val_accuracy: 0.5814 - val_loss: 2.6979\n",
      "Epoch 42/50\n",
      "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m10s\u001b[0m 468ms/step - accuracy: 0.9988 - loss: 0.0018 - val_accuracy: 0.5814 - val_loss: 2.4683\n",
      "Epoch 43/50\n",
      "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m10s\u001b[0m 467ms/step - accuracy: 0.9995 - loss: 0.0032 - val_accuracy: 0.5000 - val_loss: 2.4369\n",
      "Epoch 44/50\n",
      "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m10s\u001b[0m 462ms/step - accuracy: 1.0000 - loss: 0.0062 - val_accuracy: 0.6221 - val_loss: 1.8023\n",
      "Epoch 45/50\n",
      "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m10s\u001b[0m 457ms/step - accuracy: 0.9994 - loss: 0.0027 - val_accuracy: 0.7209 - val_loss: 1.1318\n",
      "Epoch 46/50\n",
      "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m10s\u001b[0m 456ms/step - accuracy: 0.9988 - loss: 0.0060 - val_accuracy: 0.5814 - val_loss: 1.8365\n",
      "Epoch 47/50\n",
      "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m10s\u001b[0m 457ms/step - accuracy: 1.0000 - loss: 0.0031 - val_accuracy: 0.5698 - val_loss: 2.2606\n",
      "Epoch 48/50\n",
      "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m10s\u001b[0m 463ms/step - accuracy: 0.9995 - loss: 0.0013 - val_accuracy: 0.6279 - val_loss: 1.7617\n",
      "Epoch 49/50\n",
      "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m10s\u001b[0m 461ms/step - accuracy: 0.9991 - loss: 0.0016 - val_accuracy: 0.7035 - val_loss: 1.3385\n",
      "Epoch 50/50\n",
      "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m10s\u001b[0m 465ms/step - accuracy: 1.0000 - loss: 0.0020 - val_accuracy: 0.5233 - val_loss: 2.6801\n",
      "WARNING:tensorflow:5 out of the last 11 calls to <function TensorFlowTrainer.make_predict_function.<locals>.one_step_on_data_distributed at 0x764696d3f6a0> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has reduce_retracing=True option that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/guide/function#controlling_retracing and https://www.tensorflow.org/api_docs/python/tf/function for  more details.\n",
      "\u001b[1m3/5\u001b[0m \u001b[32m━━━━━━━━━━━━\u001b[0m\u001b[37m━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 44ms/stepWARNING:tensorflow:5 out of the last 11 calls to <function TensorFlowTrainer.make_predict_function.<locals>.one_step_on_data_distributed at 0x764696d3f6a0> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has reduce_retracing=True option that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/guide/function#controlling_retracing and https://www.tensorflow.org/api_docs/python/tf/function for  more details.\n",
      "\u001b[1m5/5\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 54ms/step\n",
      "CNN Accuracy: 0.6183\n",
      "CNN Classification Report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.78      0.87      0.82        62\n",
      "           1       0.50      0.29      0.36        14\n",
      "           2       0.71      0.70      0.70        53\n",
      "\n",
      "    accuracy                           0.74       129\n",
      "   macro avg       0.66      0.62      0.63       129\n",
      "weighted avg       0.72      0.74      0.73       129\n",
      "\n",
      "Epoch 1/50\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/mojo/.local/lib/python3.12/site-packages/keras/src/layers/core/dense.py:87: UserWarning: Do not pass an `input_shape`/`input_dim` argument to a layer. When using Sequential models, prefer using an `Input(shape)` object as the first layer in the model instead.\n",
      "  super().__init__(activity_regularizer=activity_regularizer, **kwargs)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 7ms/step - accuracy: 0.5076 - loss: 1.4810 - val_accuracy: 0.3198 - val_loss: 1.1726\n",
      "Epoch 2/50\n",
      "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.6547 - loss: 0.8943 - val_accuracy: 0.5640 - val_loss: 0.8405\n",
      "Epoch 3/50\n",
      "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.6861 - loss: 0.7482 - val_accuracy: 0.5174 - val_loss: 0.9318\n",
      "Epoch 4/50\n",
      "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.6934 - loss: 0.7232 - val_accuracy: 0.5000 - val_loss: 1.0232\n",
      "Epoch 5/50\n",
      "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.7677 - loss: 0.6013 - val_accuracy: 0.5174 - val_loss: 0.9499\n",
      "Epoch 6/50\n",
      "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.8047 - loss: 0.5118 - val_accuracy: 0.5930 - val_loss: 0.9146\n",
      "Epoch 7/50\n",
      "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.8094 - loss: 0.4793 - val_accuracy: 0.5640 - val_loss: 0.9679\n",
      "Epoch 8/50\n",
      "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.8419 - loss: 0.4058 - val_accuracy: 0.5523 - val_loss: 1.0740\n",
      "Epoch 9/50\n",
      "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.8592 - loss: 0.3477 - val_accuracy: 0.5814 - val_loss: 1.1133\n",
      "Epoch 10/50\n",
      "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.8513 - loss: 0.3566 - val_accuracy: 0.6105 - val_loss: 0.9545\n",
      "Epoch 11/50\n",
      "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.8761 - loss: 0.2986 - val_accuracy: 0.6628 - val_loss: 0.9592\n",
      "Epoch 12/50\n",
      "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.8873 - loss: 0.3164 - val_accuracy: 0.5930 - val_loss: 1.3266\n",
      "Epoch 13/50\n",
      "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.9209 - loss: 0.1967 - val_accuracy: 0.5988 - val_loss: 1.2737\n",
      "Epoch 14/50\n",
      "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.9325 - loss: 0.1669 - val_accuracy: 0.6395 - val_loss: 1.2104\n",
      "Epoch 15/50\n",
      "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.9267 - loss: 0.2032 - val_accuracy: 0.6105 - val_loss: 1.3897\n",
      "Epoch 16/50\n",
      "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.9500 - loss: 0.1631 - val_accuracy: 0.6570 - val_loss: 1.2418\n",
      "Epoch 17/50\n",
      "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.9364 - loss: 0.1511 - val_accuracy: 0.6279 - val_loss: 1.5140\n",
      "Epoch 18/50\n",
      "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.9426 - loss: 0.1646 - val_accuracy: 0.5930 - val_loss: 1.5916\n",
      "Epoch 19/50\n",
      "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.9643 - loss: 0.1283 - val_accuracy: 0.5465 - val_loss: 1.7350\n",
      "Epoch 20/50\n",
      "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.9543 - loss: 0.1367 - val_accuracy: 0.5523 - val_loss: 1.6797\n",
      "Epoch 21/50\n",
      "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.9642 - loss: 0.1194 - val_accuracy: 0.5698 - val_loss: 1.7483\n",
      "Epoch 22/50\n",
      "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.9663 - loss: 0.1117 - val_accuracy: 0.5756 - val_loss: 1.7947\n",
      "Epoch 23/50\n",
      "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.9653 - loss: 0.0733 - val_accuracy: 0.5523 - val_loss: 2.3573\n",
      "Epoch 24/50\n",
      "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.9602 - loss: 0.0931 - val_accuracy: 0.5581 - val_loss: 2.2705\n",
      "Epoch 25/50\n",
      "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.9860 - loss: 0.0619 - val_accuracy: 0.5581 - val_loss: 2.4723\n",
      "Epoch 26/50\n",
      "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.9600 - loss: 0.1278 - val_accuracy: 0.5930 - val_loss: 2.1100\n",
      "Epoch 27/50\n",
      "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.9839 - loss: 0.0481 - val_accuracy: 0.5349 - val_loss: 2.5331\n",
      "Epoch 28/50\n",
      "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.9773 - loss: 0.0555 - val_accuracy: 0.6221 - val_loss: 2.0258\n",
      "Epoch 29/50\n",
      "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.9871 - loss: 0.0511 - val_accuracy: 0.5988 - val_loss: 2.2683\n",
      "Epoch 30/50\n",
      "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.9811 - loss: 0.0757 - val_accuracy: 0.5349 - val_loss: 2.6228\n",
      "Epoch 31/50\n",
      "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.9742 - loss: 0.0743 - val_accuracy: 0.5814 - val_loss: 2.1017\n",
      "Epoch 32/50\n",
      "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.9698 - loss: 0.1012 - val_accuracy: 0.5581 - val_loss: 2.5495\n",
      "Epoch 33/50\n",
      "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.9639 - loss: 0.1006 - val_accuracy: 0.5174 - val_loss: 2.8413\n",
      "Epoch 34/50\n",
      "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.9691 - loss: 0.1456 - val_accuracy: 0.5581 - val_loss: 2.4579\n",
      "Epoch 35/50\n",
      "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.9675 - loss: 0.0928 - val_accuracy: 0.5291 - val_loss: 2.9538\n",
      "Epoch 36/50\n",
      "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.9870 - loss: 0.0498 - val_accuracy: 0.5872 - val_loss: 2.5286\n",
      "Epoch 37/50\n",
      "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.9827 - loss: 0.0465 - val_accuracy: 0.5756 - val_loss: 2.5474\n",
      "Epoch 38/50\n",
      "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.9875 - loss: 0.0326 - val_accuracy: 0.6221 - val_loss: 2.1095\n",
      "Epoch 39/50\n",
      "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.9817 - loss: 0.0555 - val_accuracy: 0.5814 - val_loss: 2.5375\n",
      "Epoch 40/50\n",
      "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.9872 - loss: 0.0335 - val_accuracy: 0.6047 - val_loss: 2.3057\n",
      "Epoch 41/50\n",
      "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.9886 - loss: 0.0675 - val_accuracy: 0.5291 - val_loss: 2.9694\n",
      "Epoch 42/50\n",
      "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.9846 - loss: 0.0404 - val_accuracy: 0.5814 - val_loss: 2.5332\n",
      "Epoch 43/50\n",
      "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.9921 - loss: 0.0180 - val_accuracy: 0.6163 - val_loss: 2.0551\n",
      "Epoch 44/50\n",
      "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.9843 - loss: 0.0425 - val_accuracy: 0.5756 - val_loss: 3.0161\n",
      "Epoch 45/50\n",
      "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.9964 - loss: 0.0121 - val_accuracy: 0.5930 - val_loss: 2.8493\n",
      "Epoch 46/50\n",
      "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.9948 - loss: 0.0232 - val_accuracy: 0.5698 - val_loss: 3.4841\n",
      "Epoch 47/50\n",
      "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.9944 - loss: 0.0178 - val_accuracy: 0.5872 - val_loss: 3.3916\n",
      "Epoch 48/50\n",
      "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.9853 - loss: 0.0345 - val_accuracy: 0.5581 - val_loss: 3.4683\n",
      "Epoch 49/50\n",
      "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.9974 - loss: 0.0106 - val_accuracy: 0.5698 - val_loss: 3.3522\n",
      "Epoch 50/50\n",
      "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.9951 - loss: 0.0136 - val_accuracy: 0.5988 - val_loss: 3.1721\n",
      "\u001b[1m5/5\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step \n",
      "ANN Accuracy: 0.5779\n",
      "ANN Classification Report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.79      0.81      0.80        62\n",
      "           1       0.31      0.29      0.30        14\n",
      "           2       0.64      0.64      0.64        53\n",
      "\n",
      "    accuracy                           0.68       129\n",
      "   macro avg       0.58      0.58      0.58       129\n",
      "weighted avg       0.68      0.68      0.68       129\n",
      "\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "from sklearn.preprocessing import LabelEncoder\n",
    "from sklearn.svm import SVC\n",
    "from sklearn.metrics import balanced_accuracy_score, classification_report\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "\n",
    "# Load the data\n",
    "train_data = np.load('../Files/extracted_features/layer_features_lv60_self/train_6.npz')\n",
    "test_data = np.load('../Files/extracted_features/layer_features_lv60_self/test_6.npz')\n",
    "\n",
    "train_features = train_data['features']  # Ensure these have 1024 features\n",
    "test_features = test_data['features']    # Ensure these have 1024 features\n",
    "\n",
    "# Read Age labels instead of Gender\n",
    "train_labels = pd.read_csv('../Files/labels/y_train.csv').Age_Group\n",
    "test_labels = pd.read_csv('../Files/labels/y_test.csv').Age_Group\n",
    "\n",
    "# Encode the labels\n",
    "label_encoder = LabelEncoder()\n",
    "train_labels_encoded = label_encoder.fit_transform(train_labels)\n",
    "\n",
    "# Handle unseen labels in test set by filtering out labels not present in train set\n",
    "test_labels_filtered = test_labels[test_labels.isin(train_labels.unique())]\n",
    "test_features_filtered = test_features[test_labels.isin(train_labels.unique())]\n",
    "test_labels_encoded = label_encoder.transform(test_labels_filtered)\n",
    "\n",
    "# Standardize features\n",
    "scaler = StandardScaler()\n",
    "train_features_normalized = scaler.fit_transform(train_features)\n",
    "test_features_normalized = scaler.transform(test_features_filtered)\n",
    "\n",
    "# SVM model\n",
    "svm_model = SVC(kernel='linear', C=10.0, gamma='scale', random_state=42)\n",
    "svm_model.fit(train_features_normalized, train_labels_encoded)\n",
    "\n",
    "# SVM Prediction and Evaluation\n",
    "svm_predictions = svm_model.predict(test_features_normalized)\n",
    "svm_accuracy = balanced_accuracy_score(test_labels_encoded, svm_predictions)\n",
    "print(f\"SVM Accuracy: {svm_accuracy:.4f}\")\n",
    "print(\"SVM Classification Report:\")\n",
    "print(classification_report(test_labels_encoded, svm_predictions))\n",
    "\n",
    "# CNN model (TensorFlow)\n",
    "import tensorflow as tf\n",
    "from tensorflow.keras.models import Sequential\n",
    "from tensorflow.keras.layers import Conv1D, Flatten, Dense, Dropout\n",
    "\n",
    "train_features_cnn = np.expand_dims(train_features_normalized, axis=-1)  # Shape: (num_samples, 1024, 1)\n",
    "test_features_cnn = np.expand_dims(test_features_normalized, axis=-1)    # Shape: (num_samples, 1024, 1)\n",
    "\n",
    "cnn_model = Sequential([\n",
    "    Conv1D(64, kernel_size=5, activation='relu', input_shape=(1024, 1)),  # Updated input shape to 1024\n",
    "    Conv1D(128, kernel_size=5, activation='relu'),\n",
    "    Conv1D(256, kernel_size=5, activation='relu'),\n",
    "    Flatten(),\n",
    "    Dense(256, activation='relu'),\n",
    "    Dropout(0.5),\n",
    "    Dense(len(label_encoder.classes_), activation='softmax')\n",
    "])\n",
    "\n",
    "cnn_model.compile(optimizer='adam', loss='sparse_categorical_crossentropy', metrics=['accuracy'])\n",
    "\n",
    "cnn_model.fit(train_features_cnn, train_labels_encoded, epochs=50, batch_size=32, validation_split=0.2)\n",
    "\n",
    "# CNN Prediction and Evaluation\n",
    "cnn_predictions = np.argmax(cnn_model.predict(test_features_cnn), axis=-1)\n",
    "cnn_accuracy = balanced_accuracy_score(test_labels_encoded, cnn_predictions)\n",
    "print(f\"CNN Accuracy: {cnn_accuracy:.4f}\")\n",
    "print(\"CNN Classification Report:\")\n",
    "print(classification_report(test_labels_encoded, cnn_predictions))\n",
    "\n",
    "# ANN model (TensorFlow)\n",
    "ann_model = Sequential([\n",
    "    Dense(512, activation='relu', input_shape=(1024,)),  # Updated input shape to 1024\n",
    "    Dropout(0.5),\n",
    "    Dense(256, activation='relu'),\n",
    "    Dropout(0.5),\n",
    "    Dense(128, activation='relu'),\n",
    "    Dropout(0.5),\n",
    "    Dense(len(label_encoder.classes_), activation='softmax')\n",
    "])\n",
    "\n",
    "ann_model.compile(optimizer='adam', loss='sparse_categorical_crossentropy', metrics=['accuracy'])\n",
    "\n",
    "ann_model.fit(train_features_normalized, train_labels_encoded, epochs=50, batch_size=32, validation_split=0.2)\n",
    "\n",
    "# ANN Prediction and Evaluation\n",
    "ann_predictions = np.argmax(ann_model.predict(test_features_normalized), axis=-1)\n",
    "ann_accuracy = balanced_accuracy_score(test_labels_encoded, ann_predictions)\n",
    "print(f\"ANN Accuracy: {ann_accuracy:.4f}\")\n",
    "print(\"ANN Classification Report:\")\n",
    "print(classification_report(test_labels_encoded, ann_predictions))\n",
    "\n",
    "# PyTorch CNN Model\n",
    "import torch\n",
    "from torch.utils.data import DataLoader, TensorDataset\n",
    "\n",
    "X_train_tensor = torch.tensor(train_features_cnn, dtype=torch.float32).permute(0, 2, 1)  # Shape: (num_samples, 1, 1024)\n",
    "y_train_tensor = torch.tensor(train_labels_encoded, dtype=torch.long)\n",
    "X_test_tensor = torch.tensor(test_features_cnn, dtype=torch.float32).permute(0, 2, 1)    # Shape: (num_samples, 1, 1024)\n",
    "y_test_tensor = torch.tensor(test_labels_encoded, dtype=torch.long)\n",
    "\n",
    "train_dataset = TensorDataset(X_train_tensor, y_train_tensor)\n",
    "test_dataset = TensorDataset(X_test_tensor, y_test_tensor)\n",
    "\n",
    "train_loader = DataLoader(train_dataset, batch_size=64, shuffle=True)\n",
    "test_loader = DataLoader(test_dataset, batch_size=64, shuffle=False)\n",
    "\n",
    "import torch.nn as nn\n",
    "import torch.optim as optim\n",
    "\n",
    "class CNN1DModel(nn.Module):\n",
    "    def __init__(self, input_channels, num_classes):\n",
    "        super(CNN1DModel, self).__init__()\n",
    "        self.conv1 = nn.Conv1d(input_channels, 32, kernel_size=5, stride=1, padding=2)\n",
    "        self.bn1 = nn.BatchNorm1d(32)\n",
    "        self.relu = nn.ReLU()\n",
    "        self.conv2 = nn.Conv1d(32, 64, kernel_size=5, stride=1, padding=2)\n",
    "        self.bn2 = nn.BatchNorm1d(64)\n",
    "        self.conv3 = nn.Conv1d(64, 128, kernel_size=5, stride=1, padding=2)\n",
    "        self.bn3 = nn.BatchNorm1d(128)\n",
    "        self.flatten = nn.Flatten()\n",
    "        self.fc1 = nn.Linear(128 * 1024, 512)  # Updated to 1024 features\n",
    "        self.fc2 = nn.Linear(512, num_classes)\n",
    "        self.dropout = nn.Dropout(0.5)\n",
    "    \n",
    "    def forward(self, x):\n",
    "        x = self.relu(self.bn1(self.conv1(x)))\n",
    "        x = self.relu(self.bn2(self.conv2(x)))\n",
    "        x = self.relu(self.bn3(self.conv3(x)))\n",
    "        x = self.flatten(x)\n",
    "        x = self.dropout(self.relu(self.fc1(x)))\n",
    "        x = self.fc2(x)\n",
    "        return x\n",
    "\n",
    "input_channels = 1\n",
    "num_classes = len(label_encoder.classes_)\n",
    "model = CNN1DModel(input_channels, num_classes)\n",
    "criterion = nn.CrossEntropyLoss()\n",
    "optimizer = optim.Adam(model.parameters(), lr=0.001)\n",
    "\n",
    "# Training loop and evaluation (not shown)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "SVM Accuracy: 0.5771\n",
      "SVM Classification Report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.80      0.71      0.75        62\n",
      "           1       0.40      0.29      0.33        14\n",
      "           2       0.61      0.74      0.67        53\n",
      "\n",
      "    accuracy                           0.67       129\n",
      "   macro avg       0.60      0.58      0.58       129\n",
      "weighted avg       0.68      0.67      0.67       129\n",
      "\n",
      "Epoch 1/50\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/mojo/.local/lib/python3.12/site-packages/keras/src/layers/convolutional/base_conv.py:107: UserWarning: Do not pass an `input_shape`/`input_dim` argument to a layer. When using Sequential models, prefer using an `Input(shape)` object as the first layer in the model instead.\n",
      "  super().__init__(activity_regularizer=activity_regularizer, **kwargs)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m11s\u001b[0m 466ms/step - accuracy: 0.5364 - loss: 3.2562 - val_accuracy: 0.5523 - val_loss: 0.8279\n",
      "Epoch 2/50\n",
      "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m10s\u001b[0m 457ms/step - accuracy: 0.7366 - loss: 0.6404 - val_accuracy: 0.3256 - val_loss: 1.2592\n",
      "Epoch 3/50\n",
      "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m10s\u001b[0m 459ms/step - accuracy: 0.8429 - loss: 0.4199 - val_accuracy: 0.4942 - val_loss: 1.0050\n",
      "Epoch 4/50\n",
      "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m10s\u001b[0m 462ms/step - accuracy: 0.8830 - loss: 0.3257 - val_accuracy: 0.4826 - val_loss: 1.2201\n",
      "Epoch 5/50\n",
      "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m10s\u001b[0m 463ms/step - accuracy: 0.9376 - loss: 0.1888 - val_accuracy: 0.4593 - val_loss: 1.4034\n",
      "Epoch 6/50\n",
      "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m10s\u001b[0m 462ms/step - accuracy: 0.9834 - loss: 0.0749 - val_accuracy: 0.4186 - val_loss: 1.9964\n",
      "Epoch 7/50\n",
      "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m10s\u001b[0m 459ms/step - accuracy: 0.9916 - loss: 0.0445 - val_accuracy: 0.5174 - val_loss: 1.7780\n",
      "Epoch 8/50\n",
      "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m10s\u001b[0m 462ms/step - accuracy: 0.9950 - loss: 0.0360 - val_accuracy: 0.5872 - val_loss: 1.3307\n",
      "Epoch 9/50\n",
      "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m10s\u001b[0m 462ms/step - accuracy: 0.9938 - loss: 0.0284 - val_accuracy: 0.5174 - val_loss: 2.0242\n",
      "Epoch 10/50\n",
      "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m10s\u001b[0m 460ms/step - accuracy: 0.9934 - loss: 0.0189 - val_accuracy: 0.4826 - val_loss: 2.5187\n",
      "Epoch 11/50\n",
      "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m10s\u001b[0m 465ms/step - accuracy: 0.9935 - loss: 0.0460 - val_accuracy: 0.6512 - val_loss: 1.0689\n",
      "Epoch 12/50\n",
      "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m10s\u001b[0m 463ms/step - accuracy: 0.9896 - loss: 0.0291 - val_accuracy: 0.5233 - val_loss: 1.7028\n",
      "Epoch 13/50\n",
      "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m10s\u001b[0m 463ms/step - accuracy: 0.9994 - loss: 0.0136 - val_accuracy: 0.6395 - val_loss: 1.5001\n",
      "Epoch 14/50\n",
      "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m10s\u001b[0m 459ms/step - accuracy: 0.9982 - loss: 0.0091 - val_accuracy: 0.5000 - val_loss: 2.5652\n",
      "Epoch 15/50\n",
      "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m10s\u001b[0m 458ms/step - accuracy: 0.9997 - loss: 0.0045 - val_accuracy: 0.5233 - val_loss: 2.2966\n",
      "Epoch 16/50\n",
      "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m10s\u001b[0m 460ms/step - accuracy: 0.9982 - loss: 0.0075 - val_accuracy: 0.6570 - val_loss: 1.1845\n",
      "Epoch 17/50\n",
      "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m10s\u001b[0m 462ms/step - accuracy: 0.9978 - loss: 0.0097 - val_accuracy: 0.5988 - val_loss: 1.7093\n",
      "Epoch 18/50\n",
      "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m10s\u001b[0m 464ms/step - accuracy: 0.9980 - loss: 0.0062 - val_accuracy: 0.6221 - val_loss: 1.5903\n",
      "Epoch 19/50\n",
      "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m10s\u001b[0m 465ms/step - accuracy: 0.9969 - loss: 0.0110 - val_accuracy: 0.5291 - val_loss: 2.2758\n",
      "Epoch 20/50\n",
      "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m10s\u001b[0m 461ms/step - accuracy: 0.9988 - loss: 0.0045 - val_accuracy: 0.6105 - val_loss: 1.8150\n",
      "Epoch 21/50\n",
      "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m10s\u001b[0m 459ms/step - accuracy: 0.9949 - loss: 0.0134 - val_accuracy: 0.5291 - val_loss: 2.2513\n",
      "Epoch 22/50\n",
      "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m10s\u001b[0m 460ms/step - accuracy: 0.9986 - loss: 0.0059 - val_accuracy: 0.6337 - val_loss: 1.5608\n",
      "Epoch 23/50\n",
      "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m10s\u001b[0m 464ms/step - accuracy: 0.9970 - loss: 0.0073 - val_accuracy: 0.5233 - val_loss: 2.4497\n",
      "Epoch 24/50\n",
      "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m10s\u001b[0m 460ms/step - accuracy: 0.9998 - loss: 0.0024 - val_accuracy: 0.5988 - val_loss: 2.0492\n",
      "Epoch 25/50\n",
      "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m10s\u001b[0m 466ms/step - accuracy: 0.9986 - loss: 0.0069 - val_accuracy: 0.4884 - val_loss: 2.9083\n",
      "Epoch 26/50\n",
      "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m10s\u001b[0m 463ms/step - accuracy: 0.9949 - loss: 0.0059 - val_accuracy: 0.5640 - val_loss: 2.1929\n",
      "Epoch 27/50\n",
      "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m10s\u001b[0m 459ms/step - accuracy: 0.9978 - loss: 0.0063 - val_accuracy: 0.5174 - val_loss: 2.5565\n",
      "Epoch 28/50\n",
      "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m10s\u001b[0m 459ms/step - accuracy: 0.9963 - loss: 0.0225 - val_accuracy: 0.5233 - val_loss: 1.5550\n",
      "Epoch 29/50\n",
      "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m10s\u001b[0m 461ms/step - accuracy: 1.0000 - loss: 0.0043 - val_accuracy: 0.6163 - val_loss: 1.7948\n",
      "Epoch 30/50\n",
      "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m10s\u001b[0m 457ms/step - accuracy: 0.9993 - loss: 0.0033 - val_accuracy: 0.5930 - val_loss: 1.8753\n",
      "Epoch 31/50\n",
      "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m10s\u001b[0m 460ms/step - accuracy: 1.0000 - loss: 8.4261e-04 - val_accuracy: 0.5698 - val_loss: 2.1362\n",
      "Epoch 32/50\n",
      "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m10s\u001b[0m 467ms/step - accuracy: 1.0000 - loss: 4.4791e-04 - val_accuracy: 0.5640 - val_loss: 2.4143\n",
      "Epoch 33/50\n",
      "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m10s\u001b[0m 464ms/step - accuracy: 0.9984 - loss: 0.0045 - val_accuracy: 0.5930 - val_loss: 1.8234\n",
      "Epoch 34/50\n",
      "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m10s\u001b[0m 462ms/step - accuracy: 0.9982 - loss: 0.0158 - val_accuracy: 0.4826 - val_loss: 2.0169\n",
      "Epoch 35/50\n",
      "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m10s\u001b[0m 464ms/step - accuracy: 1.0000 - loss: 0.0016 - val_accuracy: 0.5640 - val_loss: 2.3141\n",
      "Epoch 36/50\n",
      "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m10s\u001b[0m 463ms/step - accuracy: 1.0000 - loss: 6.7597e-04 - val_accuracy: 0.5814 - val_loss: 2.4389\n",
      "Epoch 37/50\n",
      "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m10s\u001b[0m 460ms/step - accuracy: 1.0000 - loss: 2.6491e-04 - val_accuracy: 0.5174 - val_loss: 2.8808\n",
      "Epoch 38/50\n",
      "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m10s\u001b[0m 467ms/step - accuracy: 1.0000 - loss: 9.1214e-05 - val_accuracy: 0.5233 - val_loss: 2.8791\n",
      "Epoch 39/50\n",
      "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m10s\u001b[0m 466ms/step - accuracy: 1.0000 - loss: 0.0011 - val_accuracy: 0.5174 - val_loss: 3.0234\n",
      "Epoch 40/50\n",
      "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m10s\u001b[0m 462ms/step - accuracy: 1.0000 - loss: 1.1471e-04 - val_accuracy: 0.5465 - val_loss: 2.8549\n",
      "Epoch 41/50\n",
      "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m10s\u001b[0m 463ms/step - accuracy: 1.0000 - loss: 1.2948e-04 - val_accuracy: 0.5756 - val_loss: 2.6611\n",
      "Epoch 42/50\n",
      "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m10s\u001b[0m 462ms/step - accuracy: 0.9971 - loss: 0.0056 - val_accuracy: 0.4709 - val_loss: 2.9970\n",
      "Epoch 43/50\n",
      "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m10s\u001b[0m 464ms/step - accuracy: 0.9974 - loss: 0.0028 - val_accuracy: 0.5872 - val_loss: 1.9084\n",
      "Epoch 44/50\n",
      "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m10s\u001b[0m 462ms/step - accuracy: 1.0000 - loss: 5.3337e-04 - val_accuracy: 0.5930 - val_loss: 2.1390\n",
      "Epoch 45/50\n",
      "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m10s\u001b[0m 463ms/step - accuracy: 1.0000 - loss: 5.0599e-04 - val_accuracy: 0.5000 - val_loss: 2.5755\n",
      "Epoch 46/50\n",
      "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m10s\u001b[0m 465ms/step - accuracy: 0.9984 - loss: 0.0025 - val_accuracy: 0.6453 - val_loss: 1.8019\n",
      "Epoch 47/50\n",
      "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m10s\u001b[0m 461ms/step - accuracy: 0.9949 - loss: 0.0125 - val_accuracy: 0.4942 - val_loss: 2.5811\n",
      "Epoch 48/50\n",
      "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m10s\u001b[0m 463ms/step - accuracy: 0.9982 - loss: 0.0079 - val_accuracy: 0.5640 - val_loss: 1.8988\n",
      "Epoch 49/50\n",
      "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m10s\u001b[0m 461ms/step - accuracy: 0.9956 - loss: 0.0071 - val_accuracy: 0.5640 - val_loss: 2.5309\n",
      "Epoch 50/50\n",
      "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m10s\u001b[0m 461ms/step - accuracy: 0.9947 - loss: 0.0079 - val_accuracy: 0.5698 - val_loss: 2.1644\n",
      "\u001b[1m5/5\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 43ms/step\n",
      "CNN Accuracy: 0.6152\n",
      "CNN Classification Report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.79      0.79      0.79        62\n",
      "           1       0.50      0.36      0.42        14\n",
      "           2       0.65      0.70      0.67        53\n",
      "\n",
      "    accuracy                           0.71       129\n",
      "   macro avg       0.65      0.62      0.63       129\n",
      "weighted avg       0.70      0.71      0.70       129\n",
      "\n",
      "Epoch 1/50\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/mojo/.local/lib/python3.12/site-packages/keras/src/layers/core/dense.py:87: UserWarning: Do not pass an `input_shape`/`input_dim` argument to a layer. When using Sequential models, prefer using an `Input(shape)` object as the first layer in the model instead.\n",
      "  super().__init__(activity_regularizer=activity_regularizer, **kwargs)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 7ms/step - accuracy: 0.4807 - loss: 1.5286 - val_accuracy: 0.5058 - val_loss: 0.9581\n",
      "Epoch 2/50\n",
      "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.6316 - loss: 0.9685 - val_accuracy: 0.5523 - val_loss: 0.8885\n",
      "Epoch 3/50\n",
      "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.7010 - loss: 0.7356 - val_accuracy: 0.4244 - val_loss: 1.0545\n",
      "Epoch 4/50\n",
      "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.7469 - loss: 0.6464 - val_accuracy: 0.5523 - val_loss: 0.8806\n",
      "Epoch 5/50\n",
      "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.7905 - loss: 0.5245 - val_accuracy: 0.4942 - val_loss: 0.9697\n",
      "Epoch 6/50\n",
      "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.8005 - loss: 0.4933 - val_accuracy: 0.4884 - val_loss: 0.9988\n",
      "Epoch 7/50\n",
      "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.8074 - loss: 0.5427 - val_accuracy: 0.4535 - val_loss: 1.0948\n",
      "Epoch 8/50\n",
      "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.8023 - loss: 0.4560 - val_accuracy: 0.5465 - val_loss: 1.0467\n",
      "Epoch 9/50\n",
      "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.8842 - loss: 0.3452 - val_accuracy: 0.4419 - val_loss: 1.3601\n",
      "Epoch 10/50\n",
      "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.8661 - loss: 0.3077 - val_accuracy: 0.5523 - val_loss: 0.9983\n",
      "Epoch 11/50\n",
      "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.8888 - loss: 0.2995 - val_accuracy: 0.4651 - val_loss: 1.2437\n",
      "Epoch 12/50\n",
      "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.8982 - loss: 0.3063 - val_accuracy: 0.5581 - val_loss: 0.9936\n",
      "Epoch 13/50\n",
      "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.8875 - loss: 0.2580 - val_accuracy: 0.5291 - val_loss: 1.1274\n",
      "Epoch 14/50\n",
      "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.9327 - loss: 0.1833 - val_accuracy: 0.4593 - val_loss: 1.5297\n",
      "Epoch 15/50\n",
      "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.9416 - loss: 0.1786 - val_accuracy: 0.4826 - val_loss: 1.4051\n",
      "Epoch 16/50\n",
      "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.9519 - loss: 0.1674 - val_accuracy: 0.5465 - val_loss: 1.3492\n",
      "Epoch 17/50\n",
      "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.9247 - loss: 0.2016 - val_accuracy: 0.5058 - val_loss: 1.6898\n",
      "Epoch 18/50\n",
      "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.9635 - loss: 0.1106 - val_accuracy: 0.5349 - val_loss: 1.5451\n",
      "Epoch 19/50\n",
      "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.9350 - loss: 0.1608 - val_accuracy: 0.5349 - val_loss: 1.7908\n",
      "Epoch 20/50\n",
      "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.9534 - loss: 0.1510 - val_accuracy: 0.5058 - val_loss: 1.9968\n",
      "Epoch 21/50\n",
      "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.9629 - loss: 0.1386 - val_accuracy: 0.4884 - val_loss: 1.7470\n",
      "Epoch 22/50\n",
      "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.9761 - loss: 0.0782 - val_accuracy: 0.5407 - val_loss: 1.7869\n",
      "Epoch 23/50\n",
      "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.9776 - loss: 0.0725 - val_accuracy: 0.4942 - val_loss: 2.0804\n",
      "Epoch 24/50\n",
      "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.9643 - loss: 0.0777 - val_accuracy: 0.5000 - val_loss: 2.0902\n",
      "Epoch 25/50\n",
      "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.9773 - loss: 0.0632 - val_accuracy: 0.6279 - val_loss: 1.4133\n",
      "Epoch 26/50\n",
      "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.9674 - loss: 0.1088 - val_accuracy: 0.4767 - val_loss: 2.2780\n",
      "Epoch 27/50\n",
      "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.9692 - loss: 0.0973 - val_accuracy: 0.5174 - val_loss: 2.1899\n",
      "Epoch 28/50\n",
      "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.9671 - loss: 0.0993 - val_accuracy: 0.5116 - val_loss: 2.1137\n",
      "Epoch 29/50\n",
      "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.9780 - loss: 0.0810 - val_accuracy: 0.5000 - val_loss: 2.1677\n",
      "Epoch 30/50\n",
      "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.9805 - loss: 0.0532 - val_accuracy: 0.5465 - val_loss: 2.1252\n",
      "Epoch 31/50\n",
      "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.9732 - loss: 0.0861 - val_accuracy: 0.4942 - val_loss: 2.5431\n",
      "Epoch 32/50\n",
      "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.9705 - loss: 0.0722 - val_accuracy: 0.5174 - val_loss: 2.3231\n",
      "Epoch 33/50\n",
      "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.9602 - loss: 0.1149 - val_accuracy: 0.5581 - val_loss: 2.0586\n",
      "Epoch 34/50\n",
      "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.9705 - loss: 0.0804 - val_accuracy: 0.5523 - val_loss: 2.1192\n",
      "Epoch 35/50\n",
      "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.9672 - loss: 0.0884 - val_accuracy: 0.4826 - val_loss: 2.3532\n",
      "Epoch 36/50\n",
      "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.9719 - loss: 0.1038 - val_accuracy: 0.5116 - val_loss: 2.3877\n",
      "Epoch 37/50\n",
      "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.9833 - loss: 0.0425 - val_accuracy: 0.5058 - val_loss: 2.4496\n",
      "Epoch 38/50\n",
      "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.9874 - loss: 0.0356 - val_accuracy: 0.4651 - val_loss: 2.8858\n",
      "Epoch 39/50\n",
      "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.9792 - loss: 0.0696 - val_accuracy: 0.5988 - val_loss: 2.1611\n",
      "Epoch 40/50\n",
      "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.9900 - loss: 0.0375 - val_accuracy: 0.4593 - val_loss: 3.2467\n",
      "Epoch 41/50\n",
      "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.9945 - loss: 0.0196 - val_accuracy: 0.5291 - val_loss: 2.6126\n",
      "Epoch 42/50\n",
      "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.9812 - loss: 0.0779 - val_accuracy: 0.5233 - val_loss: 2.8929\n",
      "Epoch 43/50\n",
      "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.9883 - loss: 0.0355 - val_accuracy: 0.5407 - val_loss: 2.8107\n",
      "Epoch 44/50\n",
      "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.9850 - loss: 0.0432 - val_accuracy: 0.5116 - val_loss: 3.2004\n",
      "Epoch 45/50\n",
      "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.9832 - loss: 0.0454 - val_accuracy: 0.5465 - val_loss: 2.9213\n",
      "Epoch 46/50\n",
      "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.9776 - loss: 0.0589 - val_accuracy: 0.5349 - val_loss: 3.0950\n",
      "Epoch 47/50\n",
      "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.9952 - loss: 0.0242 - val_accuracy: 0.6221 - val_loss: 2.1345\n",
      "Epoch 48/50\n",
      "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.9719 - loss: 0.0549 - val_accuracy: 0.4884 - val_loss: 3.3635\n",
      "Epoch 49/50\n",
      "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.9950 - loss: 0.0186 - val_accuracy: 0.5407 - val_loss: 2.7921\n",
      "Epoch 50/50\n",
      "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.9787 - loss: 0.0584 - val_accuracy: 0.5523 - val_loss: 2.6412\n",
      "\u001b[1m5/5\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step \n",
      "ANN Accuracy: 0.5914\n",
      "ANN Classification Report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.78      0.79      0.78        62\n",
      "           1       0.40      0.29      0.33        14\n",
      "           2       0.66      0.70      0.68        53\n",
      "\n",
      "    accuracy                           0.70       129\n",
      "   macro avg       0.61      0.59      0.60       129\n",
      "weighted avg       0.69      0.70      0.69       129\n",
      "\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "from sklearn.preprocessing import LabelEncoder\n",
    "from sklearn.svm import SVC\n",
    "from sklearn.metrics import balanced_accuracy_score, classification_report\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "\n",
    "# Load the data\n",
    "train_data = np.load('../Files/extracted_features/layer_features_lv60_self/train_7.npz')\n",
    "test_data = np.load('../Files/extracted_features/layer_features_lv60_self/test_7.npz')\n",
    "\n",
    "train_features = train_data['features']  # Ensure these have 1024 features\n",
    "test_features = test_data['features']    # Ensure these have 1024 features\n",
    "\n",
    "# Read Age labels instead of Gender\n",
    "train_labels = pd.read_csv('../Files/labels/y_train.csv').Age_Group\n",
    "test_labels = pd.read_csv('../Files/labels/y_test.csv').Age_Group\n",
    "\n",
    "# Encode the labels\n",
    "label_encoder = LabelEncoder()\n",
    "train_labels_encoded = label_encoder.fit_transform(train_labels)\n",
    "\n",
    "# Handle unseen labels in test set by filtering out labels not present in train set\n",
    "test_labels_filtered = test_labels[test_labels.isin(train_labels.unique())]\n",
    "test_features_filtered = test_features[test_labels.isin(train_labels.unique())]\n",
    "test_labels_encoded = label_encoder.transform(test_labels_filtered)\n",
    "\n",
    "# Standardize features\n",
    "scaler = StandardScaler()\n",
    "train_features_normalized = scaler.fit_transform(train_features)\n",
    "test_features_normalized = scaler.transform(test_features_filtered)\n",
    "\n",
    "# SVM model\n",
    "svm_model = SVC(kernel='linear', C=10.0, gamma='scale', random_state=42)\n",
    "svm_model.fit(train_features_normalized, train_labels_encoded)\n",
    "\n",
    "# SVM Prediction and Evaluation\n",
    "svm_predictions = svm_model.predict(test_features_normalized)\n",
    "svm_accuracy = balanced_accuracy_score(test_labels_encoded, svm_predictions)\n",
    "print(f\"SVM Accuracy: {svm_accuracy:.4f}\")\n",
    "print(\"SVM Classification Report:\")\n",
    "print(classification_report(test_labels_encoded, svm_predictions))\n",
    "\n",
    "# CNN model (TensorFlow)\n",
    "import tensorflow as tf\n",
    "from tensorflow.keras.models import Sequential\n",
    "from tensorflow.keras.layers import Conv1D, Flatten, Dense, Dropout\n",
    "\n",
    "train_features_cnn = np.expand_dims(train_features_normalized, axis=-1)  # Shape: (num_samples, 1024, 1)\n",
    "test_features_cnn = np.expand_dims(test_features_normalized, axis=-1)    # Shape: (num_samples, 1024, 1)\n",
    "\n",
    "cnn_model = Sequential([\n",
    "    Conv1D(64, kernel_size=5, activation='relu', input_shape=(1024, 1)),  # Updated input shape to 1024\n",
    "    Conv1D(128, kernel_size=5, activation='relu'),\n",
    "    Conv1D(256, kernel_size=5, activation='relu'),\n",
    "    Flatten(),\n",
    "    Dense(256, activation='relu'),\n",
    "    Dropout(0.5),\n",
    "    Dense(len(label_encoder.classes_), activation='softmax')\n",
    "])\n",
    "\n",
    "cnn_model.compile(optimizer='adam', loss='sparse_categorical_crossentropy', metrics=['accuracy'])\n",
    "\n",
    "cnn_model.fit(train_features_cnn, train_labels_encoded, epochs=50, batch_size=32, validation_split=0.2)\n",
    "\n",
    "# CNN Prediction and Evaluation\n",
    "cnn_predictions = np.argmax(cnn_model.predict(test_features_cnn), axis=-1)\n",
    "cnn_accuracy = balanced_accuracy_score(test_labels_encoded, cnn_predictions)\n",
    "print(f\"CNN Accuracy: {cnn_accuracy:.4f}\")\n",
    "print(\"CNN Classification Report:\")\n",
    "print(classification_report(test_labels_encoded, cnn_predictions))\n",
    "\n",
    "# ANN model (TensorFlow)\n",
    "ann_model = Sequential([\n",
    "    Dense(512, activation='relu', input_shape=(1024,)),  # Updated input shape to 1024\n",
    "    Dropout(0.5),\n",
    "    Dense(256, activation='relu'),\n",
    "    Dropout(0.5),\n",
    "    Dense(128, activation='relu'),\n",
    "    Dropout(0.5),\n",
    "    Dense(len(label_encoder.classes_), activation='softmax')\n",
    "])\n",
    "\n",
    "ann_model.compile(optimizer='adam', loss='sparse_categorical_crossentropy', metrics=['accuracy'])\n",
    "\n",
    "ann_model.fit(train_features_normalized, train_labels_encoded, epochs=50, batch_size=32, validation_split=0.2)\n",
    "\n",
    "# ANN Prediction and Evaluation\n",
    "ann_predictions = np.argmax(ann_model.predict(test_features_normalized), axis=-1)\n",
    "ann_accuracy = balanced_accuracy_score(test_labels_encoded, ann_predictions)\n",
    "print(f\"ANN Accuracy: {ann_accuracy:.4f}\")\n",
    "print(\"ANN Classification Report:\")\n",
    "print(classification_report(test_labels_encoded, ann_predictions))\n",
    "\n",
    "# PyTorch CNN Model\n",
    "import torch\n",
    "from torch.utils.data import DataLoader, TensorDataset\n",
    "\n",
    "X_train_tensor = torch.tensor(train_features_cnn, dtype=torch.float32).permute(0, 2, 1)  # Shape: (num_samples, 1, 1024)\n",
    "y_train_tensor = torch.tensor(train_labels_encoded, dtype=torch.long)\n",
    "X_test_tensor = torch.tensor(test_features_cnn, dtype=torch.float32).permute(0, 2, 1)    # Shape: (num_samples, 1, 1024)\n",
    "y_test_tensor = torch.tensor(test_labels_encoded, dtype=torch.long)\n",
    "\n",
    "train_dataset = TensorDataset(X_train_tensor, y_train_tensor)\n",
    "test_dataset = TensorDataset(X_test_tensor, y_test_tensor)\n",
    "\n",
    "train_loader = DataLoader(train_dataset, batch_size=64, shuffle=True)\n",
    "test_loader = DataLoader(test_dataset, batch_size=64, shuffle=False)\n",
    "\n",
    "import torch.nn as nn\n",
    "import torch.optim as optim\n",
    "\n",
    "class CNN1DModel(nn.Module):\n",
    "    def __init__(self, input_channels, num_classes):\n",
    "        super(CNN1DModel, self).__init__()\n",
    "        self.conv1 = nn.Conv1d(input_channels, 32, kernel_size=5, stride=1, padding=2)\n",
    "        self.bn1 = nn.BatchNorm1d(32)\n",
    "        self.relu = nn.ReLU()\n",
    "        self.conv2 = nn.Conv1d(32, 64, kernel_size=5, stride=1, padding=2)\n",
    "        self.bn2 = nn.BatchNorm1d(64)\n",
    "        self.conv3 = nn.Conv1d(64, 128, kernel_size=5, stride=1, padding=2)\n",
    "        self.bn3 = nn.BatchNorm1d(128)\n",
    "        self.flatten = nn.Flatten()\n",
    "        self.fc1 = nn.Linear(128 * 1024, 512)  # Updated to 1024 features\n",
    "        self.fc2 = nn.Linear(512, num_classes)\n",
    "        self.dropout = nn.Dropout(0.5)\n",
    "    \n",
    "    def forward(self, x):\n",
    "        x = self.relu(self.bn1(self.conv1(x)))\n",
    "        x = self.relu(self.bn2(self.conv2(x)))\n",
    "        x = self.relu(self.bn3(self.conv3(x)))\n",
    "        x = self.flatten(x)\n",
    "        x = self.dropout(self.relu(self.fc1(x)))\n",
    "        x = self.fc2(x)\n",
    "        return x\n",
    "\n",
    "input_channels = 1\n",
    "num_classes = len(label_encoder.classes_)\n",
    "model = CNN1DModel(input_channels, num_classes)\n",
    "criterion = nn.CrossEntropyLoss()\n",
    "optimizer = optim.Adam(model.parameters(), lr=0.001)\n",
    "\n",
    "# Training loop and evaluation (not shown)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "SVM Accuracy: 0.5757\n",
      "SVM Classification Report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.76      0.71      0.73        62\n",
      "           1       0.42      0.36      0.38        14\n",
      "           2       0.59      0.66      0.62        53\n",
      "\n",
      "    accuracy                           0.65       129\n",
      "   macro avg       0.59      0.58      0.58       129\n",
      "weighted avg       0.65      0.65      0.65       129\n",
      "\n",
      "Epoch 1/50\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/mojo/.local/lib/python3.12/site-packages/keras/src/layers/convolutional/base_conv.py:107: UserWarning: Do not pass an `input_shape`/`input_dim` argument to a layer. When using Sequential models, prefer using an `Input(shape)` object as the first layer in the model instead.\n",
      "  super().__init__(activity_regularizer=activity_regularizer, **kwargs)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m12s\u001b[0m 467ms/step - accuracy: 0.5050 - loss: 2.1092 - val_accuracy: 0.0465 - val_loss: 1.3755\n",
      "Epoch 2/50\n",
      "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m10s\u001b[0m 458ms/step - accuracy: 0.6537 - loss: 0.7342 - val_accuracy: 0.3721 - val_loss: 1.0524\n",
      "Epoch 3/50\n",
      "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m10s\u001b[0m 460ms/step - accuracy: 0.8051 - loss: 0.5111 - val_accuracy: 0.5640 - val_loss: 0.8500\n",
      "Epoch 4/50\n",
      "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m10s\u001b[0m 455ms/step - accuracy: 0.8559 - loss: 0.4001 - val_accuracy: 0.6105 - val_loss: 0.8623\n",
      "Epoch 5/50\n",
      "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m10s\u001b[0m 457ms/step - accuracy: 0.9240 - loss: 0.2240 - val_accuracy: 0.6453 - val_loss: 0.7797\n",
      "Epoch 6/50\n",
      "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m10s\u001b[0m 458ms/step - accuracy: 0.9720 - loss: 0.1237 - val_accuracy: 0.5930 - val_loss: 1.2073\n",
      "Epoch 7/50\n",
      "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m10s\u001b[0m 459ms/step - accuracy: 0.9865 - loss: 0.0617 - val_accuracy: 0.5988 - val_loss: 1.3593\n",
      "Epoch 8/50\n",
      "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m10s\u001b[0m 461ms/step - accuracy: 0.9894 - loss: 0.0388 - val_accuracy: 0.5988 - val_loss: 1.6115\n",
      "Epoch 9/50\n",
      "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m10s\u001b[0m 459ms/step - accuracy: 0.9850 - loss: 0.0421 - val_accuracy: 0.6105 - val_loss: 1.3448\n",
      "Epoch 10/50\n",
      "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m10s\u001b[0m 459ms/step - accuracy: 0.9980 - loss: 0.0172 - val_accuracy: 0.6279 - val_loss: 1.5208\n",
      "Epoch 11/50\n",
      "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m10s\u001b[0m 460ms/step - accuracy: 0.9990 - loss: 0.0109 - val_accuracy: 0.5930 - val_loss: 1.7812\n",
      "Epoch 12/50\n",
      "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m10s\u001b[0m 461ms/step - accuracy: 0.9935 - loss: 0.0373 - val_accuracy: 0.5988 - val_loss: 1.5121\n",
      "Epoch 13/50\n",
      "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m10s\u001b[0m 457ms/step - accuracy: 0.9949 - loss: 0.0143 - val_accuracy: 0.5988 - val_loss: 1.9022\n",
      "Epoch 14/50\n",
      "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m10s\u001b[0m 454ms/step - accuracy: 0.9966 - loss: 0.0137 - val_accuracy: 0.6744 - val_loss: 1.2354\n",
      "Epoch 15/50\n",
      "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m10s\u001b[0m 458ms/step - accuracy: 0.9990 - loss: 0.0129 - val_accuracy: 0.5058 - val_loss: 2.2297\n",
      "Epoch 16/50\n",
      "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m10s\u001b[0m 458ms/step - accuracy: 1.0000 - loss: 0.0040 - val_accuracy: 0.5407 - val_loss: 2.4844\n",
      "Epoch 17/50\n",
      "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m10s\u001b[0m 458ms/step - accuracy: 1.0000 - loss: 0.0018 - val_accuracy: 0.5058 - val_loss: 3.1722\n",
      "Epoch 18/50\n",
      "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m10s\u001b[0m 458ms/step - accuracy: 0.9968 - loss: 0.0066 - val_accuracy: 0.6860 - val_loss: 1.4971\n",
      "Epoch 19/50\n",
      "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m10s\u001b[0m 457ms/step - accuracy: 1.0000 - loss: 0.0024 - val_accuracy: 0.5814 - val_loss: 2.4746\n",
      "Epoch 20/50\n",
      "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m10s\u001b[0m 459ms/step - accuracy: 1.0000 - loss: 0.0028 - val_accuracy: 0.5233 - val_loss: 2.9124\n",
      "Epoch 21/50\n",
      "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m10s\u001b[0m 458ms/step - accuracy: 0.9988 - loss: 0.0033 - val_accuracy: 0.5523 - val_loss: 2.3296\n",
      "Epoch 22/50\n",
      "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m10s\u001b[0m 460ms/step - accuracy: 1.0000 - loss: 0.0049 - val_accuracy: 0.5640 - val_loss: 2.5214\n",
      "Epoch 23/50\n",
      "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m10s\u001b[0m 460ms/step - accuracy: 0.9984 - loss: 0.0063 - val_accuracy: 0.5407 - val_loss: 2.3304\n",
      "Epoch 24/50\n",
      "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m10s\u001b[0m 460ms/step - accuracy: 1.0000 - loss: 0.0015 - val_accuracy: 0.5988 - val_loss: 2.1135\n",
      "Epoch 25/50\n",
      "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m10s\u001b[0m 455ms/step - accuracy: 1.0000 - loss: 0.0017 - val_accuracy: 0.5756 - val_loss: 2.5410\n",
      "Epoch 26/50\n",
      "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m10s\u001b[0m 461ms/step - accuracy: 1.0000 - loss: 5.4936e-04 - val_accuracy: 0.5581 - val_loss: 2.6308\n",
      "Epoch 27/50\n",
      "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m10s\u001b[0m 458ms/step - accuracy: 0.9993 - loss: 0.0025 - val_accuracy: 0.6802 - val_loss: 1.8506\n",
      "Epoch 28/50\n",
      "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m10s\u001b[0m 458ms/step - accuracy: 0.9994 - loss: 0.0032 - val_accuracy: 0.4593 - val_loss: 3.6292\n",
      "Epoch 29/50\n",
      "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m10s\u001b[0m 464ms/step - accuracy: 1.0000 - loss: 0.0042 - val_accuracy: 0.5756 - val_loss: 2.2008\n",
      "Epoch 30/50\n",
      "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m10s\u001b[0m 460ms/step - accuracy: 0.9986 - loss: 0.0034 - val_accuracy: 0.4535 - val_loss: 3.5850\n",
      "Epoch 31/50\n",
      "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m10s\u001b[0m 458ms/step - accuracy: 1.0000 - loss: 0.0047 - val_accuracy: 0.6047 - val_loss: 2.1713\n",
      "Epoch 32/50\n",
      "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m10s\u001b[0m 460ms/step - accuracy: 0.9981 - loss: 0.0077 - val_accuracy: 0.6628 - val_loss: 1.3303\n",
      "Epoch 33/50\n",
      "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m10s\u001b[0m 460ms/step - accuracy: 0.9954 - loss: 0.0105 - val_accuracy: 0.6337 - val_loss: 1.5873\n",
      "Epoch 34/50\n",
      "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m10s\u001b[0m 463ms/step - accuracy: 1.0000 - loss: 0.0041 - val_accuracy: 0.5640 - val_loss: 2.4171\n",
      "Epoch 35/50\n",
      "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m10s\u001b[0m 459ms/step - accuracy: 1.0000 - loss: 3.0834e-04 - val_accuracy: 0.5581 - val_loss: 2.7730\n",
      "Epoch 36/50\n",
      "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m10s\u001b[0m 463ms/step - accuracy: 1.0000 - loss: 0.0011 - val_accuracy: 0.5814 - val_loss: 2.7116\n",
      "Epoch 37/50\n",
      "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m10s\u001b[0m 465ms/step - accuracy: 1.0000 - loss: 1.6046e-04 - val_accuracy: 0.5698 - val_loss: 2.9206\n",
      "Epoch 38/50\n",
      "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m10s\u001b[0m 465ms/step - accuracy: 0.9995 - loss: 0.0049 - val_accuracy: 0.6919 - val_loss: 1.5451\n",
      "Epoch 39/50\n",
      "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m10s\u001b[0m 465ms/step - accuracy: 0.9946 - loss: 0.0094 - val_accuracy: 0.6570 - val_loss: 1.4593\n",
      "Epoch 40/50\n",
      "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m10s\u001b[0m 467ms/step - accuracy: 1.0000 - loss: 0.0041 - val_accuracy: 0.6570 - val_loss: 1.7824\n",
      "Epoch 41/50\n",
      "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m10s\u001b[0m 470ms/step - accuracy: 1.0000 - loss: 0.0035 - val_accuracy: 0.6337 - val_loss: 1.9398\n",
      "Epoch 42/50\n",
      "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m10s\u001b[0m 472ms/step - accuracy: 0.9983 - loss: 0.0074 - val_accuracy: 0.6744 - val_loss: 1.3446\n",
      "Epoch 43/50\n",
      "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m10s\u001b[0m 473ms/step - accuracy: 0.9994 - loss: 0.0054 - val_accuracy: 0.6628 - val_loss: 1.9411\n",
      "Epoch 44/50\n",
      "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m10s\u001b[0m 470ms/step - accuracy: 1.0000 - loss: 0.0021 - val_accuracy: 0.5407 - val_loss: 3.0354\n",
      "Epoch 45/50\n",
      "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m10s\u001b[0m 469ms/step - accuracy: 0.9949 - loss: 0.0104 - val_accuracy: 0.6512 - val_loss: 2.2407\n",
      "Epoch 46/50\n",
      "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m10s\u001b[0m 471ms/step - accuracy: 0.9974 - loss: 0.0058 - val_accuracy: 0.5581 - val_loss: 2.8841\n",
      "Epoch 47/50\n",
      "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m10s\u001b[0m 473ms/step - accuracy: 0.9963 - loss: 0.0141 - val_accuracy: 0.6279 - val_loss: 2.0602\n",
      "Epoch 48/50\n",
      "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m10s\u001b[0m 469ms/step - accuracy: 1.0000 - loss: 3.9303e-04 - val_accuracy: 0.5930 - val_loss: 2.4776\n",
      "Epoch 49/50\n",
      "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m10s\u001b[0m 473ms/step - accuracy: 1.0000 - loss: 0.0012 - val_accuracy: 0.5174 - val_loss: 3.5354\n",
      "Epoch 50/50\n",
      "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m10s\u001b[0m 471ms/step - accuracy: 0.9996 - loss: 0.0013 - val_accuracy: 0.6337 - val_loss: 2.2777\n",
      "\u001b[1m5/5\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 54ms/step\n",
      "CNN Accuracy: 0.5393\n",
      "CNN Classification Report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.78      0.76      0.77        62\n",
      "           1       0.22      0.14      0.17        14\n",
      "           2       0.63      0.72      0.67        53\n",
      "\n",
      "    accuracy                           0.67       129\n",
      "   macro avg       0.55      0.54      0.54       129\n",
      "weighted avg       0.66      0.67      0.67       129\n",
      "\n",
      "Epoch 1/50\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/mojo/.local/lib/python3.12/site-packages/keras/src/layers/core/dense.py:87: UserWarning: Do not pass an `input_shape`/`input_dim` argument to a layer. When using Sequential models, prefer using an `Input(shape)` object as the first layer in the model instead.\n",
      "  super().__init__(activity_regularizer=activity_regularizer, **kwargs)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 7ms/step - accuracy: 0.4572 - loss: 1.7039 - val_accuracy: 0.2151 - val_loss: 1.3302\n",
      "Epoch 2/50\n",
      "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.6011 - loss: 1.0108 - val_accuracy: 0.4012 - val_loss: 1.0916\n",
      "Epoch 3/50\n",
      "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.6781 - loss: 0.8379 - val_accuracy: 0.4302 - val_loss: 0.9871\n",
      "Epoch 4/50\n",
      "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.7269 - loss: 0.7209 - val_accuracy: 0.5233 - val_loss: 0.9391\n",
      "Epoch 5/50\n",
      "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.7404 - loss: 0.7673 - val_accuracy: 0.5581 - val_loss: 0.8805\n",
      "Epoch 6/50\n",
      "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.7652 - loss: 0.5529 - val_accuracy: 0.4535 - val_loss: 1.0479\n",
      "Epoch 7/50\n",
      "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.7812 - loss: 0.5748 - val_accuracy: 0.6802 - val_loss: 0.7896\n",
      "Epoch 8/50\n",
      "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.7872 - loss: 0.4957 - val_accuracy: 0.5872 - val_loss: 0.9457\n",
      "Epoch 9/50\n",
      "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.8247 - loss: 0.4575 - val_accuracy: 0.5407 - val_loss: 0.9970\n",
      "Epoch 10/50\n",
      "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.8129 - loss: 0.4124 - val_accuracy: 0.5465 - val_loss: 1.1037\n",
      "Epoch 11/50\n",
      "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.8456 - loss: 0.3635 - val_accuracy: 0.5640 - val_loss: 1.0415\n",
      "Epoch 12/50\n",
      "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.8640 - loss: 0.3460 - val_accuracy: 0.4767 - val_loss: 1.2195\n",
      "Epoch 13/50\n",
      "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.9055 - loss: 0.2715 - val_accuracy: 0.5407 - val_loss: 1.4023\n",
      "Epoch 14/50\n",
      "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.9122 - loss: 0.2521 - val_accuracy: 0.5640 - val_loss: 1.2840\n",
      "Epoch 15/50\n",
      "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.9234 - loss: 0.2096 - val_accuracy: 0.5116 - val_loss: 1.5231\n",
      "Epoch 16/50\n",
      "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.9065 - loss: 0.2127 - val_accuracy: 0.5291 - val_loss: 1.5517\n",
      "Epoch 17/50\n",
      "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.9163 - loss: 0.2030 - val_accuracy: 0.5640 - val_loss: 1.3489\n",
      "Epoch 18/50\n",
      "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.9385 - loss: 0.1671 - val_accuracy: 0.5523 - val_loss: 1.2811\n",
      "Epoch 19/50\n",
      "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.9414 - loss: 0.1517 - val_accuracy: 0.5233 - val_loss: 1.6131\n",
      "Epoch 20/50\n",
      "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.9447 - loss: 0.1692 - val_accuracy: 0.5058 - val_loss: 1.8946\n",
      "Epoch 21/50\n",
      "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.9438 - loss: 0.1500 - val_accuracy: 0.5465 - val_loss: 1.6172\n",
      "Epoch 22/50\n",
      "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.9474 - loss: 0.1791 - val_accuracy: 0.5116 - val_loss: 1.7812\n",
      "Epoch 23/50\n",
      "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.9523 - loss: 0.1468 - val_accuracy: 0.5174 - val_loss: 1.7644\n",
      "Epoch 24/50\n",
      "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.9650 - loss: 0.1034 - val_accuracy: 0.4651 - val_loss: 2.2268\n",
      "Epoch 25/50\n",
      "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.9648 - loss: 0.0984 - val_accuracy: 0.5407 - val_loss: 2.0018\n",
      "Epoch 26/50\n",
      "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.9597 - loss: 0.1196 - val_accuracy: 0.5640 - val_loss: 1.9237\n",
      "Epoch 27/50\n",
      "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.9554 - loss: 0.1683 - val_accuracy: 0.4651 - val_loss: 2.4386\n",
      "Epoch 28/50\n",
      "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.9608 - loss: 0.1064 - val_accuracy: 0.4767 - val_loss: 2.3092\n",
      "Epoch 29/50\n",
      "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.9634 - loss: 0.1128 - val_accuracy: 0.5058 - val_loss: 2.1984\n",
      "Epoch 30/50\n",
      "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.9586 - loss: 0.1240 - val_accuracy: 0.4593 - val_loss: 2.5459\n",
      "Epoch 31/50\n",
      "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.9772 - loss: 0.0808 - val_accuracy: 0.5174 - val_loss: 2.1469\n",
      "Epoch 32/50\n",
      "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.9765 - loss: 0.0844 - val_accuracy: 0.4942 - val_loss: 2.1924\n",
      "Epoch 33/50\n",
      "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.9796 - loss: 0.0621 - val_accuracy: 0.4884 - val_loss: 2.5418\n",
      "Epoch 34/50\n",
      "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.9774 - loss: 0.0611 - val_accuracy: 0.4942 - val_loss: 2.6748\n",
      "Epoch 35/50\n",
      "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.9733 - loss: 0.1076 - val_accuracy: 0.5233 - val_loss: 2.6027\n",
      "Epoch 36/50\n",
      "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.9853 - loss: 0.0345 - val_accuracy: 0.5640 - val_loss: 2.7176\n",
      "Epoch 37/50\n",
      "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.9819 - loss: 0.0466 - val_accuracy: 0.5174 - val_loss: 3.4311\n",
      "Epoch 38/50\n",
      "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.9699 - loss: 0.0809 - val_accuracy: 0.5174 - val_loss: 2.8433\n",
      "Epoch 39/50\n",
      "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.9809 - loss: 0.0410 - val_accuracy: 0.4942 - val_loss: 3.1765\n",
      "Epoch 40/50\n",
      "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.9773 - loss: 0.0757 - val_accuracy: 0.5116 - val_loss: 2.8880\n",
      "Epoch 41/50\n",
      "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.9781 - loss: 0.0967 - val_accuracy: 0.5640 - val_loss: 2.1844\n",
      "Epoch 42/50\n",
      "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.9778 - loss: 0.0636 - val_accuracy: 0.5465 - val_loss: 2.7124\n",
      "Epoch 43/50\n",
      "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.9708 - loss: 0.0853 - val_accuracy: 0.5930 - val_loss: 2.2108\n",
      "Epoch 44/50\n",
      "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.9821 - loss: 0.0448 - val_accuracy: 0.5640 - val_loss: 2.4013\n",
      "Epoch 45/50\n",
      "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.9841 - loss: 0.0668 - val_accuracy: 0.5407 - val_loss: 3.0278\n",
      "Epoch 46/50\n",
      "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.9863 - loss: 0.0556 - val_accuracy: 0.5465 - val_loss: 2.3050\n",
      "Epoch 47/50\n",
      "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.9788 - loss: 0.0689 - val_accuracy: 0.5349 - val_loss: 2.7326\n",
      "Epoch 48/50\n",
      "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.9855 - loss: 0.0432 - val_accuracy: 0.5349 - val_loss: 2.9274\n",
      "Epoch 49/50\n",
      "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.9752 - loss: 0.0794 - val_accuracy: 0.5233 - val_loss: 2.6667\n",
      "Epoch 50/50\n",
      "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.9732 - loss: 0.0768 - val_accuracy: 0.5233 - val_loss: 2.5378\n",
      "\u001b[1m5/5\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step \n",
      "ANN Accuracy: 0.5590\n",
      "ANN Classification Report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.71      0.81      0.76        62\n",
      "           1       0.44      0.29      0.35        14\n",
      "           2       0.62      0.58      0.60        53\n",
      "\n",
      "    accuracy                           0.66       129\n",
      "   macro avg       0.59      0.56      0.57       129\n",
      "weighted avg       0.65      0.66      0.65       129\n",
      "\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "from sklearn.preprocessing import LabelEncoder\n",
    "from sklearn.svm import SVC\n",
    "from sklearn.metrics import balanced_accuracy_score, classification_report\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "\n",
    "# Load the data\n",
    "train_data = np.load('../Files/extracted_features/layer_features_lv60_self/train_8.npz')\n",
    "test_data = np.load('../Files/extracted_features/layer_features_lv60_self/test_8.npz')\n",
    "\n",
    "train_features = train_data['features']  # Ensure these have 1024 features\n",
    "test_features = test_data['features']    # Ensure these have 1024 features\n",
    "\n",
    "# Read Age labels instead of Gender\n",
    "train_labels = pd.read_csv('../Files/labels/y_train.csv').Age_Group\n",
    "test_labels = pd.read_csv('../Files/labels/y_test.csv').Age_Group\n",
    "\n",
    "# Encode the labels\n",
    "label_encoder = LabelEncoder()\n",
    "train_labels_encoded = label_encoder.fit_transform(train_labels)\n",
    "\n",
    "# Handle unseen labels in test set by filtering out labels not present in train set\n",
    "test_labels_filtered = test_labels[test_labels.isin(train_labels.unique())]\n",
    "test_features_filtered = test_features[test_labels.isin(train_labels.unique())]\n",
    "test_labels_encoded = label_encoder.transform(test_labels_filtered)\n",
    "\n",
    "# Standardize features\n",
    "scaler = StandardScaler()\n",
    "train_features_normalized = scaler.fit_transform(train_features)\n",
    "test_features_normalized = scaler.transform(test_features_filtered)\n",
    "\n",
    "# SVM model\n",
    "svm_model = SVC(kernel='linear', C=10.0, gamma='scale', random_state=42)\n",
    "svm_model.fit(train_features_normalized, train_labels_encoded)\n",
    "\n",
    "# SVM Prediction and Evaluation\n",
    "svm_predictions = svm_model.predict(test_features_normalized)\n",
    "svm_accuracy = balanced_accuracy_score(test_labels_encoded, svm_predictions)\n",
    "print(f\"SVM Accuracy: {svm_accuracy:.4f}\")\n",
    "print(\"SVM Classification Report:\")\n",
    "print(classification_report(test_labels_encoded, svm_predictions))\n",
    "\n",
    "# CNN model (TensorFlow)\n",
    "import tensorflow as tf\n",
    "from tensorflow.keras.models import Sequential\n",
    "from tensorflow.keras.layers import Conv1D, Flatten, Dense, Dropout\n",
    "\n",
    "train_features_cnn = np.expand_dims(train_features_normalized, axis=-1)  # Shape: (num_samples, 1024, 1)\n",
    "test_features_cnn = np.expand_dims(test_features_normalized, axis=-1)    # Shape: (num_samples, 1024, 1)\n",
    "\n",
    "cnn_model = Sequential([\n",
    "    Conv1D(64, kernel_size=5, activation='relu', input_shape=(1024, 1)),  # Updated input shape to 1024\n",
    "    Conv1D(128, kernel_size=5, activation='relu'),\n",
    "    Conv1D(256, kernel_size=5, activation='relu'),\n",
    "    Flatten(),\n",
    "    Dense(256, activation='relu'),\n",
    "    Dropout(0.5),\n",
    "    Dense(len(label_encoder.classes_), activation='softmax')\n",
    "])\n",
    "\n",
    "cnn_model.compile(optimizer='adam', loss='sparse_categorical_crossentropy', metrics=['accuracy'])\n",
    "\n",
    "cnn_model.fit(train_features_cnn, train_labels_encoded, epochs=50, batch_size=32, validation_split=0.2)\n",
    "\n",
    "# CNN Prediction and Evaluation\n",
    "cnn_predictions = np.argmax(cnn_model.predict(test_features_cnn), axis=-1)\n",
    "cnn_accuracy = balanced_accuracy_score(test_labels_encoded, cnn_predictions)\n",
    "print(f\"CNN Accuracy: {cnn_accuracy:.4f}\")\n",
    "print(\"CNN Classification Report:\")\n",
    "print(classification_report(test_labels_encoded, cnn_predictions))\n",
    "\n",
    "# ANN model (TensorFlow)\n",
    "ann_model = Sequential([\n",
    "    Dense(512, activation='relu', input_shape=(1024,)),  # Updated input shape to 1024\n",
    "    Dropout(0.5),\n",
    "    Dense(256, activation='relu'),\n",
    "    Dropout(0.5),\n",
    "    Dense(128, activation='relu'),\n",
    "    Dropout(0.5),\n",
    "    Dense(len(label_encoder.classes_), activation='softmax')\n",
    "])\n",
    "\n",
    "ann_model.compile(optimizer='adam', loss='sparse_categorical_crossentropy', metrics=['accuracy'])\n",
    "\n",
    "ann_model.fit(train_features_normalized, train_labels_encoded, epochs=50, batch_size=32, validation_split=0.2)\n",
    "\n",
    "# ANN Prediction and Evaluation\n",
    "ann_predictions = np.argmax(ann_model.predict(test_features_normalized), axis=-1)\n",
    "ann_accuracy = balanced_accuracy_score(test_labels_encoded, ann_predictions)\n",
    "print(f\"ANN Accuracy: {ann_accuracy:.4f}\")\n",
    "print(\"ANN Classification Report:\")\n",
    "print(classification_report(test_labels_encoded, ann_predictions))\n",
    "\n",
    "# PyTorch CNN Model\n",
    "import torch\n",
    "from torch.utils.data import DataLoader, TensorDataset\n",
    "\n",
    "X_train_tensor = torch.tensor(train_features_cnn, dtype=torch.float32).permute(0, 2, 1)  # Shape: (num_samples, 1, 1024)\n",
    "y_train_tensor = torch.tensor(train_labels_encoded, dtype=torch.long)\n",
    "X_test_tensor = torch.tensor(test_features_cnn, dtype=torch.float32).permute(0, 2, 1)    # Shape: (num_samples, 1, 1024)\n",
    "y_test_tensor = torch.tensor(test_labels_encoded, dtype=torch.long)\n",
    "\n",
    "train_dataset = TensorDataset(X_train_tensor, y_train_tensor)\n",
    "test_dataset = TensorDataset(X_test_tensor, y_test_tensor)\n",
    "\n",
    "train_loader = DataLoader(train_dataset, batch_size=64, shuffle=True)\n",
    "test_loader = DataLoader(test_dataset, batch_size=64, shuffle=False)\n",
    "\n",
    "import torch.nn as nn\n",
    "import torch.optim as optim\n",
    "\n",
    "class CNN1DModel(nn.Module):\n",
    "    def __init__(self, input_channels, num_classes):\n",
    "        super(CNN1DModel, self).__init__()\n",
    "        self.conv1 = nn.Conv1d(input_channels, 32, kernel_size=5, stride=1, padding=2)\n",
    "        self.bn1 = nn.BatchNorm1d(32)\n",
    "        self.relu = nn.ReLU()\n",
    "        self.conv2 = nn.Conv1d(32, 64, kernel_size=5, stride=1, padding=2)\n",
    "        self.bn2 = nn.BatchNorm1d(64)\n",
    "        self.conv3 = nn.Conv1d(64, 128, kernel_size=5, stride=1, padding=2)\n",
    "        self.bn3 = nn.BatchNorm1d(128)\n",
    "        self.flatten = nn.Flatten()\n",
    "        self.fc1 = nn.Linear(128 * 1024, 512)  # Updated to 1024 features\n",
    "        self.fc2 = nn.Linear(512, num_classes)\n",
    "        self.dropout = nn.Dropout(0.5)\n",
    "    \n",
    "    def forward(self, x):\n",
    "        x = self.relu(self.bn1(self.conv1(x)))\n",
    "        x = self.relu(self.bn2(self.conv2(x)))\n",
    "        x = self.relu(self.bn3(self.conv3(x)))\n",
    "        x = self.flatten(x)\n",
    "        x = self.dropout(self.relu(self.fc1(x)))\n",
    "        x = self.fc2(x)\n",
    "        return x\n",
    "\n",
    "input_channels = 1\n",
    "num_classes = len(label_encoder.classes_)\n",
    "model = CNN1DModel(input_channels, num_classes)\n",
    "criterion = nn.CrossEntropyLoss()\n",
    "optimizer = optim.Adam(model.parameters(), lr=0.001)\n",
    "\n",
    "# Training loop and evaluation (not shown)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "SVM Accuracy: 0.5708\n",
      "SVM Classification Report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.79      0.71      0.75        62\n",
      "           1       0.36      0.29      0.32        14\n",
      "           2       0.61      0.72      0.66        53\n",
      "\n",
      "    accuracy                           0.67       129\n",
      "   macro avg       0.59      0.57      0.58       129\n",
      "weighted avg       0.67      0.67      0.66       129\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2024-12-11 18:08:28.533531: E external/local_xla/xla/stream_executor/cuda/cuda_fft.cc:485] Unable to register cuFFT factory: Attempting to register factory for plugin cuFFT when one has already been registered\n",
      "2024-12-11 18:08:28.547721: E external/local_xla/xla/stream_executor/cuda/cuda_dnn.cc:8454] Unable to register cuDNN factory: Attempting to register factory for plugin cuDNN when one has already been registered\n",
      "2024-12-11 18:08:28.551289: E external/local_xla/xla/stream_executor/cuda/cuda_blas.cc:1452] Unable to register cuBLAS factory: Attempting to register factory for plugin cuBLAS when one has already been registered\n",
      "2024-12-11 18:08:28.561679: I tensorflow/core/platform/cpu_feature_guard.cc:210] This TensorFlow binary is optimized to use available CPU instructions in performance-critical operations.\n",
      "To enable the following instructions: AVX2 FMA, in other operations, rebuild TensorFlow with the appropriate compiler flags.\n",
      "2024-12-11 18:08:29.361423: W tensorflow/compiler/tf2tensorrt/utils/py_utils.cc:38] TF-TRT Warning: Could not find TensorRT\n",
      "/home/mojo/.local/lib/python3.12/site-packages/keras/src/layers/convolutional/base_conv.py:107: UserWarning: Do not pass an `input_shape`/`input_dim` argument to a layer. When using Sequential models, prefer using an `Input(shape)` object as the first layer in the model instead.\n",
      "  super().__init__(activity_regularizer=activity_regularizer, **kwargs)\n",
      "WARNING: All log messages before absl::InitializeLog() is called are written to STDERR\n",
      "I0000 00:00:1733920709.967040  204215 cuda_executor.cc:1015] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero. See more at https://github.com/torvalds/linux/blob/v6.0/Documentation/ABI/testing/sysfs-bus-pci#L344-L355\n",
      "2024-12-11 18:08:30.002207: W tensorflow/core/common_runtime/gpu/gpu_device.cc:2343] Cannot dlopen some GPU libraries. Please make sure the missing libraries mentioned above are installed properly if you would like to use GPU. Follow the guide at https://www.tensorflow.org/install/gpu for how to download and setup the required libraries for your platform.\n",
      "Skipping registering GPU devices...\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/50\n",
      "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m11s\u001b[0m 467ms/step - accuracy: 0.5546 - loss: 1.9396 - val_accuracy: 0.4593 - val_loss: 0.9269\n",
      "Epoch 2/50\n",
      "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m10s\u001b[0m 457ms/step - accuracy: 0.7349 - loss: 0.6025 - val_accuracy: 0.5988 - val_loss: 0.8401\n",
      "Epoch 3/50\n",
      "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m10s\u001b[0m 469ms/step - accuracy: 0.8572 - loss: 0.3889 - val_accuracy: 0.6395 - val_loss: 0.7856\n",
      "Epoch 4/50\n",
      "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m11s\u001b[0m 487ms/step - accuracy: 0.9143 - loss: 0.2355 - val_accuracy: 0.6977 - val_loss: 0.7589\n",
      "Epoch 5/50\n",
      "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m10s\u001b[0m 461ms/step - accuracy: 0.9724 - loss: 0.1098 - val_accuracy: 0.4826 - val_loss: 1.9001\n",
      "Epoch 6/50\n",
      "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m10s\u001b[0m 459ms/step - accuracy: 0.9878 - loss: 0.0460 - val_accuracy: 0.6279 - val_loss: 1.3048\n",
      "Epoch 7/50\n",
      "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m10s\u001b[0m 466ms/step - accuracy: 0.9865 - loss: 0.0536 - val_accuracy: 0.6628 - val_loss: 0.9780\n",
      "Epoch 8/50\n",
      "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m10s\u001b[0m 476ms/step - accuracy: 0.9847 - loss: 0.0600 - val_accuracy: 0.5465 - val_loss: 1.7928\n",
      "Epoch 9/50\n",
      "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m10s\u001b[0m 477ms/step - accuracy: 0.9993 - loss: 0.0119 - val_accuracy: 0.5174 - val_loss: 2.1156\n",
      "Epoch 10/50\n",
      "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m10s\u001b[0m 475ms/step - accuracy: 0.9948 - loss: 0.0471 - val_accuracy: 0.4651 - val_loss: 1.5298\n",
      "Epoch 11/50\n",
      "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m21s\u001b[0m 478ms/step - accuracy: 0.9871 - loss: 0.0437 - val_accuracy: 0.5698 - val_loss: 1.8233\n",
      "Epoch 12/50\n",
      "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m11s\u001b[0m 479ms/step - accuracy: 0.9949 - loss: 0.0176 - val_accuracy: 0.6163 - val_loss: 1.5536\n",
      "Epoch 13/50\n",
      "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m11s\u001b[0m 478ms/step - accuracy: 1.0000 - loss: 0.0043 - val_accuracy: 0.5872 - val_loss: 2.1847\n",
      "Epoch 14/50\n",
      "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m11s\u001b[0m 481ms/step - accuracy: 0.9990 - loss: 0.0028 - val_accuracy: 0.5465 - val_loss: 2.4951\n",
      "Epoch 15/50\n",
      "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m11s\u001b[0m 484ms/step - accuracy: 1.0000 - loss: 0.0030 - val_accuracy: 0.6453 - val_loss: 1.9180\n",
      "Epoch 16/50\n",
      "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m11s\u001b[0m 483ms/step - accuracy: 0.9993 - loss: 0.0028 - val_accuracy: 0.5174 - val_loss: 2.9391\n",
      "Epoch 17/50\n",
      "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m10s\u001b[0m 471ms/step - accuracy: 0.9986 - loss: 0.0073 - val_accuracy: 0.6570 - val_loss: 1.6964\n",
      "Epoch 18/50\n",
      "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m10s\u001b[0m 464ms/step - accuracy: 0.9959 - loss: 0.0123 - val_accuracy: 0.6047 - val_loss: 1.7509\n",
      "Epoch 19/50\n",
      "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m10s\u001b[0m 463ms/step - accuracy: 0.9976 - loss: 0.0100 - val_accuracy: 0.6047 - val_loss: 1.6241\n",
      "Epoch 20/50\n",
      "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m10s\u001b[0m 466ms/step - accuracy: 0.9899 - loss: 0.0271 - val_accuracy: 0.5581 - val_loss: 1.9123\n",
      "Epoch 21/50\n",
      "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m10s\u001b[0m 476ms/step - accuracy: 1.0000 - loss: 0.0040 - val_accuracy: 0.5698 - val_loss: 2.2618\n",
      "Epoch 22/50\n",
      "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m11s\u001b[0m 492ms/step - accuracy: 0.9982 - loss: 0.0030 - val_accuracy: 0.5640 - val_loss: 2.3436\n",
      "Epoch 23/50\n",
      "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m20s\u001b[0m 489ms/step - accuracy: 1.0000 - loss: 6.4831e-04 - val_accuracy: 0.5407 - val_loss: 2.6517\n",
      "Epoch 24/50\n",
      "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m11s\u001b[0m 487ms/step - accuracy: 1.0000 - loss: 4.6907e-04 - val_accuracy: 0.5698 - val_loss: 2.5565\n",
      "Epoch 25/50\n",
      "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m11s\u001b[0m 492ms/step - accuracy: 0.9996 - loss: 0.0017 - val_accuracy: 0.5349 - val_loss: 2.4590\n",
      "Epoch 26/50\n",
      "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m11s\u001b[0m 485ms/step - accuracy: 0.9991 - loss: 0.0041 - val_accuracy: 0.5000 - val_loss: 2.2603\n",
      "Epoch 27/50\n",
      "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m11s\u001b[0m 482ms/step - accuracy: 1.0000 - loss: 0.0071 - val_accuracy: 0.6279 - val_loss: 1.9340\n",
      "Epoch 28/50\n",
      "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m11s\u001b[0m 507ms/step - accuracy: 0.9965 - loss: 0.0124 - val_accuracy: 0.6279 - val_loss: 1.8808\n",
      "Epoch 29/50\n",
      "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m11s\u001b[0m 486ms/step - accuracy: 0.9988 - loss: 0.0176 - val_accuracy: 0.5349 - val_loss: 1.9672\n",
      "Epoch 30/50\n",
      "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m11s\u001b[0m 482ms/step - accuracy: 0.9949 - loss: 0.0134 - val_accuracy: 0.5930 - val_loss: 1.9573\n",
      "Epoch 31/50\n",
      "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m11s\u001b[0m 491ms/step - accuracy: 0.9988 - loss: 0.0018 - val_accuracy: 0.5814 - val_loss: 2.2479\n",
      "Epoch 32/50\n",
      "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m11s\u001b[0m 486ms/step - accuracy: 0.9995 - loss: 0.0037 - val_accuracy: 0.6744 - val_loss: 1.6394\n",
      "Epoch 33/50\n",
      "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m11s\u001b[0m 491ms/step - accuracy: 1.0000 - loss: 0.0017 - val_accuracy: 0.6221 - val_loss: 1.9303\n",
      "Epoch 34/50\n",
      "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m11s\u001b[0m 497ms/step - accuracy: 1.0000 - loss: 4.0561e-04 - val_accuracy: 0.5872 - val_loss: 2.4182\n",
      "Epoch 35/50\n",
      "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m11s\u001b[0m 500ms/step - accuracy: 1.0000 - loss: 3.2037e-04 - val_accuracy: 0.5349 - val_loss: 2.8954\n",
      "Epoch 36/50\n",
      "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m11s\u001b[0m 504ms/step - accuracy: 1.0000 - loss: 0.0018 - val_accuracy: 0.6453 - val_loss: 2.2117\n",
      "Epoch 37/50\n",
      "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m11s\u001b[0m 496ms/step - accuracy: 1.0000 - loss: 2.8926e-04 - val_accuracy: 0.6512 - val_loss: 2.3895\n",
      "Epoch 38/50\n",
      "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m11s\u001b[0m 504ms/step - accuracy: 1.0000 - loss: 2.3448e-04 - val_accuracy: 0.6163 - val_loss: 2.7234\n",
      "Epoch 39/50\n",
      "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m11s\u001b[0m 491ms/step - accuracy: 0.9971 - loss: 0.0029 - val_accuracy: 0.5581 - val_loss: 3.0452\n",
      "Epoch 40/50\n",
      "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m11s\u001b[0m 498ms/step - accuracy: 0.9988 - loss: 0.0018 - val_accuracy: 0.7849 - val_loss: 1.1501\n",
      "Epoch 41/50\n",
      "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m11s\u001b[0m 494ms/step - accuracy: 0.9933 - loss: 0.0197 - val_accuracy: 0.5698 - val_loss: 2.3764\n",
      "Epoch 42/50\n",
      "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m11s\u001b[0m 499ms/step - accuracy: 0.9904 - loss: 0.0311 - val_accuracy: 0.5407 - val_loss: 3.8127\n",
      "Epoch 43/50\n",
      "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m11s\u001b[0m 507ms/step - accuracy: 0.9875 - loss: 0.0570 - val_accuracy: 0.6628 - val_loss: 1.6816\n",
      "Epoch 44/50\n",
      "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m11s\u001b[0m 508ms/step - accuracy: 0.9721 - loss: 0.0829 - val_accuracy: 0.6105 - val_loss: 1.5035\n",
      "Epoch 45/50\n",
      "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m11s\u001b[0m 500ms/step - accuracy: 0.9699 - loss: 0.0465 - val_accuracy: 0.5465 - val_loss: 2.7746\n",
      "Epoch 46/50\n",
      "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m11s\u001b[0m 501ms/step - accuracy: 0.9902 - loss: 0.0296 - val_accuracy: 0.4767 - val_loss: 2.7067\n",
      "Epoch 47/50\n",
      "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m11s\u001b[0m 489ms/step - accuracy: 0.9924 - loss: 0.0321 - val_accuracy: 0.7267 - val_loss: 1.4020\n",
      "Epoch 48/50\n",
      "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m11s\u001b[0m 496ms/step - accuracy: 0.9998 - loss: 0.0062 - val_accuracy: 0.5814 - val_loss: 3.4008\n",
      "Epoch 49/50\n",
      "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m11s\u001b[0m 481ms/step - accuracy: 0.9984 - loss: 0.0036 - val_accuracy: 0.5698 - val_loss: 3.1137\n",
      "Epoch 50/50\n",
      "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m11s\u001b[0m 484ms/step - accuracy: 0.9972 - loss: 0.0078 - val_accuracy: 0.5465 - val_loss: 2.7503\n",
      "\u001b[1m5/5\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 44ms/step\n",
      "CNN Accuracy: 0.5447\n",
      "CNN Classification Report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.80      0.73      0.76        62\n",
      "           1       0.22      0.29      0.25        14\n",
      "           2       0.60      0.62      0.61        53\n",
      "\n",
      "    accuracy                           0.64       129\n",
      "   macro avg       0.54      0.54      0.54       129\n",
      "weighted avg       0.66      0.64      0.64       129\n",
      "\n",
      "Epoch 1/50\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/mojo/.local/lib/python3.12/site-packages/keras/src/layers/core/dense.py:87: UserWarning: Do not pass an `input_shape`/`input_dim` argument to a layer. When using Sequential models, prefer using an `Input(shape)` object as the first layer in the model instead.\n",
      "  super().__init__(activity_regularizer=activity_regularizer, **kwargs)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 9ms/step - accuracy: 0.5218 - loss: 1.3326 - val_accuracy: 0.2907 - val_loss: 1.2129\n",
      "Epoch 2/50\n",
      "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.5897 - loss: 1.0528 - val_accuracy: 0.4302 - val_loss: 1.0221\n",
      "Epoch 3/50\n",
      "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.6235 - loss: 0.9368 - val_accuracy: 0.4186 - val_loss: 1.0760\n",
      "Epoch 4/50\n",
      "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.6943 - loss: 0.7490 - val_accuracy: 0.5116 - val_loss: 1.0835\n",
      "Epoch 5/50\n",
      "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.6962 - loss: 0.6864 - val_accuracy: 0.4826 - val_loss: 1.1319\n",
      "Epoch 6/50\n",
      "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.7465 - loss: 0.6421 - val_accuracy: 0.5291 - val_loss: 0.9953\n",
      "Epoch 7/50\n",
      "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.7657 - loss: 0.5158 - val_accuracy: 0.5349 - val_loss: 0.9667\n",
      "Epoch 8/50\n",
      "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.8074 - loss: 0.5059 - val_accuracy: 0.5407 - val_loss: 0.9666\n",
      "Epoch 9/50\n",
      "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.8288 - loss: 0.4358 - val_accuracy: 0.5523 - val_loss: 1.0616\n",
      "Epoch 10/50\n",
      "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.8462 - loss: 0.4616 - val_accuracy: 0.4884 - val_loss: 1.0571\n",
      "Epoch 11/50\n",
      "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.8615 - loss: 0.3949 - val_accuracy: 0.4709 - val_loss: 1.1355\n",
      "Epoch 12/50\n",
      "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.8807 - loss: 0.3122 - val_accuracy: 0.5116 - val_loss: 1.1760\n",
      "Epoch 13/50\n",
      "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.8747 - loss: 0.3160 - val_accuracy: 0.5640 - val_loss: 1.1018\n",
      "Epoch 14/50\n",
      "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.8789 - loss: 0.3136 - val_accuracy: 0.5000 - val_loss: 1.3730\n",
      "Epoch 15/50\n",
      "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.8824 - loss: 0.2713 - val_accuracy: 0.4709 - val_loss: 1.3552\n",
      "Epoch 16/50\n",
      "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.9109 - loss: 0.2583 - val_accuracy: 0.4767 - val_loss: 1.5713\n",
      "Epoch 17/50\n",
      "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.9152 - loss: 0.2138 - val_accuracy: 0.5640 - val_loss: 1.2721\n",
      "Epoch 18/50\n",
      "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.9352 - loss: 0.2033 - val_accuracy: 0.5465 - val_loss: 1.3710\n",
      "Epoch 19/50\n",
      "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.9420 - loss: 0.1767 - val_accuracy: 0.5349 - val_loss: 1.4343\n",
      "Epoch 20/50\n",
      "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.9427 - loss: 0.2129 - val_accuracy: 0.4651 - val_loss: 1.7834\n",
      "Epoch 21/50\n",
      "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.9423 - loss: 0.1725 - val_accuracy: 0.5523 - val_loss: 1.5732\n",
      "Epoch 22/50\n",
      "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.9493 - loss: 0.1579 - val_accuracy: 0.6163 - val_loss: 1.1572\n",
      "Epoch 23/50\n",
      "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.9585 - loss: 0.1330 - val_accuracy: 0.5291 - val_loss: 1.7201\n",
      "Epoch 24/50\n",
      "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.9537 - loss: 0.1396 - val_accuracy: 0.5581 - val_loss: 1.6432\n",
      "Epoch 25/50\n",
      "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.9694 - loss: 0.1069 - val_accuracy: 0.5174 - val_loss: 2.0272\n",
      "Epoch 26/50\n",
      "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.9751 - loss: 0.0785 - val_accuracy: 0.5814 - val_loss: 1.5930\n",
      "Epoch 27/50\n",
      "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.9483 - loss: 0.1165 - val_accuracy: 0.5233 - val_loss: 1.8906\n",
      "Epoch 28/50\n",
      "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.9635 - loss: 0.0959 - val_accuracy: 0.5523 - val_loss: 2.0071\n",
      "Epoch 29/50\n",
      "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.9772 - loss: 0.0806 - val_accuracy: 0.5523 - val_loss: 1.9509\n",
      "Epoch 30/50\n",
      "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.9531 - loss: 0.1346 - val_accuracy: 0.5698 - val_loss: 2.1806\n",
      "Epoch 31/50\n",
      "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.9721 - loss: 0.1019 - val_accuracy: 0.5233 - val_loss: 2.2945\n",
      "Epoch 32/50\n",
      "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.9619 - loss: 0.1110 - val_accuracy: 0.5988 - val_loss: 1.9303\n",
      "Epoch 33/50\n",
      "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.9710 - loss: 0.0799 - val_accuracy: 0.5407 - val_loss: 2.3061\n",
      "Epoch 34/50\n",
      "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.9705 - loss: 0.0771 - val_accuracy: 0.5349 - val_loss: 2.5594\n",
      "Epoch 35/50\n",
      "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.9707 - loss: 0.0754 - val_accuracy: 0.5756 - val_loss: 2.2981\n",
      "Epoch 36/50\n",
      "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.9665 - loss: 0.0787 - val_accuracy: 0.5465 - val_loss: 2.4366\n",
      "Epoch 37/50\n",
      "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.9787 - loss: 0.0803 - val_accuracy: 0.5930 - val_loss: 2.3013\n",
      "Epoch 38/50\n",
      "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.9672 - loss: 0.1035 - val_accuracy: 0.5581 - val_loss: 2.2897\n",
      "Epoch 39/50\n",
      "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.9677 - loss: 0.0905 - val_accuracy: 0.5000 - val_loss: 3.0480\n",
      "Epoch 40/50\n",
      "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.9771 - loss: 0.0601 - val_accuracy: 0.5988 - val_loss: 2.2808\n",
      "Epoch 41/50\n",
      "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.9777 - loss: 0.0825 - val_accuracy: 0.5581 - val_loss: 2.7760\n",
      "Epoch 42/50\n",
      "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.9745 - loss: 0.0790 - val_accuracy: 0.5581 - val_loss: 2.5241\n",
      "Epoch 43/50\n",
      "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.9817 - loss: 0.0586 - val_accuracy: 0.5698 - val_loss: 2.3662\n",
      "Epoch 44/50\n",
      "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.9695 - loss: 0.0932 - val_accuracy: 0.4884 - val_loss: 2.8456\n",
      "Epoch 45/50\n",
      "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.9891 - loss: 0.0445 - val_accuracy: 0.5814 - val_loss: 2.3012\n",
      "Epoch 46/50\n",
      "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.9864 - loss: 0.0418 - val_accuracy: 0.5756 - val_loss: 2.4157\n",
      "Epoch 47/50\n",
      "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.9856 - loss: 0.0708 - val_accuracy: 0.5465 - val_loss: 2.6518\n",
      "Epoch 48/50\n",
      "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.9684 - loss: 0.0989 - val_accuracy: 0.5640 - val_loss: 2.7175\n",
      "Epoch 49/50\n",
      "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.9948 - loss: 0.0188 - val_accuracy: 0.5523 - val_loss: 3.0692\n",
      "Epoch 50/50\n",
      "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.9777 - loss: 0.0559 - val_accuracy: 0.5930 - val_loss: 2.4580\n",
      "\u001b[1m5/5\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step \n",
      "ANN Accuracy: 0.6449\n",
      "ANN Classification Report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.80      0.77      0.79        62\n",
      "           1       0.41      0.50      0.45        14\n",
      "           2       0.67      0.66      0.67        53\n",
      "\n",
      "    accuracy                           0.70       129\n",
      "   macro avg       0.63      0.64      0.64       129\n",
      "weighted avg       0.71      0.70      0.70       129\n",
      "\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "from sklearn.preprocessing import LabelEncoder\n",
    "from sklearn.svm import SVC\n",
    "from sklearn.metrics import balanced_accuracy_score, classification_report\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "\n",
    "# Load the data\n",
    "train_data = np.load('../Files/extracted_features/layer_features_lv60_self/train_9.npz')\n",
    "test_data = np.load('../Files/extracted_features/layer_features_lv60_self/test_9.npz')\n",
    "\n",
    "train_features = train_data['features']  # Ensure these have 1024 features\n",
    "test_features = test_data['features']    # Ensure these have 1024 features\n",
    "\n",
    "# Read Age labels instead of Gender\n",
    "train_labels = pd.read_csv('../Files/labels/y_train.csv').Age_Group\n",
    "test_labels = pd.read_csv('../Files/labels/y_test.csv').Age_Group\n",
    "\n",
    "# Encode the labels\n",
    "label_encoder = LabelEncoder()\n",
    "train_labels_encoded = label_encoder.fit_transform(train_labels)\n",
    "\n",
    "# Handle unseen labels in test set by filtering out labels not present in train set\n",
    "test_labels_filtered = test_labels[test_labels.isin(train_labels.unique())]\n",
    "test_features_filtered = test_features[test_labels.isin(train_labels.unique())]\n",
    "test_labels_encoded = label_encoder.transform(test_labels_filtered)\n",
    "\n",
    "# Standardize features\n",
    "scaler = StandardScaler()\n",
    "train_features_normalized = scaler.fit_transform(train_features)\n",
    "test_features_normalized = scaler.transform(test_features_filtered)\n",
    "\n",
    "# SVM model\n",
    "svm_model = SVC(kernel='linear', C=10.0, gamma='scale', random_state=42)\n",
    "svm_model.fit(train_features_normalized, train_labels_encoded)\n",
    "\n",
    "# SVM Prediction and Evaluation\n",
    "svm_predictions = svm_model.predict(test_features_normalized)\n",
    "svm_accuracy = balanced_accuracy_score(test_labels_encoded, svm_predictions)\n",
    "print(f\"SVM Accuracy: {svm_accuracy:.4f}\")\n",
    "print(\"SVM Classification Report:\")\n",
    "print(classification_report(test_labels_encoded, svm_predictions))\n",
    "\n",
    "# CNN model (TensorFlow)\n",
    "import tensorflow as tf\n",
    "from tensorflow.keras.models import Sequential\n",
    "from tensorflow.keras.layers import Conv1D, Flatten, Dense, Dropout\n",
    "\n",
    "train_features_cnn = np.expand_dims(train_features_normalized, axis=-1)  # Shape: (num_samples, 1024, 1)\n",
    "test_features_cnn = np.expand_dims(test_features_normalized, axis=-1)    # Shape: (num_samples, 1024, 1)\n",
    "\n",
    "cnn_model = Sequential([\n",
    "    Conv1D(64, kernel_size=5, activation='relu', input_shape=(1024, 1)),  # Updated input shape to 1024\n",
    "    Conv1D(128, kernel_size=5, activation='relu'),\n",
    "    Conv1D(256, kernel_size=5, activation='relu'),\n",
    "    Flatten(),\n",
    "    Dense(256, activation='relu'),\n",
    "    Dropout(0.5),\n",
    "    Dense(len(label_encoder.classes_), activation='softmax')\n",
    "])\n",
    "\n",
    "cnn_model.compile(optimizer='adam', loss='sparse_categorical_crossentropy', metrics=['accuracy'])\n",
    "\n",
    "cnn_model.fit(train_features_cnn, train_labels_encoded, epochs=50, batch_size=32, validation_split=0.2)\n",
    "\n",
    "# CNN Prediction and Evaluation\n",
    "cnn_predictions = np.argmax(cnn_model.predict(test_features_cnn), axis=-1)\n",
    "cnn_accuracy = balanced_accuracy_score(test_labels_encoded, cnn_predictions)\n",
    "print(f\"CNN Accuracy: {cnn_accuracy:.4f}\")\n",
    "print(\"CNN Classification Report:\")\n",
    "print(classification_report(test_labels_encoded, cnn_predictions))\n",
    "\n",
    "# ANN model (TensorFlow)\n",
    "ann_model = Sequential([\n",
    "    Dense(512, activation='relu', input_shape=(1024,)),  # Updated input shape to 1024\n",
    "    Dropout(0.5),\n",
    "    Dense(256, activation='relu'),\n",
    "    Dropout(0.5),\n",
    "    Dense(128, activation='relu'),\n",
    "    Dropout(0.5),\n",
    "    Dense(len(label_encoder.classes_), activation='softmax')\n",
    "])\n",
    "\n",
    "ann_model.compile(optimizer='adam', loss='sparse_categorical_crossentropy', metrics=['accuracy'])\n",
    "\n",
    "ann_model.fit(train_features_normalized, train_labels_encoded, epochs=50, batch_size=32, validation_split=0.2)\n",
    "\n",
    "# ANN Prediction and Evaluation\n",
    "ann_predictions = np.argmax(ann_model.predict(test_features_normalized), axis=-1)\n",
    "ann_accuracy = balanced_accuracy_score(test_labels_encoded, ann_predictions)\n",
    "print(f\"ANN Accuracy: {ann_accuracy:.4f}\")\n",
    "print(\"ANN Classification Report:\")\n",
    "print(classification_report(test_labels_encoded, ann_predictions))\n",
    "\n",
    "# PyTorch CNN Model\n",
    "import torch\n",
    "from torch.utils.data import DataLoader, TensorDataset\n",
    "\n",
    "X_train_tensor = torch.tensor(train_features_cnn, dtype=torch.float32).permute(0, 2, 1)  # Shape: (num_samples, 1, 1024)\n",
    "y_train_tensor = torch.tensor(train_labels_encoded, dtype=torch.long)\n",
    "X_test_tensor = torch.tensor(test_features_cnn, dtype=torch.float32).permute(0, 2, 1)    # Shape: (num_samples, 1, 1024)\n",
    "y_test_tensor = torch.tensor(test_labels_encoded, dtype=torch.long)\n",
    "\n",
    "train_dataset = TensorDataset(X_train_tensor, y_train_tensor)\n",
    "test_dataset = TensorDataset(X_test_tensor, y_test_tensor)\n",
    "\n",
    "train_loader = DataLoader(train_dataset, batch_size=64, shuffle=True)\n",
    "test_loader = DataLoader(test_dataset, batch_size=64, shuffle=False)\n",
    "\n",
    "import torch.nn as nn\n",
    "import torch.optim as optim\n",
    "\n",
    "class CNN1DModel(nn.Module):\n",
    "    def __init__(self, input_channels, num_classes):\n",
    "        super(CNN1DModel, self).__init__()\n",
    "        self.conv1 = nn.Conv1d(input_channels, 32, kernel_size=5, stride=1, padding=2)\n",
    "        self.bn1 = nn.BatchNorm1d(32)\n",
    "        self.relu = nn.ReLU()\n",
    "        self.conv2 = nn.Conv1d(32, 64, kernel_size=5, stride=1, padding=2)\n",
    "        self.bn2 = nn.BatchNorm1d(64)\n",
    "        self.conv3 = nn.Conv1d(64, 128, kernel_size=5, stride=1, padding=2)\n",
    "        self.bn3 = nn.BatchNorm1d(128)\n",
    "        self.flatten = nn.Flatten()\n",
    "        self.fc1 = nn.Linear(128 * 1024, 512)  # Updated to 1024 features\n",
    "        self.fc2 = nn.Linear(512, num_classes)\n",
    "        self.dropout = nn.Dropout(0.5)\n",
    "    \n",
    "    def forward(self, x):\n",
    "        x = self.relu(self.bn1(self.conv1(x)))\n",
    "        x = self.relu(self.bn2(self.conv2(x)))\n",
    "        x = self.relu(self.bn3(self.conv3(x)))\n",
    "        x = self.flatten(x)\n",
    "        x = self.dropout(self.relu(self.fc1(x)))\n",
    "        x = self.fc2(x)\n",
    "        return x\n",
    "\n",
    "input_channels = 1\n",
    "num_classes = len(label_encoder.classes_)\n",
    "model = CNN1DModel(input_channels, num_classes)\n",
    "criterion = nn.CrossEntropyLoss()\n",
    "optimizer = optim.Adam(model.parameters(), lr=0.001)\n",
    "\n",
    "# Training loop and evaluation (not shown)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "SVM Accuracy: 0.5816\n",
      "SVM Classification Report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.74      0.69      0.72        62\n",
      "           1       0.43      0.43      0.43        14\n",
      "           2       0.58      0.62      0.60        53\n",
      "\n",
      "    accuracy                           0.64       129\n",
      "   macro avg       0.58      0.58      0.58       129\n",
      "weighted avg       0.64      0.64      0.64       129\n",
      "\n",
      "Epoch 1/50\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/mojo/.local/lib/python3.12/site-packages/keras/src/layers/convolutional/base_conv.py:107: UserWarning: Do not pass an `input_shape`/`input_dim` argument to a layer. When using Sequential models, prefer using an `Input(shape)` object as the first layer in the model instead.\n",
      "  super().__init__(activity_regularizer=activity_regularizer, **kwargs)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m12s\u001b[0m 479ms/step - accuracy: 0.5115 - loss: 4.0248 - val_accuracy: 0.0465 - val_loss: 1.5593\n",
      "Epoch 2/50\n",
      "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m11s\u001b[0m 487ms/step - accuracy: 0.6368 - loss: 0.7714 - val_accuracy: 0.4360 - val_loss: 0.9975\n",
      "Epoch 3/50\n",
      "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m11s\u001b[0m 487ms/step - accuracy: 0.7794 - loss: 0.5808 - val_accuracy: 0.3488 - val_loss: 1.4020\n",
      "Epoch 4/50\n",
      "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m11s\u001b[0m 491ms/step - accuracy: 0.7953 - loss: 0.4586 - val_accuracy: 0.4186 - val_loss: 1.1425\n",
      "Epoch 5/50\n",
      "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m10s\u001b[0m 467ms/step - accuracy: 0.8911 - loss: 0.2837 - val_accuracy: 0.6570 - val_loss: 0.7858\n",
      "Epoch 6/50\n",
      "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m11s\u001b[0m 484ms/step - accuracy: 0.9336 - loss: 0.2106 - val_accuracy: 0.4535 - val_loss: 1.5004\n",
      "Epoch 7/50\n",
      "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m10s\u001b[0m 473ms/step - accuracy: 0.9596 - loss: 0.1401 - val_accuracy: 0.6453 - val_loss: 1.2637\n",
      "Epoch 8/50\n",
      "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m10s\u001b[0m 470ms/step - accuracy: 0.9793 - loss: 0.0910 - val_accuracy: 0.5814 - val_loss: 1.4010\n",
      "Epoch 9/50\n",
      "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m11s\u001b[0m 496ms/step - accuracy: 0.9924 - loss: 0.0530 - val_accuracy: 0.5349 - val_loss: 1.7530\n",
      "Epoch 10/50\n",
      "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m11s\u001b[0m 487ms/step - accuracy: 0.9846 - loss: 0.0546 - val_accuracy: 0.5756 - val_loss: 1.4358\n",
      "Epoch 11/50\n",
      "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m11s\u001b[0m 488ms/step - accuracy: 0.9906 - loss: 0.0434 - val_accuracy: 0.5581 - val_loss: 1.9432\n",
      "Epoch 12/50\n",
      "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m11s\u001b[0m 498ms/step - accuracy: 0.9910 - loss: 0.0494 - val_accuracy: 0.5640 - val_loss: 1.8953\n",
      "Epoch 13/50\n",
      "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m11s\u001b[0m 496ms/step - accuracy: 0.9904 - loss: 0.0440 - val_accuracy: 0.5058 - val_loss: 1.9729\n",
      "Epoch 14/50\n",
      "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m11s\u001b[0m 495ms/step - accuracy: 0.9865 - loss: 0.0356 - val_accuracy: 0.5814 - val_loss: 1.9603\n",
      "Epoch 15/50\n",
      "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m10s\u001b[0m 474ms/step - accuracy: 0.9818 - loss: 0.0742 - val_accuracy: 0.4477 - val_loss: 2.7044\n",
      "Epoch 16/50\n",
      "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m10s\u001b[0m 473ms/step - accuracy: 0.9925 - loss: 0.0236 - val_accuracy: 0.5581 - val_loss: 1.9895\n",
      "Epoch 17/50\n",
      "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m11s\u001b[0m 481ms/step - accuracy: 0.9932 - loss: 0.0260 - val_accuracy: 0.4826 - val_loss: 2.7690\n",
      "Epoch 18/50\n",
      "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m11s\u001b[0m 478ms/step - accuracy: 1.0000 - loss: 0.0078 - val_accuracy: 0.5581 - val_loss: 2.3786\n",
      "Epoch 19/50\n",
      "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m11s\u001b[0m 485ms/step - accuracy: 0.9972 - loss: 0.0081 - val_accuracy: 0.5930 - val_loss: 1.8256\n",
      "Epoch 20/50\n",
      "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m11s\u001b[0m 479ms/step - accuracy: 0.9991 - loss: 0.0056 - val_accuracy: 0.4884 - val_loss: 3.1256\n",
      "Epoch 21/50\n",
      "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m10s\u001b[0m 477ms/step - accuracy: 0.9975 - loss: 0.0078 - val_accuracy: 0.6628 - val_loss: 1.7807\n",
      "Epoch 22/50\n",
      "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m10s\u001b[0m 463ms/step - accuracy: 0.9958 - loss: 0.0119 - val_accuracy: 0.4651 - val_loss: 2.6010\n",
      "Epoch 23/50\n",
      "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m11s\u001b[0m 497ms/step - accuracy: 0.9928 - loss: 0.0197 - val_accuracy: 0.5988 - val_loss: 1.6926\n",
      "Epoch 24/50\n",
      "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m12s\u001b[0m 536ms/step - accuracy: 0.9962 - loss: 0.0067 - val_accuracy: 0.5000 - val_loss: 2.8449\n",
      "Epoch 25/50\n",
      "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m11s\u001b[0m 500ms/step - accuracy: 0.9951 - loss: 0.0121 - val_accuracy: 0.5349 - val_loss: 2.0309\n",
      "Epoch 26/50\n",
      "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m11s\u001b[0m 510ms/step - accuracy: 1.0000 - loss: 0.0078 - val_accuracy: 0.5988 - val_loss: 1.9519\n",
      "Epoch 27/50\n",
      "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m11s\u001b[0m 508ms/step - accuracy: 0.9974 - loss: 0.0136 - val_accuracy: 0.4884 - val_loss: 2.3038\n",
      "Epoch 28/50\n",
      "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m11s\u001b[0m 496ms/step - accuracy: 1.0000 - loss: 0.0054 - val_accuracy: 0.5814 - val_loss: 1.8823\n",
      "Epoch 29/50\n",
      "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m11s\u001b[0m 508ms/step - accuracy: 0.9988 - loss: 0.0069 - val_accuracy: 0.5291 - val_loss: 2.7324\n",
      "Epoch 30/50\n",
      "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m11s\u001b[0m 505ms/step - accuracy: 0.9949 - loss: 0.0088 - val_accuracy: 0.6163 - val_loss: 1.8562\n",
      "Epoch 31/50\n",
      "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m11s\u001b[0m 499ms/step - accuracy: 0.9943 - loss: 0.0092 - val_accuracy: 0.5988 - val_loss: 2.0097\n",
      "Epoch 32/50\n",
      "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m11s\u001b[0m 505ms/step - accuracy: 0.9995 - loss: 0.0043 - val_accuracy: 0.5116 - val_loss: 2.4021\n",
      "Epoch 33/50\n",
      "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m11s\u001b[0m 498ms/step - accuracy: 0.9991 - loss: 0.0057 - val_accuracy: 0.6105 - val_loss: 1.9744\n",
      "Epoch 34/50\n",
      "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m11s\u001b[0m 493ms/step - accuracy: 0.9998 - loss: 0.0043 - val_accuracy: 0.5174 - val_loss: 2.9152\n",
      "Epoch 35/50\n",
      "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m11s\u001b[0m 493ms/step - accuracy: 1.0000 - loss: 0.0012 - val_accuracy: 0.5174 - val_loss: 2.9143\n",
      "Epoch 36/50\n",
      "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m11s\u001b[0m 498ms/step - accuracy: 1.0000 - loss: 0.0018 - val_accuracy: 0.5814 - val_loss: 2.4970\n",
      "Epoch 37/50\n",
      "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m11s\u001b[0m 498ms/step - accuracy: 1.0000 - loss: 3.4025e-04 - val_accuracy: 0.5872 - val_loss: 2.5220\n",
      "Epoch 38/50\n",
      "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m11s\u001b[0m 497ms/step - accuracy: 1.0000 - loss: 8.5937e-04 - val_accuracy: 0.5814 - val_loss: 2.6948\n",
      "Epoch 39/50\n",
      "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m11s\u001b[0m 508ms/step - accuracy: 1.0000 - loss: 1.2569e-04 - val_accuracy: 0.5930 - val_loss: 2.7416\n",
      "Epoch 40/50\n",
      "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m12s\u001b[0m 524ms/step - accuracy: 0.9947 - loss: 0.0061 - val_accuracy: 0.5930 - val_loss: 2.5148\n",
      "Epoch 41/50\n",
      "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m11s\u001b[0m 516ms/step - accuracy: 0.9989 - loss: 0.0016 - val_accuracy: 0.5407 - val_loss: 2.6131\n",
      "Epoch 42/50\n",
      "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m12s\u001b[0m 543ms/step - accuracy: 1.0000 - loss: 3.6277e-04 - val_accuracy: 0.5465 - val_loss: 2.6135\n",
      "Epoch 43/50\n",
      "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m12s\u001b[0m 550ms/step - accuracy: 1.0000 - loss: 0.0015 - val_accuracy: 0.5523 - val_loss: 2.5933\n",
      "Epoch 44/50\n",
      "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m11s\u001b[0m 521ms/step - accuracy: 1.0000 - loss: 5.7632e-04 - val_accuracy: 0.5698 - val_loss: 2.5924\n",
      "Epoch 45/50\n",
      "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m12s\u001b[0m 523ms/step - accuracy: 1.0000 - loss: 8.0181e-04 - val_accuracy: 0.5523 - val_loss: 3.0283\n",
      "Epoch 46/50\n",
      "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m12s\u001b[0m 523ms/step - accuracy: 0.9996 - loss: 8.1999e-04 - val_accuracy: 0.4884 - val_loss: 3.3552\n",
      "Epoch 47/50\n",
      "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m11s\u001b[0m 513ms/step - accuracy: 0.9993 - loss: 0.0020 - val_accuracy: 0.5233 - val_loss: 2.7521\n",
      "Epoch 48/50\n",
      "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m12s\u001b[0m 527ms/step - accuracy: 1.0000 - loss: 8.2583e-04 - val_accuracy: 0.5872 - val_loss: 2.4056\n",
      "Epoch 49/50\n",
      "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m11s\u001b[0m 514ms/step - accuracy: 1.0000 - loss: 0.0016 - val_accuracy: 0.5465 - val_loss: 2.9010\n",
      "Epoch 50/50\n",
      "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m11s\u001b[0m 520ms/step - accuracy: 1.0000 - loss: 0.0021 - val_accuracy: 0.5058 - val_loss: 3.3500\n",
      "WARNING:tensorflow:5 out of the last 11 calls to <function TensorFlowTrainer.make_predict_function.<locals>.one_step_on_data_distributed at 0x76e95a393060> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has reduce_retracing=True option that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/guide/function#controlling_retracing and https://www.tensorflow.org/api_docs/python/tf/function for  more details.\n",
      "\u001b[1m3/5\u001b[0m \u001b[32m━━━━━━━━━━━━\u001b[0m\u001b[37m━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 51ms/step WARNING:tensorflow:5 out of the last 11 calls to <function TensorFlowTrainer.make_predict_function.<locals>.one_step_on_data_distributed at 0x76e95a393060> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has reduce_retracing=True option that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/guide/function#controlling_retracing and https://www.tensorflow.org/api_docs/python/tf/function for  more details.\n",
      "\u001b[1m5/5\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 64ms/step\n",
      "CNN Accuracy: 0.6237\n",
      "CNN Classification Report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.79      0.84      0.81        62\n",
      "           1       0.40      0.43      0.41        14\n",
      "           2       0.67      0.60      0.63        53\n",
      "\n",
      "    accuracy                           0.70       129\n",
      "   macro avg       0.62      0.62      0.62       129\n",
      "weighted avg       0.70      0.70      0.70       129\n",
      "\n",
      "Epoch 1/50\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/mojo/.local/lib/python3.12/site-packages/keras/src/layers/core/dense.py:87: UserWarning: Do not pass an `input_shape`/`input_dim` argument to a layer. When using Sequential models, prefer using an `Input(shape)` object as the first layer in the model instead.\n",
      "  super().__init__(activity_regularizer=activity_regularizer, **kwargs)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 10ms/step - accuracy: 0.4704 - loss: 1.6793 - val_accuracy: 0.4477 - val_loss: 0.9977\n",
      "Epoch 2/50\n",
      "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - accuracy: 0.5960 - loss: 0.9882 - val_accuracy: 0.4651 - val_loss: 0.9788\n",
      "Epoch 3/50\n",
      "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - accuracy: 0.6014 - loss: 0.9495 - val_accuracy: 0.4826 - val_loss: 1.0016\n",
      "Epoch 4/50\n",
      "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.6554 - loss: 0.8236 - val_accuracy: 0.5116 - val_loss: 0.9278\n",
      "Epoch 5/50\n",
      "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - accuracy: 0.7115 - loss: 0.7031 - val_accuracy: 0.4767 - val_loss: 1.0542\n",
      "Epoch 6/50\n",
      "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - accuracy: 0.7630 - loss: 0.5865 - val_accuracy: 0.5523 - val_loss: 0.9782\n",
      "Epoch 7/50\n",
      "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - accuracy: 0.7427 - loss: 0.6007 - val_accuracy: 0.4535 - val_loss: 1.1302\n",
      "Epoch 8/50\n",
      "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.7842 - loss: 0.5067 - val_accuracy: 0.5116 - val_loss: 1.0526\n",
      "Epoch 9/50\n",
      "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.8355 - loss: 0.4046 - val_accuracy: 0.5174 - val_loss: 1.0580\n",
      "Epoch 10/50\n",
      "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - accuracy: 0.8527 - loss: 0.3994 - val_accuracy: 0.5233 - val_loss: 1.1829\n",
      "Epoch 11/50\n",
      "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - accuracy: 0.8451 - loss: 0.3646 - val_accuracy: 0.6279 - val_loss: 0.9302\n",
      "Epoch 12/50\n",
      "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.8759 - loss: 0.3476 - val_accuracy: 0.5000 - val_loss: 1.2329\n",
      "Epoch 13/50\n",
      "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - accuracy: 0.8791 - loss: 0.3317 - val_accuracy: 0.5233 - val_loss: 1.2546\n",
      "Epoch 14/50\n",
      "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - accuracy: 0.9067 - loss: 0.3102 - val_accuracy: 0.4767 - val_loss: 1.3661\n",
      "Epoch 15/50\n",
      "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.8918 - loss: 0.2929 - val_accuracy: 0.5349 - val_loss: 1.3661\n",
      "Epoch 16/50\n",
      "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - accuracy: 0.9071 - loss: 0.2692 - val_accuracy: 0.5291 - val_loss: 1.4474\n",
      "Epoch 17/50\n",
      "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - accuracy: 0.9149 - loss: 0.2605 - val_accuracy: 0.5233 - val_loss: 1.4798\n",
      "Epoch 18/50\n",
      "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.9043 - loss: 0.2504 - val_accuracy: 0.5291 - val_loss: 1.5134\n",
      "Epoch 19/50\n",
      "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.9231 - loss: 0.2053 - val_accuracy: 0.4942 - val_loss: 1.6768\n",
      "Epoch 20/50\n",
      "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - accuracy: 0.9530 - loss: 0.1610 - val_accuracy: 0.5233 - val_loss: 1.6930\n",
      "Epoch 21/50\n",
      "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.9340 - loss: 0.1821 - val_accuracy: 0.5233 - val_loss: 1.7912\n",
      "Epoch 22/50\n",
      "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.9527 - loss: 0.1697 - val_accuracy: 0.5814 - val_loss: 1.5679\n",
      "Epoch 23/50\n",
      "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - accuracy: 0.9422 - loss: 0.1723 - val_accuracy: 0.5581 - val_loss: 1.6022\n",
      "Epoch 24/50\n",
      "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - accuracy: 0.9611 - loss: 0.1078 - val_accuracy: 0.5291 - val_loss: 1.8420\n",
      "Epoch 25/50\n",
      "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.9377 - loss: 0.1707 - val_accuracy: 0.5233 - val_loss: 1.8594\n",
      "Epoch 26/50\n",
      "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - accuracy: 0.9471 - loss: 0.1473 - val_accuracy: 0.5349 - val_loss: 1.8919\n",
      "Epoch 27/50\n",
      "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - accuracy: 0.9480 - loss: 0.1749 - val_accuracy: 0.5058 - val_loss: 1.8138\n",
      "Epoch 28/50\n",
      "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - accuracy: 0.9667 - loss: 0.0880 - val_accuracy: 0.5756 - val_loss: 1.6041\n",
      "Epoch 29/50\n",
      "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - accuracy: 0.9663 - loss: 0.0903 - val_accuracy: 0.5291 - val_loss: 2.2227\n",
      "Epoch 30/50\n",
      "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - accuracy: 0.9714 - loss: 0.0749 - val_accuracy: 0.5581 - val_loss: 1.8976\n",
      "Epoch 31/50\n",
      "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.9574 - loss: 0.0993 - val_accuracy: 0.5523 - val_loss: 2.2902\n",
      "Epoch 32/50\n",
      "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.9780 - loss: 0.0996 - val_accuracy: 0.5349 - val_loss: 2.1666\n",
      "Epoch 33/50\n",
      "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.9628 - loss: 0.1160 - val_accuracy: 0.5988 - val_loss: 1.7731\n",
      "Epoch 34/50\n",
      "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.9680 - loss: 0.1198 - val_accuracy: 0.5000 - val_loss: 2.6391\n",
      "Epoch 35/50\n",
      "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - accuracy: 0.9813 - loss: 0.0749 - val_accuracy: 0.5291 - val_loss: 2.0642\n",
      "Epoch 36/50\n",
      "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - accuracy: 0.9675 - loss: 0.0807 - val_accuracy: 0.5407 - val_loss: 2.1671\n",
      "Epoch 37/50\n",
      "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.9826 - loss: 0.0808 - val_accuracy: 0.5698 - val_loss: 1.8230\n",
      "Epoch 38/50\n",
      "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.9698 - loss: 0.1111 - val_accuracy: 0.5174 - val_loss: 2.5054\n",
      "Epoch 39/50\n",
      "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.9753 - loss: 0.0546 - val_accuracy: 0.5523 - val_loss: 2.1827\n",
      "Epoch 40/50\n",
      "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.9897 - loss: 0.0372 - val_accuracy: 0.5233 - val_loss: 2.7132\n",
      "Epoch 41/50\n",
      "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.9930 - loss: 0.0253 - val_accuracy: 0.5233 - val_loss: 2.9755\n",
      "Epoch 42/50\n",
      "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.9723 - loss: 0.0807 - val_accuracy: 0.5291 - val_loss: 2.9494\n",
      "Epoch 43/50\n",
      "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.9783 - loss: 0.0710 - val_accuracy: 0.5000 - val_loss: 3.0426\n",
      "Epoch 44/50\n",
      "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.9768 - loss: 0.0869 - val_accuracy: 0.5116 - val_loss: 3.0917\n",
      "Epoch 45/50\n",
      "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - accuracy: 0.9878 - loss: 0.0681 - val_accuracy: 0.5756 - val_loss: 2.6255\n",
      "Epoch 46/50\n",
      "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - accuracy: 0.9581 - loss: 0.1160 - val_accuracy: 0.5407 - val_loss: 2.4808\n",
      "Epoch 47/50\n",
      "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - accuracy: 0.9742 - loss: 0.0852 - val_accuracy: 0.5174 - val_loss: 3.0331\n",
      "Epoch 48/50\n",
      "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - accuracy: 0.9819 - loss: 0.0668 - val_accuracy: 0.5233 - val_loss: 2.7011\n",
      "Epoch 49/50\n",
      "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.9762 - loss: 0.0909 - val_accuracy: 0.5058 - val_loss: 2.8297\n",
      "Epoch 50/50\n",
      "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - accuracy: 0.9905 - loss: 0.0461 - val_accuracy: 0.4942 - val_loss: 2.8281\n",
      "\u001b[1m5/5\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step \n",
      "ANN Accuracy: 0.5905\n",
      "ANN Classification Report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.76      0.76      0.76        62\n",
      "           1       0.35      0.43      0.39        14\n",
      "           2       0.62      0.58      0.60        53\n",
      "\n",
      "    accuracy                           0.65       129\n",
      "   macro avg       0.58      0.59      0.58       129\n",
      "weighted avg       0.66      0.65      0.65       129\n",
      "\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "from sklearn.preprocessing import LabelEncoder\n",
    "from sklearn.svm import SVC\n",
    "from sklearn.metrics import balanced_accuracy_score, classification_report\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "\n",
    "# Load the data\n",
    "train_data = np.load('../Files/extracted_features/layer_features_lv60_self/train_10.npz')\n",
    "test_data = np.load('../Files/extracted_features/layer_features_lv60_self/test_10.npz')\n",
    "\n",
    "train_features = train_data['features']  # Ensure these have 1024 features\n",
    "test_features = test_data['features']    # Ensure these have 1024 features\n",
    "\n",
    "# Read Age labels instead of Gender\n",
    "train_labels = pd.read_csv('../Files/labels/y_train.csv').Age_Group\n",
    "test_labels = pd.read_csv('../Files/labels/y_test.csv').Age_Group\n",
    "\n",
    "# Encode the labels\n",
    "label_encoder = LabelEncoder()\n",
    "train_labels_encoded = label_encoder.fit_transform(train_labels)\n",
    "\n",
    "# Handle unseen labels in test set by filtering out labels not present in train set\n",
    "test_labels_filtered = test_labels[test_labels.isin(train_labels.unique())]\n",
    "test_features_filtered = test_features[test_labels.isin(train_labels.unique())]\n",
    "test_labels_encoded = label_encoder.transform(test_labels_filtered)\n",
    "\n",
    "# Standardize features\n",
    "scaler = StandardScaler()\n",
    "train_features_normalized = scaler.fit_transform(train_features)\n",
    "test_features_normalized = scaler.transform(test_features_filtered)\n",
    "\n",
    "# SVM model\n",
    "svm_model = SVC(kernel='linear', C=10.0, gamma='scale', random_state=42)\n",
    "svm_model.fit(train_features_normalized, train_labels_encoded)\n",
    "\n",
    "# SVM Prediction and Evaluation\n",
    "svm_predictions = svm_model.predict(test_features_normalized)\n",
    "svm_accuracy = balanced_accuracy_score(test_labels_encoded, svm_predictions)\n",
    "print(f\"SVM Accuracy: {svm_accuracy:.4f}\")\n",
    "print(\"SVM Classification Report:\")\n",
    "print(classification_report(test_labels_encoded, svm_predictions))\n",
    "\n",
    "# CNN model (TensorFlow)\n",
    "import tensorflow as tf\n",
    "from tensorflow.keras.models import Sequential\n",
    "from tensorflow.keras.layers import Conv1D, Flatten, Dense, Dropout\n",
    "\n",
    "train_features_cnn = np.expand_dims(train_features_normalized, axis=-1)  # Shape: (num_samples, 1024, 1)\n",
    "test_features_cnn = np.expand_dims(test_features_normalized, axis=-1)    # Shape: (num_samples, 1024, 1)\n",
    "\n",
    "cnn_model = Sequential([\n",
    "    Conv1D(64, kernel_size=5, activation='relu', input_shape=(1024, 1)),  # Updated input shape to 1024\n",
    "    Conv1D(128, kernel_size=5, activation='relu'),\n",
    "    Conv1D(256, kernel_size=5, activation='relu'),\n",
    "    Flatten(),\n",
    "    Dense(256, activation='relu'),\n",
    "    Dropout(0.5),\n",
    "    Dense(len(label_encoder.classes_), activation='softmax')\n",
    "])\n",
    "\n",
    "cnn_model.compile(optimizer='adam', loss='sparse_categorical_crossentropy', metrics=['accuracy'])\n",
    "\n",
    "cnn_model.fit(train_features_cnn, train_labels_encoded, epochs=50, batch_size=32, validation_split=0.2)\n",
    "\n",
    "# CNN Prediction and Evaluation\n",
    "cnn_predictions = np.argmax(cnn_model.predict(test_features_cnn), axis=-1)\n",
    "cnn_accuracy = balanced_accuracy_score(test_labels_encoded, cnn_predictions)\n",
    "print(f\"CNN Accuracy: {cnn_accuracy:.4f}\")\n",
    "print(\"CNN Classification Report:\")\n",
    "print(classification_report(test_labels_encoded, cnn_predictions))\n",
    "\n",
    "# ANN model (TensorFlow)\n",
    "ann_model = Sequential([\n",
    "    Dense(512, activation='relu', input_shape=(1024,)),  # Updated input shape to 1024\n",
    "    Dropout(0.5),\n",
    "    Dense(256, activation='relu'),\n",
    "    Dropout(0.5),\n",
    "    Dense(128, activation='relu'),\n",
    "    Dropout(0.5),\n",
    "    Dense(len(label_encoder.classes_), activation='softmax')\n",
    "])\n",
    "\n",
    "ann_model.compile(optimizer='adam', loss='sparse_categorical_crossentropy', metrics=['accuracy'])\n",
    "\n",
    "ann_model.fit(train_features_normalized, train_labels_encoded, epochs=50, batch_size=32, validation_split=0.2)\n",
    "\n",
    "# ANN Prediction and Evaluation\n",
    "ann_predictions = np.argmax(ann_model.predict(test_features_normalized), axis=-1)\n",
    "ann_accuracy = balanced_accuracy_score(test_labels_encoded, ann_predictions)\n",
    "print(f\"ANN Accuracy: {ann_accuracy:.4f}\")\n",
    "print(\"ANN Classification Report:\")\n",
    "print(classification_report(test_labels_encoded, ann_predictions))\n",
    "\n",
    "# PyTorch CNN Model\n",
    "import torch\n",
    "from torch.utils.data import DataLoader, TensorDataset\n",
    "\n",
    "X_train_tensor = torch.tensor(train_features_cnn, dtype=torch.float32).permute(0, 2, 1)  # Shape: (num_samples, 1, 1024)\n",
    "y_train_tensor = torch.tensor(train_labels_encoded, dtype=torch.long)\n",
    "X_test_tensor = torch.tensor(test_features_cnn, dtype=torch.float32).permute(0, 2, 1)    # Shape: (num_samples, 1, 1024)\n",
    "y_test_tensor = torch.tensor(test_labels_encoded, dtype=torch.long)\n",
    "\n",
    "train_dataset = TensorDataset(X_train_tensor, y_train_tensor)\n",
    "test_dataset = TensorDataset(X_test_tensor, y_test_tensor)\n",
    "\n",
    "train_loader = DataLoader(train_dataset, batch_size=64, shuffle=True)\n",
    "test_loader = DataLoader(test_dataset, batch_size=64, shuffle=False)\n",
    "\n",
    "import torch.nn as nn\n",
    "import torch.optim as optim\n",
    "\n",
    "class CNN1DModel(nn.Module):\n",
    "    def __init__(self, input_channels, num_classes):\n",
    "        super(CNN1DModel, self).__init__()\n",
    "        self.conv1 = nn.Conv1d(input_channels, 32, kernel_size=5, stride=1, padding=2)\n",
    "        self.bn1 = nn.BatchNorm1d(32)\n",
    "        self.relu = nn.ReLU()\n",
    "        self.conv2 = nn.Conv1d(32, 64, kernel_size=5, stride=1, padding=2)\n",
    "        self.bn2 = nn.BatchNorm1d(64)\n",
    "        self.conv3 = nn.Conv1d(64, 128, kernel_size=5, stride=1, padding=2)\n",
    "        self.bn3 = nn.BatchNorm1d(128)\n",
    "        self.flatten = nn.Flatten()\n",
    "        self.fc1 = nn.Linear(128 * 1024, 512)  # Updated to 1024 features\n",
    "        self.fc2 = nn.Linear(512, num_classes)\n",
    "        self.dropout = nn.Dropout(0.5)\n",
    "    \n",
    "    def forward(self, x):\n",
    "        x = self.relu(self.bn1(self.conv1(x)))\n",
    "        x = self.relu(self.bn2(self.conv2(x)))\n",
    "        x = self.relu(self.bn3(self.conv3(x)))\n",
    "        x = self.flatten(x)\n",
    "        x = self.dropout(self.relu(self.fc1(x)))\n",
    "        x = self.fc2(x)\n",
    "        return x\n",
    "\n",
    "input_channels = 1\n",
    "num_classes = len(label_encoder.classes_)\n",
    "model = CNN1DModel(input_channels, num_classes)\n",
    "criterion = nn.CrossEntropyLoss()\n",
    "optimizer = optim.Adam(model.parameters(), lr=0.001)\n",
    "\n",
    "# Training loop and evaluation (not shown)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "SVM Accuracy: 0.5713\n",
      "SVM Classification Report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.75      0.68      0.71        62\n",
      "           1       0.42      0.36      0.38        14\n",
      "           2       0.59      0.68      0.63        53\n",
      "\n",
      "    accuracy                           0.64       129\n",
      "   macro avg       0.59      0.57      0.58       129\n",
      "weighted avg       0.65      0.64      0.64       129\n",
      "\n",
      "Epoch 1/50\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/mojo/.local/lib/python3.12/site-packages/keras/src/layers/convolutional/base_conv.py:107: UserWarning: Do not pass an `input_shape`/`input_dim` argument to a layer. When using Sequential models, prefer using an `Input(shape)` object as the first layer in the model instead.\n",
      "  super().__init__(activity_regularizer=activity_regularizer, **kwargs)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m12s\u001b[0m 495ms/step - accuracy: 0.5203 - loss: 2.9353 - val_accuracy: 0.3430 - val_loss: 0.9619\n",
      "Epoch 2/50\n",
      "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m11s\u001b[0m 493ms/step - accuracy: 0.7178 - loss: 0.6926 - val_accuracy: 0.2326 - val_loss: 1.3261\n",
      "Epoch 3/50\n",
      "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m11s\u001b[0m 487ms/step - accuracy: 0.7895 - loss: 0.5517 - val_accuracy: 0.6802 - val_loss: 0.7652\n",
      "Epoch 4/50\n",
      "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m11s\u001b[0m 493ms/step - accuracy: 0.8413 - loss: 0.3965 - val_accuracy: 0.5640 - val_loss: 1.0670\n",
      "Epoch 5/50\n",
      "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m11s\u001b[0m 488ms/step - accuracy: 0.9273 - loss: 0.2008 - val_accuracy: 0.5872 - val_loss: 1.1813\n",
      "Epoch 6/50\n",
      "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m11s\u001b[0m 486ms/step - accuracy: 0.9477 - loss: 0.1381 - val_accuracy: 0.5174 - val_loss: 1.4075\n",
      "Epoch 7/50\n",
      "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m11s\u001b[0m 491ms/step - accuracy: 0.9759 - loss: 0.0924 - val_accuracy: 0.5581 - val_loss: 1.5105\n",
      "Epoch 8/50\n",
      "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m11s\u001b[0m 491ms/step - accuracy: 0.9773 - loss: 0.0829 - val_accuracy: 0.5407 - val_loss: 1.4324\n",
      "Epoch 9/50\n",
      "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m11s\u001b[0m 485ms/step - accuracy: 0.9795 - loss: 0.0554 - val_accuracy: 0.5756 - val_loss: 1.7293\n",
      "Epoch 10/50\n",
      "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m10s\u001b[0m 469ms/step - accuracy: 0.9934 - loss: 0.0312 - val_accuracy: 0.5291 - val_loss: 2.3883\n",
      "Epoch 11/50\n",
      "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m10s\u001b[0m 469ms/step - accuracy: 0.9774 - loss: 0.0723 - val_accuracy: 0.3895 - val_loss: 2.4144\n",
      "Epoch 12/50\n",
      "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m10s\u001b[0m 469ms/step - accuracy: 0.9907 - loss: 0.0352 - val_accuracy: 0.6163 - val_loss: 1.7043\n",
      "Epoch 13/50\n",
      "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m10s\u001b[0m 470ms/step - accuracy: 0.9896 - loss: 0.0311 - val_accuracy: 0.5465 - val_loss: 1.9481\n",
      "Epoch 14/50\n",
      "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m10s\u001b[0m 470ms/step - accuracy: 0.9953 - loss: 0.0193 - val_accuracy: 0.5581 - val_loss: 1.8983\n",
      "Epoch 15/50\n",
      "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m10s\u001b[0m 470ms/step - accuracy: 0.9919 - loss: 0.0219 - val_accuracy: 0.4651 - val_loss: 2.8473\n",
      "Epoch 16/50\n",
      "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m10s\u001b[0m 471ms/step - accuracy: 0.9980 - loss: 0.0132 - val_accuracy: 0.5233 - val_loss: 2.2811\n",
      "Epoch 17/50\n",
      "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m10s\u001b[0m 475ms/step - accuracy: 0.9978 - loss: 0.0180 - val_accuracy: 0.5988 - val_loss: 2.0035\n",
      "Epoch 18/50\n",
      "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m21s\u001b[0m 476ms/step - accuracy: 0.9938 - loss: 0.0182 - val_accuracy: 0.5465 - val_loss: 2.0949\n",
      "Epoch 19/50\n",
      "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m11s\u001b[0m 478ms/step - accuracy: 0.9952 - loss: 0.0160 - val_accuracy: 0.5465 - val_loss: 2.4804\n",
      "Epoch 20/50\n",
      "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m10s\u001b[0m 472ms/step - accuracy: 1.0000 - loss: 0.0037 - val_accuracy: 0.4186 - val_loss: 4.0383\n",
      "Epoch 21/50\n",
      "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m11s\u001b[0m 480ms/step - accuracy: 0.9997 - loss: 0.0064 - val_accuracy: 0.5174 - val_loss: 2.5124\n",
      "Epoch 22/50\n",
      "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m11s\u001b[0m 492ms/step - accuracy: 1.0000 - loss: 0.0012 - val_accuracy: 0.4535 - val_loss: 3.1935\n",
      "Epoch 23/50\n",
      "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m11s\u001b[0m 491ms/step - accuracy: 1.0000 - loss: 0.0016 - val_accuracy: 0.5000 - val_loss: 3.0928\n",
      "Epoch 24/50\n",
      "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m11s\u001b[0m 494ms/step - accuracy: 1.0000 - loss: 6.1767e-04 - val_accuracy: 0.4884 - val_loss: 3.2535\n",
      "Epoch 25/50\n",
      "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m11s\u001b[0m 490ms/step - accuracy: 0.9998 - loss: 0.0020 - val_accuracy: 0.4709 - val_loss: 3.7652\n",
      "Epoch 26/50\n",
      "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m10s\u001b[0m 475ms/step - accuracy: 0.9986 - loss: 0.0047 - val_accuracy: 0.4419 - val_loss: 4.3254\n",
      "Epoch 27/50\n",
      "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m11s\u001b[0m 482ms/step - accuracy: 1.0000 - loss: 0.0034 - val_accuracy: 0.5640 - val_loss: 3.1967\n",
      "Epoch 28/50\n",
      "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m11s\u001b[0m 483ms/step - accuracy: 0.9974 - loss: 0.0095 - val_accuracy: 0.4360 - val_loss: 3.6637\n",
      "Epoch 29/50\n",
      "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m11s\u001b[0m 486ms/step - accuracy: 0.9885 - loss: 0.0285 - val_accuracy: 0.3721 - val_loss: 2.8581\n",
      "Epoch 30/50\n",
      "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m11s\u001b[0m 484ms/step - accuracy: 0.9912 - loss: 0.0172 - val_accuracy: 0.4419 - val_loss: 3.3186\n",
      "Epoch 31/50\n",
      "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m20s\u001b[0m 479ms/step - accuracy: 1.0000 - loss: 0.0024 - val_accuracy: 0.6279 - val_loss: 2.8036\n",
      "Epoch 32/50\n",
      "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m11s\u001b[0m 486ms/step - accuracy: 0.9976 - loss: 0.0065 - val_accuracy: 0.4244 - val_loss: 3.5070\n",
      "Epoch 33/50\n",
      "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m11s\u001b[0m 485ms/step - accuracy: 0.9967 - loss: 0.0050 - val_accuracy: 0.5872 - val_loss: 2.5253\n",
      "Epoch 34/50\n",
      "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m11s\u001b[0m 483ms/step - accuracy: 0.9940 - loss: 0.0146 - val_accuracy: 0.5756 - val_loss: 2.3713\n",
      "Epoch 35/50\n",
      "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m11s\u001b[0m 490ms/step - accuracy: 1.0000 - loss: 0.0014 - val_accuracy: 0.4826 - val_loss: 3.2875\n",
      "Epoch 36/50\n",
      "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m11s\u001b[0m 493ms/step - accuracy: 1.0000 - loss: 8.2687e-04 - val_accuracy: 0.4826 - val_loss: 3.6858\n",
      "Epoch 37/50\n",
      "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m11s\u001b[0m 489ms/step - accuracy: 1.0000 - loss: 0.0014 - val_accuracy: 0.5930 - val_loss: 2.7041\n",
      "Epoch 38/50\n",
      "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m11s\u001b[0m 493ms/step - accuracy: 1.0000 - loss: 0.0011 - val_accuracy: 0.5291 - val_loss: 3.2465\n",
      "Epoch 39/50\n",
      "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m11s\u001b[0m 518ms/step - accuracy: 1.0000 - loss: 4.5988e-04 - val_accuracy: 0.5174 - val_loss: 3.4473\n",
      "Epoch 40/50\n",
      "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m11s\u001b[0m 516ms/step - accuracy: 0.9968 - loss: 0.0098 - val_accuracy: 0.5000 - val_loss: 3.3199\n",
      "Epoch 41/50\n",
      "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m11s\u001b[0m 516ms/step - accuracy: 0.9997 - loss: 0.0022 - val_accuracy: 0.3837 - val_loss: 4.4100\n",
      "Epoch 42/50\n",
      "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m11s\u001b[0m 509ms/step - accuracy: 1.0000 - loss: 0.0021 - val_accuracy: 0.5116 - val_loss: 3.3188\n",
      "Epoch 43/50\n",
      "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m11s\u001b[0m 508ms/step - accuracy: 0.9980 - loss: 0.0034 - val_accuracy: 0.5174 - val_loss: 3.1483\n",
      "Epoch 44/50\n",
      "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m11s\u001b[0m 504ms/step - accuracy: 1.0000 - loss: 0.0020 - val_accuracy: 0.5116 - val_loss: 3.5738\n",
      "Epoch 45/50\n",
      "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m11s\u001b[0m 508ms/step - accuracy: 1.0000 - loss: 9.9360e-04 - val_accuracy: 0.5233 - val_loss: 3.8658\n",
      "Epoch 46/50\n",
      "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m11s\u001b[0m 491ms/step - accuracy: 0.9986 - loss: 0.0065 - val_accuracy: 0.6279 - val_loss: 2.3008\n",
      "Epoch 47/50\n",
      "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m11s\u001b[0m 494ms/step - accuracy: 1.0000 - loss: 0.0031 - val_accuracy: 0.4477 - val_loss: 3.9375\n",
      "Epoch 48/50\n",
      "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m21s\u001b[0m 508ms/step - accuracy: 1.0000 - loss: 0.0027 - val_accuracy: 0.5116 - val_loss: 3.4104\n",
      "Epoch 49/50\n",
      "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m11s\u001b[0m 512ms/step - accuracy: 1.0000 - loss: 4.0339e-04 - val_accuracy: 0.5930 - val_loss: 2.4962\n",
      "Epoch 50/50\n",
      "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m11s\u001b[0m 514ms/step - accuracy: 0.9998 - loss: 6.7130e-04 - val_accuracy: 0.5465 - val_loss: 3.1463\n",
      "\u001b[1m5/5\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 48ms/step\n",
      "CNN Accuracy: 0.6166\n",
      "CNN Classification Report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.81      0.74      0.77        62\n",
      "           1       0.38      0.43      0.40        14\n",
      "           2       0.64      0.68      0.66        53\n",
      "\n",
      "    accuracy                           0.68       129\n",
      "   macro avg       0.61      0.62      0.61       129\n",
      "weighted avg       0.69      0.68      0.69       129\n",
      "\n",
      "Epoch 1/50\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/mojo/.local/lib/python3.12/site-packages/keras/src/layers/core/dense.py:87: UserWarning: Do not pass an `input_shape`/`input_dim` argument to a layer. When using Sequential models, prefer using an `Input(shape)` object as the first layer in the model instead.\n",
      "  super().__init__(activity_regularizer=activity_regularizer, **kwargs)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 8ms/step - accuracy: 0.5081 - loss: 1.6494 - val_accuracy: 0.5407 - val_loss: 1.0127\n",
      "Epoch 2/50\n",
      "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.5638 - loss: 1.1107 - val_accuracy: 0.5349 - val_loss: 0.9645\n",
      "Epoch 3/50\n",
      "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.6217 - loss: 0.9234 - val_accuracy: 0.6221 - val_loss: 0.8541\n",
      "Epoch 4/50\n",
      "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.6208 - loss: 0.7871 - val_accuracy: 0.5291 - val_loss: 1.0036\n",
      "Epoch 5/50\n",
      "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.7092 - loss: 0.7544 - val_accuracy: 0.5291 - val_loss: 0.9942\n",
      "Epoch 6/50\n",
      "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.7244 - loss: 0.6668 - val_accuracy: 0.5581 - val_loss: 1.0859\n",
      "Epoch 7/50\n",
      "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.7224 - loss: 0.7222 - val_accuracy: 0.5640 - val_loss: 1.0459\n",
      "Epoch 8/50\n",
      "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.7628 - loss: 0.5902 - val_accuracy: 0.5116 - val_loss: 1.0946\n",
      "Epoch 9/50\n",
      "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.7561 - loss: 0.5588 - val_accuracy: 0.5814 - val_loss: 1.0999\n",
      "Epoch 10/50\n",
      "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.7705 - loss: 0.5100 - val_accuracy: 0.6802 - val_loss: 0.8148\n",
      "Epoch 11/50\n",
      "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.8131 - loss: 0.4213 - val_accuracy: 0.5291 - val_loss: 1.2720\n",
      "Epoch 12/50\n",
      "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.8499 - loss: 0.3979 - val_accuracy: 0.6453 - val_loss: 0.9177\n",
      "Epoch 13/50\n",
      "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.8705 - loss: 0.3362 - val_accuracy: 0.5523 - val_loss: 1.2689\n",
      "Epoch 14/50\n",
      "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.8486 - loss: 0.3847 - val_accuracy: 0.5349 - val_loss: 1.2211\n",
      "Epoch 15/50\n",
      "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.8969 - loss: 0.2628 - val_accuracy: 0.5814 - val_loss: 1.2975\n",
      "Epoch 16/50\n",
      "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.9177 - loss: 0.2521 - val_accuracy: 0.5698 - val_loss: 1.4643\n",
      "Epoch 17/50\n",
      "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.8879 - loss: 0.2531 - val_accuracy: 0.5581 - val_loss: 1.4880\n",
      "Epoch 18/50\n",
      "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.8681 - loss: 0.3006 - val_accuracy: 0.5116 - val_loss: 1.7103\n",
      "Epoch 19/50\n",
      "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.9052 - loss: 0.2720 - val_accuracy: 0.6395 - val_loss: 1.2441\n",
      "Epoch 20/50\n",
      "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.9069 - loss: 0.2814 - val_accuracy: 0.5640 - val_loss: 1.4913\n",
      "Epoch 21/50\n",
      "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.9278 - loss: 0.2339 - val_accuracy: 0.5814 - val_loss: 1.1897\n",
      "Epoch 22/50\n",
      "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.9303 - loss: 0.1780 - val_accuracy: 0.5814 - val_loss: 1.4292\n",
      "Epoch 23/50\n",
      "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.9395 - loss: 0.1839 - val_accuracy: 0.5581 - val_loss: 1.4099\n",
      "Epoch 24/50\n",
      "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.9370 - loss: 0.1590 - val_accuracy: 0.5698 - val_loss: 1.5378\n",
      "Epoch 25/50\n",
      "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.9511 - loss: 0.1376 - val_accuracy: 0.5465 - val_loss: 1.6667\n",
      "Epoch 26/50\n",
      "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.9360 - loss: 0.1441 - val_accuracy: 0.6047 - val_loss: 1.4957\n",
      "Epoch 27/50\n",
      "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.9618 - loss: 0.1140 - val_accuracy: 0.5640 - val_loss: 1.7343\n",
      "Epoch 28/50\n",
      "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.9561 - loss: 0.1206 - val_accuracy: 0.5640 - val_loss: 1.7135\n",
      "Epoch 29/50\n",
      "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.9663 - loss: 0.0993 - val_accuracy: 0.5698 - val_loss: 1.9187\n",
      "Epoch 30/50\n",
      "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.9417 - loss: 0.1686 - val_accuracy: 0.5174 - val_loss: 2.0192\n",
      "Epoch 31/50\n",
      "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.9493 - loss: 0.1045 - val_accuracy: 0.5174 - val_loss: 2.0144\n",
      "Epoch 32/50\n",
      "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.9636 - loss: 0.1288 - val_accuracy: 0.5465 - val_loss: 2.0354\n",
      "Epoch 33/50\n",
      "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.9662 - loss: 0.0987 - val_accuracy: 0.5058 - val_loss: 2.5293\n",
      "Epoch 34/50\n",
      "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.9484 - loss: 0.1739 - val_accuracy: 0.5814 - val_loss: 1.8614\n",
      "Epoch 35/50\n",
      "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.9801 - loss: 0.0597 - val_accuracy: 0.5523 - val_loss: 2.1800\n",
      "Epoch 36/50\n",
      "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.9783 - loss: 0.0902 - val_accuracy: 0.5465 - val_loss: 2.4362\n",
      "Epoch 37/50\n",
      "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.9801 - loss: 0.0494 - val_accuracy: 0.5407 - val_loss: 2.3933\n",
      "Epoch 38/50\n",
      "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.9655 - loss: 0.0763 - val_accuracy: 0.5640 - val_loss: 2.3683\n",
      "Epoch 39/50\n",
      "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.9771 - loss: 0.0754 - val_accuracy: 0.5407 - val_loss: 2.5016\n",
      "Epoch 40/50\n",
      "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.9687 - loss: 0.1040 - val_accuracy: 0.5233 - val_loss: 2.7409\n",
      "Epoch 41/50\n",
      "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - accuracy: 0.9652 - loss: 0.0886 - val_accuracy: 0.5872 - val_loss: 2.4252\n",
      "Epoch 42/50\n",
      "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.9698 - loss: 0.1054 - val_accuracy: 0.5407 - val_loss: 2.8636\n",
      "Epoch 43/50\n",
      "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.9789 - loss: 0.0800 - val_accuracy: 0.5581 - val_loss: 2.6673\n",
      "Epoch 44/50\n",
      "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.9578 - loss: 0.1314 - val_accuracy: 0.5698 - val_loss: 2.4510\n",
      "Epoch 45/50\n",
      "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.9861 - loss: 0.0459 - val_accuracy: 0.5523 - val_loss: 2.6094\n",
      "Epoch 46/50\n",
      "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.9825 - loss: 0.0482 - val_accuracy: 0.5640 - val_loss: 2.7863\n",
      "Epoch 47/50\n",
      "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.9789 - loss: 0.0559 - val_accuracy: 0.5465 - val_loss: 2.7560\n",
      "Epoch 48/50\n",
      "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.9801 - loss: 0.0581 - val_accuracy: 0.5523 - val_loss: 3.0380\n",
      "Epoch 49/50\n",
      "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.9781 - loss: 0.0608 - val_accuracy: 0.5581 - val_loss: 2.9586\n",
      "Epoch 50/50\n",
      "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.9797 - loss: 0.0587 - val_accuracy: 0.5872 - val_loss: 2.6231\n",
      "\u001b[1m5/5\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step \n",
      "ANN Accuracy: 0.6345\n",
      "ANN Classification Report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.80      0.76      0.78        62\n",
      "           1       0.60      0.43      0.50        14\n",
      "           2       0.63      0.72      0.67        53\n",
      "\n",
      "    accuracy                           0.71       129\n",
      "   macro avg       0.68      0.63      0.65       129\n",
      "weighted avg       0.71      0.71      0.70       129\n",
      "\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "from sklearn.preprocessing import LabelEncoder\n",
    "from sklearn.svm import SVC\n",
    "from sklearn.metrics import balanced_accuracy_score, classification_report\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "\n",
    "# Load the data\n",
    "train_data = np.load('../Files/extracted_features/layer_features_lv60_self/train_11.npz')\n",
    "test_data = np.load('../Files/extracted_features/layer_features_lv60_self/test_11.npz')\n",
    "\n",
    "train_features = train_data['features']  # Ensure these have 1024 features\n",
    "test_features = test_data['features']    # Ensure these have 1024 features\n",
    "\n",
    "# Read Age labels instead of Gender\n",
    "train_labels = pd.read_csv('../Files/labels/y_train.csv').Age_Group\n",
    "test_labels = pd.read_csv('../Files/labels/y_test.csv').Age_Group\n",
    "\n",
    "# Encode the labels\n",
    "label_encoder = LabelEncoder()\n",
    "train_labels_encoded = label_encoder.fit_transform(train_labels)\n",
    "\n",
    "# Handle unseen labels in test set by filtering out labels not present in train set\n",
    "test_labels_filtered = test_labels[test_labels.isin(train_labels.unique())]\n",
    "test_features_filtered = test_features[test_labels.isin(train_labels.unique())]\n",
    "test_labels_encoded = label_encoder.transform(test_labels_filtered)\n",
    "\n",
    "# Standardize features\n",
    "scaler = StandardScaler()\n",
    "train_features_normalized = scaler.fit_transform(train_features)\n",
    "test_features_normalized = scaler.transform(test_features_filtered)\n",
    "\n",
    "# SVM model\n",
    "svm_model = SVC(kernel='linear', C=10.0, gamma='scale', random_state=42)\n",
    "svm_model.fit(train_features_normalized, train_labels_encoded)\n",
    "\n",
    "# SVM Prediction and Evaluation\n",
    "svm_predictions = svm_model.predict(test_features_normalized)\n",
    "svm_accuracy = balanced_accuracy_score(test_labels_encoded, svm_predictions)\n",
    "print(f\"SVM Accuracy: {svm_accuracy:.4f}\")\n",
    "print(\"SVM Classification Report:\")\n",
    "print(classification_report(test_labels_encoded, svm_predictions))\n",
    "\n",
    "# CNN model (TensorFlow)\n",
    "import tensorflow as tf\n",
    "from tensorflow.keras.models import Sequential\n",
    "from tensorflow.keras.layers import Conv1D, Flatten, Dense, Dropout\n",
    "\n",
    "train_features_cnn = np.expand_dims(train_features_normalized, axis=-1)  # Shape: (num_samples, 1024, 1)\n",
    "test_features_cnn = np.expand_dims(test_features_normalized, axis=-1)    # Shape: (num_samples, 1024, 1)\n",
    "\n",
    "cnn_model = Sequential([\n",
    "    Conv1D(64, kernel_size=5, activation='relu', input_shape=(1024, 1)),  # Updated input shape to 1024\n",
    "    Conv1D(128, kernel_size=5, activation='relu'),\n",
    "    Conv1D(256, kernel_size=5, activation='relu'),\n",
    "    Flatten(),\n",
    "    Dense(256, activation='relu'),\n",
    "    Dropout(0.5),\n",
    "    Dense(len(label_encoder.classes_), activation='softmax')\n",
    "])\n",
    "\n",
    "cnn_model.compile(optimizer='adam', loss='sparse_categorical_crossentropy', metrics=['accuracy'])\n",
    "\n",
    "cnn_model.fit(train_features_cnn, train_labels_encoded, epochs=50, batch_size=32, validation_split=0.2)\n",
    "\n",
    "# CNN Prediction and Evaluation\n",
    "cnn_predictions = np.argmax(cnn_model.predict(test_features_cnn), axis=-1)\n",
    "cnn_accuracy = balanced_accuracy_score(test_labels_encoded, cnn_predictions)\n",
    "print(f\"CNN Accuracy: {cnn_accuracy:.4f}\")\n",
    "print(\"CNN Classification Report:\")\n",
    "print(classification_report(test_labels_encoded, cnn_predictions))\n",
    "\n",
    "# ANN model (TensorFlow)\n",
    "ann_model = Sequential([\n",
    "    Dense(512, activation='relu', input_shape=(1024,)),  # Updated input shape to 1024\n",
    "    Dropout(0.5),\n",
    "    Dense(256, activation='relu'),\n",
    "    Dropout(0.5),\n",
    "    Dense(128, activation='relu'),\n",
    "    Dropout(0.5),\n",
    "    Dense(len(label_encoder.classes_), activation='softmax')\n",
    "])\n",
    "\n",
    "ann_model.compile(optimizer='adam', loss='sparse_categorical_crossentropy', metrics=['accuracy'])\n",
    "\n",
    "ann_model.fit(train_features_normalized, train_labels_encoded, epochs=50, batch_size=32, validation_split=0.2)\n",
    "\n",
    "# ANN Prediction and Evaluation\n",
    "ann_predictions = np.argmax(ann_model.predict(test_features_normalized), axis=-1)\n",
    "ann_accuracy = balanced_accuracy_score(test_labels_encoded, ann_predictions)\n",
    "print(f\"ANN Accuracy: {ann_accuracy:.4f}\")\n",
    "print(\"ANN Classification Report:\")\n",
    "print(classification_report(test_labels_encoded, ann_predictions))\n",
    "\n",
    "# PyTorch CNN Model\n",
    "import torch\n",
    "from torch.utils.data import DataLoader, TensorDataset\n",
    "\n",
    "X_train_tensor = torch.tensor(train_features_cnn, dtype=torch.float32).permute(0, 2, 1)  # Shape: (num_samples, 1, 1024)\n",
    "y_train_tensor = torch.tensor(train_labels_encoded, dtype=torch.long)\n",
    "X_test_tensor = torch.tensor(test_features_cnn, dtype=torch.float32).permute(0, 2, 1)    # Shape: (num_samples, 1, 1024)\n",
    "y_test_tensor = torch.tensor(test_labels_encoded, dtype=torch.long)\n",
    "\n",
    "train_dataset = TensorDataset(X_train_tensor, y_train_tensor)\n",
    "test_dataset = TensorDataset(X_test_tensor, y_test_tensor)\n",
    "\n",
    "train_loader = DataLoader(train_dataset, batch_size=64, shuffle=True)\n",
    "test_loader = DataLoader(test_dataset, batch_size=64, shuffle=False)\n",
    "\n",
    "import torch.nn as nn\n",
    "import torch.optim as optim\n",
    "\n",
    "class CNN1DModel(nn.Module):\n",
    "    def __init__(self, input_channels, num_classes):\n",
    "        super(CNN1DModel, self).__init__()\n",
    "        self.conv1 = nn.Conv1d(input_channels, 32, kernel_size=5, stride=1, padding=2)\n",
    "        self.bn1 = nn.BatchNorm1d(32)\n",
    "        self.relu = nn.ReLU()\n",
    "        self.conv2 = nn.Conv1d(32, 64, kernel_size=5, stride=1, padding=2)\n",
    "        self.bn2 = nn.BatchNorm1d(64)\n",
    "        self.conv3 = nn.Conv1d(64, 128, kernel_size=5, stride=1, padding=2)\n",
    "        self.bn3 = nn.BatchNorm1d(128)\n",
    "        self.flatten = nn.Flatten()\n",
    "        self.fc1 = nn.Linear(128 * 1024, 512)  # Updated to 1024 features\n",
    "        self.fc2 = nn.Linear(512, num_classes)\n",
    "        self.dropout = nn.Dropout(0.5)\n",
    "    \n",
    "    def forward(self, x):\n",
    "        x = self.relu(self.bn1(self.conv1(x)))\n",
    "        x = self.relu(self.bn2(self.conv2(x)))\n",
    "        x = self.relu(self.bn3(self.conv3(x)))\n",
    "        x = self.flatten(x)\n",
    "        x = self.dropout(self.relu(self.fc1(x)))\n",
    "        x = self.fc2(x)\n",
    "        return x\n",
    "\n",
    "input_channels = 1\n",
    "num_classes = len(label_encoder.classes_)\n",
    "model = CNN1DModel(input_channels, num_classes)\n",
    "criterion = nn.CrossEntropyLoss()\n",
    "optimizer = optim.Adam(model.parameters(), lr=0.001)\n",
    "\n",
    "# Training loop and evaluation (not shown)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "SVM Accuracy: 0.6144\n",
      "SVM Classification Report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.86      0.69      0.77        62\n",
      "           1       0.42      0.36      0.38        14\n",
      "           2       0.63      0.79      0.70        53\n",
      "\n",
      "    accuracy                           0.70       129\n",
      "   macro avg       0.63      0.61      0.62       129\n",
      "weighted avg       0.72      0.70      0.70       129\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/mojo/.local/lib/python3.12/site-packages/keras/src/layers/convolutional/base_conv.py:107: UserWarning: Do not pass an `input_shape`/`input_dim` argument to a layer. When using Sequential models, prefer using an `Input(shape)` object as the first layer in the model instead.\n",
      "  super().__init__(activity_regularizer=activity_regularizer, **kwargs)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/50\n",
      "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m13s\u001b[0m 519ms/step - accuracy: 0.4666 - loss: 3.9443 - val_accuracy: 0.0465 - val_loss: 1.0878\n",
      "Epoch 2/50\n",
      "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m11s\u001b[0m 510ms/step - accuracy: 0.6081 - loss: 0.8268 - val_accuracy: 0.3372 - val_loss: 1.0984\n",
      "Epoch 3/50\n",
      "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m11s\u001b[0m 484ms/step - accuracy: 0.6810 - loss: 0.7228 - val_accuracy: 0.3140 - val_loss: 1.3346\n",
      "Epoch 4/50\n",
      "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m11s\u001b[0m 480ms/step - accuracy: 0.7515 - loss: 0.5786 - val_accuracy: 0.6802 - val_loss: 0.7161\n",
      "Epoch 5/50\n",
      "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m11s\u001b[0m 494ms/step - accuracy: 0.8095 - loss: 0.4639 - val_accuracy: 0.5872 - val_loss: 0.9316\n",
      "Epoch 6/50\n",
      "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m11s\u001b[0m 513ms/step - accuracy: 0.8209 - loss: 0.4151 - val_accuracy: 0.6512 - val_loss: 0.8186\n",
      "Epoch 7/50\n",
      "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m11s\u001b[0m 493ms/step - accuracy: 0.8838 - loss: 0.3107 - val_accuracy: 0.6919 - val_loss: 0.7227\n",
      "Epoch 8/50\n",
      "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m11s\u001b[0m 490ms/step - accuracy: 0.9059 - loss: 0.2422 - val_accuracy: 0.5756 - val_loss: 1.4276\n",
      "Epoch 9/50\n",
      "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m11s\u001b[0m 493ms/step - accuracy: 0.9197 - loss: 0.1802 - val_accuracy: 0.4767 - val_loss: 1.6702\n",
      "Epoch 10/50\n",
      "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m11s\u001b[0m 478ms/step - accuracy: 0.9628 - loss: 0.1239 - val_accuracy: 0.5581 - val_loss: 1.4032\n",
      "Epoch 11/50\n",
      "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m11s\u001b[0m 481ms/step - accuracy: 0.9826 - loss: 0.0727 - val_accuracy: 0.6802 - val_loss: 1.1296\n",
      "Epoch 12/50\n",
      "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m11s\u001b[0m 480ms/step - accuracy: 0.9723 - loss: 0.0876 - val_accuracy: 0.6512 - val_loss: 1.2919\n",
      "Epoch 13/50\n",
      "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m11s\u001b[0m 501ms/step - accuracy: 0.9883 - loss: 0.0526 - val_accuracy: 0.5930 - val_loss: 1.5978\n",
      "Epoch 14/50\n",
      "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m11s\u001b[0m 499ms/step - accuracy: 0.9855 - loss: 0.0507 - val_accuracy: 0.6279 - val_loss: 1.5060\n",
      "Epoch 15/50\n",
      "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m11s\u001b[0m 505ms/step - accuracy: 0.9817 - loss: 0.0688 - val_accuracy: 0.5698 - val_loss: 1.8276\n",
      "Epoch 16/50\n",
      "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m11s\u001b[0m 509ms/step - accuracy: 0.9778 - loss: 0.0678 - val_accuracy: 0.5233 - val_loss: 2.2817\n",
      "Epoch 17/50\n",
      "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m11s\u001b[0m 513ms/step - accuracy: 0.9868 - loss: 0.0473 - val_accuracy: 0.5349 - val_loss: 2.3593\n",
      "Epoch 18/50\n",
      "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m11s\u001b[0m 511ms/step - accuracy: 0.9851 - loss: 0.0322 - val_accuracy: 0.5523 - val_loss: 2.4727\n",
      "Epoch 19/50\n",
      "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m11s\u001b[0m 514ms/step - accuracy: 0.9908 - loss: 0.0374 - val_accuracy: 0.5465 - val_loss: 2.3799\n",
      "Epoch 20/50\n",
      "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m11s\u001b[0m 508ms/step - accuracy: 0.9909 - loss: 0.0277 - val_accuracy: 0.6105 - val_loss: 2.0630\n",
      "Epoch 21/50\n",
      "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m11s\u001b[0m 508ms/step - accuracy: 0.9948 - loss: 0.0192 - val_accuracy: 0.6395 - val_loss: 1.9472\n",
      "Epoch 22/50\n",
      "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m11s\u001b[0m 507ms/step - accuracy: 0.9961 - loss: 0.0114 - val_accuracy: 0.5407 - val_loss: 2.7852\n",
      "Epoch 23/50\n",
      "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m11s\u001b[0m 512ms/step - accuracy: 0.9881 - loss: 0.0239 - val_accuracy: 0.6105 - val_loss: 2.2861\n",
      "Epoch 24/50\n",
      "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m11s\u001b[0m 506ms/step - accuracy: 0.9972 - loss: 0.0255 - val_accuracy: 0.5814 - val_loss: 2.4010\n",
      "Epoch 25/50\n",
      "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m11s\u001b[0m 507ms/step - accuracy: 0.9952 - loss: 0.0182 - val_accuracy: 0.5814 - val_loss: 2.2346\n",
      "Epoch 26/50\n",
      "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m11s\u001b[0m 512ms/step - accuracy: 0.9920 - loss: 0.0218 - val_accuracy: 0.4884 - val_loss: 3.1176\n",
      "Epoch 27/50\n",
      "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m11s\u001b[0m 515ms/step - accuracy: 0.9878 - loss: 0.0364 - val_accuracy: 0.4884 - val_loss: 2.3009\n",
      "Epoch 28/50\n",
      "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m11s\u001b[0m 510ms/step - accuracy: 0.9946 - loss: 0.0253 - val_accuracy: 0.5407 - val_loss: 2.4213\n",
      "Epoch 29/50\n",
      "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m11s\u001b[0m 512ms/step - accuracy: 0.9960 - loss: 0.0174 - val_accuracy: 0.5291 - val_loss: 2.5595\n",
      "Epoch 30/50\n",
      "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m11s\u001b[0m 503ms/step - accuracy: 0.9994 - loss: 0.0086 - val_accuracy: 0.5000 - val_loss: 3.5533\n",
      "Epoch 31/50\n",
      "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m11s\u001b[0m 515ms/step - accuracy: 0.9984 - loss: 0.0105 - val_accuracy: 0.5814 - val_loss: 2.5706\n",
      "Epoch 32/50\n",
      "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m11s\u001b[0m 523ms/step - accuracy: 0.9991 - loss: 0.0104 - val_accuracy: 0.5465 - val_loss: 3.0746\n",
      "Epoch 33/50\n",
      "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m11s\u001b[0m 509ms/step - accuracy: 0.9964 - loss: 0.0146 - val_accuracy: 0.5640 - val_loss: 2.4345\n",
      "Epoch 34/50\n",
      "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m11s\u001b[0m 509ms/step - accuracy: 0.9933 - loss: 0.0201 - val_accuracy: 0.5465 - val_loss: 2.8752\n",
      "Epoch 35/50\n",
      "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m11s\u001b[0m 512ms/step - accuracy: 0.9997 - loss: 0.0068 - val_accuracy: 0.5698 - val_loss: 2.8776\n",
      "Epoch 36/50\n",
      "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m11s\u001b[0m 504ms/step - accuracy: 1.0000 - loss: 0.0028 - val_accuracy: 0.5872 - val_loss: 3.3911\n",
      "Epoch 37/50\n",
      "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m11s\u001b[0m 516ms/step - accuracy: 0.9972 - loss: 0.0044 - val_accuracy: 0.6163 - val_loss: 3.3034\n",
      "Epoch 38/50\n",
      "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m11s\u001b[0m 502ms/step - accuracy: 0.9964 - loss: 0.0051 - val_accuracy: 0.6337 - val_loss: 3.0091\n",
      "Epoch 39/50\n",
      "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m11s\u001b[0m 515ms/step - accuracy: 0.9971 - loss: 0.0098 - val_accuracy: 0.5698 - val_loss: 2.8922\n",
      "Epoch 40/50\n",
      "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m11s\u001b[0m 511ms/step - accuracy: 0.9968 - loss: 0.0089 - val_accuracy: 0.4535 - val_loss: 3.7782\n",
      "Epoch 41/50\n",
      "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m11s\u001b[0m 520ms/step - accuracy: 0.9950 - loss: 0.0185 - val_accuracy: 0.6337 - val_loss: 2.4452\n",
      "Epoch 42/50\n",
      "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m11s\u001b[0m 517ms/step - accuracy: 0.9990 - loss: 0.0059 - val_accuracy: 0.5116 - val_loss: 4.2862\n",
      "Epoch 43/50\n",
      "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m11s\u001b[0m 510ms/step - accuracy: 1.0000 - loss: 0.0030 - val_accuracy: 0.5291 - val_loss: 4.2965\n",
      "Epoch 44/50\n",
      "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m11s\u001b[0m 508ms/step - accuracy: 0.9970 - loss: 0.0070 - val_accuracy: 0.5581 - val_loss: 3.9654\n",
      "Epoch 45/50\n",
      "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m11s\u001b[0m 517ms/step - accuracy: 0.9967 - loss: 0.0080 - val_accuracy: 0.5058 - val_loss: 3.5809\n",
      "Epoch 46/50\n",
      "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m11s\u001b[0m 513ms/step - accuracy: 0.9968 - loss: 0.0131 - val_accuracy: 0.4884 - val_loss: 3.5883\n",
      "Epoch 47/50\n",
      "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m11s\u001b[0m 511ms/step - accuracy: 0.9984 - loss: 0.0181 - val_accuracy: 0.5233 - val_loss: 2.8627\n",
      "Epoch 48/50\n",
      "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m11s\u001b[0m 516ms/step - accuracy: 1.0000 - loss: 0.0080 - val_accuracy: 0.5116 - val_loss: 3.5701\n",
      "Epoch 49/50\n",
      "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m11s\u001b[0m 500ms/step - accuracy: 0.9974 - loss: 0.0083 - val_accuracy: 0.5349 - val_loss: 3.8715\n",
      "Epoch 50/50\n",
      "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m11s\u001b[0m 495ms/step - accuracy: 0.9989 - loss: 0.0070 - val_accuracy: 0.6221 - val_loss: 2.5800\n",
      "\u001b[1m5/5\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 46ms/step\n",
      "CNN Accuracy: 0.5556\n",
      "CNN Classification Report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.80      0.65      0.71        62\n",
      "           1       0.44      0.29      0.35        14\n",
      "           2       0.56      0.74      0.63        53\n",
      "\n",
      "    accuracy                           0.64       129\n",
      "   macro avg       0.60      0.56      0.57       129\n",
      "weighted avg       0.66      0.64      0.64       129\n",
      "\n",
      "Epoch 1/50\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/mojo/.local/lib/python3.12/site-packages/keras/src/layers/core/dense.py:87: UserWarning: Do not pass an `input_shape`/`input_dim` argument to a layer. When using Sequential models, prefer using an `Input(shape)` object as the first layer in the model instead.\n",
      "  super().__init__(activity_regularizer=activity_regularizer, **kwargs)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 7ms/step - accuracy: 0.4523 - loss: 1.5853 - val_accuracy: 0.2965 - val_loss: 1.3589\n",
      "Epoch 2/50\n",
      "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.5858 - loss: 1.0984 - val_accuracy: 0.4826 - val_loss: 1.1301\n",
      "Epoch 3/50\n",
      "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.6257 - loss: 0.9734 - val_accuracy: 0.4826 - val_loss: 1.0009\n",
      "Epoch 4/50\n",
      "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.6264 - loss: 0.8900 - val_accuracy: 0.6512 - val_loss: 0.9051\n",
      "Epoch 5/50\n",
      "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.6824 - loss: 0.7900 - val_accuracy: 0.4709 - val_loss: 1.1130\n",
      "Epoch 6/50\n",
      "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.7143 - loss: 0.6899 - val_accuracy: 0.6163 - val_loss: 0.9354\n",
      "Epoch 7/50\n",
      "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.7320 - loss: 0.6473 - val_accuracy: 0.5291 - val_loss: 1.0124\n",
      "Epoch 8/50\n",
      "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.7090 - loss: 0.6694 - val_accuracy: 0.5756 - val_loss: 1.0577\n",
      "Epoch 9/50\n",
      "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.7665 - loss: 0.5720 - val_accuracy: 0.5581 - val_loss: 1.0455\n",
      "Epoch 10/50\n",
      "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.8044 - loss: 0.4704 - val_accuracy: 0.5233 - val_loss: 1.1013\n",
      "Epoch 11/50\n",
      "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.8277 - loss: 0.4560 - val_accuracy: 0.4942 - val_loss: 1.1147\n",
      "Epoch 12/50\n",
      "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.8237 - loss: 0.3959 - val_accuracy: 0.5581 - val_loss: 1.0265\n",
      "Epoch 13/50\n",
      "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.8250 - loss: 0.4110 - val_accuracy: 0.5814 - val_loss: 1.0130\n",
      "Epoch 14/50\n",
      "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.8669 - loss: 0.3267 - val_accuracy: 0.5988 - val_loss: 1.1058\n",
      "Epoch 15/50\n",
      "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.8838 - loss: 0.3049 - val_accuracy: 0.6512 - val_loss: 0.9296\n",
      "Epoch 16/50\n",
      "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.8877 - loss: 0.3261 - val_accuracy: 0.6163 - val_loss: 1.1264\n",
      "Epoch 17/50\n",
      "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.8842 - loss: 0.2844 - val_accuracy: 0.5523 - val_loss: 1.3414\n",
      "Epoch 18/50\n",
      "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.8546 - loss: 0.3405 - val_accuracy: 0.5814 - val_loss: 1.2936\n",
      "Epoch 19/50\n",
      "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.9016 - loss: 0.2611 - val_accuracy: 0.5581 - val_loss: 1.2012\n",
      "Epoch 20/50\n",
      "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.9071 - loss: 0.2527 - val_accuracy: 0.5000 - val_loss: 1.5514\n",
      "Epoch 21/50\n",
      "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.9079 - loss: 0.2549 - val_accuracy: 0.5233 - val_loss: 1.4114\n",
      "Epoch 22/50\n",
      "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.9184 - loss: 0.2208 - val_accuracy: 0.5349 - val_loss: 1.6323\n",
      "Epoch 23/50\n",
      "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.9409 - loss: 0.1637 - val_accuracy: 0.5174 - val_loss: 1.6372\n",
      "Epoch 24/50\n",
      "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.9397 - loss: 0.1454 - val_accuracy: 0.5988 - val_loss: 1.4715\n",
      "Epoch 25/50\n",
      "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.9481 - loss: 0.1399 - val_accuracy: 0.5465 - val_loss: 1.5418\n",
      "Epoch 26/50\n",
      "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.9321 - loss: 0.1737 - val_accuracy: 0.5000 - val_loss: 1.9181\n",
      "Epoch 27/50\n",
      "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.9296 - loss: 0.2101 - val_accuracy: 0.5698 - val_loss: 1.8387\n",
      "Epoch 28/50\n",
      "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.9577 - loss: 0.1443 - val_accuracy: 0.5581 - val_loss: 1.7820\n",
      "Epoch 29/50\n",
      "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.9665 - loss: 0.1090 - val_accuracy: 0.6047 - val_loss: 1.5396\n",
      "Epoch 30/50\n",
      "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.9526 - loss: 0.1465 - val_accuracy: 0.5465 - val_loss: 1.7838\n",
      "Epoch 31/50\n",
      "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.9514 - loss: 0.1387 - val_accuracy: 0.5174 - val_loss: 2.0935\n",
      "Epoch 32/50\n",
      "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.9529 - loss: 0.1102 - val_accuracy: 0.5465 - val_loss: 1.9063\n",
      "Epoch 33/50\n",
      "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.9554 - loss: 0.1193 - val_accuracy: 0.5291 - val_loss: 1.9146\n",
      "Epoch 34/50\n",
      "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.9647 - loss: 0.0982 - val_accuracy: 0.4535 - val_loss: 2.3967\n",
      "Epoch 35/50\n",
      "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.9672 - loss: 0.1099 - val_accuracy: 0.5698 - val_loss: 1.9212\n",
      "Epoch 36/50\n",
      "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.9611 - loss: 0.1108 - val_accuracy: 0.4244 - val_loss: 2.5750\n",
      "Epoch 37/50\n",
      "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.9555 - loss: 0.1805 - val_accuracy: 0.5058 - val_loss: 1.9548\n",
      "Epoch 38/50\n",
      "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.9674 - loss: 0.1239 - val_accuracy: 0.5174 - val_loss: 1.9285\n",
      "Epoch 39/50\n",
      "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.9518 - loss: 0.1286 - val_accuracy: 0.5174 - val_loss: 1.9212\n",
      "Epoch 40/50\n",
      "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.9576 - loss: 0.1144 - val_accuracy: 0.5174 - val_loss: 2.1636\n",
      "Epoch 41/50\n",
      "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.9769 - loss: 0.0755 - val_accuracy: 0.5698 - val_loss: 1.9717\n",
      "Epoch 42/50\n",
      "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.9751 - loss: 0.0750 - val_accuracy: 0.5640 - val_loss: 1.9945\n",
      "Epoch 43/50\n",
      "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.9723 - loss: 0.0846 - val_accuracy: 0.5349 - val_loss: 2.4720\n",
      "Epoch 44/50\n",
      "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.9690 - loss: 0.0777 - val_accuracy: 0.5814 - val_loss: 2.0958\n",
      "Epoch 45/50\n",
      "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.9673 - loss: 0.0775 - val_accuracy: 0.5581 - val_loss: 2.4460\n",
      "Epoch 46/50\n",
      "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.9638 - loss: 0.1287 - val_accuracy: 0.6163 - val_loss: 1.9963\n",
      "Epoch 47/50\n",
      "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.9475 - loss: 0.1278 - val_accuracy: 0.5756 - val_loss: 2.2840\n",
      "Epoch 48/50\n",
      "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.9859 - loss: 0.0409 - val_accuracy: 0.5640 - val_loss: 2.2459\n",
      "Epoch 49/50\n",
      "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.9948 - loss: 0.0301 - val_accuracy: 0.5814 - val_loss: 2.3582\n",
      "Epoch 50/50\n",
      "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.9731 - loss: 0.0925 - val_accuracy: 0.5640 - val_loss: 2.3220\n",
      "\u001b[1m5/5\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step \n",
      "ANN Accuracy: 0.6565\n",
      "ANN Classification Report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.80      0.79      0.80        62\n",
      "           1       0.47      0.50      0.48        14\n",
      "           2       0.68      0.68      0.68        53\n",
      "\n",
      "    accuracy                           0.71       129\n",
      "   macro avg       0.65      0.66      0.65       129\n",
      "weighted avg       0.72      0.71      0.71       129\n",
      "\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "from sklearn.preprocessing import LabelEncoder\n",
    "from sklearn.svm import SVC\n",
    "from sklearn.metrics import balanced_accuracy_score, classification_report\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "\n",
    "# Load the data\n",
    "train_data = np.load('../Files/extracted_features/layer_features_lv60_self/train_12.npz')\n",
    "test_data = np.load('../Files/extracted_features/layer_features_lv60_self/test_12.npz')\n",
    "\n",
    "train_features = train_data['features']  # Ensure these have 1024 features\n",
    "test_features = test_data['features']    # Ensure these have 1024 features\n",
    "\n",
    "# Read Age labels instead of Gender\n",
    "train_labels = pd.read_csv('../Files/labels/y_train.csv').Age_Group\n",
    "test_labels = pd.read_csv('../Files/labels/y_test.csv').Age_Group\n",
    "\n",
    "# Encode the labels\n",
    "label_encoder = LabelEncoder()\n",
    "train_labels_encoded = label_encoder.fit_transform(train_labels)\n",
    "\n",
    "# Handle unseen labels in test set by filtering out labels not present in train set\n",
    "test_labels_filtered = test_labels[test_labels.isin(train_labels.unique())]\n",
    "test_features_filtered = test_features[test_labels.isin(train_labels.unique())]\n",
    "test_labels_encoded = label_encoder.transform(test_labels_filtered)\n",
    "\n",
    "# Standardize features\n",
    "scaler = StandardScaler()\n",
    "train_features_normalized = scaler.fit_transform(train_features)\n",
    "test_features_normalized = scaler.transform(test_features_filtered)\n",
    "\n",
    "# SVM model\n",
    "svm_model = SVC(kernel='linear', C=10.0, gamma='scale', random_state=42)\n",
    "svm_model.fit(train_features_normalized, train_labels_encoded)\n",
    "\n",
    "# SVM Prediction and Evaluation\n",
    "svm_predictions = svm_model.predict(test_features_normalized)\n",
    "svm_accuracy = balanced_accuracy_score(test_labels_encoded, svm_predictions)\n",
    "print(f\"SVM Accuracy: {svm_accuracy:.4f}\")\n",
    "print(\"SVM Classification Report:\")\n",
    "print(classification_report(test_labels_encoded, svm_predictions))\n",
    "\n",
    "# CNN model (TensorFlow)\n",
    "import tensorflow as tf\n",
    "from tensorflow.keras.models import Sequential\n",
    "from tensorflow.keras.layers import Conv1D, Flatten, Dense, Dropout\n",
    "\n",
    "train_features_cnn = np.expand_dims(train_features_normalized, axis=-1)  # Shape: (num_samples, 1024, 1)\n",
    "test_features_cnn = np.expand_dims(test_features_normalized, axis=-1)    # Shape: (num_samples, 1024, 1)\n",
    "\n",
    "cnn_model = Sequential([\n",
    "    Conv1D(64, kernel_size=5, activation='relu', input_shape=(1024, 1)),  # Updated input shape to 1024\n",
    "    Conv1D(128, kernel_size=5, activation='relu'),\n",
    "    Conv1D(256, kernel_size=5, activation='relu'),\n",
    "    Flatten(),\n",
    "    Dense(256, activation='relu'),\n",
    "    Dropout(0.5),\n",
    "    Dense(len(label_encoder.classes_), activation='softmax')\n",
    "])\n",
    "\n",
    "cnn_model.compile(optimizer='adam', loss='sparse_categorical_crossentropy', metrics=['accuracy'])\n",
    "\n",
    "cnn_model.fit(train_features_cnn, train_labels_encoded, epochs=50, batch_size=32, validation_split=0.2)\n",
    "\n",
    "# CNN Prediction and Evaluation\n",
    "cnn_predictions = np.argmax(cnn_model.predict(test_features_cnn), axis=-1)\n",
    "cnn_accuracy = balanced_accuracy_score(test_labels_encoded, cnn_predictions)\n",
    "print(f\"CNN Accuracy: {cnn_accuracy:.4f}\")\n",
    "print(\"CNN Classification Report:\")\n",
    "print(classification_report(test_labels_encoded, cnn_predictions))\n",
    "\n",
    "# ANN model (TensorFlow)\n",
    "ann_model = Sequential([\n",
    "    Dense(512, activation='relu', input_shape=(1024,)),  # Updated input shape to 1024\n",
    "    Dropout(0.5),\n",
    "    Dense(256, activation='relu'),\n",
    "    Dropout(0.5),\n",
    "    Dense(128, activation='relu'),\n",
    "    Dropout(0.5),\n",
    "    Dense(len(label_encoder.classes_), activation='softmax')\n",
    "])\n",
    "\n",
    "ann_model.compile(optimizer='adam', loss='sparse_categorical_crossentropy', metrics=['accuracy'])\n",
    "\n",
    "ann_model.fit(train_features_normalized, train_labels_encoded, epochs=50, batch_size=32, validation_split=0.2)\n",
    "\n",
    "# ANN Prediction and Evaluation\n",
    "ann_predictions = np.argmax(ann_model.predict(test_features_normalized), axis=-1)\n",
    "ann_accuracy = balanced_accuracy_score(test_labels_encoded, ann_predictions)\n",
    "print(f\"ANN Accuracy: {ann_accuracy:.4f}\")\n",
    "print(\"ANN Classification Report:\")\n",
    "print(classification_report(test_labels_encoded, ann_predictions))\n",
    "\n",
    "# PyTorch CNN Model\n",
    "import torch\n",
    "from torch.utils.data import DataLoader, TensorDataset\n",
    "\n",
    "X_train_tensor = torch.tensor(train_features_cnn, dtype=torch.float32).permute(0, 2, 1)  # Shape: (num_samples, 1, 1024)\n",
    "y_train_tensor = torch.tensor(train_labels_encoded, dtype=torch.long)\n",
    "X_test_tensor = torch.tensor(test_features_cnn, dtype=torch.float32).permute(0, 2, 1)    # Shape: (num_samples, 1, 1024)\n",
    "y_test_tensor = torch.tensor(test_labels_encoded, dtype=torch.long)\n",
    "\n",
    "train_dataset = TensorDataset(X_train_tensor, y_train_tensor)\n",
    "test_dataset = TensorDataset(X_test_tensor, y_test_tensor)\n",
    "\n",
    "train_loader = DataLoader(train_dataset, batch_size=64, shuffle=True)\n",
    "test_loader = DataLoader(test_dataset, batch_size=64, shuffle=False)\n",
    "\n",
    "import torch.nn as nn\n",
    "import torch.optim as optim\n",
    "\n",
    "class CNN1DModel(nn.Module):\n",
    "    def __init__(self, input_channels, num_classes):\n",
    "        super(CNN1DModel, self).__init__()\n",
    "        self.conv1 = nn.Conv1d(input_channels, 32, kernel_size=5, stride=1, padding=2)\n",
    "        self.bn1 = nn.BatchNorm1d(32)\n",
    "        self.relu = nn.ReLU()\n",
    "        self.conv2 = nn.Conv1d(32, 64, kernel_size=5, stride=1, padding=2)\n",
    "        self.bn2 = nn.BatchNorm1d(64)\n",
    "        self.conv3 = nn.Conv1d(64, 128, kernel_size=5, stride=1, padding=2)\n",
    "        self.bn3 = nn.BatchNorm1d(128)\n",
    "        self.flatten = nn.Flatten()\n",
    "        self.fc1 = nn.Linear(128 * 1024, 512)  # Updated to 1024 features\n",
    "        self.fc2 = nn.Linear(512, num_classes)\n",
    "        self.dropout = nn.Dropout(0.5)\n",
    "    \n",
    "    def forward(self, x):\n",
    "        x = self.relu(self.bn1(self.conv1(x)))\n",
    "        x = self.relu(self.bn2(self.conv2(x)))\n",
    "        x = self.relu(self.bn3(self.conv3(x)))\n",
    "        x = self.flatten(x)\n",
    "        x = self.dropout(self.relu(self.fc1(x)))\n",
    "        x = self.fc2(x)\n",
    "        return x\n",
    "\n",
    "input_channels = 1\n",
    "num_classes = len(label_encoder.classes_)\n",
    "model = CNN1DModel(input_channels, num_classes)\n",
    "criterion = nn.CrossEntropyLoss()\n",
    "optimizer = optim.Adam(model.parameters(), lr=0.001)\n",
    "\n",
    "# Training loop and evaluation (not shown)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "SVM Accuracy: 0.6324\n",
      "SVM Classification Report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.82      0.66      0.73        62\n",
      "           1       0.54      0.50      0.52        14\n",
      "           2       0.59      0.74      0.66        53\n",
      "\n",
      "    accuracy                           0.67       129\n",
      "   macro avg       0.65      0.63      0.64       129\n",
      "weighted avg       0.70      0.67      0.68       129\n",
      "\n",
      "Epoch 1/50\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/mojo/.local/lib/python3.12/site-packages/keras/src/layers/convolutional/base_conv.py:107: UserWarning: Do not pass an `input_shape`/`input_dim` argument to a layer. When using Sequential models, prefer using an `Input(shape)` object as the first layer in the model instead.\n",
      "  super().__init__(activity_regularizer=activity_regularizer, **kwargs)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m12s\u001b[0m 489ms/step - accuracy: 0.5150 - loss: 3.2003 - val_accuracy: 0.2093 - val_loss: 1.1338\n",
      "Epoch 2/50\n",
      "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m11s\u001b[0m 479ms/step - accuracy: 0.6799 - loss: 0.7798 - val_accuracy: 0.4593 - val_loss: 1.1496\n",
      "Epoch 3/50\n",
      "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m11s\u001b[0m 486ms/step - accuracy: 0.7593 - loss: 0.6081 - val_accuracy: 0.5640 - val_loss: 1.0228\n",
      "Epoch 4/50\n",
      "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m11s\u001b[0m 477ms/step - accuracy: 0.8052 - loss: 0.4556 - val_accuracy: 0.7500 - val_loss: 0.6621\n",
      "Epoch 5/50\n",
      "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m11s\u001b[0m 493ms/step - accuracy: 0.8915 - loss: 0.2910 - val_accuracy: 0.5233 - val_loss: 1.2183\n",
      "Epoch 6/50\n",
      "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m11s\u001b[0m 486ms/step - accuracy: 0.9531 - loss: 0.1521 - val_accuracy: 0.6105 - val_loss: 1.2014\n",
      "Epoch 7/50\n",
      "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m11s\u001b[0m 502ms/step - accuracy: 0.9686 - loss: 0.1103 - val_accuracy: 0.4593 - val_loss: 1.5674\n",
      "Epoch 8/50\n",
      "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m11s\u001b[0m 497ms/step - accuracy: 0.9568 - loss: 0.1292 - val_accuracy: 0.5291 - val_loss: 1.5862\n",
      "Epoch 9/50\n",
      "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m11s\u001b[0m 490ms/step - accuracy: 0.9764 - loss: 0.0831 - val_accuracy: 0.5872 - val_loss: 1.5345\n",
      "Epoch 10/50\n",
      "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m11s\u001b[0m 485ms/step - accuracy: 0.9857 - loss: 0.0485 - val_accuracy: 0.6047 - val_loss: 1.6107\n",
      "Epoch 11/50\n",
      "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m11s\u001b[0m 486ms/step - accuracy: 0.9915 - loss: 0.0385 - val_accuracy: 0.5349 - val_loss: 2.2466\n",
      "Epoch 12/50\n",
      "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m11s\u001b[0m 502ms/step - accuracy: 0.9893 - loss: 0.0380 - val_accuracy: 0.5698 - val_loss: 1.9559\n",
      "Epoch 13/50\n",
      "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m11s\u001b[0m 497ms/step - accuracy: 0.9850 - loss: 0.0406 - val_accuracy: 0.5058 - val_loss: 2.2045\n",
      "Epoch 14/50\n",
      "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m11s\u001b[0m 513ms/step - accuracy: 0.9836 - loss: 0.0436 - val_accuracy: 0.5058 - val_loss: 2.5097\n",
      "Epoch 15/50\n",
      "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m11s\u001b[0m 506ms/step - accuracy: 0.9904 - loss: 0.0364 - val_accuracy: 0.4360 - val_loss: 2.6920\n",
      "Epoch 16/50\n",
      "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m11s\u001b[0m 522ms/step - accuracy: 0.9941 - loss: 0.0314 - val_accuracy: 0.6047 - val_loss: 1.6015\n",
      "Epoch 17/50\n",
      "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m11s\u001b[0m 516ms/step - accuracy: 0.9993 - loss: 0.0162 - val_accuracy: 0.5233 - val_loss: 2.5919\n",
      "Epoch 18/50\n",
      "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m11s\u001b[0m 505ms/step - accuracy: 0.9887 - loss: 0.0279 - val_accuracy: 0.5640 - val_loss: 2.5413\n",
      "Epoch 19/50\n",
      "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m11s\u001b[0m 481ms/step - accuracy: 0.9883 - loss: 0.0420 - val_accuracy: 0.6337 - val_loss: 1.6223\n",
      "Epoch 20/50\n",
      "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m11s\u001b[0m 485ms/step - accuracy: 0.9992 - loss: 0.0144 - val_accuracy: 0.4535 - val_loss: 3.1178\n",
      "Epoch 21/50\n",
      "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m11s\u001b[0m 485ms/step - accuracy: 0.9996 - loss: 0.0091 - val_accuracy: 0.5291 - val_loss: 3.2195\n",
      "Epoch 22/50\n",
      "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m11s\u001b[0m 493ms/step - accuracy: 0.9943 - loss: 0.0132 - val_accuracy: 0.5581 - val_loss: 2.9338\n",
      "Epoch 23/50\n",
      "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m11s\u001b[0m 484ms/step - accuracy: 0.9964 - loss: 0.0115 - val_accuracy: 0.5174 - val_loss: 3.2215\n",
      "Epoch 24/50\n",
      "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m11s\u001b[0m 482ms/step - accuracy: 0.9907 - loss: 0.0305 - val_accuracy: 0.5988 - val_loss: 2.0811\n",
      "Epoch 25/50\n",
      "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m11s\u001b[0m 501ms/step - accuracy: 0.9954 - loss: 0.0365 - val_accuracy: 0.5174 - val_loss: 2.4256\n",
      "Epoch 26/50\n",
      "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m11s\u001b[0m 504ms/step - accuracy: 0.9880 - loss: 0.0532 - val_accuracy: 0.5000 - val_loss: 3.0657\n",
      "Epoch 27/50\n",
      "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m11s\u001b[0m 494ms/step - accuracy: 0.9903 - loss: 0.0170 - val_accuracy: 0.4826 - val_loss: 3.3214\n",
      "Epoch 28/50\n",
      "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m11s\u001b[0m 502ms/step - accuracy: 0.9907 - loss: 0.0245 - val_accuracy: 0.5814 - val_loss: 2.2351\n",
      "Epoch 29/50\n",
      "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m11s\u001b[0m 501ms/step - accuracy: 1.0000 - loss: 0.0063 - val_accuracy: 0.5291 - val_loss: 3.0527\n",
      "Epoch 30/50\n",
      "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m11s\u001b[0m 494ms/step - accuracy: 0.9970 - loss: 0.0096 - val_accuracy: 0.5291 - val_loss: 2.8457\n",
      "Epoch 31/50\n",
      "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m11s\u001b[0m 503ms/step - accuracy: 0.9989 - loss: 0.0049 - val_accuracy: 0.5581 - val_loss: 2.9224\n",
      "Epoch 32/50\n",
      "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m11s\u001b[0m 484ms/step - accuracy: 0.9960 - loss: 0.0105 - val_accuracy: 0.4477 - val_loss: 3.8580\n",
      "Epoch 33/50\n",
      "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m11s\u001b[0m 491ms/step - accuracy: 1.0000 - loss: 0.0015 - val_accuracy: 0.4477 - val_loss: 4.0246\n",
      "Epoch 34/50\n",
      "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m11s\u001b[0m 495ms/step - accuracy: 1.0000 - loss: 0.0027 - val_accuracy: 0.5407 - val_loss: 3.2653\n",
      "Epoch 35/50\n",
      "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m11s\u001b[0m 485ms/step - accuracy: 0.9972 - loss: 0.0052 - val_accuracy: 0.4884 - val_loss: 3.6922\n",
      "Epoch 36/50\n",
      "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m11s\u001b[0m 484ms/step - accuracy: 0.9845 - loss: 0.0470 - val_accuracy: 0.6221 - val_loss: 1.6373\n",
      "Epoch 37/50\n",
      "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m11s\u001b[0m 483ms/step - accuracy: 0.9859 - loss: 0.0475 - val_accuracy: 0.6337 - val_loss: 2.4468\n",
      "Epoch 38/50\n",
      "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m11s\u001b[0m 494ms/step - accuracy: 0.9957 - loss: 0.0143 - val_accuracy: 0.4884 - val_loss: 3.3855\n",
      "Epoch 39/50\n",
      "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m11s\u001b[0m 492ms/step - accuracy: 0.9976 - loss: 0.0094 - val_accuracy: 0.3837 - val_loss: 4.7725\n",
      "Epoch 40/50\n",
      "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m11s\u001b[0m 497ms/step - accuracy: 0.9995 - loss: 0.0067 - val_accuracy: 0.5291 - val_loss: 3.2775\n",
      "Epoch 41/50\n",
      "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m11s\u001b[0m 500ms/step - accuracy: 0.9984 - loss: 0.0142 - val_accuracy: 0.4419 - val_loss: 3.8449\n",
      "Epoch 42/50\n",
      "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m11s\u001b[0m 489ms/step - accuracy: 0.9932 - loss: 0.0447 - val_accuracy: 0.5814 - val_loss: 2.4571\n",
      "Epoch 43/50\n",
      "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m11s\u001b[0m 497ms/step - accuracy: 0.9943 - loss: 0.0109 - val_accuracy: 0.4186 - val_loss: 4.1347\n",
      "Epoch 44/50\n",
      "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m10s\u001b[0m 470ms/step - accuracy: 0.9997 - loss: 0.0050 - val_accuracy: 0.5465 - val_loss: 2.9824\n",
      "Epoch 45/50\n",
      "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m11s\u001b[0m 479ms/step - accuracy: 1.0000 - loss: 0.0022 - val_accuracy: 0.5291 - val_loss: 3.3673\n",
      "Epoch 46/50\n",
      "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m11s\u001b[0m 494ms/step - accuracy: 0.9985 - loss: 0.0041 - val_accuracy: 0.5698 - val_loss: 3.1889\n",
      "Epoch 47/50\n",
      "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m11s\u001b[0m 479ms/step - accuracy: 0.9979 - loss: 0.0061 - val_accuracy: 0.6105 - val_loss: 2.4135\n",
      "Epoch 48/50\n",
      "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m10s\u001b[0m 473ms/step - accuracy: 0.9995 - loss: 0.0041 - val_accuracy: 0.5116 - val_loss: 3.3298\n",
      "Epoch 49/50\n",
      "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m10s\u001b[0m 474ms/step - accuracy: 1.0000 - loss: 0.0015 - val_accuracy: 0.5756 - val_loss: 3.1985\n",
      "Epoch 50/50\n",
      "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m11s\u001b[0m 481ms/step - accuracy: 0.9986 - loss: 0.0059 - val_accuracy: 0.4884 - val_loss: 3.7092\n",
      "\u001b[1m5/5\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 47ms/step\n",
      "CNN Accuracy: 0.5959\n",
      "CNN Classification Report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.71      0.77      0.74        62\n",
      "           1       0.55      0.43      0.48        14\n",
      "           2       0.62      0.58      0.60        53\n",
      "\n",
      "    accuracy                           0.66       129\n",
      "   macro avg       0.62      0.60      0.61       129\n",
      "weighted avg       0.65      0.66      0.65       129\n",
      "\n",
      "Epoch 1/50\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/mojo/.local/lib/python3.12/site-packages/keras/src/layers/core/dense.py:87: UserWarning: Do not pass an `input_shape`/`input_dim` argument to a layer. When using Sequential models, prefer using an `Input(shape)` object as the first layer in the model instead.\n",
      "  super().__init__(activity_regularizer=activity_regularizer, **kwargs)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 9ms/step - accuracy: 0.4023 - loss: 1.8813 - val_accuracy: 0.2267 - val_loss: 1.1675\n",
      "Epoch 2/50\n",
      "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - accuracy: 0.5700 - loss: 1.0556 - val_accuracy: 0.2616 - val_loss: 1.1077\n",
      "Epoch 3/50\n",
      "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.6176 - loss: 0.8625 - val_accuracy: 0.2209 - val_loss: 1.2009\n",
      "Epoch 4/50\n",
      "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.6203 - loss: 0.8399 - val_accuracy: 0.3895 - val_loss: 1.1616\n",
      "Epoch 5/50\n",
      "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.6742 - loss: 0.7419 - val_accuracy: 0.4651 - val_loss: 1.0116\n",
      "Epoch 6/50\n",
      "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.6633 - loss: 0.7596 - val_accuracy: 0.3198 - val_loss: 1.2357\n",
      "Epoch 7/50\n",
      "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.7003 - loss: 0.6649 - val_accuracy: 0.3721 - val_loss: 1.1780\n",
      "Epoch 8/50\n",
      "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.7263 - loss: 0.6014 - val_accuracy: 0.3779 - val_loss: 1.2451\n",
      "Epoch 9/50\n",
      "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.7441 - loss: 0.5541 - val_accuracy: 0.5523 - val_loss: 1.1657\n",
      "Epoch 10/50\n",
      "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.7758 - loss: 0.4850 - val_accuracy: 0.4593 - val_loss: 1.2625\n",
      "Epoch 11/50\n",
      "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.8225 - loss: 0.4254 - val_accuracy: 0.5581 - val_loss: 1.1594\n",
      "Epoch 12/50\n",
      "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.8268 - loss: 0.4233 - val_accuracy: 0.4826 - val_loss: 1.1892\n",
      "Epoch 13/50\n",
      "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.8345 - loss: 0.4238 - val_accuracy: 0.5349 - val_loss: 1.2903\n",
      "Epoch 14/50\n",
      "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.8295 - loss: 0.3759 - val_accuracy: 0.4942 - val_loss: 1.3436\n",
      "Epoch 15/50\n",
      "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.8651 - loss: 0.4063 - val_accuracy: 0.5233 - val_loss: 1.2813\n",
      "Epoch 16/50\n",
      "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.8623 - loss: 0.3538 - val_accuracy: 0.5581 - val_loss: 1.2094\n",
      "Epoch 17/50\n",
      "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.8914 - loss: 0.3386 - val_accuracy: 0.4767 - val_loss: 1.5844\n",
      "Epoch 18/50\n",
      "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.8750 - loss: 0.2958 - val_accuracy: 0.6047 - val_loss: 1.1106\n",
      "Epoch 19/50\n",
      "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.8973 - loss: 0.3047 - val_accuracy: 0.5000 - val_loss: 1.6952\n",
      "Epoch 20/50\n",
      "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.8893 - loss: 0.2973 - val_accuracy: 0.5116 - val_loss: 1.3551\n",
      "Epoch 21/50\n",
      "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.8898 - loss: 0.2612 - val_accuracy: 0.5058 - val_loss: 1.5986\n",
      "Epoch 22/50\n",
      "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.8974 - loss: 0.2667 - val_accuracy: 0.5930 - val_loss: 1.4395\n",
      "Epoch 23/50\n",
      "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.9287 - loss: 0.1885 - val_accuracy: 0.5465 - val_loss: 1.5101\n",
      "Epoch 24/50\n",
      "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.9208 - loss: 0.2174 - val_accuracy: 0.4535 - val_loss: 1.8601\n",
      "Epoch 25/50\n",
      "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.9131 - loss: 0.2666 - val_accuracy: 0.5291 - val_loss: 1.3599\n",
      "Epoch 26/50\n",
      "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.9534 - loss: 0.1261 - val_accuracy: 0.4767 - val_loss: 1.8413\n",
      "Epoch 27/50\n",
      "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.9628 - loss: 0.1362 - val_accuracy: 0.5116 - val_loss: 1.8610\n",
      "Epoch 28/50\n",
      "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.9471 - loss: 0.1501 - val_accuracy: 0.5814 - val_loss: 1.6764\n",
      "Epoch 29/50\n",
      "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.9601 - loss: 0.1183 - val_accuracy: 0.5116 - val_loss: 2.0135\n",
      "Epoch 30/50\n",
      "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.9447 - loss: 0.1717 - val_accuracy: 0.5291 - val_loss: 2.0280\n",
      "Epoch 31/50\n",
      "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.9461 - loss: 0.1517 - val_accuracy: 0.5581 - val_loss: 1.8436\n",
      "Epoch 32/50\n",
      "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.9411 - loss: 0.1381 - val_accuracy: 0.5640 - val_loss: 1.9504\n",
      "Epoch 33/50\n",
      "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.9449 - loss: 0.1267 - val_accuracy: 0.5465 - val_loss: 2.1077\n",
      "Epoch 34/50\n",
      "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.9698 - loss: 0.0936 - val_accuracy: 0.5465 - val_loss: 1.9519\n",
      "Epoch 35/50\n",
      "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.9686 - loss: 0.1234 - val_accuracy: 0.5116 - val_loss: 2.5879\n",
      "Epoch 36/50\n",
      "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.9602 - loss: 0.1205 - val_accuracy: 0.5465 - val_loss: 2.4807\n",
      "Epoch 37/50\n",
      "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.9567 - loss: 0.1203 - val_accuracy: 0.4884 - val_loss: 2.0624\n",
      "Epoch 38/50\n",
      "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.9785 - loss: 0.0845 - val_accuracy: 0.5116 - val_loss: 2.6035\n",
      "Epoch 39/50\n",
      "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.9443 - loss: 0.1380 - val_accuracy: 0.5465 - val_loss: 1.8305\n",
      "Epoch 40/50\n",
      "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.9825 - loss: 0.0727 - val_accuracy: 0.5058 - val_loss: 2.2557\n",
      "Epoch 41/50\n",
      "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.9686 - loss: 0.0911 - val_accuracy: 0.5000 - val_loss: 2.2685\n",
      "Epoch 42/50\n",
      "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.9678 - loss: 0.1054 - val_accuracy: 0.5407 - val_loss: 2.1486\n",
      "Epoch 43/50\n",
      "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.9640 - loss: 0.1459 - val_accuracy: 0.5174 - val_loss: 2.2995\n",
      "Epoch 44/50\n",
      "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.9819 - loss: 0.0651 - val_accuracy: 0.5988 - val_loss: 2.0760\n",
      "Epoch 45/50\n",
      "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.9777 - loss: 0.0655 - val_accuracy: 0.5233 - val_loss: 2.8335\n",
      "Epoch 46/50\n",
      "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.9726 - loss: 0.0753 - val_accuracy: 0.5174 - val_loss: 3.1257\n",
      "Epoch 47/50\n",
      "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.9815 - loss: 0.0434 - val_accuracy: 0.5698 - val_loss: 2.5559\n",
      "Epoch 48/50\n",
      "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.9910 - loss: 0.0575 - val_accuracy: 0.5465 - val_loss: 3.0873\n",
      "Epoch 49/50\n",
      "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.9783 - loss: 0.0923 - val_accuracy: 0.5465 - val_loss: 2.7259\n",
      "Epoch 50/50\n",
      "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.9703 - loss: 0.1200 - val_accuracy: 0.5349 - val_loss: 2.3741\n",
      "\u001b[1m5/5\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step \n",
      "ANN Accuracy: 0.5317\n",
      "ANN Classification Report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.68      0.76      0.72        62\n",
      "           1       0.50      0.21      0.30        14\n",
      "           2       0.61      0.62      0.62        53\n",
      "\n",
      "    accuracy                           0.64       129\n",
      "   macro avg       0.60      0.53      0.54       129\n",
      "weighted avg       0.63      0.64      0.63       129\n",
      "\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "from sklearn.preprocessing import LabelEncoder\n",
    "from sklearn.svm import SVC\n",
    "from sklearn.metrics import balanced_accuracy_score, classification_report\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "\n",
    "# Load the data\n",
    "train_data = np.load('../Files/extracted_features/layer_features_lv60_self/train_13.npz')\n",
    "test_data = np.load('../Files/extracted_features/layer_features_lv60_self/test_13.npz')\n",
    "\n",
    "train_features = train_data['features']  # Ensure these have 1024 features\n",
    "test_features = test_data['features']    # Ensure these have 1024 features\n",
    "\n",
    "# Read Age labels instead of Gender\n",
    "train_labels = pd.read_csv('../Files/labels/y_train.csv').Age_Group\n",
    "test_labels = pd.read_csv('../Files/labels/y_test.csv').Age_Group\n",
    "\n",
    "# Encode the labels\n",
    "label_encoder = LabelEncoder()\n",
    "train_labels_encoded = label_encoder.fit_transform(train_labels)\n",
    "\n",
    "# Handle unseen labels in test set by filtering out labels not present in train set\n",
    "test_labels_filtered = test_labels[test_labels.isin(train_labels.unique())]\n",
    "test_features_filtered = test_features[test_labels.isin(train_labels.unique())]\n",
    "test_labels_encoded = label_encoder.transform(test_labels_filtered)\n",
    "\n",
    "# Standardize features\n",
    "scaler = StandardScaler()\n",
    "train_features_normalized = scaler.fit_transform(train_features)\n",
    "test_features_normalized = scaler.transform(test_features_filtered)\n",
    "\n",
    "# SVM model\n",
    "svm_model = SVC(kernel='linear', C=10.0, gamma='scale', random_state=42)\n",
    "svm_model.fit(train_features_normalized, train_labels_encoded)\n",
    "\n",
    "# SVM Prediction and Evaluation\n",
    "svm_predictions = svm_model.predict(test_features_normalized)\n",
    "svm_accuracy = balanced_accuracy_score(test_labels_encoded, svm_predictions)\n",
    "print(f\"SVM Accuracy: {svm_accuracy:.4f}\")\n",
    "print(\"SVM Classification Report:\")\n",
    "print(classification_report(test_labels_encoded, svm_predictions))\n",
    "\n",
    "# CNN model (TensorFlow)\n",
    "import tensorflow as tf\n",
    "from tensorflow.keras.models import Sequential\n",
    "from tensorflow.keras.layers import Conv1D, Flatten, Dense, Dropout\n",
    "\n",
    "train_features_cnn = np.expand_dims(train_features_normalized, axis=-1)  # Shape: (num_samples, 1024, 1)\n",
    "test_features_cnn = np.expand_dims(test_features_normalized, axis=-1)    # Shape: (num_samples, 1024, 1)\n",
    "\n",
    "cnn_model = Sequential([\n",
    "    Conv1D(64, kernel_size=5, activation='relu', input_shape=(1024, 1)),  # Updated input shape to 1024\n",
    "    Conv1D(128, kernel_size=5, activation='relu'),\n",
    "    Conv1D(256, kernel_size=5, activation='relu'),\n",
    "    Flatten(),\n",
    "    Dense(256, activation='relu'),\n",
    "    Dropout(0.5),\n",
    "    Dense(len(label_encoder.classes_), activation='softmax')\n",
    "])\n",
    "\n",
    "cnn_model.compile(optimizer='adam', loss='sparse_categorical_crossentropy', metrics=['accuracy'])\n",
    "\n",
    "cnn_model.fit(train_features_cnn, train_labels_encoded, epochs=50, batch_size=32, validation_split=0.2)\n",
    "\n",
    "# CNN Prediction and Evaluation\n",
    "cnn_predictions = np.argmax(cnn_model.predict(test_features_cnn), axis=-1)\n",
    "cnn_accuracy = balanced_accuracy_score(test_labels_encoded, cnn_predictions)\n",
    "print(f\"CNN Accuracy: {cnn_accuracy:.4f}\")\n",
    "print(\"CNN Classification Report:\")\n",
    "print(classification_report(test_labels_encoded, cnn_predictions))\n",
    "\n",
    "# ANN model (TensorFlow)\n",
    "ann_model = Sequential([\n",
    "    Dense(512, activation='relu', input_shape=(1024,)),  # Updated input shape to 1024\n",
    "    Dropout(0.5),\n",
    "    Dense(256, activation='relu'),\n",
    "    Dropout(0.5),\n",
    "    Dense(128, activation='relu'),\n",
    "    Dropout(0.5),\n",
    "    Dense(len(label_encoder.classes_), activation='softmax')\n",
    "])\n",
    "\n",
    "ann_model.compile(optimizer='adam', loss='sparse_categorical_crossentropy', metrics=['accuracy'])\n",
    "\n",
    "ann_model.fit(train_features_normalized, train_labels_encoded, epochs=50, batch_size=32, validation_split=0.2)\n",
    "\n",
    "# ANN Prediction and Evaluation\n",
    "ann_predictions = np.argmax(ann_model.predict(test_features_normalized), axis=-1)\n",
    "ann_accuracy = balanced_accuracy_score(test_labels_encoded, ann_predictions)\n",
    "print(f\"ANN Accuracy: {ann_accuracy:.4f}\")\n",
    "print(\"ANN Classification Report:\")\n",
    "print(classification_report(test_labels_encoded, ann_predictions))\n",
    "\n",
    "# PyTorch CNN Model\n",
    "import torch\n",
    "from torch.utils.data import DataLoader, TensorDataset\n",
    "\n",
    "X_train_tensor = torch.tensor(train_features_cnn, dtype=torch.float32).permute(0, 2, 1)  # Shape: (num_samples, 1, 1024)\n",
    "y_train_tensor = torch.tensor(train_labels_encoded, dtype=torch.long)\n",
    "X_test_tensor = torch.tensor(test_features_cnn, dtype=torch.float32).permute(0, 2, 1)    # Shape: (num_samples, 1, 1024)\n",
    "y_test_tensor = torch.tensor(test_labels_encoded, dtype=torch.long)\n",
    "\n",
    "train_dataset = TensorDataset(X_train_tensor, y_train_tensor)\n",
    "test_dataset = TensorDataset(X_test_tensor, y_test_tensor)\n",
    "\n",
    "train_loader = DataLoader(train_dataset, batch_size=64, shuffle=True)\n",
    "test_loader = DataLoader(test_dataset, batch_size=64, shuffle=False)\n",
    "\n",
    "import torch.nn as nn\n",
    "import torch.optim as optim\n",
    "\n",
    "class CNN1DModel(nn.Module):\n",
    "    def __init__(self, input_channels, num_classes):\n",
    "        super(CNN1DModel, self).__init__()\n",
    "        self.conv1 = nn.Conv1d(input_channels, 32, kernel_size=5, stride=1, padding=2)\n",
    "        self.bn1 = nn.BatchNorm1d(32)\n",
    "        self.relu = nn.ReLU()\n",
    "        self.conv2 = nn.Conv1d(32, 64, kernel_size=5, stride=1, padding=2)\n",
    "        self.bn2 = nn.BatchNorm1d(64)\n",
    "        self.conv3 = nn.Conv1d(64, 128, kernel_size=5, stride=1, padding=2)\n",
    "        self.bn3 = nn.BatchNorm1d(128)\n",
    "        self.flatten = nn.Flatten()\n",
    "        self.fc1 = nn.Linear(128 * 1024, 512)  # Updated to 1024 features\n",
    "        self.fc2 = nn.Linear(512, num_classes)\n",
    "        self.dropout = nn.Dropout(0.5)\n",
    "    \n",
    "    def forward(self, x):\n",
    "        x = self.relu(self.bn1(self.conv1(x)))\n",
    "        x = self.relu(self.bn2(self.conv2(x)))\n",
    "        x = self.relu(self.bn3(self.conv3(x)))\n",
    "        x = self.flatten(x)\n",
    "        x = self.dropout(self.relu(self.fc1(x)))\n",
    "        x = self.fc2(x)\n",
    "        return x\n",
    "\n",
    "input_channels = 1\n",
    "num_classes = len(label_encoder.classes_)\n",
    "model = CNN1DModel(input_channels, num_classes)\n",
    "criterion = nn.CrossEntropyLoss()\n",
    "optimizer = optim.Adam(model.parameters(), lr=0.001)\n",
    "\n",
    "# Training loop and evaluation (not shown)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "SVM Accuracy: 0.5812\n",
      "SVM Classification Report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.83      0.61      0.70        62\n",
      "           1       0.42      0.36      0.38        14\n",
      "           2       0.58      0.77      0.66        53\n",
      "\n",
      "    accuracy                           0.65       129\n",
      "   macro avg       0.61      0.58      0.58       129\n",
      "weighted avg       0.68      0.65      0.65       129\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2024-12-11 21:22:12.545946: E external/local_xla/xla/stream_executor/cuda/cuda_fft.cc:485] Unable to register cuFFT factory: Attempting to register factory for plugin cuFFT when one has already been registered\n",
      "2024-12-11 21:22:12.556119: E external/local_xla/xla/stream_executor/cuda/cuda_dnn.cc:8454] Unable to register cuDNN factory: Attempting to register factory for plugin cuDNN when one has already been registered\n",
      "2024-12-11 21:22:12.560204: E external/local_xla/xla/stream_executor/cuda/cuda_blas.cc:1452] Unable to register cuBLAS factory: Attempting to register factory for plugin cuBLAS when one has already been registered\n",
      "2024-12-11 21:22:12.571148: I tensorflow/core/platform/cpu_feature_guard.cc:210] This TensorFlow binary is optimized to use available CPU instructions in performance-critical operations.\n",
      "To enable the following instructions: AVX2 FMA, in other operations, rebuild TensorFlow with the appropriate compiler flags.\n",
      "2024-12-11 21:22:13.781088: W tensorflow/compiler/tf2tensorrt/utils/py_utils.cc:38] TF-TRT Warning: Could not find TensorRT\n",
      "/home/mojo/.local/lib/python3.12/site-packages/keras/src/layers/convolutional/base_conv.py:107: UserWarning: Do not pass an `input_shape`/`input_dim` argument to a layer. When using Sequential models, prefer using an `Input(shape)` object as the first layer in the model instead.\n",
      "  super().__init__(activity_regularizer=activity_regularizer, **kwargs)\n",
      "WARNING: All log messages before absl::InitializeLog() is called are written to STDERR\n",
      "I0000 00:00:1733932334.969516  311871 cuda_executor.cc:1015] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero. See more at https://github.com/torvalds/linux/blob/v6.0/Documentation/ABI/testing/sysfs-bus-pci#L344-L355\n",
      "2024-12-11 21:22:15.023874: W tensorflow/core/common_runtime/gpu/gpu_device.cc:2343] Cannot dlopen some GPU libraries. Please make sure the missing libraries mentioned above are installed properly if you would like to use GPU. Follow the guide at https://www.tensorflow.org/install/gpu for how to download and setup the required libraries for your platform.\n",
      "Skipping registering GPU devices...\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/50\n",
      "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m12s\u001b[0m 506ms/step - accuracy: 0.4851 - loss: 3.2390 - val_accuracy: 0.0465 - val_loss: 1.0071\n",
      "Epoch 2/50\n",
      "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m11s\u001b[0m 505ms/step - accuracy: 0.6447 - loss: 0.8052 - val_accuracy: 0.4070 - val_loss: 1.0361\n",
      "Epoch 3/50\n",
      "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m11s\u001b[0m 485ms/step - accuracy: 0.6964 - loss: 0.6395 - val_accuracy: 0.5116 - val_loss: 0.9363\n",
      "Epoch 4/50\n",
      "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m11s\u001b[0m 493ms/step - accuracy: 0.7883 - loss: 0.5218 - val_accuracy: 0.4593 - val_loss: 1.1037\n",
      "Epoch 5/50\n",
      "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m11s\u001b[0m 490ms/step - accuracy: 0.8662 - loss: 0.3653 - val_accuracy: 0.6163 - val_loss: 0.8376\n",
      "Epoch 6/50\n",
      "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m11s\u001b[0m 501ms/step - accuracy: 0.8739 - loss: 0.3356 - val_accuracy: 0.5930 - val_loss: 0.9153\n",
      "Epoch 7/50\n",
      "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m11s\u001b[0m 502ms/step - accuracy: 0.9077 - loss: 0.2258 - val_accuracy: 0.4651 - val_loss: 1.6204\n",
      "Epoch 8/50\n",
      "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m11s\u001b[0m 503ms/step - accuracy: 0.9485 - loss: 0.1546 - val_accuracy: 0.4767 - val_loss: 1.8886\n",
      "Epoch 9/50\n",
      "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m11s\u001b[0m 503ms/step - accuracy: 0.9559 - loss: 0.1113 - val_accuracy: 0.4826 - val_loss: 1.8434\n",
      "Epoch 10/50\n",
      "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m11s\u001b[0m 498ms/step - accuracy: 0.9636 - loss: 0.0860 - val_accuracy: 0.5756 - val_loss: 1.4851\n",
      "Epoch 11/50\n",
      "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m11s\u001b[0m 499ms/step - accuracy: 0.9688 - loss: 0.1501 - val_accuracy: 0.5233 - val_loss: 1.7971\n",
      "Epoch 12/50\n",
      "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m11s\u001b[0m 497ms/step - accuracy: 0.9857 - loss: 0.0595 - val_accuracy: 0.3779 - val_loss: 2.9616\n",
      "Epoch 13/50\n",
      "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m11s\u001b[0m 502ms/step - accuracy: 0.9796 - loss: 0.0660 - val_accuracy: 0.4826 - val_loss: 2.1686\n",
      "Epoch 14/50\n",
      "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m11s\u001b[0m 507ms/step - accuracy: 0.9912 - loss: 0.0302 - val_accuracy: 0.5814 - val_loss: 1.9213\n",
      "Epoch 15/50\n",
      "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m11s\u001b[0m 504ms/step - accuracy: 0.9928 - loss: 0.0366 - val_accuracy: 0.5233 - val_loss: 2.2375\n",
      "Epoch 16/50\n",
      "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m11s\u001b[0m 499ms/step - accuracy: 0.9910 - loss: 0.0302 - val_accuracy: 0.5581 - val_loss: 2.0387\n",
      "Epoch 17/50\n",
      "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m11s\u001b[0m 502ms/step - accuracy: 0.9860 - loss: 0.0293 - val_accuracy: 0.4767 - val_loss: 3.0858\n",
      "Epoch 18/50\n",
      "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m11s\u001b[0m 495ms/step - accuracy: 0.9972 - loss: 0.0100 - val_accuracy: 0.4942 - val_loss: 3.2559\n",
      "Epoch 19/50\n",
      "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m11s\u001b[0m 500ms/step - accuracy: 0.9926 - loss: 0.0183 - val_accuracy: 0.4419 - val_loss: 3.4164\n",
      "Epoch 20/50\n",
      "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m11s\u001b[0m 500ms/step - accuracy: 0.9829 - loss: 0.0347 - val_accuracy: 0.5698 - val_loss: 2.1130\n",
      "Epoch 21/50\n",
      "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m11s\u001b[0m 500ms/step - accuracy: 0.9915 - loss: 0.0238 - val_accuracy: 0.5581 - val_loss: 2.1920\n",
      "Epoch 22/50\n",
      "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m11s\u001b[0m 504ms/step - accuracy: 0.9834 - loss: 0.0469 - val_accuracy: 0.4070 - val_loss: 2.8796\n",
      "Epoch 23/50\n",
      "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m11s\u001b[0m 492ms/step - accuracy: 0.9912 - loss: 0.0249 - val_accuracy: 0.6047 - val_loss: 1.9529\n",
      "Epoch 24/50\n",
      "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m11s\u001b[0m 495ms/step - accuracy: 0.9893 - loss: 0.0192 - val_accuracy: 0.4942 - val_loss: 3.4412\n",
      "Epoch 25/50\n",
      "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m11s\u001b[0m 498ms/step - accuracy: 0.9915 - loss: 0.0304 - val_accuracy: 0.6105 - val_loss: 1.6089\n",
      "Epoch 26/50\n",
      "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m11s\u001b[0m 504ms/step - accuracy: 0.9950 - loss: 0.0310 - val_accuracy: 0.5174 - val_loss: 2.5087\n",
      "Epoch 27/50\n",
      "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m11s\u001b[0m 501ms/step - accuracy: 0.9944 - loss: 0.0179 - val_accuracy: 0.5233 - val_loss: 3.0761\n",
      "Epoch 28/50\n",
      "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m11s\u001b[0m 516ms/step - accuracy: 0.9930 - loss: 0.0210 - val_accuracy: 0.5174 - val_loss: 2.7387\n",
      "Epoch 29/50\n",
      "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m11s\u001b[0m 499ms/step - accuracy: 0.9922 - loss: 0.0243 - val_accuracy: 0.4302 - val_loss: 3.8393\n",
      "Epoch 30/50\n",
      "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m11s\u001b[0m 504ms/step - accuracy: 0.9875 - loss: 0.0328 - val_accuracy: 0.4826 - val_loss: 2.7861\n",
      "Epoch 31/50\n",
      "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m11s\u001b[0m 505ms/step - accuracy: 0.9988 - loss: 0.0100 - val_accuracy: 0.5058 - val_loss: 3.2165\n",
      "Epoch 32/50\n",
      "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m11s\u001b[0m 508ms/step - accuracy: 0.9955 - loss: 0.0145 - val_accuracy: 0.5233 - val_loss: 3.1727\n",
      "Epoch 33/50\n",
      "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m11s\u001b[0m 487ms/step - accuracy: 0.9984 - loss: 0.0111 - val_accuracy: 0.5756 - val_loss: 2.4718\n",
      "Epoch 34/50\n",
      "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m11s\u001b[0m 488ms/step - accuracy: 0.9976 - loss: 0.0165 - val_accuracy: 0.4535 - val_loss: 3.1601\n",
      "Epoch 35/50\n",
      "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m11s\u001b[0m 495ms/step - accuracy: 1.0000 - loss: 0.0093 - val_accuracy: 0.5000 - val_loss: 2.7329\n",
      "Epoch 36/50\n",
      "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m11s\u001b[0m 486ms/step - accuracy: 0.9991 - loss: 0.0113 - val_accuracy: 0.4477 - val_loss: 3.9504\n",
      "Epoch 37/50\n",
      "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m11s\u001b[0m 493ms/step - accuracy: 1.0000 - loss: 0.0039 - val_accuracy: 0.5058 - val_loss: 3.2575\n",
      "Epoch 38/50\n",
      "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m11s\u001b[0m 488ms/step - accuracy: 0.9988 - loss: 0.0053 - val_accuracy: 0.4826 - val_loss: 3.3496\n",
      "Epoch 39/50\n",
      "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m21s\u001b[0m 498ms/step - accuracy: 0.9989 - loss: 0.0041 - val_accuracy: 0.4186 - val_loss: 4.3958\n",
      "Epoch 40/50\n",
      "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m11s\u001b[0m 504ms/step - accuracy: 0.9964 - loss: 0.0120 - val_accuracy: 0.5174 - val_loss: 2.4622\n",
      "Epoch 41/50\n",
      "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m11s\u001b[0m 501ms/step - accuracy: 0.9980 - loss: 0.0080 - val_accuracy: 0.4884 - val_loss: 2.9310\n",
      "Epoch 42/50\n",
      "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m11s\u001b[0m 503ms/step - accuracy: 0.9995 - loss: 0.0042 - val_accuracy: 0.4651 - val_loss: 3.6358\n",
      "Epoch 43/50\n",
      "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m11s\u001b[0m 504ms/step - accuracy: 1.0000 - loss: 0.0038 - val_accuracy: 0.4535 - val_loss: 4.1028\n",
      "Epoch 44/50\n",
      "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m11s\u001b[0m 499ms/step - accuracy: 1.0000 - loss: 0.0018 - val_accuracy: 0.5291 - val_loss: 3.6418\n",
      "Epoch 45/50\n",
      "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m11s\u001b[0m 504ms/step - accuracy: 0.9995 - loss: 0.0085 - val_accuracy: 0.5349 - val_loss: 3.0473\n",
      "Epoch 46/50\n",
      "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m11s\u001b[0m 513ms/step - accuracy: 0.9986 - loss: 0.0056 - val_accuracy: 0.4826 - val_loss: 3.2807\n",
      "Epoch 47/50\n",
      "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m11s\u001b[0m 498ms/step - accuracy: 0.9995 - loss: 0.0043 - val_accuracy: 0.5349 - val_loss: 3.3260\n",
      "Epoch 48/50\n",
      "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m11s\u001b[0m 507ms/step - accuracy: 0.9965 - loss: 0.0110 - val_accuracy: 0.4651 - val_loss: 3.1008\n",
      "Epoch 49/50\n",
      "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m11s\u001b[0m 517ms/step - accuracy: 0.9949 - loss: 0.0098 - val_accuracy: 0.4302 - val_loss: 4.0813\n",
      "Epoch 50/50\n",
      "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m11s\u001b[0m 498ms/step - accuracy: 0.9964 - loss: 0.0145 - val_accuracy: 0.4477 - val_loss: 3.1971\n",
      "\u001b[1m5/5\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 46ms/step\n",
      "CNN Accuracy: 0.5802\n",
      "CNN Classification Report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.75      0.74      0.75        62\n",
      "           1       0.45      0.36      0.40        14\n",
      "           2       0.60      0.64      0.62        53\n",
      "\n",
      "    accuracy                           0.66       129\n",
      "   macro avg       0.60      0.58      0.59       129\n",
      "weighted avg       0.66      0.66      0.66       129\n",
      "\n",
      "Epoch 1/50\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/mojo/.local/lib/python3.12/site-packages/keras/src/layers/core/dense.py:87: UserWarning: Do not pass an `input_shape`/`input_dim` argument to a layer. When using Sequential models, prefer using an `Input(shape)` object as the first layer in the model instead.\n",
      "  super().__init__(activity_regularizer=activity_regularizer, **kwargs)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 7ms/step - accuracy: 0.4996 - loss: 1.4734 - val_accuracy: 0.3372 - val_loss: 1.2777\n",
      "Epoch 2/50\n",
      "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.5699 - loss: 1.0498 - val_accuracy: 0.4302 - val_loss: 1.0283\n",
      "Epoch 3/50\n",
      "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.6315 - loss: 0.9942 - val_accuracy: 0.3895 - val_loss: 1.0183\n",
      "Epoch 4/50\n",
      "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.6265 - loss: 0.8658 - val_accuracy: 0.3605 - val_loss: 1.1277\n",
      "Epoch 5/50\n",
      "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.6588 - loss: 0.7567 - val_accuracy: 0.4070 - val_loss: 1.0718\n",
      "Epoch 6/50\n",
      "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.6859 - loss: 0.6889 - val_accuracy: 0.5465 - val_loss: 0.8748\n",
      "Epoch 7/50\n",
      "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.7050 - loss: 0.6929 - val_accuracy: 0.4360 - val_loss: 1.0807\n",
      "Epoch 8/50\n",
      "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.7732 - loss: 0.6011 - val_accuracy: 0.5174 - val_loss: 0.9872\n",
      "Epoch 9/50\n",
      "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.7888 - loss: 0.5318 - val_accuracy: 0.4767 - val_loss: 1.1495\n",
      "Epoch 10/50\n",
      "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.7791 - loss: 0.5391 - val_accuracy: 0.5291 - val_loss: 1.0846\n",
      "Epoch 11/50\n",
      "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.7652 - loss: 0.5366 - val_accuracy: 0.5233 - val_loss: 1.1755\n",
      "Epoch 12/50\n",
      "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.8315 - loss: 0.4842 - val_accuracy: 0.5814 - val_loss: 1.0608\n",
      "Epoch 13/50\n",
      "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.8180 - loss: 0.4018 - val_accuracy: 0.5465 - val_loss: 1.1589\n",
      "Epoch 14/50\n",
      "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.8493 - loss: 0.3366 - val_accuracy: 0.5581 - val_loss: 1.2809\n",
      "Epoch 15/50\n",
      "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.8544 - loss: 0.3897 - val_accuracy: 0.5174 - val_loss: 1.3831\n",
      "Epoch 16/50\n",
      "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.8489 - loss: 0.4253 - val_accuracy: 0.5872 - val_loss: 1.1730\n",
      "Epoch 17/50\n",
      "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.8680 - loss: 0.3118 - val_accuracy: 0.5640 - val_loss: 1.3103\n",
      "Epoch 18/50\n",
      "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.9110 - loss: 0.2527 - val_accuracy: 0.4942 - val_loss: 1.5749\n",
      "Epoch 19/50\n",
      "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.9069 - loss: 0.2503 - val_accuracy: 0.5233 - val_loss: 1.5028\n",
      "Epoch 20/50\n",
      "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.9274 - loss: 0.2229 - val_accuracy: 0.5291 - val_loss: 1.6412\n",
      "Epoch 21/50\n",
      "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.9147 - loss: 0.2388 - val_accuracy: 0.5058 - val_loss: 1.7029\n",
      "Epoch 22/50\n",
      "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.8960 - loss: 0.2765 - val_accuracy: 0.5988 - val_loss: 1.3881\n",
      "Epoch 23/50\n",
      "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.9065 - loss: 0.2466 - val_accuracy: 0.5058 - val_loss: 1.7378\n",
      "Epoch 24/50\n",
      "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - accuracy: 0.9251 - loss: 0.2273 - val_accuracy: 0.5407 - val_loss: 1.4763\n",
      "Epoch 25/50\n",
      "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.9324 - loss: 0.2338 - val_accuracy: 0.5000 - val_loss: 1.7796\n",
      "Epoch 26/50\n",
      "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.9332 - loss: 0.1831 - val_accuracy: 0.5116 - val_loss: 1.7834\n",
      "Epoch 27/50\n",
      "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.9317 - loss: 0.2074 - val_accuracy: 0.5058 - val_loss: 1.9997\n",
      "Epoch 28/50\n",
      "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.9596 - loss: 0.1243 - val_accuracy: 0.5058 - val_loss: 1.9301\n",
      "Epoch 29/50\n",
      "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.9380 - loss: 0.1778 - val_accuracy: 0.5000 - val_loss: 1.8730\n",
      "Epoch 30/50\n",
      "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.9512 - loss: 0.1886 - val_accuracy: 0.5698 - val_loss: 1.6219\n",
      "Epoch 31/50\n",
      "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.9268 - loss: 0.2147 - val_accuracy: 0.5233 - val_loss: 1.8987\n",
      "Epoch 32/50\n",
      "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.9459 - loss: 0.1268 - val_accuracy: 0.6047 - val_loss: 1.5394\n",
      "Epoch 33/50\n",
      "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.9577 - loss: 0.1473 - val_accuracy: 0.5058 - val_loss: 1.9980\n",
      "Epoch 34/50\n",
      "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.9440 - loss: 0.1852 - val_accuracy: 0.5407 - val_loss: 2.2520\n",
      "Epoch 35/50\n",
      "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.9564 - loss: 0.1403 - val_accuracy: 0.5000 - val_loss: 2.3333\n",
      "Epoch 36/50\n",
      "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.9678 - loss: 0.0903 - val_accuracy: 0.5640 - val_loss: 1.8441\n",
      "Epoch 37/50\n",
      "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.9539 - loss: 0.1387 - val_accuracy: 0.4360 - val_loss: 2.6260\n",
      "Epoch 38/50\n",
      "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.9642 - loss: 0.0957 - val_accuracy: 0.5523 - val_loss: 1.9190\n",
      "Epoch 39/50\n",
      "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.9646 - loss: 0.0934 - val_accuracy: 0.5000 - val_loss: 2.2644\n",
      "Epoch 40/50\n",
      "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.9656 - loss: 0.0939 - val_accuracy: 0.5640 - val_loss: 2.1124\n",
      "Epoch 41/50\n",
      "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.9645 - loss: 0.1057 - val_accuracy: 0.4651 - val_loss: 2.7432\n",
      "Epoch 42/50\n",
      "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.9763 - loss: 0.0703 - val_accuracy: 0.5233 - val_loss: 2.3393\n",
      "Epoch 43/50\n",
      "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.9678 - loss: 0.1185 - val_accuracy: 0.4767 - val_loss: 2.6865\n",
      "Epoch 44/50\n",
      "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.9804 - loss: 0.0439 - val_accuracy: 0.5116 - val_loss: 2.5454\n",
      "Epoch 45/50\n",
      "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.9839 - loss: 0.0593 - val_accuracy: 0.5000 - val_loss: 2.6682\n",
      "Epoch 46/50\n",
      "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.9841 - loss: 0.0498 - val_accuracy: 0.5058 - val_loss: 2.8816\n",
      "Epoch 47/50\n",
      "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.9753 - loss: 0.0711 - val_accuracy: 0.5233 - val_loss: 2.7436\n",
      "Epoch 48/50\n",
      "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.9754 - loss: 0.0661 - val_accuracy: 0.5174 - val_loss: 2.2271\n",
      "Epoch 49/50\n",
      "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.9782 - loss: 0.0756 - val_accuracy: 0.5349 - val_loss: 2.3713\n",
      "Epoch 50/50\n",
      "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.9723 - loss: 0.0759 - val_accuracy: 0.5058 - val_loss: 2.8852\n",
      "\u001b[1m5/5\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step \n",
      "ANN Accuracy: 0.6013\n",
      "ANN Classification Report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.77      0.79      0.78        62\n",
      "           1       0.38      0.43      0.40        14\n",
      "           2       0.63      0.58      0.61        53\n",
      "\n",
      "    accuracy                           0.67       129\n",
      "   macro avg       0.59      0.60      0.60       129\n",
      "weighted avg       0.67      0.67      0.67       129\n",
      "\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "from sklearn.preprocessing import LabelEncoder\n",
    "from sklearn.svm import SVC\n",
    "from sklearn.metrics import balanced_accuracy_score, classification_report\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "\n",
    "# Load the data\n",
    "train_data = np.load('../Files/extracted_features/layer_features_lv60_self/train_14.npz')\n",
    "test_data = np.load('../Files/extracted_features/layer_features_lv60_self/test_14.npz')\n",
    "\n",
    "train_features = train_data['features']  # Ensure these have 1024 features\n",
    "test_features = test_data['features']    # Ensure these have 1024 features\n",
    "\n",
    "# Read Age labels instead of Gender\n",
    "train_labels = pd.read_csv('../Files/labels/y_train.csv').Age_Group\n",
    "test_labels = pd.read_csv('../Files/labels/y_test.csv').Age_Group\n",
    "\n",
    "# Encode the labels\n",
    "label_encoder = LabelEncoder()\n",
    "train_labels_encoded = label_encoder.fit_transform(train_labels)\n",
    "\n",
    "# Handle unseen labels in test set by filtering out labels not present in train set\n",
    "test_labels_filtered = test_labels[test_labels.isin(train_labels.unique())]\n",
    "test_features_filtered = test_features[test_labels.isin(train_labels.unique())]\n",
    "test_labels_encoded = label_encoder.transform(test_labels_filtered)\n",
    "\n",
    "# Standardize features\n",
    "scaler = StandardScaler()\n",
    "train_features_normalized = scaler.fit_transform(train_features)\n",
    "test_features_normalized = scaler.transform(test_features_filtered)\n",
    "\n",
    "# SVM model\n",
    "svm_model = SVC(kernel='linear', C=10.0, gamma='scale', random_state=42)\n",
    "svm_model.fit(train_features_normalized, train_labels_encoded)\n",
    "\n",
    "# SVM Prediction and Evaluation\n",
    "svm_predictions = svm_model.predict(test_features_normalized)\n",
    "svm_accuracy = balanced_accuracy_score(test_labels_encoded, svm_predictions)\n",
    "print(f\"SVM Accuracy: {svm_accuracy:.4f}\")\n",
    "print(\"SVM Classification Report:\")\n",
    "print(classification_report(test_labels_encoded, svm_predictions))\n",
    "\n",
    "# CNN model (TensorFlow)\n",
    "import tensorflow as tf\n",
    "from tensorflow.keras.models import Sequential\n",
    "from tensorflow.keras.layers import Conv1D, Flatten, Dense, Dropout\n",
    "\n",
    "train_features_cnn = np.expand_dims(train_features_normalized, axis=-1)  # Shape: (num_samples, 1024, 1)\n",
    "test_features_cnn = np.expand_dims(test_features_normalized, axis=-1)    # Shape: (num_samples, 1024, 1)\n",
    "\n",
    "cnn_model = Sequential([\n",
    "    Conv1D(64, kernel_size=5, activation='relu', input_shape=(1024, 1)),  # Updated input shape to 1024\n",
    "    Conv1D(128, kernel_size=5, activation='relu'),\n",
    "    Conv1D(256, kernel_size=5, activation='relu'),\n",
    "    Flatten(),\n",
    "    Dense(256, activation='relu'),\n",
    "    Dropout(0.5),\n",
    "    Dense(len(label_encoder.classes_), activation='softmax')\n",
    "])\n",
    "\n",
    "cnn_model.compile(optimizer='adam', loss='sparse_categorical_crossentropy', metrics=['accuracy'])\n",
    "\n",
    "cnn_model.fit(train_features_cnn, train_labels_encoded, epochs=50, batch_size=32, validation_split=0.2)\n",
    "\n",
    "# CNN Prediction and Evaluation\n",
    "cnn_predictions = np.argmax(cnn_model.predict(test_features_cnn), axis=-1)\n",
    "cnn_accuracy = balanced_accuracy_score(test_labels_encoded, cnn_predictions)\n",
    "print(f\"CNN Accuracy: {cnn_accuracy:.4f}\")\n",
    "print(\"CNN Classification Report:\")\n",
    "print(classification_report(test_labels_encoded, cnn_predictions))\n",
    "\n",
    "# ANN model (TensorFlow)\n",
    "ann_model = Sequential([\n",
    "    Dense(512, activation='relu', input_shape=(1024,)),  # Updated input shape to 1024\n",
    "    Dropout(0.5),\n",
    "    Dense(256, activation='relu'),\n",
    "    Dropout(0.5),\n",
    "    Dense(128, activation='relu'),\n",
    "    Dropout(0.5),\n",
    "    Dense(len(label_encoder.classes_), activation='softmax')\n",
    "])\n",
    "\n",
    "ann_model.compile(optimizer='adam', loss='sparse_categorical_crossentropy', metrics=['accuracy'])\n",
    "\n",
    "ann_model.fit(train_features_normalized, train_labels_encoded, epochs=50, batch_size=32, validation_split=0.2)\n",
    "\n",
    "# ANN Prediction and Evaluation\n",
    "ann_predictions = np.argmax(ann_model.predict(test_features_normalized), axis=-1)\n",
    "ann_accuracy = balanced_accuracy_score(test_labels_encoded, ann_predictions)\n",
    "print(f\"ANN Accuracy: {ann_accuracy:.4f}\")\n",
    "print(\"ANN Classification Report:\")\n",
    "print(classification_report(test_labels_encoded, ann_predictions))\n",
    "\n",
    "# PyTorch CNN Model\n",
    "import torch\n",
    "from torch.utils.data import DataLoader, TensorDataset\n",
    "\n",
    "X_train_tensor = torch.tensor(train_features_cnn, dtype=torch.float32).permute(0, 2, 1)  # Shape: (num_samples, 1, 1024)\n",
    "y_train_tensor = torch.tensor(train_labels_encoded, dtype=torch.long)\n",
    "X_test_tensor = torch.tensor(test_features_cnn, dtype=torch.float32).permute(0, 2, 1)    # Shape: (num_samples, 1, 1024)\n",
    "y_test_tensor = torch.tensor(test_labels_encoded, dtype=torch.long)\n",
    "\n",
    "train_dataset = TensorDataset(X_train_tensor, y_train_tensor)\n",
    "test_dataset = TensorDataset(X_test_tensor, y_test_tensor)\n",
    "\n",
    "train_loader = DataLoader(train_dataset, batch_size=64, shuffle=True)\n",
    "test_loader = DataLoader(test_dataset, batch_size=64, shuffle=False)\n",
    "\n",
    "import torch.nn as nn\n",
    "import torch.optim as optim\n",
    "\n",
    "class CNN1DModel(nn.Module):\n",
    "    def __init__(self, input_channels, num_classes):\n",
    "        super(CNN1DModel, self).__init__()\n",
    "        self.conv1 = nn.Conv1d(input_channels, 32, kernel_size=5, stride=1, padding=2)\n",
    "        self.bn1 = nn.BatchNorm1d(32)\n",
    "        self.relu = nn.ReLU()\n",
    "        self.conv2 = nn.Conv1d(32, 64, kernel_size=5, stride=1, padding=2)\n",
    "        self.bn2 = nn.BatchNorm1d(64)\n",
    "        self.conv3 = nn.Conv1d(64, 128, kernel_size=5, stride=1, padding=2)\n",
    "        self.bn3 = nn.BatchNorm1d(128)\n",
    "        self.flatten = nn.Flatten()\n",
    "        self.fc1 = nn.Linear(128 * 1024, 512)  # Updated to 1024 features\n",
    "        self.fc2 = nn.Linear(512, num_classes)\n",
    "        self.dropout = nn.Dropout(0.5)\n",
    "    \n",
    "    def forward(self, x):\n",
    "        x = self.relu(self.bn1(self.conv1(x)))\n",
    "        x = self.relu(self.bn2(self.conv2(x)))\n",
    "        x = self.relu(self.bn3(self.conv3(x)))\n",
    "        x = self.flatten(x)\n",
    "        x = self.dropout(self.relu(self.fc1(x)))\n",
    "        x = self.fc2(x)\n",
    "        return x\n",
    "\n",
    "input_channels = 1\n",
    "num_classes = len(label_encoder.classes_)\n",
    "model = CNN1DModel(input_channels, num_classes)\n",
    "criterion = nn.CrossEntropyLoss()\n",
    "optimizer = optim.Adam(model.parameters(), lr=0.001)\n",
    "\n",
    "# Training loop and evaluation (not shown)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "SVM Accuracy: 0.6188\n",
      "SVM Classification Report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.87      0.73      0.79        62\n",
      "           1       0.45      0.36      0.40        14\n",
      "           2       0.62      0.77      0.69        53\n",
      "\n",
      "    accuracy                           0.71       129\n",
      "   macro avg       0.65      0.62      0.63       129\n",
      "weighted avg       0.72      0.71      0.71       129\n",
      "\n",
      "Epoch 1/50\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/mojo/.local/lib/python3.12/site-packages/keras/src/layers/convolutional/base_conv.py:107: UserWarning: Do not pass an `input_shape`/`input_dim` argument to a layer. When using Sequential models, prefer using an `Input(shape)` object as the first layer in the model instead.\n",
      "  super().__init__(activity_regularizer=activity_regularizer, **kwargs)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m12s\u001b[0m 479ms/step - accuracy: 0.4831 - loss: 3.4142 - val_accuracy: 0.0465 - val_loss: 1.5135\n",
      "Epoch 2/50\n",
      "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m10s\u001b[0m 470ms/step - accuracy: 0.6348 - loss: 0.7776 - val_accuracy: 0.2093 - val_loss: 1.2269\n",
      "Epoch 3/50\n",
      "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m10s\u001b[0m 472ms/step - accuracy: 0.7534 - loss: 0.5944 - val_accuracy: 0.4942 - val_loss: 1.0395\n",
      "Epoch 4/50\n",
      "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m10s\u001b[0m 469ms/step - accuracy: 0.8037 - loss: 0.4831 - val_accuracy: 0.5930 - val_loss: 0.8509\n",
      "Epoch 5/50\n",
      "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m10s\u001b[0m 467ms/step - accuracy: 0.8658 - loss: 0.4045 - val_accuracy: 0.5872 - val_loss: 0.9095\n",
      "Epoch 6/50\n",
      "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m10s\u001b[0m 468ms/step - accuracy: 0.9236 - loss: 0.2562 - val_accuracy: 0.4360 - val_loss: 1.6492\n",
      "Epoch 7/50\n",
      "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m10s\u001b[0m 471ms/step - accuracy: 0.9283 - loss: 0.1926 - val_accuracy: 0.6919 - val_loss: 0.9581\n",
      "Epoch 8/50\n",
      "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m10s\u001b[0m 467ms/step - accuracy: 0.9477 - loss: 0.1513 - val_accuracy: 0.5698 - val_loss: 1.4219\n",
      "Epoch 9/50\n",
      "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m11s\u001b[0m 483ms/step - accuracy: 0.9779 - loss: 0.0856 - val_accuracy: 0.4070 - val_loss: 2.3739\n",
      "Epoch 10/50\n",
      "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m11s\u001b[0m 495ms/step - accuracy: 0.9744 - loss: 0.0951 - val_accuracy: 0.5116 - val_loss: 1.8579\n",
      "Epoch 11/50\n",
      "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m11s\u001b[0m 491ms/step - accuracy: 0.9806 - loss: 0.0562 - val_accuracy: 0.5407 - val_loss: 2.0232\n",
      "Epoch 12/50\n",
      "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m11s\u001b[0m 488ms/step - accuracy: 0.9885 - loss: 0.0475 - val_accuracy: 0.5233 - val_loss: 2.3852\n",
      "Epoch 13/50\n",
      "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m11s\u001b[0m 479ms/step - accuracy: 0.9826 - loss: 0.0429 - val_accuracy: 0.5233 - val_loss: 2.0638\n",
      "Epoch 14/50\n",
      "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m10s\u001b[0m 475ms/step - accuracy: 0.9899 - loss: 0.0447 - val_accuracy: 0.5523 - val_loss: 2.2322\n",
      "Epoch 15/50\n",
      "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m11s\u001b[0m 480ms/step - accuracy: 0.9977 - loss: 0.0234 - val_accuracy: 0.5756 - val_loss: 1.8326\n",
      "Epoch 16/50\n",
      "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m11s\u001b[0m 482ms/step - accuracy: 1.0000 - loss: 0.0092 - val_accuracy: 0.5233 - val_loss: 2.8621\n",
      "Epoch 17/50\n",
      "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m11s\u001b[0m 487ms/step - accuracy: 0.9992 - loss: 0.0067 - val_accuracy: 0.4767 - val_loss: 3.6945\n",
      "Epoch 18/50\n",
      "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m11s\u001b[0m 482ms/step - accuracy: 0.9982 - loss: 0.0152 - val_accuracy: 0.5465 - val_loss: 2.6187\n",
      "Epoch 19/50\n",
      "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m10s\u001b[0m 473ms/step - accuracy: 0.9934 - loss: 0.0231 - val_accuracy: 0.5698 - val_loss: 2.1929\n",
      "Epoch 20/50\n",
      "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m11s\u001b[0m 501ms/step - accuracy: 0.9950 - loss: 0.0186 - val_accuracy: 0.5698 - val_loss: 2.4470\n",
      "Epoch 21/50\n",
      "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m11s\u001b[0m 489ms/step - accuracy: 0.9948 - loss: 0.0183 - val_accuracy: 0.4651 - val_loss: 2.9929\n",
      "Epoch 22/50\n",
      "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m11s\u001b[0m 501ms/step - accuracy: 0.9961 - loss: 0.0172 - val_accuracy: 0.6047 - val_loss: 1.8818\n",
      "Epoch 23/50\n",
      "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m11s\u001b[0m 487ms/step - accuracy: 0.9962 - loss: 0.0159 - val_accuracy: 0.4942 - val_loss: 3.3903\n",
      "Epoch 24/50\n",
      "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m11s\u001b[0m 489ms/step - accuracy: 0.9933 - loss: 0.0179 - val_accuracy: 0.5872 - val_loss: 2.3185\n",
      "Epoch 25/50\n",
      "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m11s\u001b[0m 497ms/step - accuracy: 0.9931 - loss: 0.0153 - val_accuracy: 0.6686 - val_loss: 1.6597\n",
      "Epoch 26/50\n",
      "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m11s\u001b[0m 481ms/step - accuracy: 0.9935 - loss: 0.0209 - val_accuracy: 0.5116 - val_loss: 2.8934\n",
      "Epoch 27/50\n",
      "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m11s\u001b[0m 490ms/step - accuracy: 0.9998 - loss: 0.0062 - val_accuracy: 0.5058 - val_loss: 3.1495\n",
      "Epoch 28/50\n",
      "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m11s\u001b[0m 489ms/step - accuracy: 0.9951 - loss: 0.0081 - val_accuracy: 0.5233 - val_loss: 3.1423\n",
      "Epoch 29/50\n",
      "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m11s\u001b[0m 481ms/step - accuracy: 0.9995 - loss: 0.0029 - val_accuracy: 0.5349 - val_loss: 3.2322\n",
      "Epoch 30/50\n",
      "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m11s\u001b[0m 505ms/step - accuracy: 0.9995 - loss: 0.0092 - val_accuracy: 0.5814 - val_loss: 2.3498\n",
      "Epoch 31/50\n",
      "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m11s\u001b[0m 491ms/step - accuracy: 0.9957 - loss: 0.0184 - val_accuracy: 0.6279 - val_loss: 1.5368\n",
      "Epoch 32/50\n",
      "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m11s\u001b[0m 505ms/step - accuracy: 0.9920 - loss: 0.0488 - val_accuracy: 0.5523 - val_loss: 2.5566\n",
      "Epoch 33/50\n",
      "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m11s\u001b[0m 495ms/step - accuracy: 0.9980 - loss: 0.0130 - val_accuracy: 0.4942 - val_loss: 3.7491\n",
      "Epoch 34/50\n",
      "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m11s\u001b[0m 491ms/step - accuracy: 0.9956 - loss: 0.0246 - val_accuracy: 0.5465 - val_loss: 2.6998\n",
      "Epoch 35/50\n",
      "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m11s\u001b[0m 488ms/step - accuracy: 0.9994 - loss: 0.0072 - val_accuracy: 0.5640 - val_loss: 2.8167\n",
      "Epoch 36/50\n",
      "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m11s\u001b[0m 488ms/step - accuracy: 1.0000 - loss: 0.0031 - val_accuracy: 0.5000 - val_loss: 3.9882\n",
      "Epoch 37/50\n",
      "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m11s\u001b[0m 486ms/step - accuracy: 1.0000 - loss: 0.0013 - val_accuracy: 0.4767 - val_loss: 4.6583\n",
      "Epoch 38/50\n",
      "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m11s\u001b[0m 489ms/step - accuracy: 0.9994 - loss: 0.0020 - val_accuracy: 0.5233 - val_loss: 4.0061\n",
      "Epoch 39/50\n",
      "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m11s\u001b[0m 487ms/step - accuracy: 0.9977 - loss: 0.0038 - val_accuracy: 0.4593 - val_loss: 4.6484\n",
      "Epoch 40/50\n",
      "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m11s\u001b[0m 492ms/step - accuracy: 0.9985 - loss: 0.0072 - val_accuracy: 0.5349 - val_loss: 3.6246\n",
      "Epoch 41/50\n",
      "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m11s\u001b[0m 495ms/step - accuracy: 0.9953 - loss: 0.0115 - val_accuracy: 0.4942 - val_loss: 3.4256\n",
      "Epoch 42/50\n",
      "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m11s\u001b[0m 499ms/step - accuracy: 0.9976 - loss: 0.0112 - val_accuracy: 0.5698 - val_loss: 2.8370\n",
      "Epoch 43/50\n",
      "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m11s\u001b[0m 498ms/step - accuracy: 1.0000 - loss: 0.0048 - val_accuracy: 0.5523 - val_loss: 3.1901\n",
      "Epoch 44/50\n",
      "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m11s\u001b[0m 500ms/step - accuracy: 0.9993 - loss: 0.0034 - val_accuracy: 0.4826 - val_loss: 4.1243\n",
      "Epoch 45/50\n",
      "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m11s\u001b[0m 482ms/step - accuracy: 0.9978 - loss: 0.0053 - val_accuracy: 0.5116 - val_loss: 4.3733\n",
      "Epoch 46/50\n",
      "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m11s\u001b[0m 482ms/step - accuracy: 0.9947 - loss: 0.0073 - val_accuracy: 0.5581 - val_loss: 2.9031\n",
      "Epoch 47/50\n",
      "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m11s\u001b[0m 480ms/step - accuracy: 0.9956 - loss: 0.0087 - val_accuracy: 0.4651 - val_loss: 4.1643\n",
      "Epoch 48/50\n",
      "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m11s\u001b[0m 479ms/step - accuracy: 0.9977 - loss: 0.0051 - val_accuracy: 0.5698 - val_loss: 3.0594\n",
      "Epoch 49/50\n",
      "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m11s\u001b[0m 481ms/step - accuracy: 0.9992 - loss: 0.0030 - val_accuracy: 0.4942 - val_loss: 4.9446\n",
      "Epoch 50/50\n",
      "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m11s\u001b[0m 495ms/step - accuracy: 0.9939 - loss: 0.0148 - val_accuracy: 0.5872 - val_loss: 3.2196\n",
      "WARNING:tensorflow:5 out of the last 11 calls to <function TensorFlowTrainer.make_predict_function.<locals>.one_step_on_data_distributed at 0x75e664d5e660> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has reduce_retracing=True option that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/guide/function#controlling_retracing and https://www.tensorflow.org/api_docs/python/tf/function for  more details.\n",
      "\u001b[1m4/5\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━━━\u001b[0m \u001b[1m0s\u001b[0m 48ms/stepWARNING:tensorflow:5 out of the last 11 calls to <function TensorFlowTrainer.make_predict_function.<locals>.one_step_on_data_distributed at 0x75e664d5e660> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has reduce_retracing=True option that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/guide/function#controlling_retracing and https://www.tensorflow.org/api_docs/python/tf/function for  more details.\n",
      "\u001b[1m5/5\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 59ms/step\n",
      "CNN Accuracy: 0.6252\n",
      "CNN Classification Report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.79      0.68      0.73        62\n",
      "           1       0.39      0.50      0.44        14\n",
      "           2       0.64      0.70      0.67        53\n",
      "\n",
      "    accuracy                           0.67       129\n",
      "   macro avg       0.61      0.63      0.61       129\n",
      "weighted avg       0.69      0.67      0.67       129\n",
      "\n",
      "Epoch 1/50\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/mojo/.local/lib/python3.12/site-packages/keras/src/layers/core/dense.py:87: UserWarning: Do not pass an `input_shape`/`input_dim` argument to a layer. When using Sequential models, prefer using an `Input(shape)` object as the first layer in the model instead.\n",
      "  super().__init__(activity_regularizer=activity_regularizer, **kwargs)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 7ms/step - accuracy: 0.4671 - loss: 1.7523 - val_accuracy: 0.3198 - val_loss: 1.3169\n",
      "Epoch 2/50\n",
      "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.6046 - loss: 1.0809 - val_accuracy: 0.4826 - val_loss: 1.0114\n",
      "Epoch 3/50\n",
      "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.6135 - loss: 0.9708 - val_accuracy: 0.4419 - val_loss: 0.9844\n",
      "Epoch 4/50\n",
      "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.6575 - loss: 0.8571 - val_accuracy: 0.4709 - val_loss: 1.0697\n",
      "Epoch 5/50\n",
      "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.6404 - loss: 0.8376 - val_accuracy: 0.4826 - val_loss: 1.0246\n",
      "Epoch 6/50\n",
      "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.6729 - loss: 0.7016 - val_accuracy: 0.3605 - val_loss: 1.2131\n",
      "Epoch 7/50\n",
      "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.7020 - loss: 0.7070 - val_accuracy: 0.5233 - val_loss: 1.0304\n",
      "Epoch 8/50\n",
      "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.7572 - loss: 0.6192 - val_accuracy: 0.4709 - val_loss: 1.1178\n",
      "Epoch 9/50\n",
      "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.7441 - loss: 0.6205 - val_accuracy: 0.4128 - val_loss: 1.2480\n",
      "Epoch 10/50\n",
      "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.7823 - loss: 0.5696 - val_accuracy: 0.5000 - val_loss: 1.0898\n",
      "Epoch 11/50\n",
      "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.7887 - loss: 0.4603 - val_accuracy: 0.5581 - val_loss: 1.0915\n",
      "Epoch 12/50\n",
      "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.7558 - loss: 0.5479 - val_accuracy: 0.5523 - val_loss: 1.2300\n",
      "Epoch 13/50\n",
      "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.8190 - loss: 0.4378 - val_accuracy: 0.5233 - val_loss: 1.2903\n",
      "Epoch 14/50\n",
      "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.8136 - loss: 0.4578 - val_accuracy: 0.4593 - val_loss: 1.4587\n",
      "Epoch 15/50\n",
      "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.8446 - loss: 0.3980 - val_accuracy: 0.5872 - val_loss: 1.0631\n",
      "Epoch 16/50\n",
      "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.8653 - loss: 0.3593 - val_accuracy: 0.5174 - val_loss: 1.1666\n",
      "Epoch 17/50\n",
      "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.8408 - loss: 0.3549 - val_accuracy: 0.5407 - val_loss: 1.1384\n",
      "Epoch 18/50\n",
      "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.8656 - loss: 0.3316 - val_accuracy: 0.4302 - val_loss: 1.5810\n",
      "Epoch 19/50\n",
      "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.8910 - loss: 0.2993 - val_accuracy: 0.5407 - val_loss: 1.3080\n",
      "Epoch 20/50\n",
      "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.8869 - loss: 0.2697 - val_accuracy: 0.5465 - val_loss: 1.4954\n",
      "Epoch 21/50\n",
      "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.9107 - loss: 0.2797 - val_accuracy: 0.4942 - val_loss: 1.4849\n",
      "Epoch 22/50\n",
      "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.8807 - loss: 0.3049 - val_accuracy: 0.5000 - val_loss: 1.4570\n",
      "Epoch 23/50\n",
      "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.9402 - loss: 0.1841 - val_accuracy: 0.4942 - val_loss: 1.7216\n",
      "Epoch 24/50\n",
      "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.9358 - loss: 0.1683 - val_accuracy: 0.5581 - val_loss: 1.7070\n",
      "Epoch 25/50\n",
      "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.9173 - loss: 0.2092 - val_accuracy: 0.4826 - val_loss: 1.6688\n",
      "Epoch 26/50\n",
      "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.9304 - loss: 0.1825 - val_accuracy: 0.5523 - val_loss: 1.5647\n",
      "Epoch 27/50\n",
      "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.9298 - loss: 0.1638 - val_accuracy: 0.4942 - val_loss: 1.8737\n",
      "Epoch 28/50\n",
      "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.9254 - loss: 0.2218 - val_accuracy: 0.5698 - val_loss: 1.4402\n",
      "Epoch 29/50\n",
      "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.9269 - loss: 0.1832 - val_accuracy: 0.5988 - val_loss: 1.6616\n",
      "Epoch 30/50\n",
      "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.9423 - loss: 0.1601 - val_accuracy: 0.5349 - val_loss: 1.8838\n",
      "Epoch 31/50\n",
      "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.9600 - loss: 0.1179 - val_accuracy: 0.5000 - val_loss: 1.8305\n",
      "Epoch 32/50\n",
      "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.9523 - loss: 0.1349 - val_accuracy: 0.5523 - val_loss: 1.5401\n",
      "Epoch 33/50\n",
      "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.9512 - loss: 0.1764 - val_accuracy: 0.5000 - val_loss: 2.0399\n",
      "Epoch 34/50\n",
      "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.9632 - loss: 0.1155 - val_accuracy: 0.5291 - val_loss: 1.7910\n",
      "Epoch 35/50\n",
      "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.9495 - loss: 0.1538 - val_accuracy: 0.4942 - val_loss: 1.7604\n",
      "Epoch 36/50\n",
      "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.9671 - loss: 0.1006 - val_accuracy: 0.5640 - val_loss: 1.7859\n",
      "Epoch 37/50\n",
      "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.9449 - loss: 0.1300 - val_accuracy: 0.5116 - val_loss: 2.1792\n",
      "Epoch 38/50\n",
      "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.9683 - loss: 0.1146 - val_accuracy: 0.5291 - val_loss: 1.9465\n",
      "Epoch 39/50\n",
      "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.9661 - loss: 0.0951 - val_accuracy: 0.4884 - val_loss: 2.3485\n",
      "Epoch 40/50\n",
      "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.9804 - loss: 0.0779 - val_accuracy: 0.5000 - val_loss: 2.5922\n",
      "Epoch 41/50\n",
      "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.9605 - loss: 0.0986 - val_accuracy: 0.5465 - val_loss: 2.3726\n",
      "Epoch 42/50\n",
      "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.9713 - loss: 0.1671 - val_accuracy: 0.5349 - val_loss: 1.9261\n",
      "Epoch 43/50\n",
      "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.9518 - loss: 0.1093 - val_accuracy: 0.4884 - val_loss: 2.2052\n",
      "Epoch 44/50\n",
      "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.9526 - loss: 0.1497 - val_accuracy: 0.5058 - val_loss: 2.5565\n",
      "Epoch 45/50\n",
      "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.9456 - loss: 0.1780 - val_accuracy: 0.5116 - val_loss: 2.3149\n",
      "Epoch 46/50\n",
      "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.9510 - loss: 0.1075 - val_accuracy: 0.5233 - val_loss: 2.3632\n",
      "Epoch 47/50\n",
      "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.9713 - loss: 0.0767 - val_accuracy: 0.5174 - val_loss: 2.2309\n",
      "Epoch 48/50\n",
      "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.9731 - loss: 0.1127 - val_accuracy: 0.4884 - val_loss: 2.2969\n",
      "Epoch 49/50\n",
      "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.9685 - loss: 0.0807 - val_accuracy: 0.5058 - val_loss: 2.4686\n",
      "Epoch 50/50\n",
      "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.9811 - loss: 0.0625 - val_accuracy: 0.5523 - val_loss: 2.5929\n",
      "\u001b[1m5/5\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step \n",
      "ANN Accuracy: 0.6287\n",
      "ANN Classification Report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.86      0.77      0.81        62\n",
      "           1       0.42      0.36      0.38        14\n",
      "           2       0.66      0.75      0.70        53\n",
      "\n",
      "    accuracy                           0.72       129\n",
      "   macro avg       0.64      0.63      0.63       129\n",
      "weighted avg       0.73      0.72      0.72       129\n",
      "\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "from sklearn.preprocessing import LabelEncoder\n",
    "from sklearn.svm import SVC\n",
    "from sklearn.metrics import balanced_accuracy_score, classification_report\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "\n",
    "# Load the data\n",
    "train_data = np.load('../Files/extracted_features/layer_features_lv60_self/train_15.npz')\n",
    "test_data = np.load('../Files/extracted_features/layer_features_lv60_self/test_15.npz')\n",
    "\n",
    "train_features = train_data['features']  # Ensure these have 1024 features\n",
    "test_features = test_data['features']    # Ensure these have 1024 features\n",
    "\n",
    "# Read Age labels instead of Gender\n",
    "train_labels = pd.read_csv('../Files/labels/y_train.csv').Age_Group\n",
    "test_labels = pd.read_csv('../Files/labels/y_test.csv').Age_Group\n",
    "\n",
    "# Encode the labels\n",
    "label_encoder = LabelEncoder()\n",
    "train_labels_encoded = label_encoder.fit_transform(train_labels)\n",
    "\n",
    "# Handle unseen labels in test set by filtering out labels not present in train set\n",
    "test_labels_filtered = test_labels[test_labels.isin(train_labels.unique())]\n",
    "test_features_filtered = test_features[test_labels.isin(train_labels.unique())]\n",
    "test_labels_encoded = label_encoder.transform(test_labels_filtered)\n",
    "\n",
    "# Standardize features\n",
    "scaler = StandardScaler()\n",
    "train_features_normalized = scaler.fit_transform(train_features)\n",
    "test_features_normalized = scaler.transform(test_features_filtered)\n",
    "\n",
    "# SVM model\n",
    "svm_model = SVC(kernel='linear', C=10.0, gamma='scale', random_state=42)\n",
    "svm_model.fit(train_features_normalized, train_labels_encoded)\n",
    "\n",
    "# SVM Prediction and Evaluation\n",
    "svm_predictions = svm_model.predict(test_features_normalized)\n",
    "svm_accuracy = balanced_accuracy_score(test_labels_encoded, svm_predictions)\n",
    "print(f\"SVM Accuracy: {svm_accuracy:.4f}\")\n",
    "print(\"SVM Classification Report:\")\n",
    "print(classification_report(test_labels_encoded, svm_predictions))\n",
    "\n",
    "# CNN model (TensorFlow)\n",
    "import tensorflow as tf\n",
    "from tensorflow.keras.models import Sequential\n",
    "from tensorflow.keras.layers import Conv1D, Flatten, Dense, Dropout\n",
    "\n",
    "train_features_cnn = np.expand_dims(train_features_normalized, axis=-1)  # Shape: (num_samples, 1024, 1)\n",
    "test_features_cnn = np.expand_dims(test_features_normalized, axis=-1)    # Shape: (num_samples, 1024, 1)\n",
    "\n",
    "cnn_model = Sequential([\n",
    "    Conv1D(64, kernel_size=5, activation='relu', input_shape=(1024, 1)),  # Updated input shape to 1024\n",
    "    Conv1D(128, kernel_size=5, activation='relu'),\n",
    "    Conv1D(256, kernel_size=5, activation='relu'),\n",
    "    Flatten(),\n",
    "    Dense(256, activation='relu'),\n",
    "    Dropout(0.5),\n",
    "    Dense(len(label_encoder.classes_), activation='softmax')\n",
    "])\n",
    "\n",
    "cnn_model.compile(optimizer='adam', loss='sparse_categorical_crossentropy', metrics=['accuracy'])\n",
    "\n",
    "cnn_model.fit(train_features_cnn, train_labels_encoded, epochs=50, batch_size=32, validation_split=0.2)\n",
    "\n",
    "# CNN Prediction and Evaluation\n",
    "cnn_predictions = np.argmax(cnn_model.predict(test_features_cnn), axis=-1)\n",
    "cnn_accuracy = balanced_accuracy_score(test_labels_encoded, cnn_predictions)\n",
    "print(f\"CNN Accuracy: {cnn_accuracy:.4f}\")\n",
    "print(\"CNN Classification Report:\")\n",
    "print(classification_report(test_labels_encoded, cnn_predictions))\n",
    "\n",
    "# ANN model (TensorFlow)\n",
    "ann_model = Sequential([\n",
    "    Dense(512, activation='relu', input_shape=(1024,)),  # Updated input shape to 1024\n",
    "    Dropout(0.5),\n",
    "    Dense(256, activation='relu'),\n",
    "    Dropout(0.5),\n",
    "    Dense(128, activation='relu'),\n",
    "    Dropout(0.5),\n",
    "    Dense(len(label_encoder.classes_), activation='softmax')\n",
    "])\n",
    "\n",
    "ann_model.compile(optimizer='adam', loss='sparse_categorical_crossentropy', metrics=['accuracy'])\n",
    "\n",
    "ann_model.fit(train_features_normalized, train_labels_encoded, epochs=50, batch_size=32, validation_split=0.2)\n",
    "\n",
    "# ANN Prediction and Evaluation\n",
    "ann_predictions = np.argmax(ann_model.predict(test_features_normalized), axis=-1)\n",
    "ann_accuracy = balanced_accuracy_score(test_labels_encoded, ann_predictions)\n",
    "print(f\"ANN Accuracy: {ann_accuracy:.4f}\")\n",
    "print(\"ANN Classification Report:\")\n",
    "print(classification_report(test_labels_encoded, ann_predictions))\n",
    "\n",
    "# PyTorch CNN Model\n",
    "import torch\n",
    "from torch.utils.data import DataLoader, TensorDataset\n",
    "\n",
    "X_train_tensor = torch.tensor(train_features_cnn, dtype=torch.float32).permute(0, 2, 1)  # Shape: (num_samples, 1, 1024)\n",
    "y_train_tensor = torch.tensor(train_labels_encoded, dtype=torch.long)\n",
    "X_test_tensor = torch.tensor(test_features_cnn, dtype=torch.float32).permute(0, 2, 1)    # Shape: (num_samples, 1, 1024)\n",
    "y_test_tensor = torch.tensor(test_labels_encoded, dtype=torch.long)\n",
    "\n",
    "train_dataset = TensorDataset(X_train_tensor, y_train_tensor)\n",
    "test_dataset = TensorDataset(X_test_tensor, y_test_tensor)\n",
    "\n",
    "train_loader = DataLoader(train_dataset, batch_size=64, shuffle=True)\n",
    "test_loader = DataLoader(test_dataset, batch_size=64, shuffle=False)\n",
    "\n",
    "import torch.nn as nn\n",
    "import torch.optim as optim\n",
    "\n",
    "class CNN1DModel(nn.Module):\n",
    "    def __init__(self, input_channels, num_classes):\n",
    "        super(CNN1DModel, self).__init__()\n",
    "        self.conv1 = nn.Conv1d(input_channels, 32, kernel_size=5, stride=1, padding=2)\n",
    "        self.bn1 = nn.BatchNorm1d(32)\n",
    "        self.relu = nn.ReLU()\n",
    "        self.conv2 = nn.Conv1d(32, 64, kernel_size=5, stride=1, padding=2)\n",
    "        self.bn2 = nn.BatchNorm1d(64)\n",
    "        self.conv3 = nn.Conv1d(64, 128, kernel_size=5, stride=1, padding=2)\n",
    "        self.bn3 = nn.BatchNorm1d(128)\n",
    "        self.flatten = nn.Flatten()\n",
    "        self.fc1 = nn.Linear(128 * 1024, 512)  # Updated to 1024 features\n",
    "        self.fc2 = nn.Linear(512, num_classes)\n",
    "        self.dropout = nn.Dropout(0.5)\n",
    "    \n",
    "    def forward(self, x):\n",
    "        x = self.relu(self.bn1(self.conv1(x)))\n",
    "        x = self.relu(self.bn2(self.conv2(x)))\n",
    "        x = self.relu(self.bn3(self.conv3(x)))\n",
    "        x = self.flatten(x)\n",
    "        x = self.dropout(self.relu(self.fc1(x)))\n",
    "        x = self.fc2(x)\n",
    "        return x\n",
    "\n",
    "input_channels = 1\n",
    "num_classes = len(label_encoder.classes_)\n",
    "model = CNN1DModel(input_channels, num_classes)\n",
    "criterion = nn.CrossEntropyLoss()\n",
    "optimizer = optim.Adam(model.parameters(), lr=0.001)\n",
    "\n",
    "# Training loop and evaluation (not shown)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "from sklearn.preprocessing import LabelEncoder\n",
    "from sklearn.svm import SVC\n",
    "from sklearn.metrics import balanced_accuracy_score, classification_report\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "\n",
    "# Load the data\n",
    "train_data = np.load('../Files/extracted_features/layer_features_lv60_self/train_16.npz')\n",
    "test_data = np.load('../Files/extracted_features/layer_features_lv60_self/test_16.npz')\n",
    "\n",
    "train_features = train_data['features']  # Ensure these have 1024 features\n",
    "test_features = test_data['features']    # Ensure these have 1024 features\n",
    "\n",
    "# Read Age labels instead of Gender\n",
    "train_labels = pd.read_csv('../Files/labels/y_train.csv').Age_Group\n",
    "test_labels = pd.read_csv('../Files/labels/y_test.csv').Age_Group\n",
    "\n",
    "# Encode the labels\n",
    "label_encoder = LabelEncoder()\n",
    "train_labels_encoded = label_encoder.fit_transform(train_labels)\n",
    "\n",
    "# Handle unseen labels in test set by filtering out labels not present in train set\n",
    "test_labels_filtered = test_labels[test_labels.isin(train_labels.unique())]\n",
    "test_features_filtered = test_features[test_labels.isin(train_labels.unique())]\n",
    "test_labels_encoded = label_encoder.transform(test_labels_filtered)\n",
    "\n",
    "# Standardize features\n",
    "scaler = StandardScaler()\n",
    "train_features_normalized = scaler.fit_transform(train_features)\n",
    "test_features_normalized = scaler.transform(test_features_filtered)\n",
    "\n",
    "# SVM model\n",
    "svm_model = SVC(kernel='linear', C=10.0, gamma='scale', random_state=42)\n",
    "svm_model.fit(train_features_normalized, train_labels_encoded)\n",
    "\n",
    "# SVM Prediction and Evaluation\n",
    "svm_predictions = svm_model.predict(test_features_normalized)\n",
    "svm_accuracy = balanced_accuracy_score(test_labels_encoded, svm_predictions)\n",
    "print(f\"SVM Accuracy: {svm_accuracy:.4f}\")\n",
    "print(\"SVM Classification Report:\")\n",
    "print(classification_report(test_labels_encoded, svm_predictions))\n",
    "\n",
    "# CNN model (TensorFlow)\n",
    "import tensorflow as tf\n",
    "from tensorflow.keras.models import Sequential\n",
    "from tensorflow.keras.layers import Conv1D, Flatten, Dense, Dropout\n",
    "\n",
    "train_features_cnn = np.expand_dims(train_features_normalized, axis=-1)  # Shape: (num_samples, 1024, 1)\n",
    "test_features_cnn = np.expand_dims(test_features_normalized, axis=-1)    # Shape: (num_samples, 1024, 1)\n",
    "\n",
    "cnn_model = Sequential([\n",
    "    Conv1D(64, kernel_size=5, activation='relu', input_shape=(1024, 1)),  # Updated input shape to 1024\n",
    "    Conv1D(128, kernel_size=5, activation='relu'),\n",
    "    Conv1D(256, kernel_size=5, activation='relu'),\n",
    "    Flatten(),\n",
    "    Dense(256, activation='relu'),\n",
    "    Dropout(0.5),\n",
    "    Dense(len(label_encoder.classes_), activation='softmax')\n",
    "])\n",
    "\n",
    "cnn_model.compile(optimizer='adam', loss='sparse_categorical_crossentropy', metrics=['accuracy'])\n",
    "\n",
    "cnn_model.fit(train_features_cnn, train_labels_encoded, epochs=50, batch_size=32, validation_split=0.2)\n",
    "\n",
    "# CNN Prediction and Evaluation\n",
    "cnn_predictions = np.argmax(cnn_model.predict(test_features_cnn), axis=-1)\n",
    "cnn_accuracy = balanced_accuracy_score(test_labels_encoded, cnn_predictions)\n",
    "print(f\"CNN Accuracy: {cnn_accuracy:.4f}\")\n",
    "print(\"CNN Classification Report:\")\n",
    "print(classification_report(test_labels_encoded, cnn_predictions))\n",
    "\n",
    "# ANN model (TensorFlow)\n",
    "ann_model = Sequential([\n",
    "    Dense(512, activation='relu', input_shape=(1024,)),  # Updated input shape to 1024\n",
    "    Dropout(0.5),\n",
    "    Dense(256, activation='relu'),\n",
    "    Dropout(0.5),\n",
    "    Dense(128, activation='relu'),\n",
    "    Dropout(0.5),\n",
    "    Dense(len(label_encoder.classes_), activation='softmax')\n",
    "])\n",
    "\n",
    "ann_model.compile(optimizer='adam', loss='sparse_categorical_crossentropy', metrics=['accuracy'])\n",
    "\n",
    "ann_model.fit(train_features_normalized, train_labels_encoded, epochs=50, batch_size=32, validation_split=0.2)\n",
    "\n",
    "# ANN Prediction and Evaluation\n",
    "ann_predictions = np.argmax(ann_model.predict(test_features_normalized), axis=-1)\n",
    "ann_accuracy = balanced_accuracy_score(test_labels_encoded, ann_predictions)\n",
    "print(f\"ANN Accuracy: {ann_accuracy:.4f}\")\n",
    "print(\"ANN Classification Report:\")\n",
    "print(classification_report(test_labels_encoded, ann_predictions))\n",
    "\n",
    "# PyTorch CNN Model\n",
    "import torch\n",
    "from torch.utils.data import DataLoader, TensorDataset\n",
    "\n",
    "X_train_tensor = torch.tensor(train_features_cnn, dtype=torch.float32).permute(0, 2, 1)  # Shape: (num_samples, 1, 1024)\n",
    "y_train_tensor = torch.tensor(train_labels_encoded, dtype=torch.long)\n",
    "X_test_tensor = torch.tensor(test_features_cnn, dtype=torch.float32).permute(0, 2, 1)    # Shape: (num_samples, 1, 1024)\n",
    "y_test_tensor = torch.tensor(test_labels_encoded, dtype=torch.long)\n",
    "\n",
    "train_dataset = TensorDataset(X_train_tensor, y_train_tensor)\n",
    "test_dataset = TensorDataset(X_test_tensor, y_test_tensor)\n",
    "\n",
    "train_loader = DataLoader(train_dataset, batch_size=64, shuffle=True)\n",
    "test_loader = DataLoader(test_dataset, batch_size=64, shuffle=False)\n",
    "\n",
    "import torch.nn as nn\n",
    "import torch.optim as optim\n",
    "\n",
    "class CNN1DModel(nn.Module):\n",
    "    def __init__(self, input_channels, num_classes):\n",
    "        super(CNN1DModel, self).__init__()\n",
    "        self.conv1 = nn.Conv1d(input_channels, 32, kernel_size=5, stride=1, padding=2)\n",
    "        self.bn1 = nn.BatchNorm1d(32)\n",
    "        self.relu = nn.ReLU()\n",
    "        self.conv2 = nn.Conv1d(32, 64, kernel_size=5, stride=1, padding=2)\n",
    "        self.bn2 = nn.BatchNorm1d(64)\n",
    "        self.conv3 = nn.Conv1d(64, 128, kernel_size=5, stride=1, padding=2)\n",
    "        self.bn3 = nn.BatchNorm1d(128)\n",
    "        self.flatten = nn.Flatten()\n",
    "        self.fc1 = nn.Linear(128 * 1024, 512)  # Updated to 1024 features\n",
    "        self.fc2 = nn.Linear(512, num_classes)\n",
    "        self.dropout = nn.Dropout(0.5)\n",
    "    \n",
    "    def forward(self, x):\n",
    "        x = self.relu(self.bn1(self.conv1(x)))\n",
    "        x = self.relu(self.bn2(self.conv2(x)))\n",
    "        x = self.relu(self.bn3(self.conv3(x)))\n",
    "        x = self.flatten(x)\n",
    "        x = self.dropout(self.relu(self.fc1(x)))\n",
    "        x = self.fc2(x)\n",
    "        return x\n",
    "\n",
    "input_channels = 1\n",
    "num_classes = len(label_encoder.classes_)\n",
    "model = CNN1DModel(input_channels, num_classes)\n",
    "criterion = nn.CrossEntropyLoss()\n",
    "optimizer = optim.Adam(model.parameters(), lr=0.001)\n",
    "\n",
    "# Training loop and evaluation (not shown)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "from sklearn.preprocessing import LabelEncoder\n",
    "from sklearn.svm import SVC\n",
    "from sklearn.metrics import balanced_accuracy_score, classification_report\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "\n",
    "# Load the data\n",
    "train_data = np.load('../Files/extracted_features/layer_features_lv60_self/train_17.npz')\n",
    "test_data = np.load('../Files/extracted_features/layer_features_lv60_self/test_17.npz')\n",
    "\n",
    "train_features = train_data['features']  # Ensure these have 1024 features\n",
    "test_features = test_data['features']    # Ensure these have 1024 features\n",
    "\n",
    "# Read Age labels instead of Gender\n",
    "train_labels = pd.read_csv('../Files/labels/y_train.csv').Age_Group\n",
    "test_labels = pd.read_csv('../Files/labels/y_test.csv').Age_Group\n",
    "\n",
    "# Encode the labels\n",
    "label_encoder = LabelEncoder()\n",
    "train_labels_encoded = label_encoder.fit_transform(train_labels)\n",
    "\n",
    "# Handle unseen labels in test set by filtering out labels not present in train set\n",
    "test_labels_filtered = test_labels[test_labels.isin(train_labels.unique())]\n",
    "test_features_filtered = test_features[test_labels.isin(train_labels.unique())]\n",
    "test_labels_encoded = label_encoder.transform(test_labels_filtered)\n",
    "\n",
    "# Standardize features\n",
    "scaler = StandardScaler()\n",
    "train_features_normalized = scaler.fit_transform(train_features)\n",
    "test_features_normalized = scaler.transform(test_features_filtered)\n",
    "\n",
    "# SVM model\n",
    "svm_model = SVC(kernel='linear', C=10.0, gamma='scale', random_state=42)\n",
    "svm_model.fit(train_features_normalized, train_labels_encoded)\n",
    "\n",
    "# SVM Prediction and Evaluation\n",
    "svm_predictions = svm_model.predict(test_features_normalized)\n",
    "svm_accuracy = balanced_accuracy_score(test_labels_encoded, svm_predictions)\n",
    "print(f\"SVM Accuracy: {svm_accuracy:.4f}\")\n",
    "print(\"SVM Classification Report:\")\n",
    "print(classification_report(test_labels_encoded, svm_predictions))\n",
    "\n",
    "# CNN model (TensorFlow)\n",
    "import tensorflow as tf\n",
    "from tensorflow.keras.models import Sequential\n",
    "from tensorflow.keras.layers import Conv1D, Flatten, Dense, Dropout\n",
    "\n",
    "train_features_cnn = np.expand_dims(train_features_normalized, axis=-1)  # Shape: (num_samples, 1024, 1)\n",
    "test_features_cnn = np.expand_dims(test_features_normalized, axis=-1)    # Shape: (num_samples, 1024, 1)\n",
    "\n",
    "cnn_model = Sequential([\n",
    "    Conv1D(64, kernel_size=5, activation='relu', input_shape=(1024, 1)),  # Updated input shape to 1024\n",
    "    Conv1D(128, kernel_size=5, activation='relu'),\n",
    "    Conv1D(256, kernel_size=5, activation='relu'),\n",
    "    Flatten(),\n",
    "    Dense(256, activation='relu'),\n",
    "    Dropout(0.5),\n",
    "    Dense(len(label_encoder.classes_), activation='softmax')\n",
    "])\n",
    "\n",
    "cnn_model.compile(optimizer='adam', loss='sparse_categorical_crossentropy', metrics=['accuracy'])\n",
    "\n",
    "cnn_model.fit(train_features_cnn, train_labels_encoded, epochs=50, batch_size=32, validation_split=0.2)\n",
    "\n",
    "# CNN Prediction and Evaluation\n",
    "cnn_predictions = np.argmax(cnn_model.predict(test_features_cnn), axis=-1)\n",
    "cnn_accuracy = balanced_accuracy_score(test_labels_encoded, cnn_predictions)\n",
    "print(f\"CNN Accuracy: {cnn_accuracy:.4f}\")\n",
    "print(\"CNN Classification Report:\")\n",
    "print(classification_report(test_labels_encoded, cnn_predictions))\n",
    "\n",
    "# ANN model (TensorFlow)\n",
    "ann_model = Sequential([\n",
    "    Dense(512, activation='relu', input_shape=(1024,)),  # Updated input shape to 1024\n",
    "    Dropout(0.5),\n",
    "    Dense(256, activation='relu'),\n",
    "    Dropout(0.5),\n",
    "    Dense(128, activation='relu'),\n",
    "    Dropout(0.5),\n",
    "    Dense(len(label_encoder.classes_), activation='softmax')\n",
    "])\n",
    "\n",
    "ann_model.compile(optimizer='adam', loss='sparse_categorical_crossentropy', metrics=['accuracy'])\n",
    "\n",
    "ann_model.fit(train_features_normalized, train_labels_encoded, epochs=50, batch_size=32, validation_split=0.2)\n",
    "\n",
    "# ANN Prediction and Evaluation\n",
    "ann_predictions = np.argmax(ann_model.predict(test_features_normalized), axis=-1)\n",
    "ann_accuracy = balanced_accuracy_score(test_labels_encoded, ann_predictions)\n",
    "print(f\"ANN Accuracy: {ann_accuracy:.4f}\")\n",
    "print(\"ANN Classification Report:\")\n",
    "print(classification_report(test_labels_encoded, ann_predictions))\n",
    "\n",
    "# PyTorch CNN Model\n",
    "import torch\n",
    "from torch.utils.data import DataLoader, TensorDataset\n",
    "\n",
    "X_train_tensor = torch.tensor(train_features_cnn, dtype=torch.float32).permute(0, 2, 1)  # Shape: (num_samples, 1, 1024)\n",
    "y_train_tensor = torch.tensor(train_labels_encoded, dtype=torch.long)\n",
    "X_test_tensor = torch.tensor(test_features_cnn, dtype=torch.float32).permute(0, 2, 1)    # Shape: (num_samples, 1, 1024)\n",
    "y_test_tensor = torch.tensor(test_labels_encoded, dtype=torch.long)\n",
    "\n",
    "train_dataset = TensorDataset(X_train_tensor, y_train_tensor)\n",
    "test_dataset = TensorDataset(X_test_tensor, y_test_tensor)\n",
    "\n",
    "train_loader = DataLoader(train_dataset, batch_size=64, shuffle=True)\n",
    "test_loader = DataLoader(test_dataset, batch_size=64, shuffle=False)\n",
    "\n",
    "import torch.nn as nn\n",
    "import torch.optim as optim\n",
    "\n",
    "class CNN1DModel(nn.Module):\n",
    "    def __init__(self, input_channels, num_classes):\n",
    "        super(CNN1DModel, self).__init__()\n",
    "        self.conv1 = nn.Conv1d(input_channels, 32, kernel_size=5, stride=1, padding=2)\n",
    "        self.bn1 = nn.BatchNorm1d(32)\n",
    "        self.relu = nn.ReLU()\n",
    "        self.conv2 = nn.Conv1d(32, 64, kernel_size=5, stride=1, padding=2)\n",
    "        self.bn2 = nn.BatchNorm1d(64)\n",
    "        self.conv3 = nn.Conv1d(64, 128, kernel_size=5, stride=1, padding=2)\n",
    "        self.bn3 = nn.BatchNorm1d(128)\n",
    "        self.flatten = nn.Flatten()\n",
    "        self.fc1 = nn.Linear(128 * 1024, 512)  # Updated to 1024 features\n",
    "        self.fc2 = nn.Linear(512, num_classes)\n",
    "        self.dropout = nn.Dropout(0.5)\n",
    "    \n",
    "    def forward(self, x):\n",
    "        x = self.relu(self.bn1(self.conv1(x)))\n",
    "        x = self.relu(self.bn2(self.conv2(x)))\n",
    "        x = self.relu(self.bn3(self.conv3(x)))\n",
    "        x = self.flatten(x)\n",
    "        x = self.dropout(self.relu(self.fc1(x)))\n",
    "        x = self.fc2(x)\n",
    "        return x\n",
    "\n",
    "input_channels = 1\n",
    "num_classes = len(label_encoder.classes_)\n",
    "model = CNN1DModel(input_channels, num_classes)\n",
    "criterion = nn.CrossEntropyLoss()\n",
    "optimizer = optim.Adam(model.parameters(), lr=0.001)\n",
    "\n",
    "# Training loop and evaluation (not shown)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "from sklearn.preprocessing import LabelEncoder\n",
    "from sklearn.svm import SVC\n",
    "from sklearn.metrics import balanced_accuracy_score, classification_report\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "\n",
    "# Load the data\n",
    "train_data = np.load('../Files/extracted_features/layer_features_lv60_self/train_18.npz')\n",
    "test_data = np.load('../Files/extracted_features/layer_features_lv60_self/test_18.npz')\n",
    "\n",
    "train_features = train_data['features']  # Ensure these have 1024 features\n",
    "test_features = test_data['features']    # Ensure these have 1024 features\n",
    "\n",
    "# Read Age labels instead of Gender\n",
    "train_labels = pd.read_csv('../Files/labels/y_train.csv').Age_Group\n",
    "test_labels = pd.read_csv('../Files/labels/y_test.csv').Age_Group\n",
    "\n",
    "# Encode the labels\n",
    "label_encoder = LabelEncoder()\n",
    "train_labels_encoded = label_encoder.fit_transform(train_labels)\n",
    "\n",
    "# Handle unseen labels in test set by filtering out labels not present in train set\n",
    "test_labels_filtered = test_labels[test_labels.isin(train_labels.unique())]\n",
    "test_features_filtered = test_features[test_labels.isin(train_labels.unique())]\n",
    "test_labels_encoded = label_encoder.transform(test_labels_filtered)\n",
    "\n",
    "# Standardize features\n",
    "scaler = StandardScaler()\n",
    "train_features_normalized = scaler.fit_transform(train_features)\n",
    "test_features_normalized = scaler.transform(test_features_filtered)\n",
    "\n",
    "# SVM model\n",
    "svm_model = SVC(kernel='linear', C=10.0, gamma='scale', random_state=42)\n",
    "svm_model.fit(train_features_normalized, train_labels_encoded)\n",
    "\n",
    "# SVM Prediction and Evaluation\n",
    "svm_predictions = svm_model.predict(test_features_normalized)\n",
    "svm_accuracy = balanced_accuracy_score(test_labels_encoded, svm_predictions)\n",
    "print(f\"SVM Accuracy: {svm_accuracy:.4f}\")\n",
    "print(\"SVM Classification Report:\")\n",
    "print(classification_report(test_labels_encoded, svm_predictions))\n",
    "\n",
    "# CNN model (TensorFlow)\n",
    "import tensorflow as tf\n",
    "from tensorflow.keras.models import Sequential\n",
    "from tensorflow.keras.layers import Conv1D, Flatten, Dense, Dropout\n",
    "\n",
    "train_features_cnn = np.expand_dims(train_features_normalized, axis=-1)  # Shape: (num_samples, 1024, 1)\n",
    "test_features_cnn = np.expand_dims(test_features_normalized, axis=-1)    # Shape: (num_samples, 1024, 1)\n",
    "\n",
    "cnn_model = Sequential([\n",
    "    Conv1D(64, kernel_size=5, activation='relu', input_shape=(1024, 1)),  # Updated input shape to 1024\n",
    "    Conv1D(128, kernel_size=5, activation='relu'),\n",
    "    Conv1D(256, kernel_size=5, activation='relu'),\n",
    "    Flatten(),\n",
    "    Dense(256, activation='relu'),\n",
    "    Dropout(0.5),\n",
    "    Dense(len(label_encoder.classes_), activation='softmax')\n",
    "])\n",
    "\n",
    "cnn_model.compile(optimizer='adam', loss='sparse_categorical_crossentropy', metrics=['accuracy'])\n",
    "\n",
    "cnn_model.fit(train_features_cnn, train_labels_encoded, epochs=50, batch_size=32, validation_split=0.2)\n",
    "\n",
    "# CNN Prediction and Evaluation\n",
    "cnn_predictions = np.argmax(cnn_model.predict(test_features_cnn), axis=-1)\n",
    "cnn_accuracy = balanced_accuracy_score(test_labels_encoded, cnn_predictions)\n",
    "print(f\"CNN Accuracy: {cnn_accuracy:.4f}\")\n",
    "print(\"CNN Classification Report:\")\n",
    "print(classification_report(test_labels_encoded, cnn_predictions))\n",
    "\n",
    "# ANN model (TensorFlow)\n",
    "ann_model = Sequential([\n",
    "    Dense(512, activation='relu', input_shape=(1024,)),  # Updated input shape to 1024\n",
    "    Dropout(0.5),\n",
    "    Dense(256, activation='relu'),\n",
    "    Dropout(0.5),\n",
    "    Dense(128, activation='relu'),\n",
    "    Dropout(0.5),\n",
    "    Dense(len(label_encoder.classes_), activation='softmax')\n",
    "])\n",
    "\n",
    "ann_model.compile(optimizer='adam', loss='sparse_categorical_crossentropy', metrics=['accuracy'])\n",
    "\n",
    "ann_model.fit(train_features_normalized, train_labels_encoded, epochs=50, batch_size=32, validation_split=0.2)\n",
    "\n",
    "# ANN Prediction and Evaluation\n",
    "ann_predictions = np.argmax(ann_model.predict(test_features_normalized), axis=-1)\n",
    "ann_accuracy = balanced_accuracy_score(test_labels_encoded, ann_predictions)\n",
    "print(f\"ANN Accuracy: {ann_accuracy:.4f}\")\n",
    "print(\"ANN Classification Report:\")\n",
    "print(classification_report(test_labels_encoded, ann_predictions))\n",
    "\n",
    "# PyTorch CNN Model\n",
    "import torch\n",
    "from torch.utils.data import DataLoader, TensorDataset\n",
    "\n",
    "X_train_tensor = torch.tensor(train_features_cnn, dtype=torch.float32).permute(0, 2, 1)  # Shape: (num_samples, 1, 1024)\n",
    "y_train_tensor = torch.tensor(train_labels_encoded, dtype=torch.long)\n",
    "X_test_tensor = torch.tensor(test_features_cnn, dtype=torch.float32).permute(0, 2, 1)    # Shape: (num_samples, 1, 1024)\n",
    "y_test_tensor = torch.tensor(test_labels_encoded, dtype=torch.long)\n",
    "\n",
    "train_dataset = TensorDataset(X_train_tensor, y_train_tensor)\n",
    "test_dataset = TensorDataset(X_test_tensor, y_test_tensor)\n",
    "\n",
    "train_loader = DataLoader(train_dataset, batch_size=64, shuffle=True)\n",
    "test_loader = DataLoader(test_dataset, batch_size=64, shuffle=False)\n",
    "\n",
    "import torch.nn as nn\n",
    "import torch.optim as optim\n",
    "\n",
    "class CNN1DModel(nn.Module):\n",
    "    def __init__(self, input_channels, num_classes):\n",
    "        super(CNN1DModel, self).__init__()\n",
    "        self.conv1 = nn.Conv1d(input_channels, 32, kernel_size=5, stride=1, padding=2)\n",
    "        self.bn1 = nn.BatchNorm1d(32)\n",
    "        self.relu = nn.ReLU()\n",
    "        self.conv2 = nn.Conv1d(32, 64, kernel_size=5, stride=1, padding=2)\n",
    "        self.bn2 = nn.BatchNorm1d(64)\n",
    "        self.conv3 = nn.Conv1d(64, 128, kernel_size=5, stride=1, padding=2)\n",
    "        self.bn3 = nn.BatchNorm1d(128)\n",
    "        self.flatten = nn.Flatten()\n",
    "        self.fc1 = nn.Linear(128 * 1024, 512)  # Updated to 1024 features\n",
    "        self.fc2 = nn.Linear(512, num_classes)\n",
    "        self.dropout = nn.Dropout(0.5)\n",
    "    \n",
    "    def forward(self, x):\n",
    "        x = self.relu(self.bn1(self.conv1(x)))\n",
    "        x = self.relu(self.bn2(self.conv2(x)))\n",
    "        x = self.relu(self.bn3(self.conv3(x)))\n",
    "        x = self.flatten(x)\n",
    "        x = self.dropout(self.relu(self.fc1(x)))\n",
    "        x = self.fc2(x)\n",
    "        return x\n",
    "\n",
    "input_channels = 1\n",
    "num_classes = len(label_encoder.classes_)\n",
    "model = CNN1DModel(input_channels, num_classes)\n",
    "criterion = nn.CrossEntropyLoss()\n",
    "optimizer = optim.Adam(model.parameters(), lr=0.001)\n",
    "\n",
    "# Training loop and evaluation (not shown)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "from sklearn.preprocessing import LabelEncoder\n",
    "from sklearn.svm import SVC\n",
    "from sklearn.metrics import balanced_accuracy_score, classification_report\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "\n",
    "# Load the data\n",
    "train_data = np.load('../Files/extracted_features/layer_features_lv60_self/train_19.npz')\n",
    "test_data = np.load('../Files/extracted_features/layer_features_lv60_self/test_19.npz')\n",
    "\n",
    "train_features = train_data['features']  # Ensure these have 1024 features\n",
    "test_features = test_data['features']    # Ensure these have 1024 features\n",
    "\n",
    "# Read Age labels instead of Gender\n",
    "train_labels = pd.read_csv('../Files/labels/y_train.csv').Age_Group\n",
    "test_labels = pd.read_csv('../Files/labels/y_test.csv').Age_Group\n",
    "\n",
    "# Encode the labels\n",
    "label_encoder = LabelEncoder()\n",
    "train_labels_encoded = label_encoder.fit_transform(train_labels)\n",
    "\n",
    "# Handle unseen labels in test set by filtering out labels not present in train set\n",
    "test_labels_filtered = test_labels[test_labels.isin(train_labels.unique())]\n",
    "test_features_filtered = test_features[test_labels.isin(train_labels.unique())]\n",
    "test_labels_encoded = label_encoder.transform(test_labels_filtered)\n",
    "\n",
    "# Standardize features\n",
    "scaler = StandardScaler()\n",
    "train_features_normalized = scaler.fit_transform(train_features)\n",
    "test_features_normalized = scaler.transform(test_features_filtered)\n",
    "\n",
    "# SVM model\n",
    "svm_model = SVC(kernel='linear', C=10.0, gamma='scale', random_state=42)\n",
    "svm_model.fit(train_features_normalized, train_labels_encoded)\n",
    "\n",
    "# SVM Prediction and Evaluation\n",
    "svm_predictions = svm_model.predict(test_features_normalized)\n",
    "svm_accuracy = balanced_accuracy_score(test_labels_encoded, svm_predictions)\n",
    "print(f\"SVM Accuracy: {svm_accuracy:.4f}\")\n",
    "print(\"SVM Classification Report:\")\n",
    "print(classification_report(test_labels_encoded, svm_predictions))\n",
    "\n",
    "# CNN model (TensorFlow)\n",
    "import tensorflow as tf\n",
    "from tensorflow.keras.models import Sequential\n",
    "from tensorflow.keras.layers import Conv1D, Flatten, Dense, Dropout\n",
    "\n",
    "train_features_cnn = np.expand_dims(train_features_normalized, axis=-1)  # Shape: (num_samples, 1024, 1)\n",
    "test_features_cnn = np.expand_dims(test_features_normalized, axis=-1)    # Shape: (num_samples, 1024, 1)\n",
    "\n",
    "cnn_model = Sequential([\n",
    "    Conv1D(64, kernel_size=5, activation='relu', input_shape=(1024, 1)),  # Updated input shape to 1024\n",
    "    Conv1D(128, kernel_size=5, activation='relu'),\n",
    "    Conv1D(256, kernel_size=5, activation='relu'),\n",
    "    Flatten(),\n",
    "    Dense(256, activation='relu'),\n",
    "    Dropout(0.5),\n",
    "    Dense(len(label_encoder.classes_), activation='softmax')\n",
    "])\n",
    "\n",
    "cnn_model.compile(optimizer='adam', loss='sparse_categorical_crossentropy', metrics=['accuracy'])\n",
    "\n",
    "cnn_model.fit(train_features_cnn, train_labels_encoded, epochs=50, batch_size=32, validation_split=0.2)\n",
    "\n",
    "# CNN Prediction and Evaluation\n",
    "cnn_predictions = np.argmax(cnn_model.predict(test_features_cnn), axis=-1)\n",
    "cnn_accuracy = balanced_accuracy_score(test_labels_encoded, cnn_predictions)\n",
    "print(f\"CNN Accuracy: {cnn_accuracy:.4f}\")\n",
    "print(\"CNN Classification Report:\")\n",
    "print(classification_report(test_labels_encoded, cnn_predictions))\n",
    "\n",
    "# ANN model (TensorFlow)\n",
    "ann_model = Sequential([\n",
    "    Dense(512, activation='relu', input_shape=(1024,)),  # Updated input shape to 1024\n",
    "    Dropout(0.5),\n",
    "    Dense(256, activation='relu'),\n",
    "    Dropout(0.5),\n",
    "    Dense(128, activation='relu'),\n",
    "    Dropout(0.5),\n",
    "    Dense(len(label_encoder.classes_), activation='softmax')\n",
    "])\n",
    "\n",
    "ann_model.compile(optimizer='adam', loss='sparse_categorical_crossentropy', metrics=['accuracy'])\n",
    "\n",
    "ann_model.fit(train_features_normalized, train_labels_encoded, epochs=50, batch_size=32, validation_split=0.2)\n",
    "\n",
    "# ANN Prediction and Evaluation\n",
    "ann_predictions = np.argmax(ann_model.predict(test_features_normalized), axis=-1)\n",
    "ann_accuracy = balanced_accuracy_score(test_labels_encoded, ann_predictions)\n",
    "print(f\"ANN Accuracy: {ann_accuracy:.4f}\")\n",
    "print(\"ANN Classification Report:\")\n",
    "print(classification_report(test_labels_encoded, ann_predictions))\n",
    "\n",
    "# PyTorch CNN Model\n",
    "import torch\n",
    "from torch.utils.data import DataLoader, TensorDataset\n",
    "\n",
    "X_train_tensor = torch.tensor(train_features_cnn, dtype=torch.float32).permute(0, 2, 1)  # Shape: (num_samples, 1, 1024)\n",
    "y_train_tensor = torch.tensor(train_labels_encoded, dtype=torch.long)\n",
    "X_test_tensor = torch.tensor(test_features_cnn, dtype=torch.float32).permute(0, 2, 1)    # Shape: (num_samples, 1, 1024)\n",
    "y_test_tensor = torch.tensor(test_labels_encoded, dtype=torch.long)\n",
    "\n",
    "train_dataset = TensorDataset(X_train_tensor, y_train_tensor)\n",
    "test_dataset = TensorDataset(X_test_tensor, y_test_tensor)\n",
    "\n",
    "train_loader = DataLoader(train_dataset, batch_size=64, shuffle=True)\n",
    "test_loader = DataLoader(test_dataset, batch_size=64, shuffle=False)\n",
    "\n",
    "import torch.nn as nn\n",
    "import torch.optim as optim\n",
    "\n",
    "class CNN1DModel(nn.Module):\n",
    "    def __init__(self, input_channels, num_classes):\n",
    "        super(CNN1DModel, self).__init__()\n",
    "        self.conv1 = nn.Conv1d(input_channels, 32, kernel_size=5, stride=1, padding=2)\n",
    "        self.bn1 = nn.BatchNorm1d(32)\n",
    "        self.relu = nn.ReLU()\n",
    "        self.conv2 = nn.Conv1d(32, 64, kernel_size=5, stride=1, padding=2)\n",
    "        self.bn2 = nn.BatchNorm1d(64)\n",
    "        self.conv3 = nn.Conv1d(64, 128, kernel_size=5, stride=1, padding=2)\n",
    "        self.bn3 = nn.BatchNorm1d(128)\n",
    "        self.flatten = nn.Flatten()\n",
    "        self.fc1 = nn.Linear(128 * 1024, 512)  # Updated to 1024 features\n",
    "        self.fc2 = nn.Linear(512, num_classes)\n",
    "        self.dropout = nn.Dropout(0.5)\n",
    "    \n",
    "    def forward(self, x):\n",
    "        x = self.relu(self.bn1(self.conv1(x)))\n",
    "        x = self.relu(self.bn2(self.conv2(x)))\n",
    "        x = self.relu(self.bn3(self.conv3(x)))\n",
    "        x = self.flatten(x)\n",
    "        x = self.dropout(self.relu(self.fc1(x)))\n",
    "        x = self.fc2(x)\n",
    "        return x\n",
    "\n",
    "input_channels = 1\n",
    "num_classes = len(label_encoder.classes_)\n",
    "model = CNN1DModel(input_channels, num_classes)\n",
    "criterion = nn.CrossEntropyLoss()\n",
    "optimizer = optim.Adam(model.parameters(), lr=0.001)\n",
    "\n",
    "# Training loop and evaluation (not shown)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "from sklearn.preprocessing import LabelEncoder\n",
    "from sklearn.svm import SVC\n",
    "from sklearn.metrics import balanced_accuracy_score, classification_report\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "\n",
    "# Load the data\n",
    "train_data = np.load('../Files/extracted_features/layer_features_lv60_self/train_20.npz')\n",
    "test_data = np.load('../Files/extracted_features/layer_features_lv60_self/test_20.npz')\n",
    "\n",
    "train_features = train_data['features']  # Ensure these have 1024 features\n",
    "test_features = test_data['features']    # Ensure these have 1024 features\n",
    "\n",
    "# Read Age labels instead of Gender\n",
    "train_labels = pd.read_csv('../Files/labels/y_train.csv').Age_Group\n",
    "test_labels = pd.read_csv('../Files/labels/y_test.csv').Age_Group\n",
    "\n",
    "# Encode the labels\n",
    "label_encoder = LabelEncoder()\n",
    "train_labels_encoded = label_encoder.fit_transform(train_labels)\n",
    "\n",
    "# Handle unseen labels in test set by filtering out labels not present in train set\n",
    "test_labels_filtered = test_labels[test_labels.isin(train_labels.unique())]\n",
    "test_features_filtered = test_features[test_labels.isin(train_labels.unique())]\n",
    "test_labels_encoded = label_encoder.transform(test_labels_filtered)\n",
    "\n",
    "# Standardize features\n",
    "scaler = StandardScaler()\n",
    "train_features_normalized = scaler.fit_transform(train_features)\n",
    "test_features_normalized = scaler.transform(test_features_filtered)\n",
    "\n",
    "# SVM model\n",
    "svm_model = SVC(kernel='linear', C=10.0, gamma='scale', random_state=42)\n",
    "svm_model.fit(train_features_normalized, train_labels_encoded)\n",
    "\n",
    "# SVM Prediction and Evaluation\n",
    "svm_predictions = svm_model.predict(test_features_normalized)\n",
    "svm_accuracy = balanced_accuracy_score(test_labels_encoded, svm_predictions)\n",
    "print(f\"SVM Accuracy: {svm_accuracy:.4f}\")\n",
    "print(\"SVM Classification Report:\")\n",
    "print(classification_report(test_labels_encoded, svm_predictions))\n",
    "\n",
    "# CNN model (TensorFlow)\n",
    "import tensorflow as tf\n",
    "from tensorflow.keras.models import Sequential\n",
    "from tensorflow.keras.layers import Conv1D, Flatten, Dense, Dropout\n",
    "\n",
    "train_features_cnn = np.expand_dims(train_features_normalized, axis=-1)  # Shape: (num_samples, 1024, 1)\n",
    "test_features_cnn = np.expand_dims(test_features_normalized, axis=-1)    # Shape: (num_samples, 1024, 1)\n",
    "\n",
    "cnn_model = Sequential([\n",
    "    Conv1D(64, kernel_size=5, activation='relu', input_shape=(1024, 1)),  # Updated input shape to 1024\n",
    "    Conv1D(128, kernel_size=5, activation='relu'),\n",
    "    Conv1D(256, kernel_size=5, activation='relu'),\n",
    "    Flatten(),\n",
    "    Dense(256, activation='relu'),\n",
    "    Dropout(0.5),\n",
    "    Dense(len(label_encoder.classes_), activation='softmax')\n",
    "])\n",
    "\n",
    "cnn_model.compile(optimizer='adam', loss='sparse_categorical_crossentropy', metrics=['accuracy'])\n",
    "\n",
    "cnn_model.fit(train_features_cnn, train_labels_encoded, epochs=50, batch_size=32, validation_split=0.2)\n",
    "\n",
    "# CNN Prediction and Evaluation\n",
    "cnn_predictions = np.argmax(cnn_model.predict(test_features_cnn), axis=-1)\n",
    "cnn_accuracy = balanced_accuracy_score(test_labels_encoded, cnn_predictions)\n",
    "print(f\"CNN Accuracy: {cnn_accuracy:.4f}\")\n",
    "print(\"CNN Classification Report:\")\n",
    "print(classification_report(test_labels_encoded, cnn_predictions))\n",
    "\n",
    "# ANN model (TensorFlow)\n",
    "ann_model = Sequential([\n",
    "    Dense(512, activation='relu', input_shape=(1024,)),  # Updated input shape to 1024\n",
    "    Dropout(0.5),\n",
    "    Dense(256, activation='relu'),\n",
    "    Dropout(0.5),\n",
    "    Dense(128, activation='relu'),\n",
    "    Dropout(0.5),\n",
    "    Dense(len(label_encoder.classes_), activation='softmax')\n",
    "])\n",
    "\n",
    "ann_model.compile(optimizer='adam', loss='sparse_categorical_crossentropy', metrics=['accuracy'])\n",
    "\n",
    "ann_model.fit(train_features_normalized, train_labels_encoded, epochs=50, batch_size=32, validation_split=0.2)\n",
    "\n",
    "# ANN Prediction and Evaluation\n",
    "ann_predictions = np.argmax(ann_model.predict(test_features_normalized), axis=-1)\n",
    "ann_accuracy = balanced_accuracy_score(test_labels_encoded, ann_predictions)\n",
    "print(f\"ANN Accuracy: {ann_accuracy:.4f}\")\n",
    "print(\"ANN Classification Report:\")\n",
    "print(classification_report(test_labels_encoded, ann_predictions))\n",
    "\n",
    "# PyTorch CNN Model\n",
    "import torch\n",
    "from torch.utils.data import DataLoader, TensorDataset\n",
    "\n",
    "X_train_tensor = torch.tensor(train_features_cnn, dtype=torch.float32).permute(0, 2, 1)  # Shape: (num_samples, 1, 1024)\n",
    "y_train_tensor = torch.tensor(train_labels_encoded, dtype=torch.long)\n",
    "X_test_tensor = torch.tensor(test_features_cnn, dtype=torch.float32).permute(0, 2, 1)    # Shape: (num_samples, 1, 1024)\n",
    "y_test_tensor = torch.tensor(test_labels_encoded, dtype=torch.long)\n",
    "\n",
    "train_dataset = TensorDataset(X_train_tensor, y_train_tensor)\n",
    "test_dataset = TensorDataset(X_test_tensor, y_test_tensor)\n",
    "\n",
    "train_loader = DataLoader(train_dataset, batch_size=64, shuffle=True)\n",
    "test_loader = DataLoader(test_dataset, batch_size=64, shuffle=False)\n",
    "\n",
    "import torch.nn as nn\n",
    "import torch.optim as optim\n",
    "\n",
    "class CNN1DModel(nn.Module):\n",
    "    def __init__(self, input_channels, num_classes):\n",
    "        super(CNN1DModel, self).__init__()\n",
    "        self.conv1 = nn.Conv1d(input_channels, 32, kernel_size=5, stride=1, padding=2)\n",
    "        self.bn1 = nn.BatchNorm1d(32)\n",
    "        self.relu = nn.ReLU()\n",
    "        self.conv2 = nn.Conv1d(32, 64, kernel_size=5, stride=1, padding=2)\n",
    "        self.bn2 = nn.BatchNorm1d(64)\n",
    "        self.conv3 = nn.Conv1d(64, 128, kernel_size=5, stride=1, padding=2)\n",
    "        self.bn3 = nn.BatchNorm1d(128)\n",
    "        self.flatten = nn.Flatten()\n",
    "        self.fc1 = nn.Linear(128 * 1024, 512)  # Updated to 1024 features\n",
    "        self.fc2 = nn.Linear(512, num_classes)\n",
    "        self.dropout = nn.Dropout(0.5)\n",
    "    \n",
    "    def forward(self, x):\n",
    "        x = self.relu(self.bn1(self.conv1(x)))\n",
    "        x = self.relu(self.bn2(self.conv2(x)))\n",
    "        x = self.relu(self.bn3(self.conv3(x)))\n",
    "        x = self.flatten(x)\n",
    "        x = self.dropout(self.relu(self.fc1(x)))\n",
    "        x = self.fc2(x)\n",
    "        return x\n",
    "\n",
    "input_channels = 1\n",
    "num_classes = len(label_encoder.classes_)\n",
    "model = CNN1DModel(input_channels, num_classes)\n",
    "criterion = nn.CrossEntropyLoss()\n",
    "optimizer = optim.Adam(model.parameters(), lr=0.001)\n",
    "\n",
    "# Training loop and evaluation (not shown)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "from sklearn.preprocessing import LabelEncoder\n",
    "from sklearn.svm import SVC\n",
    "from sklearn.metrics import balanced_accuracy_score, classification_report\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "\n",
    "# Load the data\n",
    "train_data = np.load('../Files/extracted_features/layer_features_lv60_self/train_21.npz')\n",
    "test_data = np.load('../Files/extracted_features/layer_features_lv60_self/test_21.npz')\n",
    "\n",
    "train_features = train_data['features']  # Ensure these have 1024 features\n",
    "test_features = test_data['features']    # Ensure these have 1024 features\n",
    "\n",
    "# Read Age labels instead of Gender\n",
    "train_labels = pd.read_csv('../Files/labels/y_train.csv').Age_Group\n",
    "test_labels = pd.read_csv('../Files/labels/y_test.csv').Age_Group\n",
    "\n",
    "# Encode the labels\n",
    "label_encoder = LabelEncoder()\n",
    "train_labels_encoded = label_encoder.fit_transform(train_labels)\n",
    "\n",
    "# Handle unseen labels in test set by filtering out labels not present in train set\n",
    "test_labels_filtered = test_labels[test_labels.isin(train_labels.unique())]\n",
    "test_features_filtered = test_features[test_labels.isin(train_labels.unique())]\n",
    "test_labels_encoded = label_encoder.transform(test_labels_filtered)\n",
    "\n",
    "# Standardize features\n",
    "scaler = StandardScaler()\n",
    "train_features_normalized = scaler.fit_transform(train_features)\n",
    "test_features_normalized = scaler.transform(test_features_filtered)\n",
    "\n",
    "# SVM model\n",
    "svm_model = SVC(kernel='linear', C=10.0, gamma='scale', random_state=42)\n",
    "svm_model.fit(train_features_normalized, train_labels_encoded)\n",
    "\n",
    "# SVM Prediction and Evaluation\n",
    "svm_predictions = svm_model.predict(test_features_normalized)\n",
    "svm_accuracy = balanced_accuracy_score(test_labels_encoded, svm_predictions)\n",
    "print(f\"SVM Accuracy: {svm_accuracy:.4f}\")\n",
    "print(\"SVM Classification Report:\")\n",
    "print(classification_report(test_labels_encoded, svm_predictions))\n",
    "\n",
    "# CNN model (TensorFlow)\n",
    "import tensorflow as tf\n",
    "from tensorflow.keras.models import Sequential\n",
    "from tensorflow.keras.layers import Conv1D, Flatten, Dense, Dropout\n",
    "\n",
    "train_features_cnn = np.expand_dims(train_features_normalized, axis=-1)  # Shape: (num_samples, 1024, 1)\n",
    "test_features_cnn = np.expand_dims(test_features_normalized, axis=-1)    # Shape: (num_samples, 1024, 1)\n",
    "\n",
    "cnn_model = Sequential([\n",
    "    Conv1D(64, kernel_size=5, activation='relu', input_shape=(1024, 1)),  # Updated input shape to 1024\n",
    "    Conv1D(128, kernel_size=5, activation='relu'),\n",
    "    Conv1D(256, kernel_size=5, activation='relu'),\n",
    "    Flatten(),\n",
    "    Dense(256, activation='relu'),\n",
    "    Dropout(0.5),\n",
    "    Dense(len(label_encoder.classes_), activation='softmax')\n",
    "])\n",
    "\n",
    "cnn_model.compile(optimizer='adam', loss='sparse_categorical_crossentropy', metrics=['accuracy'])\n",
    "\n",
    "cnn_model.fit(train_features_cnn, train_labels_encoded, epochs=50, batch_size=32, validation_split=0.2)\n",
    "\n",
    "# CNN Prediction and Evaluation\n",
    "cnn_predictions = np.argmax(cnn_model.predict(test_features_cnn), axis=-1)\n",
    "cnn_accuracy = balanced_accuracy_score(test_labels_encoded, cnn_predictions)\n",
    "print(f\"CNN Accuracy: {cnn_accuracy:.4f}\")\n",
    "print(\"CNN Classification Report:\")\n",
    "print(classification_report(test_labels_encoded, cnn_predictions))\n",
    "\n",
    "# ANN model (TensorFlow)\n",
    "ann_model = Sequential([\n",
    "    Dense(512, activation='relu', input_shape=(1024,)),  # Updated input shape to 1024\n",
    "    Dropout(0.5),\n",
    "    Dense(256, activation='relu'),\n",
    "    Dropout(0.5),\n",
    "    Dense(128, activation='relu'),\n",
    "    Dropout(0.5),\n",
    "    Dense(len(label_encoder.classes_), activation='softmax')\n",
    "])\n",
    "\n",
    "ann_model.compile(optimizer='adam', loss='sparse_categorical_crossentropy', metrics=['accuracy'])\n",
    "\n",
    "ann_model.fit(train_features_normalized, train_labels_encoded, epochs=50, batch_size=32, validation_split=0.2)\n",
    "\n",
    "# ANN Prediction and Evaluation\n",
    "ann_predictions = np.argmax(ann_model.predict(test_features_normalized), axis=-1)\n",
    "ann_accuracy = balanced_accuracy_score(test_labels_encoded, ann_predictions)\n",
    "print(f\"ANN Accuracy: {ann_accuracy:.4f}\")\n",
    "print(\"ANN Classification Report:\")\n",
    "print(classification_report(test_labels_encoded, ann_predictions))\n",
    "\n",
    "# PyTorch CNN Model\n",
    "import torch\n",
    "from torch.utils.data import DataLoader, TensorDataset\n",
    "\n",
    "X_train_tensor = torch.tensor(train_features_cnn, dtype=torch.float32).permute(0, 2, 1)  # Shape: (num_samples, 1, 1024)\n",
    "y_train_tensor = torch.tensor(train_labels_encoded, dtype=torch.long)\n",
    "X_test_tensor = torch.tensor(test_features_cnn, dtype=torch.float32).permute(0, 2, 1)    # Shape: (num_samples, 1, 1024)\n",
    "y_test_tensor = torch.tensor(test_labels_encoded, dtype=torch.long)\n",
    "\n",
    "train_dataset = TensorDataset(X_train_tensor, y_train_tensor)\n",
    "test_dataset = TensorDataset(X_test_tensor, y_test_tensor)\n",
    "\n",
    "train_loader = DataLoader(train_dataset, batch_size=64, shuffle=True)\n",
    "test_loader = DataLoader(test_dataset, batch_size=64, shuffle=False)\n",
    "\n",
    "import torch.nn as nn\n",
    "import torch.optim as optim\n",
    "\n",
    "class CNN1DModel(nn.Module):\n",
    "    def __init__(self, input_channels, num_classes):\n",
    "        super(CNN1DModel, self).__init__()\n",
    "        self.conv1 = nn.Conv1d(input_channels, 32, kernel_size=5, stride=1, padding=2)\n",
    "        self.bn1 = nn.BatchNorm1d(32)\n",
    "        self.relu = nn.ReLU()\n",
    "        self.conv2 = nn.Conv1d(32, 64, kernel_size=5, stride=1, padding=2)\n",
    "        self.bn2 = nn.BatchNorm1d(64)\n",
    "        self.conv3 = nn.Conv1d(64, 128, kernel_size=5, stride=1, padding=2)\n",
    "        self.bn3 = nn.BatchNorm1d(128)\n",
    "        self.flatten = nn.Flatten()\n",
    "        self.fc1 = nn.Linear(128 * 1024, 512)  # Updated to 1024 features\n",
    "        self.fc2 = nn.Linear(512, num_classes)\n",
    "        self.dropout = nn.Dropout(0.5)\n",
    "    \n",
    "    def forward(self, x):\n",
    "        x = self.relu(self.bn1(self.conv1(x)))\n",
    "        x = self.relu(self.bn2(self.conv2(x)))\n",
    "        x = self.relu(self.bn3(self.conv3(x)))\n",
    "        x = self.flatten(x)\n",
    "        x = self.dropout(self.relu(self.fc1(x)))\n",
    "        x = self.fc2(x)\n",
    "        return x\n",
    "\n",
    "input_channels = 1\n",
    "num_classes = len(label_encoder.classes_)\n",
    "model = CNN1DModel(input_channels, num_classes)\n",
    "criterion = nn.CrossEntropyLoss()\n",
    "optimizer = optim.Adam(model.parameters(), lr=0.001)\n",
    "\n",
    "# Training loop and evaluation (not shown)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "from sklearn.preprocessing import LabelEncoder\n",
    "from sklearn.svm import SVC\n",
    "from sklearn.metrics import balanced_accuracy_score, classification_report\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "\n",
    "# Load the data\n",
    "train_data = np.load('../Files/extracted_features/layer_features_lv60_self/train_22.npz')\n",
    "test_data = np.load('../Files/extracted_features/layer_features_lv60_self/test_22.npz')\n",
    "\n",
    "train_features = train_data['features']  # Ensure these have 1024 features\n",
    "test_features = test_data['features']    # Ensure these have 1024 features\n",
    "\n",
    "# Read Age labels instead of Gender\n",
    "train_labels = pd.read_csv('../Files/labels/y_train.csv').Age_Group\n",
    "test_labels = pd.read_csv('../Files/labels/y_test.csv').Age_Group\n",
    "\n",
    "# Encode the labels\n",
    "label_encoder = LabelEncoder()\n",
    "train_labels_encoded = label_encoder.fit_transform(train_labels)\n",
    "\n",
    "# Handle unseen labels in test set by filtering out labels not present in train set\n",
    "test_labels_filtered = test_labels[test_labels.isin(train_labels.unique())]\n",
    "test_features_filtered = test_features[test_labels.isin(train_labels.unique())]\n",
    "test_labels_encoded = label_encoder.transform(test_labels_filtered)\n",
    "\n",
    "# Standardize features\n",
    "scaler = StandardScaler()\n",
    "train_features_normalized = scaler.fit_transform(train_features)\n",
    "test_features_normalized = scaler.transform(test_features_filtered)\n",
    "\n",
    "# SVM model\n",
    "svm_model = SVC(kernel='linear', C=10.0, gamma='scale', random_state=42)\n",
    "svm_model.fit(train_features_normalized, train_labels_encoded)\n",
    "\n",
    "# SVM Prediction and Evaluation\n",
    "svm_predictions = svm_model.predict(test_features_normalized)\n",
    "svm_accuracy = balanced_accuracy_score(test_labels_encoded, svm_predictions)\n",
    "print(f\"SVM Accuracy: {svm_accuracy:.4f}\")\n",
    "print(\"SVM Classification Report:\")\n",
    "print(classification_report(test_labels_encoded, svm_predictions))\n",
    "\n",
    "# CNN model (TensorFlow)\n",
    "import tensorflow as tf\n",
    "from tensorflow.keras.models import Sequential\n",
    "from tensorflow.keras.layers import Conv1D, Flatten, Dense, Dropout\n",
    "\n",
    "train_features_cnn = np.expand_dims(train_features_normalized, axis=-1)  # Shape: (num_samples, 1024, 1)\n",
    "test_features_cnn = np.expand_dims(test_features_normalized, axis=-1)    # Shape: (num_samples, 1024, 1)\n",
    "\n",
    "cnn_model = Sequential([\n",
    "    Conv1D(64, kernel_size=5, activation='relu', input_shape=(1024, 1)),  # Updated input shape to 1024\n",
    "    Conv1D(128, kernel_size=5, activation='relu'),\n",
    "    Conv1D(256, kernel_size=5, activation='relu'),\n",
    "    Flatten(),\n",
    "    Dense(256, activation='relu'),\n",
    "    Dropout(0.5),\n",
    "    Dense(len(label_encoder.classes_), activation='softmax')\n",
    "])\n",
    "\n",
    "cnn_model.compile(optimizer='adam', loss='sparse_categorical_crossentropy', metrics=['accuracy'])\n",
    "\n",
    "cnn_model.fit(train_features_cnn, train_labels_encoded, epochs=50, batch_size=32, validation_split=0.2)\n",
    "\n",
    "# CNN Prediction and Evaluation\n",
    "cnn_predictions = np.argmax(cnn_model.predict(test_features_cnn), axis=-1)\n",
    "cnn_accuracy = balanced_accuracy_score(test_labels_encoded, cnn_predictions)\n",
    "print(f\"CNN Accuracy: {cnn_accuracy:.4f}\")\n",
    "print(\"CNN Classification Report:\")\n",
    "print(classification_report(test_labels_encoded, cnn_predictions))\n",
    "\n",
    "# ANN model (TensorFlow)\n",
    "ann_model = Sequential([\n",
    "    Dense(512, activation='relu', input_shape=(1024,)),  # Updated input shape to 1024\n",
    "    Dropout(0.5),\n",
    "    Dense(256, activation='relu'),\n",
    "    Dropout(0.5),\n",
    "    Dense(128, activation='relu'),\n",
    "    Dropout(0.5),\n",
    "    Dense(len(label_encoder.classes_), activation='softmax')\n",
    "])\n",
    "\n",
    "ann_model.compile(optimizer='adam', loss='sparse_categorical_crossentropy', metrics=['accuracy'])\n",
    "\n",
    "ann_model.fit(train_features_normalized, train_labels_encoded, epochs=50, batch_size=32, validation_split=0.2)\n",
    "\n",
    "# ANN Prediction and Evaluation\n",
    "ann_predictions = np.argmax(ann_model.predict(test_features_normalized), axis=-1)\n",
    "ann_accuracy = balanced_accuracy_score(test_labels_encoded, ann_predictions)\n",
    "print(f\"ANN Accuracy: {ann_accuracy:.4f}\")\n",
    "print(\"ANN Classification Report:\")\n",
    "print(classification_report(test_labels_encoded, ann_predictions))\n",
    "\n",
    "# PyTorch CNN Model\n",
    "import torch\n",
    "from torch.utils.data import DataLoader, TensorDataset\n",
    "\n",
    "X_train_tensor = torch.tensor(train_features_cnn, dtype=torch.float32).permute(0, 2, 1)  # Shape: (num_samples, 1, 1024)\n",
    "y_train_tensor = torch.tensor(train_labels_encoded, dtype=torch.long)\n",
    "X_test_tensor = torch.tensor(test_features_cnn, dtype=torch.float32).permute(0, 2, 1)    # Shape: (num_samples, 1, 1024)\n",
    "y_test_tensor = torch.tensor(test_labels_encoded, dtype=torch.long)\n",
    "\n",
    "train_dataset = TensorDataset(X_train_tensor, y_train_tensor)\n",
    "test_dataset = TensorDataset(X_test_tensor, y_test_tensor)\n",
    "\n",
    "train_loader = DataLoader(train_dataset, batch_size=64, shuffle=True)\n",
    "test_loader = DataLoader(test_dataset, batch_size=64, shuffle=False)\n",
    "\n",
    "import torch.nn as nn\n",
    "import torch.optim as optim\n",
    "\n",
    "class CNN1DModel(nn.Module):\n",
    "    def __init__(self, input_channels, num_classes):\n",
    "        super(CNN1DModel, self).__init__()\n",
    "        self.conv1 = nn.Conv1d(input_channels, 32, kernel_size=5, stride=1, padding=2)\n",
    "        self.bn1 = nn.BatchNorm1d(32)\n",
    "        self.relu = nn.ReLU()\n",
    "        self.conv2 = nn.Conv1d(32, 64, kernel_size=5, stride=1, padding=2)\n",
    "        self.bn2 = nn.BatchNorm1d(64)\n",
    "        self.conv3 = nn.Conv1d(64, 128, kernel_size=5, stride=1, padding=2)\n",
    "        self.bn3 = nn.BatchNorm1d(128)\n",
    "        self.flatten = nn.Flatten()\n",
    "        self.fc1 = nn.Linear(128 * 1024, 512)  # Updated to 1024 features\n",
    "        self.fc2 = nn.Linear(512, num_classes)\n",
    "        self.dropout = nn.Dropout(0.5)\n",
    "    \n",
    "    def forward(self, x):\n",
    "        x = self.relu(self.bn1(self.conv1(x)))\n",
    "        x = self.relu(self.bn2(self.conv2(x)))\n",
    "        x = self.relu(self.bn3(self.conv3(x)))\n",
    "        x = self.flatten(x)\n",
    "        x = self.dropout(self.relu(self.fc1(x)))\n",
    "        x = self.fc2(x)\n",
    "        return x\n",
    "\n",
    "input_channels = 1\n",
    "num_classes = len(label_encoder.classes_)\n",
    "model = CNN1DModel(input_channels, num_classes)\n",
    "criterion = nn.CrossEntropyLoss()\n",
    "optimizer = optim.Adam(model.parameters(), lr=0.001)\n",
    "\n",
    "# Training loop and evaluation (not shown)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "from sklearn.preprocessing import LabelEncoder\n",
    "from sklearn.svm import SVC\n",
    "from sklearn.metrics import balanced_accuracy_score, classification_report\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "\n",
    "# Load the data\n",
    "train_data = np.load('../Files/extracted_features/layer_features_lv60_self/train_23.npz')\n",
    "test_data = np.load('../Files/extracted_features/layer_features_lv60_self/test_23.npz')\n",
    "\n",
    "train_features = train_data['features']  # Ensure these have 1024 features\n",
    "test_features = test_data['features']    # Ensure these have 1024 features\n",
    "\n",
    "# Read Age labels instead of Gender\n",
    "train_labels = pd.read_csv('../Files/labels/y_train.csv').Age_Group\n",
    "test_labels = pd.read_csv('../Files/labels/y_test.csv').Age_Group\n",
    "\n",
    "# Encode the labels\n",
    "label_encoder = LabelEncoder()\n",
    "train_labels_encoded = label_encoder.fit_transform(train_labels)\n",
    "\n",
    "# Handle unseen labels in test set by filtering out labels not present in train set\n",
    "test_labels_filtered = test_labels[test_labels.isin(train_labels.unique())]\n",
    "test_features_filtered = test_features[test_labels.isin(train_labels.unique())]\n",
    "test_labels_encoded = label_encoder.transform(test_labels_filtered)\n",
    "\n",
    "# Standardize features\n",
    "scaler = StandardScaler()\n",
    "train_features_normalized = scaler.fit_transform(train_features)\n",
    "test_features_normalized = scaler.transform(test_features_filtered)\n",
    "\n",
    "# SVM model\n",
    "svm_model = SVC(kernel='linear', C=10.0, gamma='scale', random_state=42)\n",
    "svm_model.fit(train_features_normalized, train_labels_encoded)\n",
    "\n",
    "# SVM Prediction and Evaluation\n",
    "svm_predictions = svm_model.predict(test_features_normalized)\n",
    "svm_accuracy = balanced_accuracy_score(test_labels_encoded, svm_predictions)\n",
    "print(f\"SVM Accuracy: {svm_accuracy:.4f}\")\n",
    "print(\"SVM Classification Report:\")\n",
    "print(classification_report(test_labels_encoded, svm_predictions))\n",
    "\n",
    "# CNN model (TensorFlow)\n",
    "import tensorflow as tf\n",
    "from tensorflow.keras.models import Sequential\n",
    "from tensorflow.keras.layers import Conv1D, Flatten, Dense, Dropout\n",
    "\n",
    "train_features_cnn = np.expand_dims(train_features_normalized, axis=-1)  # Shape: (num_samples, 1024, 1)\n",
    "test_features_cnn = np.expand_dims(test_features_normalized, axis=-1)    # Shape: (num_samples, 1024, 1)\n",
    "\n",
    "cnn_model = Sequential([\n",
    "    Conv1D(64, kernel_size=5, activation='relu', input_shape=(1024, 1)),  # Updated input shape to 1024\n",
    "    Conv1D(128, kernel_size=5, activation='relu'),\n",
    "    Conv1D(256, kernel_size=5, activation='relu'),\n",
    "    Flatten(),\n",
    "    Dense(256, activation='relu'),\n",
    "    Dropout(0.5),\n",
    "    Dense(len(label_encoder.classes_), activation='softmax')\n",
    "])\n",
    "\n",
    "cnn_model.compile(optimizer='adam', loss='sparse_categorical_crossentropy', metrics=['accuracy'])\n",
    "\n",
    "cnn_model.fit(train_features_cnn, train_labels_encoded, epochs=50, batch_size=32, validation_split=0.2)\n",
    "\n",
    "# CNN Prediction and Evaluation\n",
    "cnn_predictions = np.argmax(cnn_model.predict(test_features_cnn), axis=-1)\n",
    "cnn_accuracy = balanced_accuracy_score(test_labels_encoded, cnn_predictions)\n",
    "print(f\"CNN Accuracy: {cnn_accuracy:.4f}\")\n",
    "print(\"CNN Classification Report:\")\n",
    "print(classification_report(test_labels_encoded, cnn_predictions))\n",
    "\n",
    "# ANN model (TensorFlow)\n",
    "ann_model = Sequential([\n",
    "    Dense(512, activation='relu', input_shape=(1024,)),  # Updated input shape to 1024\n",
    "    Dropout(0.5),\n",
    "    Dense(256, activation='relu'),\n",
    "    Dropout(0.5),\n",
    "    Dense(128, activation='relu'),\n",
    "    Dropout(0.5),\n",
    "    Dense(len(label_encoder.classes_), activation='softmax')\n",
    "])\n",
    "\n",
    "ann_model.compile(optimizer='adam', loss='sparse_categorical_crossentropy', metrics=['accuracy'])\n",
    "\n",
    "ann_model.fit(train_features_normalized, train_labels_encoded, epochs=50, batch_size=32, validation_split=0.2)\n",
    "\n",
    "# ANN Prediction and Evaluation\n",
    "ann_predictions = np.argmax(ann_model.predict(test_features_normalized), axis=-1)\n",
    "ann_accuracy = balanced_accuracy_score(test_labels_encoded, ann_predictions)\n",
    "print(f\"ANN Accuracy: {ann_accuracy:.4f}\")\n",
    "print(\"ANN Classification Report:\")\n",
    "print(classification_report(test_labels_encoded, ann_predictions))\n",
    "\n",
    "# PyTorch CNN Model\n",
    "import torch\n",
    "from torch.utils.data import DataLoader, TensorDataset\n",
    "\n",
    "X_train_tensor = torch.tensor(train_features_cnn, dtype=torch.float32).permute(0, 2, 1)  # Shape: (num_samples, 1, 1024)\n",
    "y_train_tensor = torch.tensor(train_labels_encoded, dtype=torch.long)\n",
    "X_test_tensor = torch.tensor(test_features_cnn, dtype=torch.float32).permute(0, 2, 1)    # Shape: (num_samples, 1, 1024)\n",
    "y_test_tensor = torch.tensor(test_labels_encoded, dtype=torch.long)\n",
    "\n",
    "train_dataset = TensorDataset(X_train_tensor, y_train_tensor)\n",
    "test_dataset = TensorDataset(X_test_tensor, y_test_tensor)\n",
    "\n",
    "train_loader = DataLoader(train_dataset, batch_size=64, shuffle=True)\n",
    "test_loader = DataLoader(test_dataset, batch_size=64, shuffle=False)\n",
    "\n",
    "import torch.nn as nn\n",
    "import torch.optim as optim\n",
    "\n",
    "class CNN1DModel(nn.Module):\n",
    "    def __init__(self, input_channels, num_classes):\n",
    "        super(CNN1DModel, self).__init__()\n",
    "        self.conv1 = nn.Conv1d(input_channels, 32, kernel_size=5, stride=1, padding=2)\n",
    "        self.bn1 = nn.BatchNorm1d(32)\n",
    "        self.relu = nn.ReLU()\n",
    "        self.conv2 = nn.Conv1d(32, 64, kernel_size=5, stride=1, padding=2)\n",
    "        self.bn2 = nn.BatchNorm1d(64)\n",
    "        self.conv3 = nn.Conv1d(64, 128, kernel_size=5, stride=1, padding=2)\n",
    "        self.bn3 = nn.BatchNorm1d(128)\n",
    "        self.flatten = nn.Flatten()\n",
    "        self.fc1 = nn.Linear(128 * 1024, 512)  # Updated to 1024 features\n",
    "        self.fc2 = nn.Linear(512, num_classes)\n",
    "        self.dropout = nn.Dropout(0.5)\n",
    "    \n",
    "    def forward(self, x):\n",
    "        x = self.relu(self.bn1(self.conv1(x)))\n",
    "        x = self.relu(self.bn2(self.conv2(x)))\n",
    "        x = self.relu(self.bn3(self.conv3(x)))\n",
    "        x = self.flatten(x)\n",
    "        x = self.dropout(self.relu(self.fc1(x)))\n",
    "        x = self.fc2(x)\n",
    "        return x\n",
    "\n",
    "input_channels = 1\n",
    "num_classes = len(label_encoder.classes_)\n",
    "model = CNN1DModel(input_channels, num_classes)\n",
    "criterion = nn.CrossEntropyLoss()\n",
    "optimizer = optim.Adam(model.parameters(), lr=0.001)\n",
    "\n",
    "# Training loop and evaluation (not shown)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "from sklearn.preprocessing import LabelEncoder\n",
    "from sklearn.svm import SVC\n",
    "from sklearn.metrics import balanced_accuracy_score, classification_report\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "\n",
    "# Load the data\n",
    "train_data = np.load('../Files/extracted_features/layer_features_lv60_self/train_24.npz')\n",
    "test_data = np.load('../Files/extracted_features/layer_features_lv60_self/test_24.npz')\n",
    "\n",
    "train_features = train_data['features']  # Ensure these have 1024 features\n",
    "test_features = test_data['features']    # Ensure these have 1024 features\n",
    "\n",
    "# Read Age labels instead of Gender\n",
    "train_labels = pd.read_csv('../Files/labels/y_train.csv').Age_Group\n",
    "test_labels = pd.read_csv('../Files/labels/y_test.csv').Age_Group\n",
    "\n",
    "# Encode the labels\n",
    "label_encoder = LabelEncoder()\n",
    "train_labels_encoded = label_encoder.fit_transform(train_labels)\n",
    "\n",
    "# Handle unseen labels in test set by filtering out labels not present in train set\n",
    "test_labels_filtered = test_labels[test_labels.isin(train_labels.unique())]\n",
    "test_features_filtered = test_features[test_labels.isin(train_labels.unique())]\n",
    "test_labels_encoded = label_encoder.transform(test_labels_filtered)\n",
    "\n",
    "# Standardize features\n",
    "scaler = StandardScaler()\n",
    "train_features_normalized = scaler.fit_transform(train_features)\n",
    "test_features_normalized = scaler.transform(test_features_filtered)\n",
    "\n",
    "# SVM model\n",
    "svm_model = SVC(kernel='linear', C=10.0, gamma='scale', random_state=42)\n",
    "svm_model.fit(train_features_normalized, train_labels_encoded)\n",
    "\n",
    "# SVM Prediction and Evaluation\n",
    "svm_predictions = svm_model.predict(test_features_normalized)\n",
    "svm_accuracy = balanced_accuracy_score(test_labels_encoded, svm_predictions)\n",
    "print(f\"SVM Accuracy: {svm_accuracy:.4f}\")\n",
    "print(\"SVM Classification Report:\")\n",
    "print(classification_report(test_labels_encoded, svm_predictions))\n",
    "\n",
    "# CNN model (TensorFlow)\n",
    "import tensorflow as tf\n",
    "from tensorflow.keras.models import Sequential\n",
    "from tensorflow.keras.layers import Conv1D, Flatten, Dense, Dropout\n",
    "\n",
    "train_features_cnn = np.expand_dims(train_features_normalized, axis=-1)  # Shape: (num_samples, 1024, 1)\n",
    "test_features_cnn = np.expand_dims(test_features_normalized, axis=-1)    # Shape: (num_samples, 1024, 1)\n",
    "\n",
    "cnn_model = Sequential([\n",
    "    Conv1D(64, kernel_size=5, activation='relu', input_shape=(1024, 1)),  # Updated input shape to 1024\n",
    "    Conv1D(128, kernel_size=5, activation='relu'),\n",
    "    Conv1D(256, kernel_size=5, activation='relu'),\n",
    "    Flatten(),\n",
    "    Dense(256, activation='relu'),\n",
    "    Dropout(0.5),\n",
    "    Dense(len(label_encoder.classes_), activation='softmax')\n",
    "])\n",
    "\n",
    "cnn_model.compile(optimizer='adam', loss='sparse_categorical_crossentropy', metrics=['accuracy'])\n",
    "\n",
    "cnn_model.fit(train_features_cnn, train_labels_encoded, epochs=50, batch_size=32, validation_split=0.2)\n",
    "\n",
    "# CNN Prediction and Evaluation\n",
    "cnn_predictions = np.argmax(cnn_model.predict(test_features_cnn), axis=-1)\n",
    "cnn_accuracy = balanced_accuracy_score(test_labels_encoded, cnn_predictions)\n",
    "print(f\"CNN Accuracy: {cnn_accuracy:.4f}\")\n",
    "print(\"CNN Classification Report:\")\n",
    "print(classification_report(test_labels_encoded, cnn_predictions))\n",
    "\n",
    "# ANN model (TensorFlow)\n",
    "ann_model = Sequential([\n",
    "    Dense(512, activation='relu', input_shape=(1024,)),  # Updated input shape to 1024\n",
    "    Dropout(0.5),\n",
    "    Dense(256, activation='relu'),\n",
    "    Dropout(0.5),\n",
    "    Dense(128, activation='relu'),\n",
    "    Dropout(0.5),\n",
    "    Dense(len(label_encoder.classes_), activation='softmax')\n",
    "])\n",
    "\n",
    "ann_model.compile(optimizer='adam', loss='sparse_categorical_crossentropy', metrics=['accuracy'])\n",
    "\n",
    "ann_model.fit(train_features_normalized, train_labels_encoded, epochs=50, batch_size=32, validation_split=0.2)\n",
    "\n",
    "# ANN Prediction and Evaluation\n",
    "ann_predictions = np.argmax(ann_model.predict(test_features_normalized), axis=-1)\n",
    "ann_accuracy = balanced_accuracy_score(test_labels_encoded, ann_predictions)\n",
    "print(f\"ANN Accuracy: {ann_accuracy:.4f}\")\n",
    "print(\"ANN Classification Report:\")\n",
    "print(classification_report(test_labels_encoded, ann_predictions))\n",
    "\n",
    "# PyTorch CNN Model\n",
    "import torch\n",
    "from torch.utils.data import DataLoader, TensorDataset\n",
    "\n",
    "X_train_tensor = torch.tensor(train_features_cnn, dtype=torch.float32).permute(0, 2, 1)  # Shape: (num_samples, 1, 1024)\n",
    "y_train_tensor = torch.tensor(train_labels_encoded, dtype=torch.long)\n",
    "X_test_tensor = torch.tensor(test_features_cnn, dtype=torch.float32).permute(0, 2, 1)    # Shape: (num_samples, 1, 1024)\n",
    "y_test_tensor = torch.tensor(test_labels_encoded, dtype=torch.long)\n",
    "\n",
    "train_dataset = TensorDataset(X_train_tensor, y_train_tensor)\n",
    "test_dataset = TensorDataset(X_test_tensor, y_test_tensor)\n",
    "\n",
    "train_loader = DataLoader(train_dataset, batch_size=64, shuffle=True)\n",
    "test_loader = DataLoader(test_dataset, batch_size=64, shuffle=False)\n",
    "\n",
    "import torch.nn as nn\n",
    "import torch.optim as optim\n",
    "\n",
    "class CNN1DModel(nn.Module):\n",
    "    def __init__(self, input_channels, num_classes):\n",
    "        super(CNN1DModel, self).__init__()\n",
    "        self.conv1 = nn.Conv1d(input_channels, 32, kernel_size=5, stride=1, padding=2)\n",
    "        self.bn1 = nn.BatchNorm1d(32)\n",
    "        self.relu = nn.ReLU()\n",
    "        self.conv2 = nn.Conv1d(32, 64, kernel_size=5, stride=1, padding=2)\n",
    "        self.bn2 = nn.BatchNorm1d(64)\n",
    "        self.conv3 = nn.Conv1d(64, 128, kernel_size=5, stride=1, padding=2)\n",
    "        self.bn3 = nn.BatchNorm1d(128)\n",
    "        self.flatten = nn.Flatten()\n",
    "        self.fc1 = nn.Linear(128 * 1024, 512)  # Updated to 1024 features\n",
    "        self.fc2 = nn.Linear(512, num_classes)\n",
    "        self.dropout = nn.Dropout(0.5)\n",
    "    \n",
    "    def forward(self, x):\n",
    "        x = self.relu(self.bn1(self.conv1(x)))\n",
    "        x = self.relu(self.bn2(self.conv2(x)))\n",
    "        x = self.relu(self.bn3(self.conv3(x)))\n",
    "        x = self.flatten(x)\n",
    "        x = self.dropout(self.relu(self.fc1(x)))\n",
    "        x = self.fc2(x)\n",
    "        return x\n",
    "\n",
    "input_channels = 1\n",
    "num_classes = len(label_encoder.classes_)\n",
    "model = CNN1DModel(input_channels, num_classes)\n",
    "criterion = nn.CrossEntropyLoss()\n",
    "optimizer = optim.Adam(model.parameters(), lr=0.001)\n",
    "\n",
    "# Training loop and evaluation (not shown)\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
