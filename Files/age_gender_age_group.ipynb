{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/mojo/.local/lib/python3.12/site-packages/keras/src/layers/convolutional/base_conv.py:107: UserWarning: Do not pass an `input_shape`/`input_dim` argument to a layer. When using Sequential models, prefer using an `Input(shape)` object as the first layer in the model instead.\n",
      "  super().__init__(activity_regularizer=activity_regularizer, **kwargs)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/20\n",
      "\u001b[1m27/27\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m14s\u001b[0m 457ms/step - accuracy: 0.5602 - loss: 67.1915 - val_accuracy: 0.6124 - val_loss: 1.1308\n",
      "Epoch 2/20\n",
      "\u001b[1m27/27\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m12s\u001b[0m 441ms/step - accuracy: 0.8619 - loss: 0.8889 - val_accuracy: 0.7829 - val_loss: 0.6651\n",
      "Epoch 3/20\n",
      "\u001b[1m27/27\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m12s\u001b[0m 441ms/step - accuracy: 0.9655 - loss: 0.1144 - val_accuracy: 0.8140 - val_loss: 0.5433\n",
      "Epoch 4/20\n",
      "\u001b[1m27/27\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m12s\u001b[0m 457ms/step - accuracy: 0.9714 - loss: 0.0594 - val_accuracy: 0.8605 - val_loss: 0.3914\n",
      "Epoch 5/20\n",
      "\u001b[1m27/27\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m13s\u001b[0m 467ms/step - accuracy: 0.9962 - loss: 0.0315 - val_accuracy: 0.8217 - val_loss: 0.4527\n",
      "Epoch 6/20\n",
      "\u001b[1m27/27\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m13s\u001b[0m 468ms/step - accuracy: 0.9973 - loss: 0.0159 - val_accuracy: 0.8450 - val_loss: 0.3752\n",
      "Epoch 7/20\n",
      "\u001b[1m27/27\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m12s\u001b[0m 449ms/step - accuracy: 0.9985 - loss: 0.0087 - val_accuracy: 0.7984 - val_loss: 0.5220\n",
      "Epoch 8/20\n",
      "\u001b[1m27/27\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m12s\u001b[0m 448ms/step - accuracy: 0.9955 - loss: 0.0147 - val_accuracy: 0.8605 - val_loss: 0.2846\n",
      "Epoch 9/20\n",
      "\u001b[1m27/27\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m12s\u001b[0m 447ms/step - accuracy: 1.0000 - loss: 0.0053 - val_accuracy: 0.8992 - val_loss: 0.2647\n",
      "Epoch 10/20\n",
      "\u001b[1m27/27\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m12s\u001b[0m 445ms/step - accuracy: 1.0000 - loss: 0.0032 - val_accuracy: 0.8915 - val_loss: 0.2563\n",
      "Epoch 11/20\n",
      "\u001b[1m27/27\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m12s\u001b[0m 447ms/step - accuracy: 1.0000 - loss: 0.0034 - val_accuracy: 0.9147 - val_loss: 0.2102\n",
      "Epoch 12/20\n",
      "\u001b[1m27/27\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m12s\u001b[0m 447ms/step - accuracy: 0.9993 - loss: 0.0037 - val_accuracy: 0.8915 - val_loss: 0.3128\n",
      "Epoch 13/20\n",
      "\u001b[1m27/27\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m12s\u001b[0m 456ms/step - accuracy: 0.9967 - loss: 0.0092 - val_accuracy: 0.9147 - val_loss: 0.1804\n",
      "Epoch 14/20\n",
      "\u001b[1m27/27\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m12s\u001b[0m 454ms/step - accuracy: 1.0000 - loss: 0.0028 - val_accuracy: 0.9457 - val_loss: 0.1563\n",
      "Epoch 15/20\n",
      "\u001b[1m27/27\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m12s\u001b[0m 446ms/step - accuracy: 1.0000 - loss: 0.0013 - val_accuracy: 0.9380 - val_loss: 0.1619\n",
      "Epoch 16/20\n",
      "\u001b[1m27/27\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m12s\u001b[0m 449ms/step - accuracy: 1.0000 - loss: 0.0011 - val_accuracy: 0.9380 - val_loss: 0.1473\n",
      "Epoch 17/20\n",
      "\u001b[1m27/27\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m12s\u001b[0m 446ms/step - accuracy: 1.0000 - loss: 0.0011 - val_accuracy: 0.9380 - val_loss: 0.1950\n",
      "Epoch 18/20\n",
      "\u001b[1m27/27\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m12s\u001b[0m 443ms/step - accuracy: 1.0000 - loss: 9.8036e-04 - val_accuracy: 0.9380 - val_loss: 0.1698\n",
      "Epoch 19/20\n",
      "\u001b[1m27/27\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m12s\u001b[0m 440ms/step - accuracy: 1.0000 - loss: 8.3681e-04 - val_accuracy: 0.9380 - val_loss: 0.1438\n",
      "Epoch 20/20\n",
      "\u001b[1m27/27\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m12s\u001b[0m 450ms/step - accuracy: 1.0000 - loss: 7.3280e-04 - val_accuracy: 0.9380 - val_loss: 0.1859\n",
      "\u001b[1m5/5\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 37ms/step\n",
      "Classification Report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "       10-14       0.98      0.89      0.93        62\n",
      "         4-6       1.00      0.93      0.96        14\n",
      "         7-9       0.88      1.00      0.94        53\n",
      "\n",
      "    accuracy                           0.94       129\n",
      "   macro avg       0.96      0.94      0.94       129\n",
      "weighted avg       0.94      0.94      0.94       129\n",
      "\n",
      "Accuracy for age group 10-14: 88.71%\n",
      "Accuracy for age group 4-6: 92.86%\n",
      "Accuracy for age group 7-9: 100.00%\n",
      "Overall Accuracy: 93.80%\n"
     ]
    }
   ],
   "source": [
    "import tensorflow as tf\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "from sklearn.preprocessing import LabelEncoder\n",
    "from sklearn.metrics import classification_report, accuracy_score\n",
    "\n",
    "# Load the data\n",
    "train_features = pd.read_csv('hubert_features_train_3.csv'  ).values  # (samples, 1024)\n",
    "test_features = pd.read_csv('hubert_features_test_3.csv').values    # (samples, 1024)\n",
    "train_labels = pd.read_csv('y_train_age_group.csv')['Age_Group']\n",
    "test_labels = pd.read_csv('y_test_age_group.csv')['Age_Group']\n",
    "\n",
    "# Encode the age groups\n",
    "label_encoder = LabelEncoder()\n",
    "train_labels = label_encoder.fit_transform(train_labels)  # Convert '4-6', '7-9', '10-14' to numerical values\n",
    "test_labels = label_encoder.transform(test_labels)\n",
    "\n",
    "# Reshape the features for 1D CNN input\n",
    "train_features = train_features.reshape(-1, 1024, 1)\n",
    "test_features = test_features.reshape(-1, 1024, 1)\n",
    "\n",
    "# Build the CNN model\n",
    "def create_cnn_model(input_shape):\n",
    "    model = tf.keras.Sequential([\n",
    "        tf.keras.layers.Conv1D(32, kernel_size=3, activation='relu', input_shape=input_shape),\n",
    "        tf.keras.layers.BatchNormalization(),\n",
    "        tf.keras.layers.Conv1D(64, kernel_size=3, activation='relu'),\n",
    "        tf.keras.layers.BatchNormalization(),\n",
    "        tf.keras.layers.Conv1D(128, kernel_size=3, activation='relu'),\n",
    "        tf.keras.layers.BatchNormalization(),\n",
    "        tf.keras.layers.Flatten(),\n",
    "        tf.keras.layers.Dropout(0.5),\n",
    "        tf.keras.layers.Dense(512, activation='relu'),\n",
    "        tf.keras.layers.Dense(3, activation='softmax')  # 3 output neurons for 3 age groups\n",
    "    ])\n",
    "    return model\n",
    "\n",
    "# Initialize the model\n",
    "input_shape = (1024, 1)\n",
    "model = create_cnn_model(input_shape)\n",
    "\n",
    "# Compile the model\n",
    "model.compile(optimizer='adam', loss='sparse_categorical_crossentropy', metrics=['accuracy'])\n",
    "\n",
    "# Train the model\n",
    "history = model.fit(train_features, train_labels, epochs=20, batch_size=32, validation_data=(test_features, test_labels))\n",
    "\n",
    "# Evaluate the model\n",
    "predictions = model.predict(test_features)\n",
    "predicted_labels = np.argmax(predictions, axis=1)\n",
    "\n",
    "# Calculate and print classification report and overall accuracy\n",
    "print(\"Classification Report:\")\n",
    "print(classification_report(test_labels, predicted_labels, target_names=label_encoder.classes_))\n",
    "\n",
    "# Calculate individual accuracy for each age group\n",
    "age_groups = label_encoder.classes_\n",
    "individual_accuracies = {}\n",
    "\n",
    "for idx, age_group in enumerate(age_groups):\n",
    "    group_indices = (test_labels == idx)  # Find all indices of this specific age group\n",
    "    group_accuracy = accuracy_score(test_labels[group_indices], predicted_labels[group_indices])\n",
    "    individual_accuracies[age_group] = group_accuracy * 100\n",
    "\n",
    "# Print individual accuracies\n",
    "for age_group, accuracy in individual_accuracies.items():\n",
    "    print(f\"Accuracy for age group {age_group}: {accuracy:.2f}%\")\n",
    "\n",
    "# Print overall accuracy\n",
    "overall_accuracy = accuracy_score(test_labels, predicted_labels)\n",
    "print(f\"Overall Accuracy: {overall_accuracy * 100:.2f}%\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/20\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/mojo/.local/lib/python3.12/site-packages/keras/src/layers/convolutional/base_conv.py:107: UserWarning: Do not pass an `input_shape`/`input_dim` argument to a layer. When using Sequential models, prefer using an `Input(shape)` object as the first layer in the model instead.\n",
      "  super().__init__(activity_regularizer=activity_regularizer, **kwargs)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m27/27\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 7ms/step - accuracy: 0.6347 - loss: 1.0840 - val_accuracy: 0.6667 - val_loss: 0.7175\n",
      "Epoch 2/20\n",
      "\u001b[1m27/27\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.8236 - loss: 0.4617 - val_accuracy: 0.8140 - val_loss: 0.5342\n",
      "Epoch 3/20\n",
      "\u001b[1m27/27\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.8519 - loss: 0.3979 - val_accuracy: 0.8450 - val_loss: 0.5450\n",
      "Epoch 4/20\n",
      "\u001b[1m27/27\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.8845 - loss: 0.3419 - val_accuracy: 0.8527 - val_loss: 0.4473\n",
      "Epoch 5/20\n",
      "\u001b[1m27/27\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.9050 - loss: 0.2491 - val_accuracy: 0.8682 - val_loss: 0.3973\n",
      "Epoch 6/20\n",
      "\u001b[1m27/27\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.9353 - loss: 0.1893 - val_accuracy: 0.8760 - val_loss: 0.4094\n",
      "Epoch 7/20\n",
      "\u001b[1m27/27\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.9214 - loss: 0.1729 - val_accuracy: 0.9070 - val_loss: 0.3094\n",
      "Epoch 8/20\n",
      "\u001b[1m27/27\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.9309 - loss: 0.1669 - val_accuracy: 0.9070 - val_loss: 0.3639\n",
      "Epoch 9/20\n",
      "\u001b[1m27/27\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.9454 - loss: 0.1414 - val_accuracy: 0.8992 - val_loss: 0.2869\n",
      "Epoch 10/20\n",
      "\u001b[1m27/27\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.9579 - loss: 0.1280 - val_accuracy: 0.9070 - val_loss: 0.2956\n",
      "Epoch 11/20\n",
      "\u001b[1m27/27\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.9610 - loss: 0.1110 - val_accuracy: 0.8992 - val_loss: 0.3591\n",
      "Epoch 12/20\n",
      "\u001b[1m27/27\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.9683 - loss: 0.0925 - val_accuracy: 0.8837 - val_loss: 0.2857\n",
      "Epoch 13/20\n",
      "\u001b[1m27/27\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.9637 - loss: 0.1005 - val_accuracy: 0.9070 - val_loss: 0.3163\n",
      "Epoch 14/20\n",
      "\u001b[1m27/27\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.9751 - loss: 0.0806 - val_accuracy: 0.9070 - val_loss: 0.4106\n",
      "Epoch 15/20\n",
      "\u001b[1m27/27\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.9783 - loss: 0.0517 - val_accuracy: 0.8915 - val_loss: 0.3917\n",
      "Epoch 16/20\n",
      "\u001b[1m27/27\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.9779 - loss: 0.0566 - val_accuracy: 0.9070 - val_loss: 0.4365\n",
      "Epoch 17/20\n",
      "\u001b[1m27/27\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.9876 - loss: 0.0449 - val_accuracy: 0.9070 - val_loss: 0.4800\n",
      "Epoch 18/20\n",
      "\u001b[1m27/27\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.9872 - loss: 0.0367 - val_accuracy: 0.9070 - val_loss: 0.3777\n",
      "Epoch 19/20\n",
      "\u001b[1m27/27\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.9871 - loss: 0.0317 - val_accuracy: 0.9070 - val_loss: 0.5338\n",
      "Epoch 20/20\n",
      "\u001b[1m27/27\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.9968 - loss: 0.0183 - val_accuracy: 0.9070 - val_loss: 0.5594\n",
      "\u001b[1m5/5\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 12ms/step\n",
      "Classification Report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "       10-14       0.98      0.87      0.92        62\n",
      "         4-6       0.75      0.86      0.80        14\n",
      "         7-9       0.88      0.96      0.92        53\n",
      "\n",
      "    accuracy                           0.91       129\n",
      "   macro avg       0.87      0.90      0.88       129\n",
      "weighted avg       0.91      0.91      0.91       129\n",
      "\n",
      "Accuracy for age group 10-14: 87.10%\n",
      "Accuracy for age group 4-6: 85.71%\n",
      "Accuracy for age group 7-9: 96.23%\n",
      "Overall Accuracy: 90.70%\n"
     ]
    }
   ],
   "source": [
    "import tensorflow as tf\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "from sklearn.preprocessing import LabelEncoder\n",
    "from sklearn.metrics import classification_report, accuracy_score\n",
    "\n",
    "# Load the data\n",
    "train_features = pd.read_csv('mfcc_features_train.csv').values  # (samples, 26)\n",
    "test_features = pd.read_csv('mfcc_features_test.csv').values    # (samples, 26)\n",
    "train_labels = pd.read_csv('y_train_age_group.csv')['Age_Group']\n",
    "test_labels = pd.read_csv('y_test_age_group.csv')['Age_Group']\n",
    "\n",
    "# Encode the age groups\n",
    "label_encoder = LabelEncoder()\n",
    "train_labels = label_encoder.fit_transform(train_labels)  # Convert '4-6', '7-9', '10-14' to numerical values\n",
    "test_labels = label_encoder.transform(test_labels)\n",
    "\n",
    "# Reshape the features for 1D CNN input\n",
    "train_features = train_features.reshape(-1, 26, 1)  # Adjusted for 26 features\n",
    "test_features = test_features.reshape(-1, 26, 1)    # Adjusted for 26 features\n",
    "\n",
    "# Build the CNN model\n",
    "def create_cnn_model(input_shape):\n",
    "    model = tf.keras.Sequential([\n",
    "        tf.keras.layers.Conv1D(32, kernel_size=3, activation='relu', input_shape=input_shape),\n",
    "        tf.keras.layers.BatchNormalization(),\n",
    "        tf.keras.layers.Conv1D(64, kernel_size=3, activation='relu'),\n",
    "        tf.keras.layers.BatchNormalization(),\n",
    "        tf.keras.layers.Flatten(),\n",
    "        tf.keras.layers.Dropout(0.5),\n",
    "        tf.keras.layers.Dense(128, activation='relu'),\n",
    "        tf.keras.layers.Dense(3, activation='softmax')  # 3 output neurons for 3 age groups\n",
    "    ])\n",
    "    return model\n",
    "\n",
    "# Initialize the model\n",
    "input_shape = (26, 1)  # Input shape for 26 features\n",
    "model = create_cnn_model(input_shape)\n",
    "\n",
    "# Compile the model\n",
    "model.compile(optimizer='adam', loss='sparse_categorical_crossentropy', metrics=['accuracy'])\n",
    "\n",
    "# Train the model\n",
    "history = model.fit(train_features, train_labels, epochs=20, batch_size=32, validation_data=(test_features, test_labels))\n",
    "\n",
    "# Evaluate the model\n",
    "predictions = model.predict(test_features)\n",
    "predicted_labels = np.argmax(predictions, axis=1)\n",
    "\n",
    "# Calculate and print classification report and overall accuracy\n",
    "print(\"Classification Report:\")\n",
    "print(classification_report(test_labels, predicted_labels, target_names=label_encoder.classes_))\n",
    "\n",
    "# Calculate individual accuracy for each age group\n",
    "age_groups = label_encoder.classes_\n",
    "individual_accuracies = {}\n",
    "\n",
    "for idx, age_group in enumerate(age_groups):\n",
    "    group_indices = (test_labels == idx)  # Find all indices of this specific age group\n",
    "    group_accuracy = accuracy_score(test_labels[group_indices], predicted_labels[group_indices])\n",
    "    individual_accuracies[age_group] = group_accuracy * 100\n",
    "\n",
    "# Print individual accuracies\n",
    "for age_group, accuracy in individual_accuracies.items():\n",
    "    print(f\"Accuracy for age group {age_group}: {accuracy:.2f}%\")\n",
    "\n",
    "# Print overall accuracy\n",
    "overall_accuracy = accuracy_score(test_labels, predicted_labels)\n",
    "print(f\"Overall Accuracy: {overall_accuracy * 100:.2f}%\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import tensorflow as tf\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "from sklearn.preprocessing import LabelEncoder\n",
    "from sklearn.metrics import accuracy_score, classification_report\n",
    "\n",
    "# Load features and labels\n",
    "train_features = pd.read_csv('hubert_features_train_3.csv').values  # Training features\n",
    "test_features = pd.read_csv('hubert_features_test_3.csv').values    # Testing features\n",
    "train_data = pd.read_csv('y_train_age_group.csv')  # Contains Age_Group, Age, Gender columns\n",
    "test_data = pd.read_csv('y_test_age_group.csv')    # Contains Age_Group, Age, Gender columns\n",
    "\n",
    "# Combine train and test labels for consistent encoding\n",
    "combined_data = pd.concat([train_data, test_data])\n",
    "\n",
    "# Encode the age groups, ages, and genders\n",
    "age_group_encoder = LabelEncoder()\n",
    "combined_data['Age_Group'] = age_group_encoder.fit_transform(combined_data['Age_Group'])\n",
    "train_data['Age_Group'] = age_group_encoder.transform(train_data['Age_Group'])\n",
    "test_data['Age_Group'] = age_group_encoder.transform(test_data['Age_Group'])\n",
    "\n",
    "age_encoder = LabelEncoder()\n",
    "combined_data['Age'] = age_encoder.fit_transform(combined_data['Age'])\n",
    "train_data['Age'] = age_encoder.transform(train_data['Age'])\n",
    "test_data['Age'] = age_encoder.transform(test_data['Age'])\n",
    "\n",
    "gender_encoder = LabelEncoder()\n",
    "combined_data['Gender'] = gender_encoder.fit_transform(combined_data['Gender'])\n",
    "train_data['Gender'] = gender_encoder.transform(train_data['Gender'])\n",
    "test_data['Gender'] = gender_encoder.transform(test_data['Gender'])\n",
    "\n",
    "# Prepare features for the CNN model\n",
    "train_features = train_features.reshape(-1, 1024, 1)\n",
    "test_features = test_features.reshape(-1, 1024, 1)\n",
    "\n",
    "# Build the CNN model\n",
    "def create_cnn_model(input_shape, output_neurons):\n",
    "    model = tf.keras.Sequential([\n",
    "        tf.keras.layers.Conv1D(32, kernel_size=3, activation='relu', input_shape=input_shape),\n",
    "        tf.keras.layers.BatchNormalization(),\n",
    "        tf.keras.layers.Conv1D(64, kernel_size=3, activation='relu'),\n",
    "        tf.keras.layers.BatchNormalization(),\n",
    "        tf.keras.layers.Conv1D(128, kernel_size=3, activation='relu'),\n",
    "        tf.keras.layers.BatchNormalization(),\n",
    "        tf.keras.layers.Flatten(),\n",
    "        tf.keras.layers.Dropout(0.5),\n",
    "        tf.keras.layers.Dense(512, activation='relu'),\n",
    "        tf.keras.layers.Dense(output_neurons, activation='softmax')\n",
    "    ])\n",
    "    return model\n",
    "\n",
    "# Train Age Group Model\n",
    "age_group_model = create_cnn_model((1024, 1), output_neurons=3)  # 3 Age Groups\n",
    "age_group_model.compile(optimizer='adam', loss='sparse_categorical_crossentropy', metrics=['accuracy'])\n",
    "age_group_model.fit(train_features, train_data['Age_Group'], epochs=20, batch_size=32, validation_split=0.2)\n",
    "\n",
    "# Train Age Model\n",
    "age_model = create_cnn_model((1024, 1), output_neurons=len(age_encoder.classes_))  # Number of unique ages\n",
    "age_model.compile(optimizer='adam', loss='sparse_categorical_crossentropy', metrics=['accuracy'])\n",
    "age_model.fit(train_features, train_data['Age'], epochs=20, batch_size=32, validation_split=0.2)\n",
    "\n",
    "# Train Gender Model\n",
    "gender_model = create_cnn_model((1024, 1), output_neurons=2)  # Male and Female\n",
    "gender_model.compile(optimizer='adam', loss='sparse_categorical_crossentropy', metrics=['accuracy'])\n",
    "gender_model.fit(train_features, train_data['Gender'], epochs=20, batch_size=32, validation_split=0.2)\n",
    "\n",
    "# Predict Age Group, Age, and Gender\n",
    "age_group_predictions = age_group_model.predict(test_features)\n",
    "age_group_pred_labels = np.argmax(age_group_predictions, axis=1)\n",
    "\n",
    "age_predictions = age_model.predict(test_features)\n",
    "age_pred_labels = np.argmax(age_predictions, axis=1)\n",
    "\n",
    "gender_predictions = gender_model.predict(test_features)\n",
    "gender_pred_labels = np.argmax(gender_predictions, axis=1)\n",
    "\n",
    "# Initialize dictionaries to store overall accuracies for ages and genders within each age group\n",
    "group_accuracies = {}\n",
    "\n",
    "# Iterate over each age group and calculate overall accuracy for ages and genders\n",
    "for idx, age_group_name in enumerate(age_group_encoder.classes_):\n",
    "    # Find indices where the predicted age group matches the actual age group\n",
    "    correct_group_indices = (age_group_pred_labels == idx) & (test_data['Age_Group'].values == idx)\n",
    "    \n",
    "    # Extract the true and predicted ages for samples in this age group\n",
    "    true_ages = test_data['Age'][correct_group_indices].values\n",
    "    pred_ages = age_pred_labels[correct_group_indices]\n",
    "    \n",
    "    # Extract the true and predicted genders for samples in this age group\n",
    "    true_genders = test_data['Gender'][correct_group_indices].values\n",
    "    pred_genders = gender_pred_labels[correct_group_indices]\n",
    "    \n",
    "    # Calculate overall accuracy for age and gender identification within the group\n",
    "    if len(true_ages) > 0:\n",
    "        age_accuracy = accuracy_score(true_ages, pred_ages) * 100\n",
    "        gender_accuracy = accuracy_score(true_genders, pred_genders) * 100\n",
    "        \n",
    "        # Store results\n",
    "        group_accuracies[age_group_name] = {\n",
    "            \"Age Accuracy\": age_accuracy,\n",
    "            \"Gender Accuracy\": gender_accuracy\n",
    "        }\n",
    "\n",
    "# Print overall accuracy for ages and genders within each group\n",
    "print(\"Age Group Classification Report:\")\n",
    "print(classification_report(test_data['Age_Group'], age_group_pred_labels, target_names=age_group_encoder.classes_))\n",
    "\n",
    "for group, metrics in group_accuracies.items():\n",
    "    print(f\"Group {group}:\")\n",
    "    print(f\"  Overall Age Identification Accuracy: {metrics['Age Accuracy']:.2f}%\")\n",
    "    print(f\"  Overall Gender Identification Accuracy: {metrics['Gender Accuracy']:.2f}%\")\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
