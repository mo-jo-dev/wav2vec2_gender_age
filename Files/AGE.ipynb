{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "bed6707f",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/lib/python3/dist-packages/scipy/__init__.py:146: UserWarning: A NumPy version >=1.17.3 and <1.25.0 is required for this version of SciPy (detected version 1.26.4\n",
      "  warnings.warn(f\"A NumPy version >={np_minversion} and <{np_maxversion}\"\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "SVM Accuracy: 0.7874\n",
      "SVM Classification Report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           1       0.69      0.75      0.72        12\n",
      "           2       0.50      0.50      0.50         8\n",
      "           3       0.84      0.92      0.88        39\n",
      "           4       0.86      1.00      0.92         6\n",
      "           5       0.80      0.79      0.80        42\n",
      "           6       0.80      0.50      0.62        16\n",
      "           7       0.67      1.00      0.80         2\n",
      "           8       1.00      1.00      1.00         2\n",
      "\n",
      "    accuracy                           0.79       127\n",
      "   macro avg       0.77      0.81      0.78       127\n",
      "weighted avg       0.79      0.79      0.78       127\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2024-09-08 17:21:46.556100: I tensorflow/core/platform/cpu_feature_guard.cc:210] This TensorFlow binary is optimized to use available CPU instructions in performance-critical operations.\n",
      "To enable the following instructions: AVX2 FMA, in other operations, rebuild TensorFlow with the appropriate compiler flags.\n",
      "2024-09-08 17:21:47.461214: W tensorflow/compiler/tf2tensorrt/utils/py_utils.cc:38] TF-TRT Warning: Could not find TensorRT\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/50\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/mojo/.local/lib/python3.10/site-packages/keras/src/layers/convolutional/base_conv.py:107: UserWarning: Do not pass an `input_shape`/`input_dim` argument to a layer. When using Sequential models, prefer using an `Input(shape)` object as the first layer in the model instead.\n",
      "  super().__init__(activity_regularizer=activity_regularizer, **kwargs)\n",
      "2024-09-08 17:21:48.272855: I external/local_xla/xla/stream_executor/cuda/cuda_executor.cc:998] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero. See more at https://github.com/torvalds/linux/blob/v6.0/Documentation/ABI/testing/sysfs-bus-pci#L344-L355\n",
      "2024-09-08 17:21:48.291049: W tensorflow/core/common_runtime/gpu/gpu_device.cc:2251] Cannot dlopen some GPU libraries. Please make sure the missing libraries mentioned above are installed properly if you would like to use GPU. Follow the guide at https://www.tensorflow.org/install/gpu for how to download and setup the required libraries for your platform.\n",
      "Skipping registering GPU devices...\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m9s\u001b[0m 365ms/step - accuracy: 0.3157 - loss: 3.0772 - val_accuracy: 0.0465 - val_loss: 4.0797\n",
      "Epoch 2/50\n",
      "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m8s\u001b[0m 356ms/step - accuracy: 0.7316 - loss: 0.8635 - val_accuracy: 0.1047 - val_loss: 3.1800\n",
      "Epoch 3/50\n",
      "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m8s\u001b[0m 359ms/step - accuracy: 0.8640 - loss: 0.3741 - val_accuracy: 0.1686 - val_loss: 3.4819\n",
      "Epoch 4/50\n",
      "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m8s\u001b[0m 350ms/step - accuracy: 0.9624 - loss: 0.1427 - val_accuracy: 0.1453 - val_loss: 4.9774\n",
      "Epoch 5/50\n",
      "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m8s\u001b[0m 347ms/step - accuracy: 0.9572 - loss: 0.1104 - val_accuracy: 0.1570 - val_loss: 5.3400\n",
      "Epoch 6/50\n",
      "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m8s\u001b[0m 345ms/step - accuracy: 0.9784 - loss: 0.0512 - val_accuracy: 0.2267 - val_loss: 5.0027\n",
      "Epoch 7/50\n",
      "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m8s\u001b[0m 349ms/step - accuracy: 0.9876 - loss: 0.0357 - val_accuracy: 0.2035 - val_loss: 4.9064\n",
      "Epoch 8/50\n",
      "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m8s\u001b[0m 348ms/step - accuracy: 0.9921 - loss: 0.0411 - val_accuracy: 0.1570 - val_loss: 6.4293\n",
      "Epoch 9/50\n",
      "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m8s\u001b[0m 348ms/step - accuracy: 0.9942 - loss: 0.0192 - val_accuracy: 0.1512 - val_loss: 6.1988\n",
      "Epoch 10/50\n",
      "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m8s\u001b[0m 349ms/step - accuracy: 0.9990 - loss: 0.0160 - val_accuracy: 0.2209 - val_loss: 5.5820\n",
      "Epoch 11/50\n",
      "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m10s\u001b[0m 349ms/step - accuracy: 0.9992 - loss: 0.0086 - val_accuracy: 0.2907 - val_loss: 5.5827\n",
      "Epoch 12/50\n",
      "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m8s\u001b[0m 351ms/step - accuracy: 0.9915 - loss: 0.0357 - val_accuracy: 0.2442 - val_loss: 4.9326\n",
      "Epoch 13/50\n",
      "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m8s\u001b[0m 348ms/step - accuracy: 0.9936 - loss: 0.0319 - val_accuracy: 0.2151 - val_loss: 6.1525\n",
      "Epoch 14/50\n",
      "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m8s\u001b[0m 350ms/step - accuracy: 0.9993 - loss: 0.0093 - val_accuracy: 0.2209 - val_loss: 6.3756\n",
      "Epoch 15/50\n",
      "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m8s\u001b[0m 350ms/step - accuracy: 0.9887 - loss: 0.0297 - val_accuracy: 0.1744 - val_loss: 5.3813\n",
      "Epoch 16/50\n",
      "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m8s\u001b[0m 349ms/step - accuracy: 1.0000 - loss: 0.0060 - val_accuracy: 0.1860 - val_loss: 7.4948\n",
      "Epoch 17/50\n",
      "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m8s\u001b[0m 350ms/step - accuracy: 0.9997 - loss: 0.0027 - val_accuracy: 0.2209 - val_loss: 7.0006\n",
      "Epoch 18/50\n",
      "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m8s\u001b[0m 350ms/step - accuracy: 0.9989 - loss: 0.0041 - val_accuracy: 0.2209 - val_loss: 6.7755\n",
      "Epoch 19/50\n",
      "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m8s\u001b[0m 352ms/step - accuracy: 0.9987 - loss: 0.0036 - val_accuracy: 0.2093 - val_loss: 7.9738\n",
      "Epoch 20/50\n",
      "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m8s\u001b[0m 350ms/step - accuracy: 0.9971 - loss: 0.0065 - val_accuracy: 0.2209 - val_loss: 6.8821\n",
      "Epoch 21/50\n",
      "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m8s\u001b[0m 349ms/step - accuracy: 1.0000 - loss: 0.0044 - val_accuracy: 0.1570 - val_loss: 8.7074\n",
      "Epoch 22/50\n",
      "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m8s\u001b[0m 349ms/step - accuracy: 0.9976 - loss: 0.0062 - val_accuracy: 0.2384 - val_loss: 7.4684\n",
      "Epoch 23/50\n",
      "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m8s\u001b[0m 350ms/step - accuracy: 0.9976 - loss: 0.0141 - val_accuracy: 0.2267 - val_loss: 5.6127\n",
      "Epoch 24/50\n",
      "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m8s\u001b[0m 351ms/step - accuracy: 0.9976 - loss: 0.0118 - val_accuracy: 0.1977 - val_loss: 6.2070\n",
      "Epoch 25/50\n",
      "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m8s\u001b[0m 350ms/step - accuracy: 0.9989 - loss: 0.0054 - val_accuracy: 0.2151 - val_loss: 6.5259\n",
      "Epoch 26/50\n",
      "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m8s\u001b[0m 348ms/step - accuracy: 0.9970 - loss: 0.0170 - val_accuracy: 0.2151 - val_loss: 6.4705\n",
      "Epoch 27/50\n",
      "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m8s\u001b[0m 351ms/step - accuracy: 0.9986 - loss: 0.0034 - val_accuracy: 0.1919 - val_loss: 7.4366\n",
      "Epoch 28/50\n",
      "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m8s\u001b[0m 351ms/step - accuracy: 0.9972 - loss: 0.0100 - val_accuracy: 0.2500 - val_loss: 6.6613\n",
      "Epoch 29/50\n",
      "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m8s\u001b[0m 350ms/step - accuracy: 0.9974 - loss: 0.0082 - val_accuracy: 0.2151 - val_loss: 6.3662\n",
      "Epoch 30/50\n",
      "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m8s\u001b[0m 352ms/step - accuracy: 0.9975 - loss: 0.0105 - val_accuracy: 0.2093 - val_loss: 5.8705\n",
      "Epoch 31/50\n",
      "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m8s\u001b[0m 352ms/step - accuracy: 0.9984 - loss: 0.0048 - val_accuracy: 0.2326 - val_loss: 6.2420\n",
      "Epoch 32/50\n",
      "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m8s\u001b[0m 352ms/step - accuracy: 0.9964 - loss: 0.0145 - val_accuracy: 0.2384 - val_loss: 6.0293\n",
      "Epoch 33/50\n",
      "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m8s\u001b[0m 352ms/step - accuracy: 0.9992 - loss: 0.0064 - val_accuracy: 0.1570 - val_loss: 7.9235\n",
      "Epoch 34/50\n",
      "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m8s\u001b[0m 353ms/step - accuracy: 0.9963 - loss: 0.0047 - val_accuracy: 0.1570 - val_loss: 8.7320\n",
      "Epoch 35/50\n",
      "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m8s\u001b[0m 353ms/step - accuracy: 0.9968 - loss: 0.0153 - val_accuracy: 0.2442 - val_loss: 6.8289\n",
      "Epoch 36/50\n",
      "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m8s\u001b[0m 351ms/step - accuracy: 0.9979 - loss: 0.0057 - val_accuracy: 0.2209 - val_loss: 8.5881\n",
      "Epoch 37/50\n",
      "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m8s\u001b[0m 352ms/step - accuracy: 0.9992 - loss: 0.0054 - val_accuracy: 0.1686 - val_loss: 8.3568\n",
      "Epoch 38/50\n",
      "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m8s\u001b[0m 352ms/step - accuracy: 0.9975 - loss: 0.0067 - val_accuracy: 0.1744 - val_loss: 8.0780\n",
      "Epoch 39/50\n",
      "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m8s\u001b[0m 353ms/step - accuracy: 0.9952 - loss: 0.0252 - val_accuracy: 0.1919 - val_loss: 5.4863\n",
      "Epoch 40/50\n",
      "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m8s\u001b[0m 354ms/step - accuracy: 0.9980 - loss: 0.0114 - val_accuracy: 0.1977 - val_loss: 6.9789\n",
      "Epoch 41/50\n",
      "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m8s\u001b[0m 354ms/step - accuracy: 1.0000 - loss: 0.0026 - val_accuracy: 0.1628 - val_loss: 7.8593\n",
      "Epoch 42/50\n",
      "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m8s\u001b[0m 353ms/step - accuracy: 0.9994 - loss: 0.0032 - val_accuracy: 0.2384 - val_loss: 6.4477\n",
      "Epoch 43/50\n",
      "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m8s\u001b[0m 355ms/step - accuracy: 0.9991 - loss: 0.0045 - val_accuracy: 0.2093 - val_loss: 7.2035\n",
      "Epoch 44/50\n",
      "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m8s\u001b[0m 358ms/step - accuracy: 0.9982 - loss: 0.0115 - val_accuracy: 0.2326 - val_loss: 5.1695\n",
      "Epoch 45/50\n",
      "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m8s\u001b[0m 359ms/step - accuracy: 0.9984 - loss: 0.0068 - val_accuracy: 0.2384 - val_loss: 4.7348\n",
      "Epoch 46/50\n",
      "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m8s\u001b[0m 358ms/step - accuracy: 1.0000 - loss: 0.0028 - val_accuracy: 0.2442 - val_loss: 6.1065\n",
      "Epoch 47/50\n",
      "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m8s\u001b[0m 358ms/step - accuracy: 0.9947 - loss: 0.0150 - val_accuracy: 0.2151 - val_loss: 6.6418\n",
      "Epoch 48/50\n",
      "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m8s\u001b[0m 354ms/step - accuracy: 0.9990 - loss: 0.0070 - val_accuracy: 0.2209 - val_loss: 6.1011\n",
      "Epoch 49/50\n",
      "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m8s\u001b[0m 353ms/step - accuracy: 0.9919 - loss: 0.0130 - val_accuracy: 0.2093 - val_loss: 5.7961\n",
      "Epoch 50/50\n",
      "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m8s\u001b[0m 356ms/step - accuracy: 1.0000 - loss: 0.0012 - val_accuracy: 0.2035 - val_loss: 7.2828\n",
      "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 35ms/step - accuracy: 0.7481 - loss: 1.7720\n",
      "CNN Test Accuracy: 0.7402\n",
      "Epoch 1/50\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/mojo/.local/lib/python3.10/site-packages/keras/src/layers/core/dense.py:87: UserWarning: Do not pass an `input_shape`/`input_dim` argument to a layer. When using Sequential models, prefer using an `Input(shape)` object as the first layer in the model instead.\n",
      "  super().__init__(activity_regularizer=activity_regularizer, **kwargs)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 8ms/step - accuracy: 0.2448 - loss: 2.7834 - val_accuracy: 0.0407 - val_loss: 2.2815\n",
      "Epoch 2/50\n",
      "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.3970 - loss: 1.8079 - val_accuracy: 0.0756 - val_loss: 2.1231\n",
      "Epoch 3/50\n",
      "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.5222 - loss: 1.5004 - val_accuracy: 0.0581 - val_loss: 2.3332\n",
      "Epoch 4/50\n",
      "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.6071 - loss: 1.1474 - val_accuracy: 0.1628 - val_loss: 2.1380\n",
      "Epoch 5/50\n",
      "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.6575 - loss: 1.0440 - val_accuracy: 0.2209 - val_loss: 2.1312\n",
      "Epoch 6/50\n",
      "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.6617 - loss: 1.1380 - val_accuracy: 0.1628 - val_loss: 2.5671\n",
      "Epoch 7/50\n",
      "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.7178 - loss: 0.8536 - val_accuracy: 0.2849 - val_loss: 2.3034\n",
      "Epoch 8/50\n",
      "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.6893 - loss: 0.8740 - val_accuracy: 0.2500 - val_loss: 2.4500\n",
      "Epoch 9/50\n",
      "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - accuracy: 0.7719 - loss: 0.6421 - val_accuracy: 0.2907 - val_loss: 2.4669\n",
      "Epoch 10/50\n",
      "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.7704 - loss: 0.6978 - val_accuracy: 0.1860 - val_loss: 3.0743\n",
      "Epoch 11/50\n",
      "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.7756 - loss: 0.7060 - val_accuracy: 0.2442 - val_loss: 3.4674\n",
      "Epoch 12/50\n",
      "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.8233 - loss: 0.4894 - val_accuracy: 0.2151 - val_loss: 3.7757\n",
      "Epoch 13/50\n",
      "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.7713 - loss: 0.6808 - val_accuracy: 0.2093 - val_loss: 4.1228\n",
      "Epoch 14/50\n",
      "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.8468 - loss: 0.4441 - val_accuracy: 0.2965 - val_loss: 3.5768\n",
      "Epoch 15/50\n",
      "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.8538 - loss: 0.4817 - val_accuracy: 0.1977 - val_loss: 4.5512\n",
      "Epoch 16/50\n",
      "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.8575 - loss: 0.4249 - val_accuracy: 0.2267 - val_loss: 3.7509\n",
      "Epoch 17/50\n",
      "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.8702 - loss: 0.3957 - val_accuracy: 0.2384 - val_loss: 3.8714\n",
      "Epoch 18/50\n",
      "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.8582 - loss: 0.3405 - val_accuracy: 0.1919 - val_loss: 4.7738\n",
      "Epoch 19/50\n",
      "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.8820 - loss: 0.3517 - val_accuracy: 0.1860 - val_loss: 5.2502\n",
      "Epoch 20/50\n",
      "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.8831 - loss: 0.3218 - val_accuracy: 0.2151 - val_loss: 4.6647\n",
      "Epoch 21/50\n",
      "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.9027 - loss: 0.3094 - val_accuracy: 0.2209 - val_loss: 5.2118\n",
      "Epoch 22/50\n",
      "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.9015 - loss: 0.2750 - val_accuracy: 0.2035 - val_loss: 5.2556\n",
      "Epoch 23/50\n",
      "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - accuracy: 0.8900 - loss: 0.3081 - val_accuracy: 0.1977 - val_loss: 5.4094\n",
      "Epoch 24/50\n",
      "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.9218 - loss: 0.2358 - val_accuracy: 0.2326 - val_loss: 5.2775\n",
      "Epoch 25/50\n",
      "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.9282 - loss: 0.1880 - val_accuracy: 0.2267 - val_loss: 4.8972\n",
      "Epoch 26/50\n",
      "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.9341 - loss: 0.2147 - val_accuracy: 0.2035 - val_loss: 5.3971\n",
      "Epoch 27/50\n",
      "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.9198 - loss: 0.2438 - val_accuracy: 0.2558 - val_loss: 5.4012\n",
      "Epoch 28/50\n",
      "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.9377 - loss: 0.2182 - val_accuracy: 0.2674 - val_loss: 4.9842\n",
      "Epoch 29/50\n",
      "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.9323 - loss: 0.2316 - val_accuracy: 0.2674 - val_loss: 4.9397\n",
      "Epoch 30/50\n",
      "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.9460 - loss: 0.1556 - val_accuracy: 0.2442 - val_loss: 5.2366\n",
      "Epoch 31/50\n",
      "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.9162 - loss: 0.2008 - val_accuracy: 0.1860 - val_loss: 7.4425\n",
      "Epoch 32/50\n",
      "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.9143 - loss: 0.2137 - val_accuracy: 0.2209 - val_loss: 6.7428\n",
      "Epoch 33/50\n",
      "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.9175 - loss: 0.2563 - val_accuracy: 0.2500 - val_loss: 6.3991\n",
      "Epoch 34/50\n",
      "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.9383 - loss: 0.1965 - val_accuracy: 0.1570 - val_loss: 8.4498\n",
      "Epoch 35/50\n",
      "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.9463 - loss: 0.1816 - val_accuracy: 0.1628 - val_loss: 8.6212\n",
      "Epoch 36/50\n",
      "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.9538 - loss: 0.1484 - val_accuracy: 0.1802 - val_loss: 8.2229\n",
      "Epoch 37/50\n",
      "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.9400 - loss: 0.1805 - val_accuracy: 0.1977 - val_loss: 8.1687\n",
      "Epoch 38/50\n",
      "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.9467 - loss: 0.1965 - val_accuracy: 0.2267 - val_loss: 8.0421\n",
      "Epoch 39/50\n",
      "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.9532 - loss: 0.1338 - val_accuracy: 0.1512 - val_loss: 9.7890\n",
      "Epoch 40/50\n",
      "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.9663 - loss: 0.0988 - val_accuracy: 0.1686 - val_loss: 9.4757\n",
      "Epoch 41/50\n",
      "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.9488 - loss: 0.1527 - val_accuracy: 0.1628 - val_loss: 9.5354\n",
      "Epoch 42/50\n",
      "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.9669 - loss: 0.1064 - val_accuracy: 0.2151 - val_loss: 9.1301\n",
      "Epoch 43/50\n",
      "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.9638 - loss: 0.0921 - val_accuracy: 0.1628 - val_loss: 9.9319\n",
      "Epoch 44/50\n",
      "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.9594 - loss: 0.1077 - val_accuracy: 0.2035 - val_loss: 9.0542\n",
      "Epoch 45/50\n",
      "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.9594 - loss: 0.1117 - val_accuracy: 0.2209 - val_loss: 8.4204\n",
      "Epoch 46/50\n",
      "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.9626 - loss: 0.1261 - val_accuracy: 0.1570 - val_loss: 11.1474\n",
      "Epoch 47/50\n",
      "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.9569 - loss: 0.1447 - val_accuracy: 0.2384 - val_loss: 9.2408\n",
      "Epoch 48/50\n",
      "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.9712 - loss: 0.1110 - val_accuracy: 0.1686 - val_loss: 9.7384\n",
      "Epoch 49/50\n",
      "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.9687 - loss: 0.0929 - val_accuracy: 0.1221 - val_loss: 10.4449\n",
      "Epoch 50/50\n",
      "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.9591 - loss: 0.0730 - val_accuracy: 0.1395 - val_loss: 11.2013\n",
      "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - accuracy: 0.6802 - loss: 1.7510 \n",
      "ANN Test Accuracy: 0.6772\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "from sklearn.preprocessing import LabelEncoder\n",
    "from sklearn.svm import SVC\n",
    "from sklearn.metrics import accuracy_score, classification_report\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "\n",
    "# Load the data\n",
    "train_data = np.load('./layer_features_base_960h/train_0.npz')\n",
    "test_data = np.load('./layer_features_base_960h/test_0.npz')\n",
    "\n",
    "train_features = train_data['features']\n",
    "test_features = test_data['features']\n",
    "\n",
    "# Read Age labels instead of Gender\n",
    "train_labels = pd.read_csv('y_train.csv').Age\n",
    "test_labels = pd.read_csv('y_test.csv').Age\n",
    "\n",
    "# Encode the labels\n",
    "label_encoder = LabelEncoder()\n",
    "train_labels_encoded = label_encoder.fit_transform(train_labels)\n",
    "\n",
    "# Handle unseen labels in test set by filtering out labels not present in train set\n",
    "test_labels_filtered = test_labels[test_labels.isin(train_labels.unique())]\n",
    "test_features_filtered = test_features[test_labels.isin(train_labels.unique())]\n",
    "test_labels_encoded = label_encoder.transform(test_labels_filtered)\n",
    "\n",
    "# Standardize features\n",
    "scaler = StandardScaler()\n",
    "train_features_normalized = scaler.fit_transform(train_features)\n",
    "test_features_normalized = scaler.transform(test_features_filtered)\n",
    "\n",
    "# SVM model\n",
    "svm_model = SVC(kernel='linear', C=10.0, gamma='scale', random_state=42)\n",
    "svm_model.fit(train_features_normalized, train_labels_encoded)\n",
    "\n",
    "# Prediction and Evaluation\n",
    "svm_predictions = svm_model.predict(test_features_normalized)\n",
    "svm_accuracy = accuracy_score(test_labels_encoded, svm_predictions)\n",
    "print(f\"SVM Accuracy: {svm_accuracy:.4f}\")\n",
    "print(\"SVM Classification Report:\")\n",
    "print(classification_report(test_labels_encoded, svm_predictions))\n",
    "\n",
    "# CNN model (TensorFlow)\n",
    "import tensorflow as tf\n",
    "from tensorflow.keras.models import Sequential\n",
    "from tensorflow.keras.layers import Conv1D, Flatten, Dense, Dropout\n",
    "\n",
    "train_features_cnn = np.expand_dims(train_features_normalized, axis=-1)  # Shape: (num_samples, 768, 1)\n",
    "test_features_cnn = np.expand_dims(test_features_normalized, axis=-1)    # Shape: (num_samples, 768, 1)\n",
    "\n",
    "cnn_model = Sequential([\n",
    "    Conv1D(64, kernel_size=5, activation='relu', input_shape=(768, 1)),  # Update input shape to 768 features\n",
    "    Conv1D(128, kernel_size=5, activation='relu'),\n",
    "    Conv1D(256, kernel_size=5, activation='relu'),\n",
    "    Flatten(),\n",
    "    Dense(256, activation='relu'),\n",
    "    Dropout(0.5),\n",
    "    Dense(len(label_encoder.classes_), activation='softmax')\n",
    "])\n",
    "\n",
    "cnn_model.compile(optimizer='adam', loss='sparse_categorical_crossentropy', metrics=['accuracy'])\n",
    "\n",
    "cnn_model.fit(train_features_cnn, train_labels_encoded, epochs=50, batch_size=32, validation_split=0.2)\n",
    "\n",
    "cnn_test_loss, cnn_test_accuracy = cnn_model.evaluate(test_features_cnn, test_labels_encoded)\n",
    "print(f\"CNN Test Accuracy: {cnn_test_accuracy:.4f}\")\n",
    "\n",
    "# ANN model (TensorFlow)\n",
    "ann_model = Sequential([\n",
    "    Dense(512, activation='relu', input_shape=(768,)),  # Update input shape to 768 features\n",
    "    Dropout(0.5),\n",
    "    Dense(256, activation='relu'),\n",
    "    Dropout(0.5),\n",
    "    Dense(128, activation='relu'),\n",
    "    Dropout(0.5),\n",
    "    Dense(len(label_encoder.classes_), activation='softmax')\n",
    "])\n",
    "\n",
    "ann_model.compile(optimizer='adam', loss='sparse_categorical_crossentropy', metrics=['accuracy'])\n",
    "\n",
    "ann_model.fit(train_features_normalized, train_labels_encoded, epochs=50, batch_size=32, validation_split=0.2)\n",
    "\n",
    "ann_test_loss, ann_test_accuracy = ann_model.evaluate(test_features_normalized, test_labels_encoded)\n",
    "print(f\"ANN Test Accuracy: {ann_test_accuracy:.4f}\")\n",
    "\n",
    "# PyTorch CNN Model\n",
    "import torch\n",
    "from torch.utils.data import DataLoader, TensorDataset\n",
    "\n",
    "X_train_tensor = torch.tensor(train_features_cnn, dtype=torch.float32).permute(0, 2, 1)  # Shape: (num_samples, 1, 768)\n",
    "y_train_tensor = torch.tensor(train_labels_encoded, dtype=torch.long)\n",
    "X_test_tensor = torch.tensor(test_features_cnn, dtype=torch.float32).permute(0, 2, 1)    # Shape: (num_samples, 1, 768)\n",
    "y_test_tensor = torch.tensor(test_labels_encoded, dtype=torch.long)\n",
    "\n",
    "train_dataset = TensorDataset(X_train_tensor, y_train_tensor)\n",
    "test_dataset = TensorDataset(X_test_tensor, y_test_tensor)\n",
    "\n",
    "train_loader = DataLoader(train_dataset, batch_size=64, shuffle=True)\n",
    "test_loader = DataLoader(test_dataset, batch_size=64, shuffle=False)\n",
    "\n",
    "import torch.nn as nn\n",
    "import torch.optim as optim\n",
    "\n",
    "class CNN1DModel(nn.Module):\n",
    "    def __init__(self, input_channels, num_classes):\n",
    "        super(CNN1DModel, self).__init__()\n",
    "        self.conv1 = nn.Conv1d(input_channels, 32, kernel_size=5, stride=1, padding=2)\n",
    "        self.bn1 = nn.BatchNorm1d(32)\n",
    "        self.relu = nn.ReLU()\n",
    "        self.conv2 = nn.Conv1d(32, 64, kernel_size=5, stride=1, padding=2)\n",
    "        self.bn2 = nn.BatchNorm1d(64)\n",
    "        self.conv3 = nn.Conv1d(64, 128, kernel_size=5, stride=1, padding=2)\n",
    "        self.bn3 = nn.BatchNorm1d(128)\n",
    "        self.flatten = nn.Flatten()\n",
    "        self.fc1 = nn.Linear(128 * 768, 512)  # Update to 768 features\n",
    "        self.fc2 = nn.Linear(512, num_classes)\n",
    "        self.dropout = nn.Dropout(0.5)\n",
    "    \n",
    "    def forward(self, x):\n",
    "        x = self.relu(self.bn1(self.conv1(x)))\n",
    "        x = self.relu(self.bn2(self.conv2(x)))\n",
    "        x = self.relu(self.bn3(self.conv3(x)))\n",
    "        x = self.flatten(x)\n",
    "        x = self.dropout(self.relu(self.fc1(x)))\n",
    "        x = self.fc2(x)\n",
    "        return x\n",
    "\n",
    "input_channels = 1\n",
    "num_classes = len(label_encoder.classes_)\n",
    "model = CNN1DModel(input_channels, num_classes)\n",
    "criterion = nn.CrossEntropyLoss()\n",
    "optimizer = optim.Adam(model.parameters(), lr=0.001)\n",
    "\n",
    "# Training and testing as before\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "470dbee5",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "SVM Accuracy: 0.8583\n",
      "SVM Classification Report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           1       0.83      0.83      0.83        12\n",
      "           2       0.86      0.75      0.80         8\n",
      "           3       0.83      0.97      0.89        39\n",
      "           4       1.00      1.00      1.00         6\n",
      "           5       0.86      0.86      0.86        42\n",
      "           6       1.00      0.56      0.72        16\n",
      "           7       0.67      1.00      0.80         2\n",
      "           8       1.00      1.00      1.00         2\n",
      "\n",
      "    accuracy                           0.86       127\n",
      "   macro avg       0.88      0.87      0.86       127\n",
      "weighted avg       0.87      0.86      0.85       127\n",
      "\n",
      "Epoch 1/50\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/mojo/.local/lib/python3.10/site-packages/keras/src/layers/convolutional/base_conv.py:107: UserWarning: Do not pass an `input_shape`/`input_dim` argument to a layer. When using Sequential models, prefer using an `Input(shape)` object as the first layer in the model instead.\n",
      "  super().__init__(activity_regularizer=activity_regularizer, **kwargs)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m8s\u001b[0m 345ms/step - accuracy: 0.3357 - loss: 2.8946 - val_accuracy: 0.3953 - val_loss: 1.8562\n",
      "Epoch 2/50\n",
      "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m7s\u001b[0m 334ms/step - accuracy: 0.8011 - loss: 0.5673 - val_accuracy: 0.1686 - val_loss: 3.8049\n",
      "Epoch 3/50\n",
      "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m7s\u001b[0m 334ms/step - accuracy: 0.9354 - loss: 0.2019 - val_accuracy: 0.2209 - val_loss: 4.5423\n",
      "Epoch 4/50\n",
      "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m10s\u001b[0m 335ms/step - accuracy: 0.9804 - loss: 0.0673 - val_accuracy: 0.1453 - val_loss: 7.6773\n",
      "Epoch 5/50\n",
      "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m7s\u001b[0m 340ms/step - accuracy: 0.9836 - loss: 0.0685 - val_accuracy: 0.3256 - val_loss: 4.4402\n",
      "Epoch 6/50\n",
      "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m7s\u001b[0m 337ms/step - accuracy: 0.9972 - loss: 0.0212 - val_accuracy: 0.2093 - val_loss: 6.2420\n",
      "Epoch 7/50\n",
      "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m7s\u001b[0m 337ms/step - accuracy: 0.9900 - loss: 0.0452 - val_accuracy: 0.1919 - val_loss: 5.6889\n",
      "Epoch 8/50\n",
      "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m7s\u001b[0m 337ms/step - accuracy: 0.9887 - loss: 0.0587 - val_accuracy: 0.2326 - val_loss: 4.5544\n",
      "Epoch 9/50\n",
      "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m7s\u001b[0m 339ms/step - accuracy: 0.9913 - loss: 0.0281 - val_accuracy: 0.2326 - val_loss: 5.9788\n",
      "Epoch 10/50\n",
      "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m7s\u001b[0m 340ms/step - accuracy: 1.0000 - loss: 0.0085 - val_accuracy: 0.2442 - val_loss: 7.2375\n",
      "Epoch 11/50\n",
      "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m7s\u001b[0m 340ms/step - accuracy: 0.9948 - loss: 0.0161 - val_accuracy: 0.2267 - val_loss: 5.2564\n",
      "Epoch 12/50\n",
      "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m7s\u001b[0m 339ms/step - accuracy: 0.9992 - loss: 0.0129 - val_accuracy: 0.2442 - val_loss: 5.1950\n",
      "Epoch 13/50\n",
      "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m7s\u001b[0m 339ms/step - accuracy: 0.9993 - loss: 0.0076 - val_accuracy: 0.2035 - val_loss: 7.7012\n",
      "Epoch 14/50\n",
      "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m10s\u001b[0m 351ms/step - accuracy: 0.9980 - loss: 0.0091 - val_accuracy: 0.2326 - val_loss: 6.8947\n",
      "Epoch 15/50\n",
      "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m8s\u001b[0m 351ms/step - accuracy: 0.9945 - loss: 0.0189 - val_accuracy: 0.2500 - val_loss: 5.5614\n",
      "Epoch 16/50\n",
      "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m8s\u001b[0m 351ms/step - accuracy: 0.9970 - loss: 0.0055 - val_accuracy: 0.2035 - val_loss: 7.4221\n",
      "Epoch 17/50\n",
      "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m8s\u001b[0m 349ms/step - accuracy: 1.0000 - loss: 0.0017 - val_accuracy: 0.1860 - val_loss: 9.5069\n",
      "Epoch 18/50\n",
      "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m8s\u001b[0m 352ms/step - accuracy: 1.0000 - loss: 0.0013 - val_accuracy: 0.1919 - val_loss: 9.1984\n",
      "Epoch 19/50\n",
      "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m8s\u001b[0m 351ms/step - accuracy: 1.0000 - loss: 7.0261e-04 - val_accuracy: 0.2035 - val_loss: 8.9681\n",
      "Epoch 20/50\n",
      "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m8s\u001b[0m 353ms/step - accuracy: 0.9935 - loss: 0.0300 - val_accuracy: 0.2093 - val_loss: 5.0243\n",
      "Epoch 21/50\n",
      "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m8s\u001b[0m 357ms/step - accuracy: 0.9941 - loss: 0.0212 - val_accuracy: 0.2151 - val_loss: 6.3669\n",
      "Epoch 22/50\n",
      "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m8s\u001b[0m 354ms/step - accuracy: 1.0000 - loss: 0.0016 - val_accuracy: 0.2209 - val_loss: 7.5621\n",
      "Epoch 23/50\n",
      "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m8s\u001b[0m 357ms/step - accuracy: 0.9988 - loss: 0.0025 - val_accuracy: 0.1919 - val_loss: 7.6018\n",
      "Epoch 24/50\n",
      "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m8s\u001b[0m 359ms/step - accuracy: 1.0000 - loss: 0.0026 - val_accuracy: 0.1744 - val_loss: 8.5579\n",
      "Epoch 25/50\n",
      "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m8s\u001b[0m 356ms/step - accuracy: 0.9962 - loss: 0.0098 - val_accuracy: 0.2035 - val_loss: 7.6933\n",
      "Epoch 26/50\n",
      "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m8s\u001b[0m 357ms/step - accuracy: 0.9996 - loss: 0.0060 - val_accuracy: 0.2384 - val_loss: 5.2170\n",
      "Epoch 27/50\n",
      "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m8s\u001b[0m 354ms/step - accuracy: 0.9976 - loss: 0.0157 - val_accuracy: 0.2035 - val_loss: 5.4361\n",
      "Epoch 28/50\n",
      "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m8s\u001b[0m 356ms/step - accuracy: 0.9984 - loss: 0.0072 - val_accuracy: 0.1977 - val_loss: 7.1255\n",
      "Epoch 29/50\n",
      "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m8s\u001b[0m 356ms/step - accuracy: 1.0000 - loss: 0.0010 - val_accuracy: 0.2616 - val_loss: 7.3768\n",
      "Epoch 30/50\n",
      "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m8s\u001b[0m 353ms/step - accuracy: 1.0000 - loss: 9.8630e-04 - val_accuracy: 0.2267 - val_loss: 8.7222\n",
      "Epoch 31/50\n",
      "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m8s\u001b[0m 356ms/step - accuracy: 0.9968 - loss: 0.0074 - val_accuracy: 0.2267 - val_loss: 4.9257\n",
      "Epoch 32/50\n",
      "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m8s\u001b[0m 355ms/step - accuracy: 0.9926 - loss: 0.0266 - val_accuracy: 0.1919 - val_loss: 5.8117\n",
      "Epoch 33/50\n",
      "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m8s\u001b[0m 361ms/step - accuracy: 0.9982 - loss: 0.0041 - val_accuracy: 0.1802 - val_loss: 8.8528\n",
      "Epoch 34/50\n",
      "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m8s\u001b[0m 362ms/step - accuracy: 0.9992 - loss: 0.0072 - val_accuracy: 0.1860 - val_loss: 7.1829\n",
      "Epoch 35/50\n",
      "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m8s\u001b[0m 357ms/step - accuracy: 0.9991 - loss: 0.0090 - val_accuracy: 0.1802 - val_loss: 7.1996\n",
      "Epoch 36/50\n",
      "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m8s\u001b[0m 355ms/step - accuracy: 0.9991 - loss: 0.0046 - val_accuracy: 0.1860 - val_loss: 7.2648\n",
      "Epoch 37/50\n",
      "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m8s\u001b[0m 354ms/step - accuracy: 0.9895 - loss: 0.0259 - val_accuracy: 0.1686 - val_loss: 6.2898\n",
      "Epoch 38/50\n",
      "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m8s\u001b[0m 359ms/step - accuracy: 0.9966 - loss: 0.0156 - val_accuracy: 0.2267 - val_loss: 6.2049\n",
      "Epoch 39/50\n",
      "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m8s\u001b[0m 354ms/step - accuracy: 0.9984 - loss: 0.0046 - val_accuracy: 0.1744 - val_loss: 8.8391\n",
      "Epoch 40/50\n",
      "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m8s\u001b[0m 362ms/step - accuracy: 0.9963 - loss: 0.0071 - val_accuracy: 0.1977 - val_loss: 7.6092\n",
      "Epoch 41/50\n",
      "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m8s\u001b[0m 361ms/step - accuracy: 0.9992 - loss: 0.0030 - val_accuracy: 0.2442 - val_loss: 7.1988\n",
      "Epoch 42/50\n",
      "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m8s\u001b[0m 359ms/step - accuracy: 1.0000 - loss: 0.0014 - val_accuracy: 0.2151 - val_loss: 9.7869\n",
      "Epoch 43/50\n",
      "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m8s\u001b[0m 360ms/step - accuracy: 1.0000 - loss: 0.0013 - val_accuracy: 0.2384 - val_loss: 9.7389\n",
      "Epoch 44/50\n",
      "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m8s\u001b[0m 355ms/step - accuracy: 1.0000 - loss: 5.5114e-04 - val_accuracy: 0.2442 - val_loss: 9.8148\n",
      "Epoch 45/50\n",
      "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m8s\u001b[0m 356ms/step - accuracy: 0.9990 - loss: 0.0011 - val_accuracy: 0.2326 - val_loss: 9.5048\n",
      "Epoch 46/50\n",
      "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m8s\u001b[0m 347ms/step - accuracy: 0.9988 - loss: 0.0026 - val_accuracy: 0.2093 - val_loss: 8.9690\n",
      "Epoch 47/50\n",
      "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m8s\u001b[0m 357ms/step - accuracy: 1.0000 - loss: 4.2234e-04 - val_accuracy: 0.2093 - val_loss: 9.4031\n",
      "Epoch 48/50\n",
      "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m8s\u001b[0m 355ms/step - accuracy: 1.0000 - loss: 3.1946e-04 - val_accuracy: 0.2151 - val_loss: 9.8638\n",
      "Epoch 49/50\n",
      "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m8s\u001b[0m 354ms/step - accuracy: 1.0000 - loss: 9.8875e-05 - val_accuracy: 0.2151 - val_loss: 9.9935\n",
      "Epoch 50/50\n",
      "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m8s\u001b[0m 361ms/step - accuracy: 1.0000 - loss: 8.8614e-04 - val_accuracy: 0.2151 - val_loss: 9.6918\n",
      "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 42ms/step - accuracy: 0.8098 - loss: 1.8059\n",
      "CNN Test Accuracy: 0.7953\n",
      "Epoch 1/50\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/mojo/.local/lib/python3.10/site-packages/keras/src/layers/core/dense.py:87: UserWarning: Do not pass an `input_shape`/`input_dim` argument to a layer. When using Sequential models, prefer using an `Input(shape)` object as the first layer in the model instead.\n",
      "  super().__init__(activity_regularizer=activity_regularizer, **kwargs)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 9ms/step - accuracy: 0.2732 - loss: 2.8772 - val_accuracy: 0.0814 - val_loss: 2.1314\n",
      "Epoch 2/50\n",
      "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.4488 - loss: 1.7445 - val_accuracy: 0.2616 - val_loss: 1.9903\n",
      "Epoch 3/50\n",
      "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.5165 - loss: 1.4535 - val_accuracy: 0.2791 - val_loss: 2.1066\n",
      "Epoch 4/50\n",
      "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.5708 - loss: 1.3121 - val_accuracy: 0.3081 - val_loss: 1.9813\n",
      "Epoch 5/50\n",
      "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.6442 - loss: 1.1347 - val_accuracy: 0.3023 - val_loss: 2.1314\n",
      "Epoch 6/50\n",
      "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.7043 - loss: 0.9124 - val_accuracy: 0.3372 - val_loss: 2.1929\n",
      "Epoch 7/50\n",
      "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - accuracy: 0.7519 - loss: 0.7567 - val_accuracy: 0.2674 - val_loss: 2.3769\n",
      "Epoch 8/50\n",
      "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.7930 - loss: 0.6856 - val_accuracy: 0.3837 - val_loss: 1.9911\n",
      "Epoch 9/50\n",
      "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.7787 - loss: 0.6660 - val_accuracy: 0.2674 - val_loss: 2.5977\n",
      "Epoch 10/50\n",
      "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.7872 - loss: 0.5532 - val_accuracy: 0.3547 - val_loss: 2.1129\n",
      "Epoch 11/50\n",
      "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.8666 - loss: 0.4220 - val_accuracy: 0.2791 - val_loss: 2.8909\n",
      "Epoch 12/50\n",
      "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.8083 - loss: 0.5167 - val_accuracy: 0.2849 - val_loss: 3.0822\n",
      "Epoch 13/50\n",
      "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.8782 - loss: 0.3909 - val_accuracy: 0.2267 - val_loss: 4.4501\n",
      "Epoch 14/50\n",
      "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.8724 - loss: 0.4010 - val_accuracy: 0.2384 - val_loss: 3.6820\n",
      "Epoch 15/50\n",
      "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.8858 - loss: 0.3402 - val_accuracy: 0.2209 - val_loss: 4.1587\n",
      "Epoch 16/50\n",
      "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.9022 - loss: 0.2784 - val_accuracy: 0.2151 - val_loss: 4.5282\n",
      "Epoch 17/50\n",
      "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.9142 - loss: 0.2257 - val_accuracy: 0.2442 - val_loss: 4.5568\n",
      "Epoch 18/50\n",
      "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.9315 - loss: 0.2071 - val_accuracy: 0.2267 - val_loss: 5.0163\n",
      "Epoch 19/50\n",
      "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.9193 - loss: 0.2875 - val_accuracy: 0.1512 - val_loss: 5.4586\n",
      "Epoch 20/50\n",
      "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - accuracy: 0.9217 - loss: 0.2487 - val_accuracy: 0.2209 - val_loss: 5.4329\n",
      "Epoch 21/50\n",
      "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.9466 - loss: 0.1797 - val_accuracy: 0.2035 - val_loss: 6.0621\n",
      "Epoch 22/50\n",
      "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.9378 - loss: 0.2152 - val_accuracy: 0.1512 - val_loss: 6.3684\n",
      "Epoch 23/50\n",
      "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.9270 - loss: 0.2762 - val_accuracy: 0.1570 - val_loss: 5.6770\n",
      "Epoch 24/50\n",
      "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.9274 - loss: 0.1980 - val_accuracy: 0.1570 - val_loss: 6.3426\n",
      "Epoch 25/50\n",
      "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.9483 - loss: 0.1529 - val_accuracy: 0.2500 - val_loss: 5.5126\n",
      "Epoch 26/50\n",
      "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.9394 - loss: 0.1935 - val_accuracy: 0.1686 - val_loss: 6.9576\n",
      "Epoch 27/50\n",
      "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.9423 - loss: 0.1717 - val_accuracy: 0.1570 - val_loss: 7.0108\n",
      "Epoch 28/50\n",
      "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.9486 - loss: 0.1354 - val_accuracy: 0.2093 - val_loss: 5.9906\n",
      "Epoch 29/50\n",
      "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.9622 - loss: 0.1435 - val_accuracy: 0.2093 - val_loss: 6.7031\n",
      "Epoch 30/50\n",
      "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.9698 - loss: 0.1118 - val_accuracy: 0.2500 - val_loss: 6.2870\n",
      "Epoch 31/50\n",
      "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.9517 - loss: 0.1352 - val_accuracy: 0.2151 - val_loss: 7.4665\n",
      "Epoch 32/50\n",
      "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.9620 - loss: 0.1196 - val_accuracy: 0.1977 - val_loss: 9.0339\n",
      "Epoch 33/50\n",
      "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.9615 - loss: 0.0826 - val_accuracy: 0.2267 - val_loss: 8.5573\n",
      "Epoch 34/50\n",
      "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.9729 - loss: 0.1047 - val_accuracy: 0.2267 - val_loss: 8.7257\n",
      "Epoch 35/50\n",
      "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - accuracy: 0.9582 - loss: 0.1139 - val_accuracy: 0.2326 - val_loss: 8.4868\n",
      "Epoch 36/50\n",
      "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.9669 - loss: 0.0892 - val_accuracy: 0.1860 - val_loss: 9.0037\n",
      "Epoch 37/50\n",
      "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.9739 - loss: 0.1037 - val_accuracy: 0.1628 - val_loss: 10.3944\n",
      "Epoch 38/50\n",
      "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.9837 - loss: 0.0765 - val_accuracy: 0.1977 - val_loss: 8.7182\n",
      "Epoch 39/50\n",
      "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.9696 - loss: 0.0733 - val_accuracy: 0.2035 - val_loss: 8.9097\n",
      "Epoch 40/50\n",
      "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.9821 - loss: 0.0889 - val_accuracy: 0.1453 - val_loss: 10.6333\n",
      "Epoch 41/50\n",
      "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.9654 - loss: 0.1364 - val_accuracy: 0.2209 - val_loss: 8.0538\n",
      "Epoch 42/50\n",
      "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.9789 - loss: 0.0695 - val_accuracy: 0.2035 - val_loss: 9.0274\n",
      "Epoch 43/50\n",
      "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.9772 - loss: 0.0821 - val_accuracy: 0.1977 - val_loss: 8.7595\n",
      "Epoch 44/50\n",
      "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.9735 - loss: 0.0839 - val_accuracy: 0.1919 - val_loss: 7.9767\n",
      "Epoch 45/50\n",
      "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.9679 - loss: 0.0957 - val_accuracy: 0.2791 - val_loss: 6.6302\n",
      "Epoch 46/50\n",
      "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.9838 - loss: 0.0654 - val_accuracy: 0.1802 - val_loss: 8.1127\n",
      "Epoch 47/50\n",
      "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.9829 - loss: 0.0596 - val_accuracy: 0.1395 - val_loss: 9.7264\n",
      "Epoch 48/50\n",
      "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.9771 - loss: 0.1158 - val_accuracy: 0.1919 - val_loss: 7.8952\n",
      "Epoch 49/50\n",
      "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.9716 - loss: 0.1109 - val_accuracy: 0.2209 - val_loss: 6.9909\n",
      "Epoch 50/50\n",
      "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - accuracy: 0.9811 - loss: 0.0718 - val_accuracy: 0.2500 - val_loss: 7.5768\n",
      "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - accuracy: 0.7534 - loss: 2.3179 \n",
      "ANN Test Accuracy: 0.7559\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "from sklearn.preprocessing import LabelEncoder\n",
    "from sklearn.svm import SVC\n",
    "from sklearn.metrics import accuracy_score, classification_report\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "\n",
    "# Load the data\n",
    "train_data = np.load('./layer_features_base_960h/train_1.npz')\n",
    "test_data = np.load('./layer_features_base_960h/test_1.npz')\n",
    "\n",
    "train_features = train_data['features']\n",
    "test_features = test_data['features']\n",
    "\n",
    "# Read Age labels instead of Gender\n",
    "train_labels = pd.read_csv('y_train.csv').Age\n",
    "test_labels = pd.read_csv('y_test.csv').Age\n",
    "\n",
    "# Encode the labels\n",
    "label_encoder = LabelEncoder()\n",
    "train_labels_encoded = label_encoder.fit_transform(train_labels)\n",
    "\n",
    "# Handle unseen labels in test set by filtering out labels not present in train set\n",
    "test_labels_filtered = test_labels[test_labels.isin(train_labels.unique())]\n",
    "test_features_filtered = test_features[test_labels.isin(train_labels.unique())]\n",
    "test_labels_encoded = label_encoder.transform(test_labels_filtered)\n",
    "\n",
    "# Standardize features\n",
    "scaler = StandardScaler()\n",
    "train_features_normalized = scaler.fit_transform(train_features)\n",
    "test_features_normalized = scaler.transform(test_features_filtered)\n",
    "\n",
    "# SVM model\n",
    "svm_model = SVC(kernel='linear', C=10.0, gamma='scale', random_state=42)\n",
    "svm_model.fit(train_features_normalized, train_labels_encoded)\n",
    "\n",
    "# Prediction and Evaluation\n",
    "svm_predictions = svm_model.predict(test_features_normalized)\n",
    "svm_accuracy = accuracy_score(test_labels_encoded, svm_predictions)\n",
    "print(f\"SVM Accuracy: {svm_accuracy:.4f}\")\n",
    "print(\"SVM Classification Report:\")\n",
    "print(classification_report(test_labels_encoded, svm_predictions))\n",
    "\n",
    "# CNN model (TensorFlow)\n",
    "import tensorflow as tf\n",
    "from tensorflow.keras.models import Sequential\n",
    "from tensorflow.keras.layers import Conv1D, Flatten, Dense, Dropout\n",
    "\n",
    "train_features_cnn = np.expand_dims(train_features_normalized, axis=-1)  # Shape: (num_samples, 768, 1)\n",
    "test_features_cnn = np.expand_dims(test_features_normalized, axis=-1)    # Shape: (num_samples, 768, 1)\n",
    "\n",
    "cnn_model = Sequential([\n",
    "    Conv1D(64, kernel_size=5, activation='relu', input_shape=(768, 1)),  # Update input shape to 768 features\n",
    "    Conv1D(128, kernel_size=5, activation='relu'),\n",
    "    Conv1D(256, kernel_size=5, activation='relu'),\n",
    "    Flatten(),\n",
    "    Dense(256, activation='relu'),\n",
    "    Dropout(0.5),\n",
    "    Dense(len(label_encoder.classes_), activation='softmax')\n",
    "])\n",
    "\n",
    "cnn_model.compile(optimizer='adam', loss='sparse_categorical_crossentropy', metrics=['accuracy'])\n",
    "\n",
    "cnn_model.fit(train_features_cnn, train_labels_encoded, epochs=50, batch_size=32, validation_split=0.2)\n",
    "\n",
    "cnn_test_loss, cnn_test_accuracy = cnn_model.evaluate(test_features_cnn, test_labels_encoded)\n",
    "print(f\"CNN Test Accuracy: {cnn_test_accuracy:.4f}\")\n",
    "\n",
    "# ANN model (TensorFlow)\n",
    "ann_model = Sequential([\n",
    "    Dense(512, activation='relu', input_shape=(768,)),  # Update input shape to 768 features\n",
    "    Dropout(0.5),\n",
    "    Dense(256, activation='relu'),\n",
    "    Dropout(0.5),\n",
    "    Dense(128, activation='relu'),\n",
    "    Dropout(0.5),\n",
    "    Dense(len(label_encoder.classes_), activation='softmax')\n",
    "])\n",
    "\n",
    "ann_model.compile(optimizer='adam', loss='sparse_categorical_crossentropy', metrics=['accuracy'])\n",
    "\n",
    "ann_model.fit(train_features_normalized, train_labels_encoded, epochs=50, batch_size=32, validation_split=0.2)\n",
    "\n",
    "ann_test_loss, ann_test_accuracy = ann_model.evaluate(test_features_normalized, test_labels_encoded)\n",
    "print(f\"ANN Test Accuracy: {ann_test_accuracy:.4f}\")\n",
    "\n",
    "# PyTorch CNN Model\n",
    "import torch\n",
    "from torch.utils.data import DataLoader, TensorDataset\n",
    "\n",
    "X_train_tensor = torch.tensor(train_features_cnn, dtype=torch.float32).permute(0, 2, 1)  # Shape: (num_samples, 1, 768)\n",
    "y_train_tensor = torch.tensor(train_labels_encoded, dtype=torch.long)\n",
    "X_test_tensor = torch.tensor(test_features_cnn, dtype=torch.float32).permute(0, 2, 1)    # Shape: (num_samples, 1, 768)\n",
    "y_test_tensor = torch.tensor(test_labels_encoded, dtype=torch.long)\n",
    "\n",
    "train_dataset = TensorDataset(X_train_tensor, y_train_tensor)\n",
    "test_dataset = TensorDataset(X_test_tensor, y_test_tensor)\n",
    "\n",
    "train_loader = DataLoader(train_dataset, batch_size=64, shuffle=True)\n",
    "test_loader = DataLoader(test_dataset, batch_size=64, shuffle=False)\n",
    "\n",
    "import torch.nn as nn\n",
    "import torch.optim as optim\n",
    "\n",
    "class CNN1DModel(nn.Module):\n",
    "    def __init__(self, input_channels, num_classes):\n",
    "        super(CNN1DModel, self).__init__()\n",
    "        self.conv1 = nn.Conv1d(input_channels, 32, kernel_size=5, stride=1, padding=2)\n",
    "        self.bn1 = nn.BatchNorm1d(32)\n",
    "        self.relu = nn.ReLU()\n",
    "        self.conv2 = nn.Conv1d(32, 64, kernel_size=5, stride=1, padding=2)\n",
    "        self.bn2 = nn.BatchNorm1d(64)\n",
    "        self.conv3 = nn.Conv1d(64, 128, kernel_size=5, stride=1, padding=2)\n",
    "        self.bn3 = nn.BatchNorm1d(128)\n",
    "        self.flatten = nn.Flatten()\n",
    "        self.fc1 = nn.Linear(128 * 768, 512)  # Update to 768 features\n",
    "        self.fc2 = nn.Linear(512, num_classes)\n",
    "        self.dropout = nn.Dropout(0.5)\n",
    "    \n",
    "    def forward(self, x):\n",
    "        x = self.relu(self.bn1(self.conv1(x)))\n",
    "        x = self.relu(self.bn2(self.conv2(x)))\n",
    "        x = self.relu(self.bn3(self.conv3(x)))\n",
    "        x = self.flatten(x)\n",
    "        x = self.dropout(self.relu(self.fc1(x)))\n",
    "        x = self.fc2(x)\n",
    "        return x\n",
    "\n",
    "input_channels = 1\n",
    "num_classes = len(label_encoder.classes_)\n",
    "model = CNN1DModel(input_channels, num_classes)\n",
    "criterion = nn.CrossEntropyLoss()\n",
    "optimizer = optim.Adam(model.parameters(), lr=0.001)\n",
    "\n",
    "# Training and testing as before\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "f4518437",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "SVM Accuracy: 0.8504\n",
      "SVM Classification Report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           1       1.00      0.83      0.91        12\n",
      "           2       0.75      0.75      0.75         8\n",
      "           3       0.80      0.95      0.87        39\n",
      "           4       0.75      1.00      0.86         6\n",
      "           5       0.88      0.86      0.87        42\n",
      "           6       0.90      0.56      0.69        16\n",
      "           7       1.00      1.00      1.00         2\n",
      "           8       1.00      1.00      1.00         2\n",
      "\n",
      "    accuracy                           0.85       127\n",
      "   macro avg       0.89      0.87      0.87       127\n",
      "weighted avg       0.86      0.85      0.85       127\n",
      "\n",
      "Epoch 1/50\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/mojo/.local/lib/python3.10/site-packages/keras/src/layers/convolutional/base_conv.py:107: UserWarning: Do not pass an `input_shape`/`input_dim` argument to a layer. When using Sequential models, prefer using an `Input(shape)` object as the first layer in the model instead.\n",
      "  super().__init__(activity_regularizer=activity_regularizer, **kwargs)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m9s\u001b[0m 351ms/step - accuracy: 0.3571 - loss: 3.5172 - val_accuracy: 0.1977 - val_loss: 2.3074\n",
      "Epoch 2/50\n",
      "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m8s\u001b[0m 351ms/step - accuracy: 0.8124 - loss: 0.5498 - val_accuracy: 0.2733 - val_loss: 2.6801\n",
      "Epoch 3/50\n",
      "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m8s\u001b[0m 346ms/step - accuracy: 0.9320 - loss: 0.2273 - val_accuracy: 0.3663 - val_loss: 2.8147\n",
      "Epoch 4/50\n",
      "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m8s\u001b[0m 349ms/step - accuracy: 0.9727 - loss: 0.0950 - val_accuracy: 0.2209 - val_loss: 3.9458\n",
      "Epoch 5/50\n",
      "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m8s\u001b[0m 348ms/step - accuracy: 0.9971 - loss: 0.0330 - val_accuracy: 0.3023 - val_loss: 3.8096\n",
      "Epoch 6/50\n",
      "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m8s\u001b[0m 352ms/step - accuracy: 0.9949 - loss: 0.0356 - val_accuracy: 0.2384 - val_loss: 3.6950\n",
      "Epoch 7/50\n",
      "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m8s\u001b[0m 357ms/step - accuracy: 0.9907 - loss: 0.0246 - val_accuracy: 0.3081 - val_loss: 3.7125\n",
      "Epoch 8/50\n",
      "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m8s\u001b[0m 352ms/step - accuracy: 0.9963 - loss: 0.0203 - val_accuracy: 0.2326 - val_loss: 4.4883\n",
      "Epoch 9/50\n",
      "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m8s\u001b[0m 350ms/step - accuracy: 0.9956 - loss: 0.0126 - val_accuracy: 0.3198 - val_loss: 3.9420\n",
      "Epoch 10/50\n",
      "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m8s\u001b[0m 350ms/step - accuracy: 0.9939 - loss: 0.0145 - val_accuracy: 0.2674 - val_loss: 4.9590\n",
      "Epoch 11/50\n",
      "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m8s\u001b[0m 343ms/step - accuracy: 1.0000 - loss: 0.0043 - val_accuracy: 0.2558 - val_loss: 6.2344\n",
      "Epoch 12/50\n",
      "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m8s\u001b[0m 347ms/step - accuracy: 1.0000 - loss: 0.0016 - val_accuracy: 0.2674 - val_loss: 6.2293\n",
      "Epoch 13/50\n",
      "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m8s\u001b[0m 343ms/step - accuracy: 1.0000 - loss: 0.0023 - val_accuracy: 0.2326 - val_loss: 7.2882\n",
      "Epoch 14/50\n",
      "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m8s\u001b[0m 345ms/step - accuracy: 1.0000 - loss: 0.0030 - val_accuracy: 0.4186 - val_loss: 5.2703\n",
      "Epoch 15/50\n",
      "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m10s\u001b[0m 345ms/step - accuracy: 0.9932 - loss: 0.0116 - val_accuracy: 0.3314 - val_loss: 4.3997\n",
      "Epoch 16/50\n",
      "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m8s\u001b[0m 347ms/step - accuracy: 0.9990 - loss: 0.0072 - val_accuracy: 0.3256 - val_loss: 4.9440\n",
      "Epoch 17/50\n",
      "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m8s\u001b[0m 343ms/step - accuracy: 0.9994 - loss: 0.0050 - val_accuracy: 0.3488 - val_loss: 4.1952\n",
      "Epoch 18/50\n",
      "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m8s\u001b[0m 346ms/step - accuracy: 0.9986 - loss: 0.0073 - val_accuracy: 0.3140 - val_loss: 5.0426\n",
      "Epoch 19/50\n",
      "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m8s\u001b[0m 345ms/step - accuracy: 0.9911 - loss: 0.0328 - val_accuracy: 0.2733 - val_loss: 3.6066\n",
      "Epoch 20/50\n",
      "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m8s\u001b[0m 345ms/step - accuracy: 0.9951 - loss: 0.0263 - val_accuracy: 0.2442 - val_loss: 5.5959\n",
      "Epoch 21/50\n",
      "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m8s\u001b[0m 346ms/step - accuracy: 0.9980 - loss: 0.0065 - val_accuracy: 0.3198 - val_loss: 4.5540\n",
      "Epoch 22/50\n",
      "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m8s\u001b[0m 345ms/step - accuracy: 0.9970 - loss: 0.0080 - val_accuracy: 0.2674 - val_loss: 5.3734\n",
      "Epoch 23/50\n",
      "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m8s\u001b[0m 347ms/step - accuracy: 0.9970 - loss: 0.0052 - val_accuracy: 0.2267 - val_loss: 5.9491\n",
      "Epoch 24/50\n",
      "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m8s\u001b[0m 345ms/step - accuracy: 0.9988 - loss: 0.0057 - val_accuracy: 0.2733 - val_loss: 4.5205\n",
      "Epoch 25/50\n",
      "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m8s\u001b[0m 348ms/step - accuracy: 1.0000 - loss: 0.0019 - val_accuracy: 0.2965 - val_loss: 5.0767\n",
      "Epoch 26/50\n",
      "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m8s\u001b[0m 345ms/step - accuracy: 0.9976 - loss: 0.0044 - val_accuracy: 0.3895 - val_loss: 4.4477\n",
      "Epoch 27/50\n",
      "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m8s\u001b[0m 345ms/step - accuracy: 0.9998 - loss: 0.0041 - val_accuracy: 0.3488 - val_loss: 4.8718\n",
      "Epoch 28/50\n",
      "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m8s\u001b[0m 352ms/step - accuracy: 0.9978 - loss: 0.0058 - val_accuracy: 0.2733 - val_loss: 4.7593\n",
      "Epoch 29/50\n",
      "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m8s\u001b[0m 350ms/step - accuracy: 0.9954 - loss: 0.0094 - val_accuracy: 0.2791 - val_loss: 5.2399\n",
      "Epoch 30/50\n",
      "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m8s\u001b[0m 357ms/step - accuracy: 0.9997 - loss: 0.0035 - val_accuracy: 0.2791 - val_loss: 5.1635\n",
      "Epoch 31/50\n",
      "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m8s\u001b[0m 354ms/step - accuracy: 1.0000 - loss: 0.0017 - val_accuracy: 0.2791 - val_loss: 5.3507\n",
      "Epoch 32/50\n",
      "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m8s\u001b[0m 357ms/step - accuracy: 0.9995 - loss: 0.0021 - val_accuracy: 0.2791 - val_loss: 5.8346\n",
      "Epoch 33/50\n",
      "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m8s\u001b[0m 357ms/step - accuracy: 1.0000 - loss: 8.9458e-04 - val_accuracy: 0.2616 - val_loss: 6.4165\n",
      "Epoch 34/50\n",
      "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m8s\u001b[0m 354ms/step - accuracy: 1.0000 - loss: 0.0015 - val_accuracy: 0.2791 - val_loss: 6.0703\n",
      "Epoch 35/50\n",
      "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m8s\u001b[0m 356ms/step - accuracy: 1.0000 - loss: 2.3252e-04 - val_accuracy: 0.2907 - val_loss: 6.1012\n",
      "Epoch 36/50\n",
      "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m8s\u001b[0m 354ms/step - accuracy: 1.0000 - loss: 3.2049e-04 - val_accuracy: 0.2849 - val_loss: 6.3620\n",
      "Epoch 37/50\n",
      "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m8s\u001b[0m 357ms/step - accuracy: 1.0000 - loss: 0.0014 - val_accuracy: 0.3605 - val_loss: 5.3353\n",
      "Epoch 38/50\n",
      "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m8s\u001b[0m 356ms/step - accuracy: 1.0000 - loss: 1.1640e-04 - val_accuracy: 0.3663 - val_loss: 5.4672\n",
      "Epoch 39/50\n",
      "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m8s\u001b[0m 354ms/step - accuracy: 1.0000 - loss: 3.6660e-04 - val_accuracy: 0.3605 - val_loss: 5.7310\n",
      "Epoch 40/50\n",
      "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m8s\u001b[0m 353ms/step - accuracy: 1.0000 - loss: 9.1576e-05 - val_accuracy: 0.3314 - val_loss: 6.1620\n",
      "Epoch 41/50\n",
      "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m8s\u001b[0m 351ms/step - accuracy: 1.0000 - loss: 1.9458e-04 - val_accuracy: 0.3256 - val_loss: 6.4681\n",
      "Epoch 42/50\n",
      "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m8s\u001b[0m 354ms/step - accuracy: 1.0000 - loss: 1.3475e-04 - val_accuracy: 0.3198 - val_loss: 6.5913\n",
      "Epoch 43/50\n",
      "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m8s\u001b[0m 357ms/step - accuracy: 1.0000 - loss: 3.3170e-05 - val_accuracy: 0.3081 - val_loss: 6.6144\n",
      "Epoch 44/50\n",
      "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m8s\u001b[0m 354ms/step - accuracy: 1.0000 - loss: 1.4091e-04 - val_accuracy: 0.3023 - val_loss: 6.8184\n",
      "Epoch 45/50\n",
      "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m8s\u001b[0m 354ms/step - accuracy: 0.9996 - loss: 9.1966e-04 - val_accuracy: 0.2965 - val_loss: 6.9833\n",
      "Epoch 46/50\n",
      "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m8s\u001b[0m 355ms/step - accuracy: 1.0000 - loss: 1.7805e-04 - val_accuracy: 0.2733 - val_loss: 7.0584\n",
      "Epoch 47/50\n",
      "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m8s\u001b[0m 354ms/step - accuracy: 1.0000 - loss: 1.0388e-04 - val_accuracy: 0.2733 - val_loss: 7.4067\n",
      "Epoch 48/50\n",
      "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m8s\u001b[0m 353ms/step - accuracy: 1.0000 - loss: 6.0099e-04 - val_accuracy: 0.2326 - val_loss: 8.5697\n",
      "Epoch 49/50\n",
      "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m8s\u001b[0m 354ms/step - accuracy: 1.0000 - loss: 4.0992e-04 - val_accuracy: 0.2500 - val_loss: 8.3629\n",
      "Epoch 50/50\n",
      "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m8s\u001b[0m 353ms/step - accuracy: 1.0000 - loss: 8.6102e-04 - val_accuracy: 0.2500 - val_loss: 8.3287\n",
      "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 39ms/step - accuracy: 0.7921 - loss: 1.9541\n",
      "CNN Test Accuracy: 0.8031\n",
      "Epoch 1/50\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/mojo/.local/lib/python3.10/site-packages/keras/src/layers/core/dense.py:87: UserWarning: Do not pass an `input_shape`/`input_dim` argument to a layer. When using Sequential models, prefer using an `Input(shape)` object as the first layer in the model instead.\n",
      "  super().__init__(activity_regularizer=activity_regularizer, **kwargs)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 7ms/step - accuracy: 0.3137 - loss: 2.6858 - val_accuracy: 0.0058 - val_loss: 2.5678\n",
      "Epoch 2/50\n",
      "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.4674 - loss: 1.7812 - val_accuracy: 0.1047 - val_loss: 2.4914\n",
      "Epoch 3/50\n",
      "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.5590 - loss: 1.3429 - val_accuracy: 0.2093 - val_loss: 2.3061\n",
      "Epoch 4/50\n",
      "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.6637 - loss: 1.0778 - val_accuracy: 0.2791 - val_loss: 2.2079\n",
      "Epoch 5/50\n",
      "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.6806 - loss: 0.9500 - val_accuracy: 0.3023 - val_loss: 2.1665\n",
      "Epoch 6/50\n",
      "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.7238 - loss: 0.8080 - val_accuracy: 0.3372 - val_loss: 2.1859\n",
      "Epoch 7/50\n",
      "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.7460 - loss: 0.7439 - val_accuracy: 0.3488 - val_loss: 2.3061\n",
      "Epoch 8/50\n",
      "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.8178 - loss: 0.5312 - val_accuracy: 0.4070 - val_loss: 2.2105\n",
      "Epoch 9/50\n",
      "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.8530 - loss: 0.4513 - val_accuracy: 0.3081 - val_loss: 2.7087\n",
      "Epoch 10/50\n",
      "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.8136 - loss: 0.4619 - val_accuracy: 0.2616 - val_loss: 3.3189\n",
      "Epoch 11/50\n",
      "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.8795 - loss: 0.3558 - val_accuracy: 0.3140 - val_loss: 3.0539\n",
      "Epoch 12/50\n",
      "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.9067 - loss: 0.2807 - val_accuracy: 0.2616 - val_loss: 3.2415\n",
      "Epoch 13/50\n",
      "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.9190 - loss: 0.2812 - val_accuracy: 0.2558 - val_loss: 3.8241\n",
      "Epoch 14/50\n",
      "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.9166 - loss: 0.2647 - val_accuracy: 0.3372 - val_loss: 3.5653\n",
      "Epoch 15/50\n",
      "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.9470 - loss: 0.1826 - val_accuracy: 0.3023 - val_loss: 3.8364\n",
      "Epoch 16/50\n",
      "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.9461 - loss: 0.2100 - val_accuracy: 0.2616 - val_loss: 4.3800\n",
      "Epoch 17/50\n",
      "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.9451 - loss: 0.1565 - val_accuracy: 0.2965 - val_loss: 4.3876\n",
      "Epoch 18/50\n",
      "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.9336 - loss: 0.1854 - val_accuracy: 0.2674 - val_loss: 4.0039\n",
      "Epoch 19/50\n",
      "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.9464 - loss: 0.1360 - val_accuracy: 0.3140 - val_loss: 3.8581\n",
      "Epoch 20/50\n",
      "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.9391 - loss: 0.1869 - val_accuracy: 0.2965 - val_loss: 4.1028\n",
      "Epoch 21/50\n",
      "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.9498 - loss: 0.1614 - val_accuracy: 0.2442 - val_loss: 4.9330\n",
      "Epoch 22/50\n",
      "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.9324 - loss: 0.1516 - val_accuracy: 0.2791 - val_loss: 4.7490\n",
      "Epoch 23/50\n",
      "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.9680 - loss: 0.0970 - val_accuracy: 0.3256 - val_loss: 4.5494\n",
      "Epoch 24/50\n",
      "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.9688 - loss: 0.1284 - val_accuracy: 0.3198 - val_loss: 5.4505\n",
      "Epoch 25/50\n",
      "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.9767 - loss: 0.0902 - val_accuracy: 0.2500 - val_loss: 5.6423\n",
      "Epoch 26/50\n",
      "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.9667 - loss: 0.1028 - val_accuracy: 0.2093 - val_loss: 5.6632\n",
      "Epoch 27/50\n",
      "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.9759 - loss: 0.0835 - val_accuracy: 0.2209 - val_loss: 5.8215\n",
      "Epoch 28/50\n",
      "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - accuracy: 0.9839 - loss: 0.0657 - val_accuracy: 0.3256 - val_loss: 5.5393\n",
      "Epoch 29/50\n",
      "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.9697 - loss: 0.1095 - val_accuracy: 0.3430 - val_loss: 5.5715\n",
      "Epoch 30/50\n",
      "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.9870 - loss: 0.0447 - val_accuracy: 0.2616 - val_loss: 6.9154\n",
      "Epoch 31/50\n",
      "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.9723 - loss: 0.0621 - val_accuracy: 0.2849 - val_loss: 6.7413\n",
      "Epoch 32/50\n",
      "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.9803 - loss: 0.0650 - val_accuracy: 0.2151 - val_loss: 7.8336\n",
      "Epoch 33/50\n",
      "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.9567 - loss: 0.1704 - val_accuracy: 0.3023 - val_loss: 6.3865\n",
      "Epoch 34/50\n",
      "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.9747 - loss: 0.1190 - val_accuracy: 0.2849 - val_loss: 6.6006\n",
      "Epoch 35/50\n",
      "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.9721 - loss: 0.1069 - val_accuracy: 0.2616 - val_loss: 6.5824\n",
      "Epoch 36/50\n",
      "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.9707 - loss: 0.0921 - val_accuracy: 0.3372 - val_loss: 5.8650\n",
      "Epoch 37/50\n",
      "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.9554 - loss: 0.1227 - val_accuracy: 0.1977 - val_loss: 7.9152\n",
      "Epoch 38/50\n",
      "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.9696 - loss: 0.0945 - val_accuracy: 0.3081 - val_loss: 6.6814\n",
      "Epoch 39/50\n",
      "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.9783 - loss: 0.0897 - val_accuracy: 0.2965 - val_loss: 6.9103\n",
      "Epoch 40/50\n",
      "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.9863 - loss: 0.0486 - val_accuracy: 0.3198 - val_loss: 6.7661\n",
      "Epoch 41/50\n",
      "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.9645 - loss: 0.0929 - val_accuracy: 0.2151 - val_loss: 7.4942\n",
      "Epoch 42/50\n",
      "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.9785 - loss: 0.0753 - val_accuracy: 0.2733 - val_loss: 6.6499\n",
      "Epoch 43/50\n",
      "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - accuracy: 0.9862 - loss: 0.0591 - val_accuracy: 0.2616 - val_loss: 7.0277\n",
      "Epoch 44/50\n",
      "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.9886 - loss: 0.0561 - val_accuracy: 0.2442 - val_loss: 8.2052\n",
      "Epoch 45/50\n",
      "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.9848 - loss: 0.0577 - val_accuracy: 0.2907 - val_loss: 7.6832\n",
      "Epoch 46/50\n",
      "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.9691 - loss: 0.0882 - val_accuracy: 0.2209 - val_loss: 9.3053\n",
      "Epoch 47/50\n",
      "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.9815 - loss: 0.0525 - val_accuracy: 0.2209 - val_loss: 10.1676\n",
      "Epoch 48/50\n",
      "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.9602 - loss: 0.1019 - val_accuracy: 0.2965 - val_loss: 8.5279\n",
      "Epoch 49/50\n",
      "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.9846 - loss: 0.0633 - val_accuracy: 0.2849 - val_loss: 8.2360\n",
      "Epoch 50/50\n",
      "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.9942 - loss: 0.0336 - val_accuracy: 0.2674 - val_loss: 8.6067\n",
      "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.7806 - loss: 2.1959 \n",
      "ANN Test Accuracy: 0.8031\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "from sklearn.preprocessing import LabelEncoder\n",
    "from sklearn.svm import SVC\n",
    "from sklearn.metrics import accuracy_score, classification_report\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "\n",
    "# Load the data\n",
    "train_data = np.load('./layer_features_base_960h/train_2.npz')\n",
    "test_data = np.load('./layer_features_base_960h/test_2.npz')\n",
    "\n",
    "train_features = train_data['features']\n",
    "test_features = test_data['features']\n",
    "\n",
    "# Read Age labels instead of Gender\n",
    "train_labels = pd.read_csv('y_train.csv').Age\n",
    "test_labels = pd.read_csv('y_test.csv').Age\n",
    "\n",
    "# Encode the labels\n",
    "label_encoder = LabelEncoder()\n",
    "train_labels_encoded = label_encoder.fit_transform(train_labels)\n",
    "\n",
    "# Handle unseen labels in test set by filtering out labels not present in train set\n",
    "test_labels_filtered = test_labels[test_labels.isin(train_labels.unique())]\n",
    "test_features_filtered = test_features[test_labels.isin(train_labels.unique())]\n",
    "test_labels_encoded = label_encoder.transform(test_labels_filtered)\n",
    "\n",
    "# Standardize features\n",
    "scaler = StandardScaler()\n",
    "train_features_normalized = scaler.fit_transform(train_features)\n",
    "test_features_normalized = scaler.transform(test_features_filtered)\n",
    "\n",
    "# SVM model\n",
    "svm_model = SVC(kernel='linear', C=10.0, gamma='scale', random_state=42)\n",
    "svm_model.fit(train_features_normalized, train_labels_encoded)\n",
    "\n",
    "# Prediction and Evaluation\n",
    "svm_predictions = svm_model.predict(test_features_normalized)\n",
    "svm_accuracy = accuracy_score(test_labels_encoded, svm_predictions)\n",
    "print(f\"SVM Accuracy: {svm_accuracy:.4f}\")\n",
    "print(\"SVM Classification Report:\")\n",
    "print(classification_report(test_labels_encoded, svm_predictions))\n",
    "\n",
    "# CNN model (TensorFlow)\n",
    "import tensorflow as tf\n",
    "from tensorflow.keras.models import Sequential\n",
    "from tensorflow.keras.layers import Conv1D, Flatten, Dense, Dropout\n",
    "\n",
    "train_features_cnn = np.expand_dims(train_features_normalized, axis=-1)  # Shape: (num_samples, 768, 1)\n",
    "test_features_cnn = np.expand_dims(test_features_normalized, axis=-1)    # Shape: (num_samples, 768, 1)\n",
    "\n",
    "cnn_model = Sequential([\n",
    "    Conv1D(64, kernel_size=5, activation='relu', input_shape=(768, 1)),  # Update input shape to 768 features\n",
    "    Conv1D(128, kernel_size=5, activation='relu'),\n",
    "    Conv1D(256, kernel_size=5, activation='relu'),\n",
    "    Flatten(),\n",
    "    Dense(256, activation='relu'),\n",
    "    Dropout(0.5),\n",
    "    Dense(len(label_encoder.classes_), activation='softmax')\n",
    "])\n",
    "\n",
    "cnn_model.compile(optimizer='adam', loss='sparse_categorical_crossentropy', metrics=['accuracy'])\n",
    "\n",
    "cnn_model.fit(train_features_cnn, train_labels_encoded, epochs=50, batch_size=32, validation_split=0.2)\n",
    "\n",
    "cnn_test_loss, cnn_test_accuracy = cnn_model.evaluate(test_features_cnn, test_labels_encoded)\n",
    "print(f\"CNN Test Accuracy: {cnn_test_accuracy:.4f}\")\n",
    "\n",
    "# ANN model (TensorFlow)\n",
    "ann_model = Sequential([\n",
    "    Dense(512, activation='relu', input_shape=(768,)),  # Update input shape to 768 features\n",
    "    Dropout(0.5),\n",
    "    Dense(256, activation='relu'),\n",
    "    Dropout(0.5),\n",
    "    Dense(128, activation='relu'),\n",
    "    Dropout(0.5),\n",
    "    Dense(len(label_encoder.classes_), activation='softmax')\n",
    "])\n",
    "\n",
    "ann_model.compile(optimizer='adam', loss='sparse_categorical_crossentropy', metrics=['accuracy'])\n",
    "\n",
    "ann_model.fit(train_features_normalized, train_labels_encoded, epochs=50, batch_size=32, validation_split=0.2)\n",
    "\n",
    "ann_test_loss, ann_test_accuracy = ann_model.evaluate(test_features_normalized, test_labels_encoded)\n",
    "print(f\"ANN Test Accuracy: {ann_test_accuracy:.4f}\")\n",
    "\n",
    "# PyTorch CNN Model\n",
    "import torch\n",
    "from torch.utils.data import DataLoader, TensorDataset\n",
    "\n",
    "X_train_tensor = torch.tensor(train_features_cnn, dtype=torch.float32).permute(0, 2, 1)  # Shape: (num_samples, 1, 768)\n",
    "y_train_tensor = torch.tensor(train_labels_encoded, dtype=torch.long)\n",
    "X_test_tensor = torch.tensor(test_features_cnn, dtype=torch.float32).permute(0, 2, 1)    # Shape: (num_samples, 1, 768)\n",
    "y_test_tensor = torch.tensor(test_labels_encoded, dtype=torch.long)\n",
    "\n",
    "train_dataset = TensorDataset(X_train_tensor, y_train_tensor)\n",
    "test_dataset = TensorDataset(X_test_tensor, y_test_tensor)\n",
    "\n",
    "train_loader = DataLoader(train_dataset, batch_size=64, shuffle=True)\n",
    "test_loader = DataLoader(test_dataset, batch_size=64, shuffle=False)\n",
    "\n",
    "import torch.nn as nn\n",
    "import torch.optim as optim\n",
    "\n",
    "class CNN1DModel(nn.Module):\n",
    "    def __init__(self, input_channels, num_classes):\n",
    "        super(CNN1DModel, self).__init__()\n",
    "        self.conv1 = nn.Conv1d(input_channels, 32, kernel_size=5, stride=1, padding=2)\n",
    "        self.bn1 = nn.BatchNorm1d(32)\n",
    "        self.relu = nn.ReLU()\n",
    "        self.conv2 = nn.Conv1d(32, 64, kernel_size=5, stride=1, padding=2)\n",
    "        self.bn2 = nn.BatchNorm1d(64)\n",
    "        self.conv3 = nn.Conv1d(64, 128, kernel_size=5, stride=1, padding=2)\n",
    "        self.bn3 = nn.BatchNorm1d(128)\n",
    "        self.flatten = nn.Flatten()\n",
    "        self.fc1 = nn.Linear(128 * 768, 512)  # Update to 768 features\n",
    "        self.fc2 = nn.Linear(512, num_classes)\n",
    "        self.dropout = nn.Dropout(0.5)\n",
    "    \n",
    "    def forward(self, x):\n",
    "        x = self.relu(self.bn1(self.conv1(x)))\n",
    "        x = self.relu(self.bn2(self.conv2(x)))\n",
    "        x = self.relu(self.bn3(self.conv3(x)))\n",
    "        x = self.flatten(x)\n",
    "        x = self.dropout(self.relu(self.fc1(x)))\n",
    "        x = self.fc2(x)\n",
    "        return x\n",
    "\n",
    "input_channels = 1\n",
    "num_classes = len(label_encoder.classes_)\n",
    "model = CNN1DModel(input_channels, num_classes)\n",
    "criterion = nn.CrossEntropyLoss()\n",
    "optimizer = optim.Adam(model.parameters(), lr=0.001)\n",
    "\n",
    "# Training and testing as before\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "f8b22b56",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "SVM Accuracy: 0.8898\n",
      "SVM Classification Report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           1       0.91      0.83      0.87        12\n",
      "           2       0.78      0.88      0.82         8\n",
      "           3       0.87      1.00      0.93        39\n",
      "           4       1.00      1.00      1.00         6\n",
      "           5       0.90      0.90      0.90        42\n",
      "           6       0.90      0.56      0.69        16\n",
      "           7       1.00      1.00      1.00         2\n",
      "           8       1.00      1.00      1.00         2\n",
      "\n",
      "    accuracy                           0.89       127\n",
      "   macro avg       0.92      0.90      0.90       127\n",
      "weighted avg       0.89      0.89      0.88       127\n",
      "\n",
      "Epoch 1/50\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/mojo/.local/lib/python3.10/site-packages/keras/src/layers/convolutional/base_conv.py:107: UserWarning: Do not pass an `input_shape`/`input_dim` argument to a layer. When using Sequential models, prefer using an `Input(shape)` object as the first layer in the model instead.\n",
      "  super().__init__(activity_regularizer=activity_regularizer, **kwargs)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m9s\u001b[0m 372ms/step - accuracy: 0.3627 - loss: 2.8811 - val_accuracy: 0.4186 - val_loss: 1.5319\n",
      "Epoch 2/50\n",
      "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m8s\u001b[0m 360ms/step - accuracy: 0.8424 - loss: 0.4827 - val_accuracy: 0.3198 - val_loss: 2.4800\n",
      "Epoch 3/50\n",
      "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m8s\u001b[0m 361ms/step - accuracy: 0.9680 - loss: 0.1408 - val_accuracy: 0.2035 - val_loss: 3.8111\n",
      "Epoch 4/50\n",
      "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m8s\u001b[0m 358ms/step - accuracy: 0.9873 - loss: 0.0628 - val_accuracy: 0.2267 - val_loss: 3.8456\n",
      "Epoch 5/50\n",
      "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m8s\u001b[0m 358ms/step - accuracy: 0.9937 - loss: 0.0306 - val_accuracy: 0.3081 - val_loss: 3.0564\n",
      "Epoch 6/50\n",
      "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m8s\u001b[0m 359ms/step - accuracy: 0.9990 - loss: 0.0167 - val_accuracy: 0.2733 - val_loss: 3.9437\n",
      "Epoch 7/50\n",
      "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m8s\u001b[0m 357ms/step - accuracy: 0.9980 - loss: 0.0111 - val_accuracy: 0.2849 - val_loss: 3.7745\n",
      "Epoch 8/50\n",
      "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m8s\u001b[0m 357ms/step - accuracy: 0.9977 - loss: 0.0064 - val_accuracy: 0.3488 - val_loss: 3.8600\n",
      "Epoch 9/50\n",
      "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m8s\u001b[0m 357ms/step - accuracy: 0.9923 - loss: 0.0135 - val_accuracy: 0.3430 - val_loss: 4.0992\n",
      "Epoch 10/50\n",
      "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m8s\u001b[0m 361ms/step - accuracy: 0.9976 - loss: 0.0118 - val_accuracy: 0.3779 - val_loss: 2.8524\n",
      "Epoch 11/50\n",
      "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m8s\u001b[0m 363ms/step - accuracy: 0.9958 - loss: 0.0128 - val_accuracy: 0.3605 - val_loss: 3.0441\n",
      "Epoch 12/50\n",
      "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m8s\u001b[0m 364ms/step - accuracy: 0.9980 - loss: 0.0097 - val_accuracy: 0.3198 - val_loss: 4.0140\n",
      "Epoch 13/50\n",
      "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m8s\u001b[0m 362ms/step - accuracy: 1.0000 - loss: 0.0021 - val_accuracy: 0.2733 - val_loss: 4.6817\n",
      "Epoch 14/50\n",
      "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m8s\u001b[0m 371ms/step - accuracy: 0.9993 - loss: 0.0029 - val_accuracy: 0.2849 - val_loss: 4.9728\n",
      "Epoch 15/50\n",
      "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m8s\u001b[0m 369ms/step - accuracy: 0.9832 - loss: 0.0338 - val_accuracy: 0.2907 - val_loss: 3.6804\n",
      "Epoch 16/50\n",
      "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m8s\u001b[0m 368ms/step - accuracy: 0.9974 - loss: 0.0087 - val_accuracy: 0.1279 - val_loss: 6.4612\n",
      "Epoch 17/50\n",
      "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m8s\u001b[0m 373ms/step - accuracy: 0.9973 - loss: 0.0141 - val_accuracy: 0.2267 - val_loss: 4.9278\n",
      "Epoch 18/50\n",
      "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m8s\u001b[0m 368ms/step - accuracy: 0.9975 - loss: 0.0082 - val_accuracy: 0.2965 - val_loss: 4.1451\n",
      "Epoch 19/50\n",
      "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m8s\u001b[0m 368ms/step - accuracy: 1.0000 - loss: 0.0040 - val_accuracy: 0.2558 - val_loss: 5.2945\n",
      "Epoch 20/50\n",
      "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m8s\u001b[0m 366ms/step - accuracy: 0.9963 - loss: 0.0111 - val_accuracy: 0.1977 - val_loss: 5.8782\n",
      "Epoch 21/50\n",
      "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m8s\u001b[0m 367ms/step - accuracy: 1.0000 - loss: 7.0703e-04 - val_accuracy: 0.2035 - val_loss: 6.8995\n",
      "Epoch 22/50\n",
      "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m8s\u001b[0m 368ms/step - accuracy: 1.0000 - loss: 6.8532e-04 - val_accuracy: 0.2616 - val_loss: 6.6449\n",
      "Epoch 23/50\n",
      "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m8s\u001b[0m 371ms/step - accuracy: 1.0000 - loss: 4.4752e-04 - val_accuracy: 0.3140 - val_loss: 6.1902\n",
      "Epoch 24/50\n",
      "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m8s\u001b[0m 367ms/step - accuracy: 1.0000 - loss: 2.5609e-04 - val_accuracy: 0.2733 - val_loss: 6.5836\n",
      "Epoch 25/50\n",
      "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m8s\u001b[0m 368ms/step - accuracy: 0.9982 - loss: 0.0052 - val_accuracy: 0.2500 - val_loss: 6.8641\n",
      "Epoch 26/50\n",
      "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m8s\u001b[0m 368ms/step - accuracy: 0.9961 - loss: 0.0070 - val_accuracy: 0.2849 - val_loss: 5.0892\n",
      "Epoch 27/50\n",
      "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m8s\u001b[0m 368ms/step - accuracy: 1.0000 - loss: 0.0024 - val_accuracy: 0.2849 - val_loss: 5.9272\n",
      "Epoch 28/50\n",
      "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m8s\u001b[0m 367ms/step - accuracy: 0.9997 - loss: 8.3073e-04 - val_accuracy: 0.2674 - val_loss: 6.4783\n",
      "Epoch 29/50\n",
      "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m8s\u001b[0m 367ms/step - accuracy: 1.0000 - loss: 9.2677e-04 - val_accuracy: 0.2733 - val_loss: 6.6763\n",
      "Epoch 30/50\n",
      "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m8s\u001b[0m 363ms/step - accuracy: 0.9980 - loss: 0.0039 - val_accuracy: 0.3256 - val_loss: 6.5251\n",
      "Epoch 31/50\n",
      "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m8s\u001b[0m 365ms/step - accuracy: 0.9980 - loss: 0.0046 - val_accuracy: 0.2907 - val_loss: 6.8754\n",
      "Epoch 32/50\n",
      "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m8s\u001b[0m 366ms/step - accuracy: 0.9998 - loss: 0.0019 - val_accuracy: 0.3023 - val_loss: 6.4138\n",
      "Epoch 33/50\n",
      "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m8s\u001b[0m 364ms/step - accuracy: 1.0000 - loss: 0.0035 - val_accuracy: 0.2907 - val_loss: 5.1908\n",
      "Epoch 34/50\n",
      "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m8s\u001b[0m 366ms/step - accuracy: 1.0000 - loss: 6.2397e-04 - val_accuracy: 0.3140 - val_loss: 5.3266\n",
      "Epoch 35/50\n",
      "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m8s\u001b[0m 365ms/step - accuracy: 0.9949 - loss: 0.0068 - val_accuracy: 0.3198 - val_loss: 5.5684\n",
      "Epoch 36/50\n",
      "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m8s\u001b[0m 361ms/step - accuracy: 0.9996 - loss: 9.8272e-04 - val_accuracy: 0.3314 - val_loss: 5.5115\n",
      "Epoch 37/50\n",
      "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m8s\u001b[0m 364ms/step - accuracy: 1.0000 - loss: 3.0883e-04 - val_accuracy: 0.2791 - val_loss: 6.3546\n",
      "Epoch 38/50\n",
      "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m8s\u001b[0m 364ms/step - accuracy: 1.0000 - loss: 0.0014 - val_accuracy: 0.3256 - val_loss: 6.2578\n",
      "Epoch 39/50\n",
      "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m8s\u001b[0m 362ms/step - accuracy: 1.0000 - loss: 5.0114e-04 - val_accuracy: 0.3023 - val_loss: 6.5758\n",
      "Epoch 40/50\n",
      "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m8s\u001b[0m 361ms/step - accuracy: 1.0000 - loss: 8.2718e-05 - val_accuracy: 0.2791 - val_loss: 7.3599\n",
      "Epoch 41/50\n",
      "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m8s\u001b[0m 361ms/step - accuracy: 1.0000 - loss: 1.5955e-04 - val_accuracy: 0.2791 - val_loss: 7.3847\n",
      "Epoch 42/50\n",
      "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m8s\u001b[0m 367ms/step - accuracy: 1.0000 - loss: 5.1230e-04 - val_accuracy: 0.2674 - val_loss: 7.8807\n",
      "Epoch 43/50\n",
      "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m8s\u001b[0m 363ms/step - accuracy: 1.0000 - loss: 1.2482e-04 - val_accuracy: 0.2558 - val_loss: 8.1480\n",
      "Epoch 44/50\n",
      "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m8s\u001b[0m 365ms/step - accuracy: 1.0000 - loss: 1.6188e-04 - val_accuracy: 0.2209 - val_loss: 8.6824\n",
      "Epoch 45/50\n",
      "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m8s\u001b[0m 366ms/step - accuracy: 1.0000 - loss: 7.6608e-05 - val_accuracy: 0.2151 - val_loss: 8.9162\n",
      "Epoch 46/50\n",
      "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m8s\u001b[0m 364ms/step - accuracy: 0.9974 - loss: 0.0028 - val_accuracy: 0.3198 - val_loss: 5.9915\n",
      "Epoch 47/50\n",
      "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m8s\u001b[0m 366ms/step - accuracy: 0.9993 - loss: 0.0023 - val_accuracy: 0.3140 - val_loss: 4.9939\n",
      "Epoch 48/50\n",
      "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m8s\u001b[0m 364ms/step - accuracy: 1.0000 - loss: 0.0022 - val_accuracy: 0.3023 - val_loss: 5.9522\n",
      "Epoch 49/50\n",
      "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m8s\u001b[0m 359ms/step - accuracy: 1.0000 - loss: 6.0496e-04 - val_accuracy: 0.2674 - val_loss: 6.9139\n",
      "Epoch 50/50\n",
      "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m8s\u001b[0m 361ms/step - accuracy: 1.0000 - loss: 4.4688e-04 - val_accuracy: 0.2500 - val_loss: 7.6022\n",
      "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 36ms/step - accuracy: 0.7836 - loss: 2.0042\n",
      "CNN Test Accuracy: 0.7638\n",
      "Epoch 1/50\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/mojo/.local/lib/python3.10/site-packages/keras/src/layers/core/dense.py:87: UserWarning: Do not pass an `input_shape`/`input_dim` argument to a layer. When using Sequential models, prefer using an `Input(shape)` object as the first layer in the model instead.\n",
      "  super().__init__(activity_regularizer=activity_regularizer, **kwargs)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 7ms/step - accuracy: 0.2485 - loss: 3.0386 - val_accuracy: 0.0640 - val_loss: 2.2277\n",
      "Epoch 2/50\n",
      "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.4549 - loss: 1.6887 - val_accuracy: 0.1686 - val_loss: 2.2179\n",
      "Epoch 3/50\n",
      "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.5351 - loss: 1.5303 - val_accuracy: 0.3081 - val_loss: 2.0016\n",
      "Epoch 4/50\n",
      "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.5687 - loss: 1.0992 - val_accuracy: 0.3547 - val_loss: 2.1092\n",
      "Epoch 5/50\n",
      "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.6638 - loss: 0.9482 - val_accuracy: 0.2907 - val_loss: 2.3329\n",
      "Epoch 6/50\n",
      "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.7460 - loss: 0.7550 - val_accuracy: 0.3372 - val_loss: 2.3549\n",
      "Epoch 7/50\n",
      "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.7763 - loss: 0.6610 - val_accuracy: 0.2965 - val_loss: 2.5506\n",
      "Epoch 8/50\n",
      "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.7769 - loss: 0.6444 - val_accuracy: 0.3663 - val_loss: 2.6948\n",
      "Epoch 9/50\n",
      "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.7991 - loss: 0.4963 - val_accuracy: 0.3663 - val_loss: 2.9136\n",
      "Epoch 10/50\n",
      "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.8698 - loss: 0.3495 - val_accuracy: 0.3023 - val_loss: 3.5012\n",
      "Epoch 11/50\n",
      "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.8811 - loss: 0.3655 - val_accuracy: 0.3198 - val_loss: 3.2559\n",
      "Epoch 12/50\n",
      "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.9126 - loss: 0.2824 - val_accuracy: 0.2849 - val_loss: 3.5750\n",
      "Epoch 13/50\n",
      "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.9153 - loss: 0.2645 - val_accuracy: 0.3081 - val_loss: 3.8226\n",
      "Epoch 14/50\n",
      "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.9508 - loss: 0.1738 - val_accuracy: 0.3256 - val_loss: 4.2324\n",
      "Epoch 15/50\n",
      "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.9413 - loss: 0.1968 - val_accuracy: 0.2791 - val_loss: 5.1169\n",
      "Epoch 16/50\n",
      "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.9407 - loss: 0.1590 - val_accuracy: 0.3081 - val_loss: 5.3392\n",
      "Epoch 17/50\n",
      "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.9530 - loss: 0.1611 - val_accuracy: 0.3081 - val_loss: 4.8117\n",
      "Epoch 18/50\n",
      "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.9587 - loss: 0.1311 - val_accuracy: 0.2965 - val_loss: 5.2224\n",
      "Epoch 19/50\n",
      "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.9586 - loss: 0.1080 - val_accuracy: 0.2384 - val_loss: 6.6284\n",
      "Epoch 20/50\n",
      "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.9597 - loss: 0.1380 - val_accuracy: 0.2849 - val_loss: 5.4517\n",
      "Epoch 21/50\n",
      "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.9568 - loss: 0.1046 - val_accuracy: 0.3140 - val_loss: 4.5696\n",
      "Epoch 22/50\n",
      "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - accuracy: 0.9641 - loss: 0.1099 - val_accuracy: 0.2849 - val_loss: 5.1751\n",
      "Epoch 23/50\n",
      "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.9538 - loss: 0.1148 - val_accuracy: 0.2907 - val_loss: 5.5394\n",
      "Epoch 24/50\n",
      "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.9762 - loss: 0.0863 - val_accuracy: 0.2791 - val_loss: 5.4259\n",
      "Epoch 25/50\n",
      "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.9671 - loss: 0.1156 - val_accuracy: 0.1860 - val_loss: 6.6890\n",
      "Epoch 26/50\n",
      "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.9648 - loss: 0.1248 - val_accuracy: 0.2616 - val_loss: 6.1937\n",
      "Epoch 27/50\n",
      "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.9716 - loss: 0.1133 - val_accuracy: 0.3314 - val_loss: 4.4322\n",
      "Epoch 28/50\n",
      "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.9805 - loss: 0.0518 - val_accuracy: 0.3663 - val_loss: 4.0432\n",
      "Epoch 29/50\n",
      "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.9817 - loss: 0.0508 - val_accuracy: 0.2733 - val_loss: 5.1683\n",
      "Epoch 30/50\n",
      "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.9744 - loss: 0.0802 - val_accuracy: 0.2907 - val_loss: 5.3553\n",
      "Epoch 31/50\n",
      "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.9647 - loss: 0.0747 - val_accuracy: 0.2500 - val_loss: 5.4198\n",
      "Epoch 32/50\n",
      "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.9917 - loss: 0.0487 - val_accuracy: 0.2326 - val_loss: 6.3905\n",
      "Epoch 33/50\n",
      "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.9769 - loss: 0.0721 - val_accuracy: 0.2442 - val_loss: 6.5296\n",
      "Epoch 34/50\n",
      "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.9812 - loss: 0.0394 - val_accuracy: 0.2965 - val_loss: 5.9250\n",
      "Epoch 35/50\n",
      "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.9750 - loss: 0.0902 - val_accuracy: 0.2209 - val_loss: 8.2911\n",
      "Epoch 36/50\n",
      "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.9841 - loss: 0.1027 - val_accuracy: 0.2849 - val_loss: 6.7477\n",
      "Epoch 37/50\n",
      "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.9833 - loss: 0.0659 - val_accuracy: 0.2733 - val_loss: 6.3181\n",
      "Epoch 38/50\n",
      "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.9910 - loss: 0.0371 - val_accuracy: 0.2500 - val_loss: 6.9576\n",
      "Epoch 39/50\n",
      "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.9862 - loss: 0.0306 - val_accuracy: 0.2558 - val_loss: 6.6467\n",
      "Epoch 40/50\n",
      "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.9866 - loss: 0.0718 - val_accuracy: 0.3256 - val_loss: 6.6559\n",
      "Epoch 41/50\n",
      "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.9845 - loss: 0.0695 - val_accuracy: 0.2674 - val_loss: 7.7844\n",
      "Epoch 42/50\n",
      "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.9721 - loss: 0.1343 - val_accuracy: 0.2965 - val_loss: 7.2290\n",
      "Epoch 43/50\n",
      "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.9770 - loss: 0.0763 - val_accuracy: 0.3081 - val_loss: 7.1210\n",
      "Epoch 44/50\n",
      "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.9968 - loss: 0.0159 - val_accuracy: 0.2907 - val_loss: 7.2092\n",
      "Epoch 45/50\n",
      "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.9881 - loss: 0.0427 - val_accuracy: 0.2733 - val_loss: 7.8587\n",
      "Epoch 46/50\n",
      "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.9850 - loss: 0.0297 - val_accuracy: 0.2791 - val_loss: 7.1205\n",
      "Epoch 47/50\n",
      "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.9804 - loss: 0.0524 - val_accuracy: 0.2267 - val_loss: 7.9894\n",
      "Epoch 48/50\n",
      "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.9896 - loss: 0.0650 - val_accuracy: 0.2209 - val_loss: 8.4130\n",
      "Epoch 49/50\n",
      "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.9916 - loss: 0.0240 - val_accuracy: 0.2616 - val_loss: 8.3419\n",
      "Epoch 50/50\n",
      "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.9770 - loss: 0.0896 - val_accuracy: 0.2674 - val_loss: 8.7345\n",
      "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - accuracy: 0.7887 - loss: 1.8536 \n",
      "ANN Test Accuracy: 0.7323\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "from sklearn.preprocessing import LabelEncoder\n",
    "from sklearn.svm import SVC\n",
    "from sklearn.metrics import accuracy_score, classification_report\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "\n",
    "# Load the data\n",
    "train_data = np.load('./layer_features_base_960h/train_3.npz')\n",
    "test_data = np.load('./layer_features_base_960h/test_3.npz')\n",
    "\n",
    "train_features = train_data['features']\n",
    "test_features = test_data['features']\n",
    "\n",
    "# Read Age labels instead of Gender\n",
    "train_labels = pd.read_csv('y_train.csv').Age\n",
    "test_labels = pd.read_csv('y_test.csv').Age\n",
    "\n",
    "# Encode the labels\n",
    "label_encoder = LabelEncoder()\n",
    "train_labels_encoded = label_encoder.fit_transform(train_labels)\n",
    "\n",
    "# Handle unseen labels in test set by filtering out labels not present in train set\n",
    "test_labels_filtered = test_labels[test_labels.isin(train_labels.unique())]\n",
    "test_features_filtered = test_features[test_labels.isin(train_labels.unique())]\n",
    "test_labels_encoded = label_encoder.transform(test_labels_filtered)\n",
    "\n",
    "# Standardize features\n",
    "scaler = StandardScaler()\n",
    "train_features_normalized = scaler.fit_transform(train_features)\n",
    "test_features_normalized = scaler.transform(test_features_filtered)\n",
    "\n",
    "# SVM model\n",
    "svm_model = SVC(kernel='linear', C=10.0, gamma='scale', random_state=42)\n",
    "svm_model.fit(train_features_normalized, train_labels_encoded)\n",
    "\n",
    "# Prediction and Evaluation\n",
    "svm_predictions = svm_model.predict(test_features_normalized)\n",
    "svm_accuracy = accuracy_score(test_labels_encoded, svm_predictions)\n",
    "print(f\"SVM Accuracy: {svm_accuracy:.4f}\")\n",
    "print(\"SVM Classification Report:\")\n",
    "print(classification_report(test_labels_encoded, svm_predictions))\n",
    "\n",
    "# CNN model (TensorFlow)\n",
    "import tensorflow as tf\n",
    "from tensorflow.keras.models import Sequential\n",
    "from tensorflow.keras.layers import Conv1D, Flatten, Dense, Dropout\n",
    "\n",
    "train_features_cnn = np.expand_dims(train_features_normalized, axis=-1)  # Shape: (num_samples, 768, 1)\n",
    "test_features_cnn = np.expand_dims(test_features_normalized, axis=-1)    # Shape: (num_samples, 768, 1)\n",
    "\n",
    "cnn_model = Sequential([\n",
    "    Conv1D(64, kernel_size=5, activation='relu', input_shape=(768, 1)),  # Update input shape to 768 features\n",
    "    Conv1D(128, kernel_size=5, activation='relu'),\n",
    "    Conv1D(256, kernel_size=5, activation='relu'),\n",
    "    Flatten(),\n",
    "    Dense(256, activation='relu'),\n",
    "    Dropout(0.5),\n",
    "    Dense(len(label_encoder.classes_), activation='softmax')\n",
    "])\n",
    "\n",
    "cnn_model.compile(optimizer='adam', loss='sparse_categorical_crossentropy', metrics=['accuracy'])\n",
    "\n",
    "cnn_model.fit(train_features_cnn, train_labels_encoded, epochs=50, batch_size=32, validation_split=0.2)\n",
    "\n",
    "cnn_test_loss, cnn_test_accuracy = cnn_model.evaluate(test_features_cnn, test_labels_encoded)\n",
    "print(f\"CNN Test Accuracy: {cnn_test_accuracy:.4f}\")\n",
    "\n",
    "# ANN model (TensorFlow)\n",
    "ann_model = Sequential([\n",
    "    Dense(512, activation='relu', input_shape=(768,)),  # Update input shape to 768 features\n",
    "    Dropout(0.5),\n",
    "    Dense(256, activation='relu'),\n",
    "    Dropout(0.5),\n",
    "    Dense(128, activation='relu'),\n",
    "    Dropout(0.5),\n",
    "    Dense(len(label_encoder.classes_), activation='softmax')\n",
    "])\n",
    "\n",
    "ann_model.compile(optimizer='adam', loss='sparse_categorical_crossentropy', metrics=['accuracy'])\n",
    "\n",
    "ann_model.fit(train_features_normalized, train_labels_encoded, epochs=50, batch_size=32, validation_split=0.2)\n",
    "\n",
    "ann_test_loss, ann_test_accuracy = ann_model.evaluate(test_features_normalized, test_labels_encoded)\n",
    "print(f\"ANN Test Accuracy: {ann_test_accuracy:.4f}\")\n",
    "\n",
    "# PyTorch CNN Model\n",
    "import torch\n",
    "from torch.utils.data import DataLoader, TensorDataset\n",
    "\n",
    "X_train_tensor = torch.tensor(train_features_cnn, dtype=torch.float32).permute(0, 2, 1)  # Shape: (num_samples, 1, 768)\n",
    "y_train_tensor = torch.tensor(train_labels_encoded, dtype=torch.long)\n",
    "X_test_tensor = torch.tensor(test_features_cnn, dtype=torch.float32).permute(0, 2, 1)    # Shape: (num_samples, 1, 768)\n",
    "y_test_tensor = torch.tensor(test_labels_encoded, dtype=torch.long)\n",
    "\n",
    "train_dataset = TensorDataset(X_train_tensor, y_train_tensor)\n",
    "test_dataset = TensorDataset(X_test_tensor, y_test_tensor)\n",
    "\n",
    "train_loader = DataLoader(train_dataset, batch_size=64, shuffle=True)\n",
    "test_loader = DataLoader(test_dataset, batch_size=64, shuffle=False)\n",
    "\n",
    "import torch.nn as nn\n",
    "import torch.optim as optim\n",
    "\n",
    "class CNN1DModel(nn.Module):\n",
    "    def __init__(self, input_channels, num_classes):\n",
    "        super(CNN1DModel, self).__init__()\n",
    "        self.conv1 = nn.Conv1d(input_channels, 32, kernel_size=5, stride=1, padding=2)\n",
    "        self.bn1 = nn.BatchNorm1d(32)\n",
    "        self.relu = nn.ReLU()\n",
    "        self.conv2 = nn.Conv1d(32, 64, kernel_size=5, stride=1, padding=2)\n",
    "        self.bn2 = nn.BatchNorm1d(64)\n",
    "        self.conv3 = nn.Conv1d(64, 128, kernel_size=5, stride=1, padding=2)\n",
    "        self.bn3 = nn.BatchNorm1d(128)\n",
    "        self.flatten = nn.Flatten()\n",
    "        self.fc1 = nn.Linear(128 * 768, 512)  # Update to 768 features\n",
    "        self.fc2 = nn.Linear(512, num_classes)\n",
    "        self.dropout = nn.Dropout(0.5)\n",
    "    \n",
    "    def forward(self, x):\n",
    "        x = self.relu(self.bn1(self.conv1(x)))\n",
    "        x = self.relu(self.bn2(self.conv2(x)))\n",
    "        x = self.relu(self.bn3(self.conv3(x)))\n",
    "        x = self.flatten(x)\n",
    "        x = self.dropout(self.relu(self.fc1(x)))\n",
    "        x = self.fc2(x)\n",
    "        return x\n",
    "\n",
    "input_channels = 1\n",
    "num_classes = len(label_encoder.classes_)\n",
    "model = CNN1DModel(input_channels, num_classes)\n",
    "criterion = nn.CrossEntropyLoss()\n",
    "optimizer = optim.Adam(model.parameters(), lr=0.001)\n",
    "\n",
    "# Training and testing as before\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "5e302680",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "SVM Accuracy: 0.8898\n",
      "SVM Classification Report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           1       0.91      0.83      0.87        12\n",
      "           2       0.70      0.88      0.78         8\n",
      "           3       0.93      1.00      0.96        39\n",
      "           4       0.83      0.83      0.83         6\n",
      "           5       0.89      0.93      0.91        42\n",
      "           6       1.00      0.62      0.77        16\n",
      "           7       1.00      1.00      1.00         2\n",
      "           8       1.00      0.50      0.67         2\n",
      "           9       0.00      0.00      0.00         0\n",
      "\n",
      "    accuracy                           0.89       127\n",
      "   macro avg       0.81      0.73      0.75       127\n",
      "weighted avg       0.91      0.89      0.89       127\n",
      "\n",
      "Epoch 1/50\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/mojo/.local/lib/python3.10/site-packages/sklearn/metrics/_classification.py:1509: UndefinedMetricWarning: Recall is ill-defined and being set to 0.0 in labels with no true samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", len(result))\n",
      "/home/mojo/.local/lib/python3.10/site-packages/sklearn/metrics/_classification.py:1509: UndefinedMetricWarning: Recall is ill-defined and being set to 0.0 in labels with no true samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", len(result))\n",
      "/home/mojo/.local/lib/python3.10/site-packages/sklearn/metrics/_classification.py:1509: UndefinedMetricWarning: Recall is ill-defined and being set to 0.0 in labels with no true samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", len(result))\n",
      "/home/mojo/.local/lib/python3.10/site-packages/keras/src/layers/convolutional/base_conv.py:107: UserWarning: Do not pass an `input_shape`/`input_dim` argument to a layer. When using Sequential models, prefer using an `Input(shape)` object as the first layer in the model instead.\n",
      "  super().__init__(activity_regularizer=activity_regularizer, **kwargs)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m9s\u001b[0m 377ms/step - accuracy: 0.3162 - loss: 3.1373 - val_accuracy: 0.1570 - val_loss: 2.1179\n",
      "Epoch 2/50\n",
      "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m8s\u001b[0m 362ms/step - accuracy: 0.8374 - loss: 0.5423 - val_accuracy: 0.1977 - val_loss: 2.9008\n",
      "Epoch 3/50\n",
      "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m8s\u001b[0m 365ms/step - accuracy: 0.9396 - loss: 0.1786 - val_accuracy: 0.1919 - val_loss: 3.8043\n",
      "Epoch 4/50\n",
      "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m8s\u001b[0m 364ms/step - accuracy: 0.9706 - loss: 0.1039 - val_accuracy: 0.1977 - val_loss: 4.0832\n",
      "Epoch 5/50\n",
      "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m8s\u001b[0m 364ms/step - accuracy: 0.9872 - loss: 0.0444 - val_accuracy: 0.3198 - val_loss: 3.9029\n",
      "Epoch 6/50\n",
      "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m8s\u001b[0m 365ms/step - accuracy: 0.9904 - loss: 0.0380 - val_accuracy: 0.2384 - val_loss: 4.2630\n",
      "Epoch 7/50\n",
      "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m8s\u001b[0m 361ms/step - accuracy: 0.9967 - loss: 0.0124 - val_accuracy: 0.3837 - val_loss: 3.5443\n",
      "Epoch 8/50\n",
      "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m8s\u001b[0m 363ms/step - accuracy: 0.9991 - loss: 0.0074 - val_accuracy: 0.2093 - val_loss: 6.1685\n",
      "Epoch 9/50\n",
      "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m8s\u001b[0m 364ms/step - accuracy: 0.9971 - loss: 0.0108 - val_accuracy: 0.2616 - val_loss: 5.1926\n",
      "Epoch 10/50\n",
      "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m8s\u001b[0m 363ms/step - accuracy: 0.9923 - loss: 0.0183 - val_accuracy: 0.1919 - val_loss: 5.0869\n",
      "Epoch 11/50\n",
      "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m8s\u001b[0m 363ms/step - accuracy: 0.9884 - loss: 0.0319 - val_accuracy: 0.2267 - val_loss: 4.0823\n",
      "Epoch 12/50\n",
      "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m8s\u001b[0m 364ms/step - accuracy: 0.9988 - loss: 0.0095 - val_accuracy: 0.2500 - val_loss: 5.0547\n",
      "Epoch 13/50\n",
      "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m8s\u001b[0m 359ms/step - accuracy: 0.9971 - loss: 0.0059 - val_accuracy: 0.2965 - val_loss: 4.7825\n",
      "Epoch 14/50\n",
      "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m8s\u001b[0m 362ms/step - accuracy: 0.9963 - loss: 0.0104 - val_accuracy: 0.2035 - val_loss: 5.8432\n",
      "Epoch 15/50\n",
      "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m8s\u001b[0m 361ms/step - accuracy: 0.9999 - loss: 0.0021 - val_accuracy: 0.1802 - val_loss: 6.7250\n",
      "Epoch 16/50\n",
      "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m8s\u001b[0m 363ms/step - accuracy: 0.9982 - loss: 0.0091 - val_accuracy: 0.1395 - val_loss: 5.7337\n",
      "Epoch 17/50\n",
      "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m8s\u001b[0m 363ms/step - accuracy: 1.0000 - loss: 0.0010 - val_accuracy: 0.1977 - val_loss: 6.5784\n",
      "Epoch 18/50\n",
      "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m8s\u001b[0m 364ms/step - accuracy: 0.9981 - loss: 0.0025 - val_accuracy: 0.2500 - val_loss: 6.0905\n",
      "Epoch 19/50\n",
      "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m8s\u001b[0m 359ms/step - accuracy: 1.0000 - loss: 0.0015 - val_accuracy: 0.2616 - val_loss: 6.5952\n",
      "Epoch 20/50\n",
      "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m8s\u001b[0m 358ms/step - accuracy: 1.0000 - loss: 0.0027 - val_accuracy: 0.3023 - val_loss: 6.3550\n",
      "Epoch 21/50\n",
      "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m8s\u001b[0m 352ms/step - accuracy: 0.9963 - loss: 0.0043 - val_accuracy: 0.2267 - val_loss: 6.3390\n",
      "Epoch 22/50\n",
      "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m8s\u001b[0m 357ms/step - accuracy: 0.9979 - loss: 0.0130 - val_accuracy: 0.2965 - val_loss: 3.5478\n",
      "Epoch 23/50\n",
      "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m8s\u001b[0m 360ms/step - accuracy: 0.9984 - loss: 0.0055 - val_accuracy: 0.2384 - val_loss: 5.9204\n",
      "Epoch 24/50\n",
      "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m8s\u001b[0m 360ms/step - accuracy: 0.9993 - loss: 0.0057 - val_accuracy: 0.1744 - val_loss: 5.8786\n",
      "Epoch 25/50\n",
      "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m8s\u001b[0m 362ms/step - accuracy: 1.0000 - loss: 0.0026 - val_accuracy: 0.2093 - val_loss: 6.7993\n",
      "Epoch 26/50\n",
      "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m8s\u001b[0m 364ms/step - accuracy: 1.0000 - loss: 1.5737e-04 - val_accuracy: 0.2209 - val_loss: 6.8059\n",
      "Epoch 27/50\n",
      "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m8s\u001b[0m 361ms/step - accuracy: 0.9995 - loss: 0.0015 - val_accuracy: 0.1802 - val_loss: 5.7085\n",
      "Epoch 28/50\n",
      "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m8s\u001b[0m 361ms/step - accuracy: 0.9961 - loss: 0.0158 - val_accuracy: 0.2035 - val_loss: 4.3256\n",
      "Epoch 29/50\n",
      "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m8s\u001b[0m 360ms/step - accuracy: 0.9949 - loss: 0.0165 - val_accuracy: 0.2791 - val_loss: 5.2626\n",
      "Epoch 30/50\n",
      "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m8s\u001b[0m 356ms/step - accuracy: 1.0000 - loss: 0.0013 - val_accuracy: 0.2558 - val_loss: 6.4165\n",
      "Epoch 31/50\n",
      "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m8s\u001b[0m 361ms/step - accuracy: 0.9966 - loss: 0.0199 - val_accuracy: 0.2209 - val_loss: 4.4645\n",
      "Epoch 32/50\n",
      "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m8s\u001b[0m 364ms/step - accuracy: 0.9949 - loss: 0.0130 - val_accuracy: 0.2326 - val_loss: 5.5603\n",
      "Epoch 33/50\n",
      "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m8s\u001b[0m 361ms/step - accuracy: 1.0000 - loss: 0.0031 - val_accuracy: 0.2500 - val_loss: 6.2976\n",
      "Epoch 34/50\n",
      "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m8s\u001b[0m 360ms/step - accuracy: 1.0000 - loss: 3.9969e-04 - val_accuracy: 0.2907 - val_loss: 6.0370\n",
      "Epoch 35/50\n",
      "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m8s\u001b[0m 357ms/step - accuracy: 0.9982 - loss: 0.0049 - val_accuracy: 0.2151 - val_loss: 5.7408\n",
      "Epoch 36/50\n",
      "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m8s\u001b[0m 361ms/step - accuracy: 1.0000 - loss: 0.0035 - val_accuracy: 0.2791 - val_loss: 5.6200\n",
      "Epoch 37/50\n",
      "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m8s\u001b[0m 358ms/step - accuracy: 1.0000 - loss: 0.0043 - val_accuracy: 0.0988 - val_loss: 8.5263\n",
      "Epoch 38/50\n",
      "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m8s\u001b[0m 360ms/step - accuracy: 1.0000 - loss: 7.6193e-04 - val_accuracy: 0.1512 - val_loss: 7.6897\n",
      "Epoch 39/50\n",
      "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m8s\u001b[0m 361ms/step - accuracy: 1.0000 - loss: 0.0011 - val_accuracy: 0.1163 - val_loss: 9.2119\n",
      "Epoch 40/50\n",
      "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m8s\u001b[0m 364ms/step - accuracy: 0.9966 - loss: 0.0088 - val_accuracy: 0.2035 - val_loss: 5.6308\n",
      "Epoch 41/50\n",
      "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m8s\u001b[0m 363ms/step - accuracy: 0.9999 - loss: 0.0015 - val_accuracy: 0.2267 - val_loss: 6.3518\n",
      "Epoch 42/50\n",
      "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m8s\u001b[0m 353ms/step - accuracy: 1.0000 - loss: 0.0034 - val_accuracy: 0.1453 - val_loss: 8.7100\n",
      "Epoch 43/50\n",
      "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m8s\u001b[0m 352ms/step - accuracy: 1.0000 - loss: 0.0021 - val_accuracy: 0.0872 - val_loss: 10.0616\n",
      "Epoch 44/50\n",
      "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m8s\u001b[0m 351ms/step - accuracy: 0.9993 - loss: 0.0022 - val_accuracy: 0.1919 - val_loss: 7.1231\n",
      "Epoch 45/50\n",
      "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m8s\u001b[0m 353ms/step - accuracy: 0.9972 - loss: 0.0116 - val_accuracy: 0.1628 - val_loss: 6.9866\n",
      "Epoch 46/50\n",
      "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m8s\u001b[0m 361ms/step - accuracy: 0.9978 - loss: 0.0070 - val_accuracy: 0.2616 - val_loss: 4.6828\n",
      "Epoch 47/50\n",
      "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m8s\u001b[0m 357ms/step - accuracy: 1.0000 - loss: 0.0030 - val_accuracy: 0.2267 - val_loss: 6.3527\n",
      "Epoch 48/50\n",
      "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m8s\u001b[0m 368ms/step - accuracy: 1.0000 - loss: 0.0030 - val_accuracy: 0.2849 - val_loss: 6.0303\n",
      "Epoch 49/50\n",
      "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m8s\u001b[0m 369ms/step - accuracy: 1.0000 - loss: 2.1842e-04 - val_accuracy: 0.2733 - val_loss: 6.4522\n",
      "Epoch 50/50\n",
      "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m8s\u001b[0m 369ms/step - accuracy: 1.0000 - loss: 2.4053e-04 - val_accuracy: 0.2500 - val_loss: 7.1926\n",
      "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 37ms/step - accuracy: 0.8129 - loss: 1.5313\n",
      "CNN Test Accuracy: 0.7953\n",
      "Epoch 1/50\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/mojo/.local/lib/python3.10/site-packages/keras/src/layers/core/dense.py:87: UserWarning: Do not pass an `input_shape`/`input_dim` argument to a layer. When using Sequential models, prefer using an `Input(shape)` object as the first layer in the model instead.\n",
      "  super().__init__(activity_regularizer=activity_regularizer, **kwargs)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 8ms/step - accuracy: 0.2414 - loss: 2.7828 - val_accuracy: 0.0814 - val_loss: 2.0992\n",
      "Epoch 2/50\n",
      "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - accuracy: 0.4812 - loss: 1.6107 - val_accuracy: 0.0233 - val_loss: 2.2901\n",
      "Epoch 3/50\n",
      "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.5123 - loss: 1.4334 - val_accuracy: 0.1570 - val_loss: 2.0118\n",
      "Epoch 4/50\n",
      "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.6210 - loss: 1.1208 - val_accuracy: 0.1453 - val_loss: 2.1295\n",
      "Epoch 5/50\n",
      "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.6566 - loss: 0.9760 - val_accuracy: 0.2674 - val_loss: 2.0755\n",
      "Epoch 6/50\n",
      "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.7140 - loss: 0.7882 - val_accuracy: 0.2384 - val_loss: 2.3644\n",
      "Epoch 7/50\n",
      "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.7730 - loss: 0.6933 - val_accuracy: 0.2093 - val_loss: 3.0665\n",
      "Epoch 8/50\n",
      "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.7595 - loss: 0.6558 - val_accuracy: 0.2616 - val_loss: 2.7801\n",
      "Epoch 9/50\n",
      "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.8210 - loss: 0.5031 - val_accuracy: 0.3081 - val_loss: 2.7315\n",
      "Epoch 10/50\n",
      "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.8514 - loss: 0.4147 - val_accuracy: 0.2558 - val_loss: 2.9314\n",
      "Epoch 11/50\n",
      "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.8852 - loss: 0.3263 - val_accuracy: 0.2733 - val_loss: 3.3281\n",
      "Epoch 12/50\n",
      "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.9119 - loss: 0.2803 - val_accuracy: 0.2616 - val_loss: 3.7354\n",
      "Epoch 13/50\n",
      "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.9101 - loss: 0.3149 - val_accuracy: 0.2674 - val_loss: 3.9294\n",
      "Epoch 14/50\n",
      "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.9255 - loss: 0.2090 - val_accuracy: 0.1977 - val_loss: 4.3456\n",
      "Epoch 15/50\n",
      "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.9210 - loss: 0.2120 - val_accuracy: 0.1860 - val_loss: 4.4333\n",
      "Epoch 16/50\n",
      "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.9352 - loss: 0.1842 - val_accuracy: 0.2209 - val_loss: 4.2188\n",
      "Epoch 17/50\n",
      "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.9450 - loss: 0.1884 - val_accuracy: 0.1686 - val_loss: 4.6310\n",
      "Epoch 18/50\n",
      "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.9554 - loss: 0.1750 - val_accuracy: 0.2674 - val_loss: 3.8800\n",
      "Epoch 19/50\n",
      "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.9560 - loss: 0.1614 - val_accuracy: 0.2384 - val_loss: 4.3219\n",
      "Epoch 20/50\n",
      "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.9596 - loss: 0.1216 - val_accuracy: 0.2500 - val_loss: 4.7164\n",
      "Epoch 21/50\n",
      "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.9708 - loss: 0.1135 - val_accuracy: 0.2209 - val_loss: 5.3270\n",
      "Epoch 22/50\n",
      "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.9496 - loss: 0.1597 - val_accuracy: 0.2035 - val_loss: 5.6157\n",
      "Epoch 23/50\n",
      "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.9556 - loss: 0.1230 - val_accuracy: 0.2035 - val_loss: 5.3837\n",
      "Epoch 24/50\n",
      "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.9688 - loss: 0.0879 - val_accuracy: 0.2267 - val_loss: 5.7239\n",
      "Epoch 25/50\n",
      "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.9680 - loss: 0.0938 - val_accuracy: 0.3023 - val_loss: 5.1403\n",
      "Epoch 26/50\n",
      "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.9847 - loss: 0.0555 - val_accuracy: 0.2849 - val_loss: 5.6807\n",
      "Epoch 27/50\n",
      "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.9704 - loss: 0.0818 - val_accuracy: 0.2326 - val_loss: 6.1352\n",
      "Epoch 28/50\n",
      "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.9711 - loss: 0.0834 - val_accuracy: 0.2733 - val_loss: 6.3833\n",
      "Epoch 29/50\n",
      "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.9672 - loss: 0.1064 - val_accuracy: 0.2384 - val_loss: 6.9104\n",
      "Epoch 30/50\n",
      "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.9745 - loss: 0.0723 - val_accuracy: 0.2616 - val_loss: 6.0087\n",
      "Epoch 31/50\n",
      "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.9807 - loss: 0.0624 - val_accuracy: 0.2209 - val_loss: 5.7199\n",
      "Epoch 32/50\n",
      "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.9869 - loss: 0.0636 - val_accuracy: 0.2209 - val_loss: 5.9777\n",
      "Epoch 33/50\n",
      "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.9769 - loss: 0.0708 - val_accuracy: 0.2151 - val_loss: 6.1217\n",
      "Epoch 34/50\n",
      "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.9763 - loss: 0.0750 - val_accuracy: 0.2965 - val_loss: 5.2048\n",
      "Epoch 35/50\n",
      "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.9754 - loss: 0.0654 - val_accuracy: 0.2442 - val_loss: 6.4598\n",
      "Epoch 36/50\n",
      "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.9741 - loss: 0.0796 - val_accuracy: 0.2093 - val_loss: 6.6304\n",
      "Epoch 37/50\n",
      "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.9806 - loss: 0.0556 - val_accuracy: 0.2151 - val_loss: 7.1812\n",
      "Epoch 38/50\n",
      "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.9644 - loss: 0.0939 - val_accuracy: 0.1570 - val_loss: 8.7508\n",
      "Epoch 39/50\n",
      "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.9836 - loss: 0.0585 - val_accuracy: 0.2151 - val_loss: 6.9086\n",
      "Epoch 40/50\n",
      "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.9669 - loss: 0.1124 - val_accuracy: 0.2151 - val_loss: 6.8481\n",
      "Epoch 41/50\n",
      "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.9861 - loss: 0.0335 - val_accuracy: 0.2733 - val_loss: 6.8070\n",
      "Epoch 42/50\n",
      "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.9767 - loss: 0.0653 - val_accuracy: 0.2907 - val_loss: 6.9198\n",
      "Epoch 43/50\n",
      "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.9756 - loss: 0.0639 - val_accuracy: 0.2674 - val_loss: 6.9855\n",
      "Epoch 44/50\n",
      "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - accuracy: 0.9791 - loss: 0.0527 - val_accuracy: 0.2093 - val_loss: 8.0474\n",
      "Epoch 45/50\n",
      "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.9817 - loss: 0.0583 - val_accuracy: 0.2442 - val_loss: 7.5919\n",
      "Epoch 46/50\n",
      "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.9872 - loss: 0.0537 - val_accuracy: 0.2791 - val_loss: 7.4087\n",
      "Epoch 47/50\n",
      "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.9885 - loss: 0.0490 - val_accuracy: 0.2733 - val_loss: 7.0900\n",
      "Epoch 48/50\n",
      "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.9772 - loss: 0.0841 - val_accuracy: 0.2035 - val_loss: 8.8028\n",
      "Epoch 49/50\n",
      "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.9821 - loss: 0.0436 - val_accuracy: 0.3140 - val_loss: 7.8148\n",
      "Epoch 50/50\n",
      "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.9859 - loss: 0.0583 - val_accuracy: 0.2442 - val_loss: 8.3690\n",
      "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - accuracy: 0.8098 - loss: 1.4335 \n",
      "ANN Test Accuracy: 0.7953\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "from sklearn.preprocessing import LabelEncoder\n",
    "from sklearn.svm import SVC\n",
    "from sklearn.metrics import accuracy_score, classification_report\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "\n",
    "# Load the data\n",
    "train_data = np.load('./layer_features_base_960h/train_4.npz')\n",
    "test_data = np.load('./layer_features_base_960h/test_4.npz')\n",
    "\n",
    "train_features = train_data['features']\n",
    "test_features = test_data['features']\n",
    "\n",
    "# Read Age labels instead of Gender\n",
    "train_labels = pd.read_csv('y_train.csv').Age\n",
    "test_labels = pd.read_csv('y_test.csv').Age\n",
    "\n",
    "# Encode the labels\n",
    "label_encoder = LabelEncoder()\n",
    "train_labels_encoded = label_encoder.fit_transform(train_labels)\n",
    "\n",
    "# Handle unseen labels in test set by filtering out labels not present in train set\n",
    "test_labels_filtered = test_labels[test_labels.isin(train_labels.unique())]\n",
    "test_features_filtered = test_features[test_labels.isin(train_labels.unique())]\n",
    "test_labels_encoded = label_encoder.transform(test_labels_filtered)\n",
    "\n",
    "# Standardize features\n",
    "scaler = StandardScaler()\n",
    "train_features_normalized = scaler.fit_transform(train_features)\n",
    "test_features_normalized = scaler.transform(test_features_filtered)\n",
    "\n",
    "# SVM model\n",
    "svm_model = SVC(kernel='linear', C=10.0, gamma='scale', random_state=42)\n",
    "svm_model.fit(train_features_normalized, train_labels_encoded)\n",
    "\n",
    "# Prediction and Evaluation\n",
    "svm_predictions = svm_model.predict(test_features_normalized)\n",
    "svm_accuracy = accuracy_score(test_labels_encoded, svm_predictions)\n",
    "print(f\"SVM Accuracy: {svm_accuracy:.4f}\")\n",
    "print(\"SVM Classification Report:\")\n",
    "print(classification_report(test_labels_encoded, svm_predictions))\n",
    "\n",
    "# CNN model (TensorFlow)\n",
    "import tensorflow as tf\n",
    "from tensorflow.keras.models import Sequential\n",
    "from tensorflow.keras.layers import Conv1D, Flatten, Dense, Dropout\n",
    "\n",
    "train_features_cnn = np.expand_dims(train_features_normalized, axis=-1)  # Shape: (num_samples, 768, 1)\n",
    "test_features_cnn = np.expand_dims(test_features_normalized, axis=-1)    # Shape: (num_samples, 768, 1)\n",
    "\n",
    "cnn_model = Sequential([\n",
    "    Conv1D(64, kernel_size=5, activation='relu', input_shape=(768, 1)),  # Update input shape to 768 features\n",
    "    Conv1D(128, kernel_size=5, activation='relu'),\n",
    "    Conv1D(256, kernel_size=5, activation='relu'),\n",
    "    Flatten(),\n",
    "    Dense(256, activation='relu'),\n",
    "    Dropout(0.5),\n",
    "    Dense(len(label_encoder.classes_), activation='softmax')\n",
    "])\n",
    "\n",
    "cnn_model.compile(optimizer='adam', loss='sparse_categorical_crossentropy', metrics=['accuracy'])\n",
    "\n",
    "cnn_model.fit(train_features_cnn, train_labels_encoded, epochs=50, batch_size=32, validation_split=0.2)\n",
    "\n",
    "cnn_test_loss, cnn_test_accuracy = cnn_model.evaluate(test_features_cnn, test_labels_encoded)\n",
    "print(f\"CNN Test Accuracy: {cnn_test_accuracy:.4f}\")\n",
    "\n",
    "# ANN model (TensorFlow)\n",
    "ann_model = Sequential([\n",
    "    Dense(512, activation='relu', input_shape=(768,)),  # Update input shape to 768 features\n",
    "    Dropout(0.5),\n",
    "    Dense(256, activation='relu'),\n",
    "    Dropout(0.5),\n",
    "    Dense(128, activation='relu'),\n",
    "    Dropout(0.5),\n",
    "    Dense(len(label_encoder.classes_), activation='softmax')\n",
    "])\n",
    "\n",
    "ann_model.compile(optimizer='adam', loss='sparse_categorical_crossentropy', metrics=['accuracy'])\n",
    "\n",
    "ann_model.fit(train_features_normalized, train_labels_encoded, epochs=50, batch_size=32, validation_split=0.2)\n",
    "\n",
    "ann_test_loss, ann_test_accuracy = ann_model.evaluate(test_features_normalized, test_labels_encoded)\n",
    "print(f\"ANN Test Accuracy: {ann_test_accuracy:.4f}\")\n",
    "\n",
    "# PyTorch CNN Model\n",
    "import torch\n",
    "from torch.utils.data import DataLoader, TensorDataset\n",
    "\n",
    "X_train_tensor = torch.tensor(train_features_cnn, dtype=torch.float32).permute(0, 2, 1)  # Shape: (num_samples, 1, 768)\n",
    "y_train_tensor = torch.tensor(train_labels_encoded, dtype=torch.long)\n",
    "X_test_tensor = torch.tensor(test_features_cnn, dtype=torch.float32).permute(0, 2, 1)    # Shape: (num_samples, 1, 768)\n",
    "y_test_tensor = torch.tensor(test_labels_encoded, dtype=torch.long)\n",
    "\n",
    "train_dataset = TensorDataset(X_train_tensor, y_train_tensor)\n",
    "test_dataset = TensorDataset(X_test_tensor, y_test_tensor)\n",
    "\n",
    "train_loader = DataLoader(train_dataset, batch_size=64, shuffle=True)\n",
    "test_loader = DataLoader(test_dataset, batch_size=64, shuffle=False)\n",
    "\n",
    "import torch.nn as nn\n",
    "import torch.optim as optim\n",
    "\n",
    "class CNN1DModel(nn.Module):\n",
    "    def __init__(self, input_channels, num_classes):\n",
    "        super(CNN1DModel, self).__init__()\n",
    "        self.conv1 = nn.Conv1d(input_channels, 32, kernel_size=5, stride=1, padding=2)\n",
    "        self.bn1 = nn.BatchNorm1d(32)\n",
    "        self.relu = nn.ReLU()\n",
    "        self.conv2 = nn.Conv1d(32, 64, kernel_size=5, stride=1, padding=2)\n",
    "        self.bn2 = nn.BatchNorm1d(64)\n",
    "        self.conv3 = nn.Conv1d(64, 128, kernel_size=5, stride=1, padding=2)\n",
    "        self.bn3 = nn.BatchNorm1d(128)\n",
    "        self.flatten = nn.Flatten()\n",
    "        self.fc1 = nn.Linear(128 * 768, 512)  # Update to 768 features\n",
    "        self.fc2 = nn.Linear(512, num_classes)\n",
    "        self.dropout = nn.Dropout(0.5)\n",
    "    \n",
    "    def forward(self, x):\n",
    "        x = self.relu(self.bn1(self.conv1(x)))\n",
    "        x = self.relu(self.bn2(self.conv2(x)))\n",
    "        x = self.relu(self.bn3(self.conv3(x)))\n",
    "        x = self.flatten(x)\n",
    "        x = self.dropout(self.relu(self.fc1(x)))\n",
    "        x = self.fc2(x)\n",
    "        return x\n",
    "\n",
    "input_channels = 1\n",
    "num_classes = len(label_encoder.classes_)\n",
    "model = CNN1DModel(input_channels, num_classes)\n",
    "criterion = nn.CrossEntropyLoss()\n",
    "optimizer = optim.Adam(model.parameters(), lr=0.001)\n",
    "\n",
    "# Training and testing as before\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "81284d47",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "SVM Accuracy: 0.8976\n",
      "SVM Classification Report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           1       0.91      0.83      0.87        12\n",
      "           2       0.70      0.88      0.78         8\n",
      "           3       0.93      1.00      0.96        39\n",
      "           4       0.75      1.00      0.86         6\n",
      "           5       0.91      0.93      0.92        42\n",
      "           6       1.00      0.56      0.72        16\n",
      "           7       1.00      1.00      1.00         2\n",
      "           8       1.00      1.00      1.00         2\n",
      "\n",
      "    accuracy                           0.90       127\n",
      "   macro avg       0.90      0.90      0.89       127\n",
      "weighted avg       0.91      0.90      0.89       127\n",
      "\n",
      "Epoch 1/50\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/mojo/.local/lib/python3.10/site-packages/keras/src/layers/convolutional/base_conv.py:107: UserWarning: Do not pass an `input_shape`/`input_dim` argument to a layer. When using Sequential models, prefer using an `Input(shape)` object as the first layer in the model instead.\n",
      "  super().__init__(activity_regularizer=activity_regularizer, **kwargs)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m9s\u001b[0m 384ms/step - accuracy: 0.3254 - loss: 3.0363 - val_accuracy: 0.0116 - val_loss: 2.5758\n",
      "Epoch 2/50\n",
      "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m8s\u001b[0m 372ms/step - accuracy: 0.6490 - loss: 0.9938 - val_accuracy: 0.0698 - val_loss: 3.1020\n",
      "Epoch 3/50\n",
      "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m9s\u001b[0m 388ms/step - accuracy: 0.8699 - loss: 0.4276 - val_accuracy: 0.2791 - val_loss: 3.4107\n",
      "Epoch 4/50\n",
      "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m9s\u001b[0m 390ms/step - accuracy: 0.9441 - loss: 0.1663 - val_accuracy: 0.2849 - val_loss: 3.6416\n",
      "Epoch 5/50\n",
      "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m9s\u001b[0m 387ms/step - accuracy: 0.9560 - loss: 0.1139 - val_accuracy: 0.1919 - val_loss: 4.5569\n",
      "Epoch 6/50\n",
      "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m9s\u001b[0m 395ms/step - accuracy: 0.9929 - loss: 0.0513 - val_accuracy: 0.2209 - val_loss: 4.9527\n",
      "Epoch 7/50\n",
      "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m8s\u001b[0m 363ms/step - accuracy: 0.9831 - loss: 0.0431 - val_accuracy: 0.1860 - val_loss: 4.9720\n",
      "Epoch 8/50\n",
      "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m9s\u001b[0m 389ms/step - accuracy: 0.9821 - loss: 0.0434 - val_accuracy: 0.3140 - val_loss: 3.5516\n",
      "Epoch 9/50\n",
      "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m8s\u001b[0m 347ms/step - accuracy: 0.9959 - loss: 0.0193 - val_accuracy: 0.2674 - val_loss: 5.3901\n",
      "Epoch 10/50\n",
      "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m8s\u001b[0m 353ms/step - accuracy: 0.9957 - loss: 0.0172 - val_accuracy: 0.4244 - val_loss: 4.1810\n",
      "Epoch 11/50\n",
      "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m8s\u001b[0m 351ms/step - accuracy: 0.9871 - loss: 0.0338 - val_accuracy: 0.1919 - val_loss: 5.2975\n",
      "Epoch 12/50\n",
      "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m8s\u001b[0m 353ms/step - accuracy: 0.9832 - loss: 0.0511 - val_accuracy: 0.2267 - val_loss: 5.7697\n",
      "Epoch 13/50\n",
      "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m8s\u001b[0m 353ms/step - accuracy: 0.9975 - loss: 0.0182 - val_accuracy: 0.2907 - val_loss: 4.8593\n",
      "Epoch 14/50\n",
      "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m8s\u001b[0m 355ms/step - accuracy: 0.9989 - loss: 0.0097 - val_accuracy: 0.1570 - val_loss: 6.2445\n",
      "Epoch 15/50\n",
      "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m8s\u001b[0m 356ms/step - accuracy: 0.9865 - loss: 0.0418 - val_accuracy: 0.2616 - val_loss: 5.1041\n",
      "Epoch 16/50\n",
      "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m8s\u001b[0m 364ms/step - accuracy: 0.9966 - loss: 0.0136 - val_accuracy: 0.2907 - val_loss: 5.1116\n",
      "Epoch 17/50\n",
      "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m8s\u001b[0m 363ms/step - accuracy: 0.9997 - loss: 0.0049 - val_accuracy: 0.3140 - val_loss: 4.9257\n",
      "Epoch 18/50\n",
      "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m8s\u001b[0m 371ms/step - accuracy: 0.9976 - loss: 0.0074 - val_accuracy: 0.2500 - val_loss: 5.5349\n",
      "Epoch 19/50\n",
      "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m8s\u001b[0m 357ms/step - accuracy: 0.9976 - loss: 0.0046 - val_accuracy: 0.2558 - val_loss: 5.7205\n",
      "Epoch 20/50\n",
      "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m8s\u001b[0m 375ms/step - accuracy: 1.0000 - loss: 0.0030 - val_accuracy: 0.2384 - val_loss: 6.6256\n",
      "Epoch 21/50\n",
      "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m8s\u001b[0m 358ms/step - accuracy: 1.0000 - loss: 0.0034 - val_accuracy: 0.2326 - val_loss: 6.9611\n",
      "Epoch 22/50\n",
      "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m8s\u001b[0m 342ms/step - accuracy: 0.9996 - loss: 0.0031 - val_accuracy: 0.2558 - val_loss: 6.3961\n",
      "Epoch 23/50\n",
      "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m8s\u001b[0m 349ms/step - accuracy: 0.9981 - loss: 0.0044 - val_accuracy: 0.2093 - val_loss: 6.8711\n",
      "Epoch 24/50\n",
      "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m8s\u001b[0m 360ms/step - accuracy: 0.9968 - loss: 0.0164 - val_accuracy: 0.2733 - val_loss: 4.5771\n",
      "Epoch 25/50\n",
      "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m8s\u001b[0m 357ms/step - accuracy: 0.9989 - loss: 0.0067 - val_accuracy: 0.2791 - val_loss: 5.7756\n",
      "Epoch 26/50\n",
      "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m8s\u001b[0m 354ms/step - accuracy: 0.9996 - loss: 0.0031 - val_accuracy: 0.3198 - val_loss: 5.5766\n",
      "Epoch 27/50\n",
      "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m8s\u001b[0m 356ms/step - accuracy: 1.0000 - loss: 0.0015 - val_accuracy: 0.2326 - val_loss: 7.0147\n",
      "Epoch 28/50\n",
      "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m8s\u001b[0m 355ms/step - accuracy: 0.9949 - loss: 0.0076 - val_accuracy: 0.2849 - val_loss: 6.4008\n",
      "Epoch 29/50\n",
      "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m8s\u001b[0m 353ms/step - accuracy: 0.9997 - loss: 0.0015 - val_accuracy: 0.2616 - val_loss: 7.0861\n",
      "Epoch 30/50\n",
      "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m8s\u001b[0m 352ms/step - accuracy: 0.9941 - loss: 0.0143 - val_accuracy: 0.2093 - val_loss: 6.1617\n",
      "Epoch 31/50\n",
      "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m8s\u001b[0m 345ms/step - accuracy: 0.9967 - loss: 0.0178 - val_accuracy: 0.2442 - val_loss: 4.8308\n",
      "Epoch 32/50\n",
      "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m8s\u001b[0m 345ms/step - accuracy: 0.9988 - loss: 0.0097 - val_accuracy: 0.3140 - val_loss: 5.0045\n",
      "Epoch 33/50\n",
      "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m8s\u001b[0m 347ms/step - accuracy: 0.9992 - loss: 0.0061 - val_accuracy: 0.2849 - val_loss: 6.8501\n",
      "Epoch 34/50\n",
      "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m8s\u001b[0m 346ms/step - accuracy: 0.9946 - loss: 0.0307 - val_accuracy: 0.1977 - val_loss: 5.3756\n",
      "Epoch 35/50\n",
      "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m8s\u001b[0m 351ms/step - accuracy: 0.9972 - loss: 0.0118 - val_accuracy: 0.2442 - val_loss: 5.8151\n",
      "Epoch 36/50\n",
      "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m8s\u001b[0m 348ms/step - accuracy: 0.9997 - loss: 0.0048 - val_accuracy: 0.2558 - val_loss: 6.3030\n",
      "Epoch 37/50\n",
      "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m8s\u001b[0m 348ms/step - accuracy: 0.9992 - loss: 0.0043 - val_accuracy: 0.1919 - val_loss: 6.5822\n",
      "Epoch 38/50\n",
      "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m8s\u001b[0m 350ms/step - accuracy: 0.9958 - loss: 0.0124 - val_accuracy: 0.2384 - val_loss: 5.4601\n",
      "Epoch 39/50\n",
      "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m7s\u001b[0m 337ms/step - accuracy: 0.9997 - loss: 0.0050 - val_accuracy: 0.2267 - val_loss: 5.3617\n",
      "Epoch 40/50\n",
      "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m7s\u001b[0m 340ms/step - accuracy: 0.9966 - loss: 0.0060 - val_accuracy: 0.2733 - val_loss: 5.5140\n",
      "Epoch 41/50\n",
      "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m8s\u001b[0m 345ms/step - accuracy: 1.0000 - loss: 0.0037 - val_accuracy: 0.3023 - val_loss: 6.0318\n",
      "Epoch 42/50\n",
      "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m8s\u001b[0m 345ms/step - accuracy: 1.0000 - loss: 0.0013 - val_accuracy: 0.2907 - val_loss: 6.4513\n",
      "Epoch 43/50\n",
      "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m8s\u001b[0m 351ms/step - accuracy: 1.0000 - loss: 0.0020 - val_accuracy: 0.2558 - val_loss: 8.0878\n",
      "Epoch 44/50\n",
      "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m8s\u001b[0m 349ms/step - accuracy: 0.9993 - loss: 0.0062 - val_accuracy: 0.2151 - val_loss: 5.9435\n",
      "Epoch 45/50\n",
      "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m8s\u001b[0m 355ms/step - accuracy: 0.9988 - loss: 0.0037 - val_accuracy: 0.2442 - val_loss: 6.1001\n",
      "Epoch 46/50\n",
      "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m8s\u001b[0m 354ms/step - accuracy: 0.9976 - loss: 0.0094 - val_accuracy: 0.2035 - val_loss: 6.0278\n",
      "Epoch 47/50\n",
      "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m8s\u001b[0m 357ms/step - accuracy: 0.9972 - loss: 0.0230 - val_accuracy: 0.2267 - val_loss: 6.0893\n",
      "Epoch 48/50\n",
      "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m8s\u001b[0m 354ms/step - accuracy: 0.9960 - loss: 0.0113 - val_accuracy: 0.1919 - val_loss: 6.6022\n",
      "Epoch 49/50\n",
      "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m8s\u001b[0m 341ms/step - accuracy: 1.0000 - loss: 0.0025 - val_accuracy: 0.1628 - val_loss: 8.8466\n",
      "Epoch 50/50\n",
      "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m8s\u001b[0m 341ms/step - accuracy: 1.0000 - loss: 8.2239e-04 - val_accuracy: 0.2035 - val_loss: 8.7183\n",
      "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 35ms/step - accuracy: 0.8088 - loss: 1.6701\n",
      "CNN Test Accuracy: 0.8189\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/mojo/.local/lib/python3.10/site-packages/keras/src/layers/core/dense.py:87: UserWarning: Do not pass an `input_shape`/`input_dim` argument to a layer. When using Sequential models, prefer using an `Input(shape)` object as the first layer in the model instead.\n",
      "  super().__init__(activity_regularizer=activity_regularizer, **kwargs)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/50\n",
      "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 8ms/step - accuracy: 0.2026 - loss: 3.0825 - val_accuracy: 0.0000e+00 - val_loss: 2.6350\n",
      "Epoch 2/50\n",
      "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.4147 - loss: 1.8745 - val_accuracy: 0.0640 - val_loss: 2.2213\n",
      "Epoch 3/50\n",
      "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.5052 - loss: 1.5211 - val_accuracy: 0.0872 - val_loss: 2.3401\n",
      "Epoch 4/50\n",
      "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.6050 - loss: 1.2581 - val_accuracy: 0.1221 - val_loss: 2.3505\n",
      "Epoch 5/50\n",
      "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.6164 - loss: 1.0990 - val_accuracy: 0.1802 - val_loss: 2.3826\n",
      "Epoch 6/50\n",
      "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.7041 - loss: 0.9671 - val_accuracy: 0.1919 - val_loss: 2.4832\n",
      "Epoch 7/50\n",
      "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.6466 - loss: 1.0010 - val_accuracy: 0.1977 - val_loss: 2.5945\n",
      "Epoch 8/50\n",
      "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.7603 - loss: 0.7517 - val_accuracy: 0.2326 - val_loss: 2.3634\n",
      "Epoch 9/50\n",
      "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.7977 - loss: 0.5761 - val_accuracy: 0.2442 - val_loss: 2.7899\n",
      "Epoch 10/50\n",
      "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.8228 - loss: 0.5277 - val_accuracy: 0.1860 - val_loss: 3.2124\n",
      "Epoch 11/50\n",
      "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.8450 - loss: 0.4393 - val_accuracy: 0.2442 - val_loss: 2.8468\n",
      "Epoch 12/50\n",
      "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.8477 - loss: 0.4046 - val_accuracy: 0.2384 - val_loss: 3.4995\n",
      "Epoch 13/50\n",
      "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.8745 - loss: 0.3788 - val_accuracy: 0.2442 - val_loss: 3.4252\n",
      "Epoch 14/50\n",
      "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.8758 - loss: 0.3471 - val_accuracy: 0.2442 - val_loss: 3.4863\n",
      "Epoch 15/50\n",
      "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.8754 - loss: 0.3326 - val_accuracy: 0.2733 - val_loss: 3.5289\n",
      "Epoch 16/50\n",
      "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.9238 - loss: 0.2309 - val_accuracy: 0.2500 - val_loss: 4.0342\n",
      "Epoch 17/50\n",
      "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.9247 - loss: 0.2894 - val_accuracy: 0.2326 - val_loss: 4.6475\n",
      "Epoch 18/50\n",
      "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.8940 - loss: 0.2835 - val_accuracy: 0.2209 - val_loss: 4.7266\n",
      "Epoch 19/50\n",
      "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.9362 - loss: 0.1667 - val_accuracy: 0.1802 - val_loss: 5.5466\n",
      "Epoch 20/50\n",
      "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.9459 - loss: 0.1983 - val_accuracy: 0.2500 - val_loss: 5.4986\n",
      "Epoch 21/50\n",
      "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.9560 - loss: 0.1459 - val_accuracy: 0.3081 - val_loss: 4.9205\n",
      "Epoch 22/50\n",
      "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.9632 - loss: 0.1455 - val_accuracy: 0.2791 - val_loss: 5.1899\n",
      "Epoch 23/50\n",
      "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.9546 - loss: 0.1414 - val_accuracy: 0.2733 - val_loss: 5.2964\n",
      "Epoch 24/50\n",
      "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.9572 - loss: 0.1137 - val_accuracy: 0.2500 - val_loss: 5.3314\n",
      "Epoch 25/50\n",
      "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.9543 - loss: 0.1715 - val_accuracy: 0.2442 - val_loss: 5.6876\n",
      "Epoch 26/50\n",
      "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.9631 - loss: 0.1137 - val_accuracy: 0.2674 - val_loss: 5.6420\n",
      "Epoch 27/50\n",
      "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.9611 - loss: 0.1071 - val_accuracy: 0.1919 - val_loss: 6.8965\n",
      "Epoch 28/50\n",
      "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.9650 - loss: 0.1088 - val_accuracy: 0.2209 - val_loss: 6.4466\n",
      "Epoch 29/50\n",
      "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.9750 - loss: 0.1039 - val_accuracy: 0.2616 - val_loss: 5.8462\n",
      "Epoch 30/50\n",
      "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.9710 - loss: 0.0897 - val_accuracy: 0.2791 - val_loss: 5.7217\n",
      "Epoch 31/50\n",
      "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.9456 - loss: 0.1729 - val_accuracy: 0.2209 - val_loss: 6.1040\n",
      "Epoch 32/50\n",
      "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.9637 - loss: 0.0882 - val_accuracy: 0.2267 - val_loss: 6.1177\n",
      "Epoch 33/50\n",
      "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.9798 - loss: 0.0610 - val_accuracy: 0.2558 - val_loss: 5.8830\n",
      "Epoch 34/50\n",
      "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.9802 - loss: 0.0631 - val_accuracy: 0.2442 - val_loss: 6.3924\n",
      "Epoch 35/50\n",
      "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.9776 - loss: 0.1189 - val_accuracy: 0.2558 - val_loss: 6.9987\n",
      "Epoch 36/50\n",
      "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.9756 - loss: 0.0846 - val_accuracy: 0.3314 - val_loss: 6.0387\n",
      "Epoch 37/50\n",
      "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.9744 - loss: 0.0699 - val_accuracy: 0.2500 - val_loss: 7.5316\n",
      "Epoch 38/50\n",
      "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.9772 - loss: 0.0775 - val_accuracy: 0.3140 - val_loss: 6.7232\n",
      "Epoch 39/50\n",
      "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.9796 - loss: 0.0633 - val_accuracy: 0.2500 - val_loss: 7.9375\n",
      "Epoch 40/50\n",
      "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.9748 - loss: 0.0872 - val_accuracy: 0.3314 - val_loss: 7.5842\n",
      "Epoch 41/50\n",
      "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.9826 - loss: 0.0505 - val_accuracy: 0.2674 - val_loss: 8.5713\n",
      "Epoch 42/50\n",
      "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.9829 - loss: 0.0410 - val_accuracy: 0.2500 - val_loss: 9.1812\n",
      "Epoch 43/50\n",
      "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.9792 - loss: 0.0813 - val_accuracy: 0.2035 - val_loss: 8.7501\n",
      "Epoch 44/50\n",
      "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.9862 - loss: 0.0429 - val_accuracy: 0.2093 - val_loss: 8.8541\n",
      "Epoch 45/50\n",
      "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.9811 - loss: 0.0900 - val_accuracy: 0.3023 - val_loss: 7.5866\n",
      "Epoch 46/50\n",
      "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.9774 - loss: 0.0666 - val_accuracy: 0.2151 - val_loss: 9.5559\n",
      "Epoch 47/50\n",
      "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.9755 - loss: 0.0658 - val_accuracy: 0.2035 - val_loss: 9.5054\n",
      "Epoch 48/50\n",
      "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.9751 - loss: 0.1200 - val_accuracy: 0.2035 - val_loss: 7.8521\n",
      "Epoch 49/50\n",
      "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.9664 - loss: 0.1187 - val_accuracy: 0.1802 - val_loss: 8.3935\n",
      "Epoch 50/50\n",
      "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.9753 - loss: 0.1193 - val_accuracy: 0.2442 - val_loss: 7.6459\n",
      "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.8172 - loss: 1.2487 \n",
      "ANN Test Accuracy: 0.8346\n"
     ]
    },
    {
     "ename": "",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31mThe Kernel crashed while executing code in the current cell or a previous cell. \n",
      "\u001b[1;31mPlease review the code in the cell(s) to identify a possible cause of the failure. \n",
      "\u001b[1;31mClick <a href='https://aka.ms/vscodeJupyterKernelCrash'>here</a> for more info. \n",
      "\u001b[1;31mView Jupyter <a href='command:jupyter.viewOutput'>log</a> for further details."
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "from sklearn.preprocessing import LabelEncoder\n",
    "from sklearn.svm import SVC\n",
    "from sklearn.metrics import accuracy_score, classification_report\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "\n",
    "# Load the data\n",
    "train_data = np.load('./layer_features_base_960h/train_5.npz')\n",
    "test_data = np.load('./layer_features_base_960h/test_5.npz')\n",
    "\n",
    "train_features = train_data['features']\n",
    "test_features = test_data['features']\n",
    "\n",
    "# Read Age labels instead of Gender\n",
    "train_labels = pd.read_csv('y_train.csv').Age\n",
    "test_labels = pd.read_csv('y_test.csv').Age\n",
    "\n",
    "# Encode the labels\n",
    "label_encoder = LabelEncoder()\n",
    "train_labels_encoded = label_encoder.fit_transform(train_labels)\n",
    "\n",
    "# Handle unseen labels in test set by filtering out labels not present in train set\n",
    "test_labels_filtered = test_labels[test_labels.isin(train_labels.unique())]\n",
    "test_features_filtered = test_features[test_labels.isin(train_labels.unique())]\n",
    "test_labels_encoded = label_encoder.transform(test_labels_filtered)\n",
    "\n",
    "# Standardize features\n",
    "scaler = StandardScaler()\n",
    "train_features_normalized = scaler.fit_transform(train_features)\n",
    "test_features_normalized = scaler.transform(test_features_filtered)\n",
    "\n",
    "# SVM model\n",
    "svm_model = SVC(kernel='linear', C=10.0, gamma='scale', random_state=42)\n",
    "svm_model.fit(train_features_normalized, train_labels_encoded)\n",
    "\n",
    "# Prediction and Evaluation\n",
    "svm_predictions = svm_model.predict(test_features_normalized)\n",
    "svm_accuracy = accuracy_score(test_labels_encoded, svm_predictions)\n",
    "print(f\"SVM Accuracy: {svm_accuracy:.4f}\")\n",
    "print(\"SVM Classification Report:\")\n",
    "print(classification_report(test_labels_encoded, svm_predictions))\n",
    "\n",
    "# CNN model (TensorFlow)\n",
    "import tensorflow as tf\n",
    "from tensorflow.keras.models import Sequential\n",
    "from tensorflow.keras.layers import Conv1D, Flatten, Dense, Dropout\n",
    "\n",
    "train_features_cnn = np.expand_dims(train_features_normalized, axis=-1)  # Shape: (num_samples, 768, 1)\n",
    "test_features_cnn = np.expand_dims(test_features_normalized, axis=-1)    # Shape: (num_samples, 768, 1)\n",
    "\n",
    "cnn_model = Sequential([\n",
    "    Conv1D(64, kernel_size=5, activation='relu', input_shape=(768, 1)),  # Update input shape to 768 features\n",
    "    Conv1D(128, kernel_size=5, activation='relu'),\n",
    "    Conv1D(256, kernel_size=5, activation='relu'),\n",
    "    Flatten(),\n",
    "    Dense(256, activation='relu'),\n",
    "    Dropout(0.5),\n",
    "    Dense(len(label_encoder.classes_), activation='softmax')\n",
    "])\n",
    "\n",
    "cnn_model.compile(optimizer='adam', loss='sparse_categorical_crossentropy', metrics=['accuracy'])\n",
    "\n",
    "cnn_model.fit(train_features_cnn, train_labels_encoded, epochs=50, batch_size=32, validation_split=0.2)\n",
    "\n",
    "cnn_test_loss, cnn_test_accuracy = cnn_model.evaluate(test_features_cnn, test_labels_encoded)\n",
    "print(f\"CNN Test Accuracy: {cnn_test_accuracy:.4f}\")\n",
    "\n",
    "# ANN model (TensorFlow)\n",
    "ann_model = Sequential([\n",
    "    Dense(512, activation='relu', input_shape=(768,)),  # Update input shape to 768 features\n",
    "    Dropout(0.5),\n",
    "    Dense(256, activation='relu'),\n",
    "    Dropout(0.5),\n",
    "    Dense(128, activation='relu'),\n",
    "    Dropout(0.5),\n",
    "    Dense(len(label_encoder.classes_), activation='softmax')\n",
    "])\n",
    "\n",
    "ann_model.compile(optimizer='adam', loss='sparse_categorical_crossentropy', metrics=['accuracy'])\n",
    "\n",
    "ann_model.fit(train_features_normalized, train_labels_encoded, epochs=50, batch_size=32, validation_split=0.2)\n",
    "\n",
    "ann_test_loss, ann_test_accuracy = ann_model.evaluate(test_features_normalized, test_labels_encoded)\n",
    "print(f\"ANN Test Accuracy: {ann_test_accuracy:.4f}\")\n",
    "\n",
    "# PyTorch CNN Model\n",
    "import torch\n",
    "from torch.utils.data import DataLoader, TensorDataset\n",
    "\n",
    "X_train_tensor = torch.tensor(train_features_cnn, dtype=torch.float32).permute(0, 2, 1)  # Shape: (num_samples, 1, 768)\n",
    "y_train_tensor = torch.tensor(train_labels_encoded, dtype=torch.long)\n",
    "X_test_tensor = torch.tensor(test_features_cnn, dtype=torch.float32).permute(0, 2, 1)    # Shape: (num_samples, 1, 768)\n",
    "y_test_tensor = torch.tensor(test_labels_encoded, dtype=torch.long)\n",
    "\n",
    "train_dataset = TensorDataset(X_train_tensor, y_train_tensor)\n",
    "test_dataset = TensorDataset(X_test_tensor, y_test_tensor)\n",
    "\n",
    "train_loader = DataLoader(train_dataset, batch_size=64, shuffle=True)\n",
    "test_loader = DataLoader(test_dataset, batch_size=64, shuffle=False)\n",
    "\n",
    "import torch.nn as nn\n",
    "import torch.optim as optim\n",
    "\n",
    "class CNN1DModel(nn.Module):\n",
    "    def __init__(self, input_channels, num_classes):\n",
    "        super(CNN1DModel, self).__init__()\n",
    "        self.conv1 = nn.Conv1d(input_channels, 32, kernel_size=5, stride=1, padding=2)\n",
    "        self.bn1 = nn.BatchNorm1d(32)\n",
    "        self.relu = nn.ReLU()\n",
    "        self.conv2 = nn.Conv1d(32, 64, kernel_size=5, stride=1, padding=2)\n",
    "        self.bn2 = nn.BatchNorm1d(64)\n",
    "        self.conv3 = nn.Conv1d(64, 128, kernel_size=5, stride=1, padding=2)\n",
    "        self.bn3 = nn.BatchNorm1d(128)\n",
    "        self.flatten = nn.Flatten()\n",
    "        self.fc1 = nn.Linear(128 * 768, 512)  # Update to 768 features\n",
    "        self.fc2 = nn.Linear(512, num_classes)\n",
    "        self.dropout = nn.Dropout(0.5)\n",
    "    \n",
    "    def forward(self, x):\n",
    "        x = self.relu(self.bn1(self.conv1(x)))\n",
    "        x = self.relu(self.bn2(self.conv2(x)))\n",
    "        x = self.relu(self.bn3(self.conv3(x)))\n",
    "        x = self.flatten(x)\n",
    "        x = self.dropout(self.relu(self.fc1(x)))\n",
    "        x = self.fc2(x)\n",
    "        return x\n",
    "\n",
    "input_channels = 1\n",
    "num_classes = len(label_encoder.classes_)\n",
    "model = CNN1DModel(input_channels, num_classes)\n",
    "criterion = nn.CrossEntropyLoss()\n",
    "optimizer = optim.Adam(model.parameters(), lr=0.001)\n",
    "\n",
    "# Training and testing as before\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "a5399278",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/lib/python3/dist-packages/scipy/__init__.py:146: UserWarning: A NumPy version >=1.17.3 and <1.25.0 is required for this version of SciPy (detected version 1.26.4\n",
      "  warnings.warn(f\"A NumPy version >={np_minversion} and <{np_maxversion}\"\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "SVM Accuracy: 0.8819\n",
      "SVM Classification Report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           1       1.00      0.83      0.91        12\n",
      "           2       0.75      0.75      0.75         8\n",
      "           3       0.87      1.00      0.93        39\n",
      "           4       1.00      0.83      0.91         6\n",
      "           5       0.85      0.93      0.89        42\n",
      "           6       1.00      0.56      0.72        16\n",
      "           7       1.00      1.00      1.00         2\n",
      "           8       1.00      1.00      1.00         2\n",
      "\n",
      "    accuracy                           0.88       127\n",
      "   macro avg       0.93      0.86      0.89       127\n",
      "weighted avg       0.89      0.88      0.88       127\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2024-09-08 18:15:22.317933: I tensorflow/core/platform/cpu_feature_guard.cc:210] This TensorFlow binary is optimized to use available CPU instructions in performance-critical operations.\n",
      "To enable the following instructions: AVX2 FMA, in other operations, rebuild TensorFlow with the appropriate compiler flags.\n",
      "2024-09-08 18:15:23.236229: W tensorflow/compiler/tf2tensorrt/utils/py_utils.cc:38] TF-TRT Warning: Could not find TensorRT\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/50\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/mojo/.local/lib/python3.10/site-packages/keras/src/layers/convolutional/base_conv.py:107: UserWarning: Do not pass an `input_shape`/`input_dim` argument to a layer. When using Sequential models, prefer using an `Input(shape)` object as the first layer in the model instead.\n",
      "  super().__init__(activity_regularizer=activity_regularizer, **kwargs)\n",
      "2024-09-08 18:15:24.375596: I external/local_xla/xla/stream_executor/cuda/cuda_executor.cc:998] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero. See more at https://github.com/torvalds/linux/blob/v6.0/Documentation/ABI/testing/sysfs-bus-pci#L344-L355\n",
      "2024-09-08 18:15:24.401527: W tensorflow/core/common_runtime/gpu/gpu_device.cc:2251] Cannot dlopen some GPU libraries. Please make sure the missing libraries mentioned above are installed properly if you would like to use GPU. Follow the guide at https://www.tensorflow.org/install/gpu for how to download and setup the required libraries for your platform.\n",
      "Skipping registering GPU devices...\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m9s\u001b[0m 362ms/step - accuracy: 0.2984 - loss: 4.3799 - val_accuracy: 0.0058 - val_loss: 2.5095\n",
      "Epoch 2/50\n",
      "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m8s\u001b[0m 353ms/step - accuracy: 0.5874 - loss: 1.1663 - val_accuracy: 0.2384 - val_loss: 2.0675\n",
      "Epoch 3/50\n",
      "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m8s\u001b[0m 356ms/step - accuracy: 0.8368 - loss: 0.5120 - val_accuracy: 0.1047 - val_loss: 3.2344\n",
      "Epoch 4/50\n",
      "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m8s\u001b[0m 357ms/step - accuracy: 0.8988 - loss: 0.3036 - val_accuracy: 0.1860 - val_loss: 3.3733\n",
      "Epoch 5/50\n",
      "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m8s\u001b[0m 356ms/step - accuracy: 0.9568 - loss: 0.1668 - val_accuracy: 0.1919 - val_loss: 3.6770\n",
      "Epoch 6/50\n",
      "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m8s\u001b[0m 358ms/step - accuracy: 0.9622 - loss: 0.0959 - val_accuracy: 0.2093 - val_loss: 4.5221\n",
      "Epoch 7/50\n",
      "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m8s\u001b[0m 358ms/step - accuracy: 0.9804 - loss: 0.0583 - val_accuracy: 0.1860 - val_loss: 4.2418\n",
      "Epoch 8/50\n",
      "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m8s\u001b[0m 360ms/step - accuracy: 0.9890 - loss: 0.0546 - val_accuracy: 0.2558 - val_loss: 4.3782\n",
      "Epoch 9/50\n",
      "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m8s\u001b[0m 372ms/step - accuracy: 0.9782 - loss: 0.0668 - val_accuracy: 0.2209 - val_loss: 4.8916\n",
      "Epoch 10/50\n",
      "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m8s\u001b[0m 365ms/step - accuracy: 0.9873 - loss: 0.0546 - val_accuracy: 0.2035 - val_loss: 3.8610\n",
      "Epoch 11/50\n",
      "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m8s\u001b[0m 368ms/step - accuracy: 0.9993 - loss: 0.0241 - val_accuracy: 0.1570 - val_loss: 6.5325\n",
      "Epoch 12/50\n",
      "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m8s\u001b[0m 357ms/step - accuracy: 0.9967 - loss: 0.0204 - val_accuracy: 0.3023 - val_loss: 5.0443\n",
      "Epoch 13/50\n",
      "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m8s\u001b[0m 365ms/step - accuracy: 0.9960 - loss: 0.0198 - val_accuracy: 0.1453 - val_loss: 5.2841\n",
      "Epoch 14/50\n",
      "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m8s\u001b[0m 375ms/step - accuracy: 0.9965 - loss: 0.0138 - val_accuracy: 0.1628 - val_loss: 5.3882\n",
      "Epoch 15/50\n",
      "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m8s\u001b[0m 370ms/step - accuracy: 0.9942 - loss: 0.0189 - val_accuracy: 0.1802 - val_loss: 5.9779\n",
      "Epoch 16/50\n",
      "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m8s\u001b[0m 360ms/step - accuracy: 0.9882 - loss: 0.0394 - val_accuracy: 0.2151 - val_loss: 5.2840\n",
      "Epoch 17/50\n",
      "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m8s\u001b[0m 374ms/step - accuracy: 0.9915 - loss: 0.0287 - val_accuracy: 0.2442 - val_loss: 6.5179\n",
      "Epoch 18/50\n",
      "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m8s\u001b[0m 377ms/step - accuracy: 0.9926 - loss: 0.0927 - val_accuracy: 0.2500 - val_loss: 5.0002\n",
      "Epoch 19/50\n",
      "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m8s\u001b[0m 366ms/step - accuracy: 0.9950 - loss: 0.0156 - val_accuracy: 0.1919 - val_loss: 6.8500\n",
      "Epoch 20/50\n",
      "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m8s\u001b[0m 369ms/step - accuracy: 0.9968 - loss: 0.0199 - val_accuracy: 0.2733 - val_loss: 5.3607\n",
      "Epoch 21/50\n",
      "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m8s\u001b[0m 369ms/step - accuracy: 0.9982 - loss: 0.0052 - val_accuracy: 0.1570 - val_loss: 7.8857\n",
      "Epoch 22/50\n",
      "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m8s\u001b[0m 373ms/step - accuracy: 0.9986 - loss: 0.0053 - val_accuracy: 0.2093 - val_loss: 7.1310\n",
      "Epoch 23/50\n",
      "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m8s\u001b[0m 363ms/step - accuracy: 1.0000 - loss: 0.0027 - val_accuracy: 0.2093 - val_loss: 8.0748\n",
      "Epoch 24/50\n",
      "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m8s\u001b[0m 361ms/step - accuracy: 1.0000 - loss: 0.0041 - val_accuracy: 0.2151 - val_loss: 8.0784\n",
      "Epoch 25/50\n",
      "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m8s\u001b[0m 367ms/step - accuracy: 0.9984 - loss: 0.0035 - val_accuracy: 0.2151 - val_loss: 7.7885\n",
      "Epoch 26/50\n",
      "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m8s\u001b[0m 370ms/step - accuracy: 0.9988 - loss: 0.0115 - val_accuracy: 0.1919 - val_loss: 7.3048\n",
      "Epoch 27/50\n",
      "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m8s\u001b[0m 362ms/step - accuracy: 0.9946 - loss: 0.0223 - val_accuracy: 0.1395 - val_loss: 6.4304\n",
      "Epoch 28/50\n",
      "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m8s\u001b[0m 371ms/step - accuracy: 0.9991 - loss: 0.0068 - val_accuracy: 0.1279 - val_loss: 7.8584\n",
      "Epoch 29/50\n",
      "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m8s\u001b[0m 368ms/step - accuracy: 0.9990 - loss: 0.0034 - val_accuracy: 0.1686 - val_loss: 6.9972\n",
      "Epoch 30/50\n",
      "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m8s\u001b[0m 364ms/step - accuracy: 0.9920 - loss: 0.0100 - val_accuracy: 0.1977 - val_loss: 7.0600\n",
      "Epoch 31/50\n",
      "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m8s\u001b[0m 361ms/step - accuracy: 0.9939 - loss: 0.0115 - val_accuracy: 0.1977 - val_loss: 5.5980\n",
      "Epoch 32/50\n",
      "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m8s\u001b[0m 366ms/step - accuracy: 1.0000 - loss: 0.0058 - val_accuracy: 0.2267 - val_loss: 6.0917\n",
      "Epoch 33/50\n",
      "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m8s\u001b[0m 359ms/step - accuracy: 0.9945 - loss: 0.0119 - val_accuracy: 0.1279 - val_loss: 7.7896\n",
      "Epoch 34/50\n",
      "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m8s\u001b[0m 358ms/step - accuracy: 0.9983 - loss: 0.0105 - val_accuracy: 0.2384 - val_loss: 5.9260\n",
      "Epoch 35/50\n",
      "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m8s\u001b[0m 359ms/step - accuracy: 0.9990 - loss: 0.0059 - val_accuracy: 0.1686 - val_loss: 6.6233\n",
      "Epoch 36/50\n",
      "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m8s\u001b[0m 363ms/step - accuracy: 0.9951 - loss: 0.0118 - val_accuracy: 0.0640 - val_loss: 9.1741\n",
      "Epoch 37/50\n",
      "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m8s\u001b[0m 363ms/step - accuracy: 0.9952 - loss: 0.0170 - val_accuracy: 0.1686 - val_loss: 6.2299\n",
      "Epoch 38/50\n",
      "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m8s\u001b[0m 369ms/step - accuracy: 0.9892 - loss: 0.0409 - val_accuracy: 0.1279 - val_loss: 6.3986\n",
      "Epoch 39/50\n",
      "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m8s\u001b[0m 367ms/step - accuracy: 1.0000 - loss: 0.0059 - val_accuracy: 0.1977 - val_loss: 7.7408\n",
      "Epoch 40/50\n",
      "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m8s\u001b[0m 367ms/step - accuracy: 1.0000 - loss: 0.0028 - val_accuracy: 0.1977 - val_loss: 8.0616\n",
      "Epoch 41/50\n",
      "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m8s\u001b[0m 357ms/step - accuracy: 0.9997 - loss: 0.0051 - val_accuracy: 0.2035 - val_loss: 7.9237\n",
      "Epoch 42/50\n",
      "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m8s\u001b[0m 361ms/step - accuracy: 0.9928 - loss: 0.0115 - val_accuracy: 0.1744 - val_loss: 5.3213\n",
      "Epoch 43/50\n",
      "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m8s\u001b[0m 359ms/step - accuracy: 0.9995 - loss: 0.0106 - val_accuracy: 0.2384 - val_loss: 5.1916\n",
      "Epoch 44/50\n",
      "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m8s\u001b[0m 357ms/step - accuracy: 0.9993 - loss: 0.0046 - val_accuracy: 0.2791 - val_loss: 5.7296\n",
      "Epoch 45/50\n",
      "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m8s\u001b[0m 355ms/step - accuracy: 1.0000 - loss: 0.0019 - val_accuracy: 0.3314 - val_loss: 6.0361\n",
      "Epoch 46/50\n",
      "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m8s\u001b[0m 346ms/step - accuracy: 0.9987 - loss: 0.0120 - val_accuracy: 0.3023 - val_loss: 5.8388\n",
      "Epoch 47/50\n",
      "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m8s\u001b[0m 351ms/step - accuracy: 0.9959 - loss: 0.0099 - val_accuracy: 0.2500 - val_loss: 6.4761\n",
      "Epoch 48/50\n",
      "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m8s\u001b[0m 352ms/step - accuracy: 1.0000 - loss: 0.0025 - val_accuracy: 0.2326 - val_loss: 6.9969\n",
      "Epoch 49/50\n",
      "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m8s\u001b[0m 348ms/step - accuracy: 1.0000 - loss: 7.9552e-04 - val_accuracy: 0.2209 - val_loss: 8.1560\n",
      "Epoch 50/50\n",
      "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m8s\u001b[0m 352ms/step - accuracy: 0.9973 - loss: 0.0071 - val_accuracy: 0.1279 - val_loss: 9.2396\n",
      "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 36ms/step - accuracy: 0.7365 - loss: 1.9235\n",
      "CNN Test Accuracy: 0.6850\n",
      "Epoch 1/50\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/mojo/.local/lib/python3.10/site-packages/keras/src/layers/core/dense.py:87: UserWarning: Do not pass an `input_shape`/`input_dim` argument to a layer. When using Sequential models, prefer using an `Input(shape)` object as the first layer in the model instead.\n",
      "  super().__init__(activity_regularizer=activity_regularizer, **kwargs)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 8ms/step - accuracy: 0.2938 - loss: 2.7029 - val_accuracy: 0.0058 - val_loss: 2.5995\n",
      "Epoch 2/50\n",
      "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.4549 - loss: 1.8551 - val_accuracy: 0.0465 - val_loss: 2.5842\n",
      "Epoch 3/50\n",
      "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.4624 - loss: 1.5771 - val_accuracy: 0.0465 - val_loss: 2.2871\n",
      "Epoch 4/50\n",
      "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.5024 - loss: 1.5584 - val_accuracy: 0.0523 - val_loss: 2.1923\n",
      "Epoch 5/50\n",
      "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.5477 - loss: 1.2997 - val_accuracy: 0.0523 - val_loss: 2.3541\n",
      "Epoch 6/50\n",
      "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.5936 - loss: 1.1269 - val_accuracy: 0.0872 - val_loss: 2.1811\n",
      "Epoch 7/50\n",
      "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.6261 - loss: 0.9903 - val_accuracy: 0.1395 - val_loss: 2.1667\n",
      "Epoch 8/50\n",
      "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - accuracy: 0.6726 - loss: 0.9115 - val_accuracy: 0.3140 - val_loss: 1.8413\n",
      "Epoch 9/50\n",
      "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.7133 - loss: 0.8437 - val_accuracy: 0.2151 - val_loss: 2.2250\n",
      "Epoch 10/50\n",
      "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.7194 - loss: 0.7020 - val_accuracy: 0.2674 - val_loss: 2.1223\n",
      "Epoch 11/50\n",
      "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.7415 - loss: 0.6931 - val_accuracy: 0.2965 - val_loss: 2.3364\n",
      "Epoch 12/50\n",
      "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.7873 - loss: 0.5858 - val_accuracy: 0.3081 - val_loss: 2.8005\n",
      "Epoch 13/50\n",
      "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.8146 - loss: 0.6335 - val_accuracy: 0.3081 - val_loss: 2.6157\n",
      "Epoch 14/50\n",
      "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.8147 - loss: 0.4787 - val_accuracy: 0.2616 - val_loss: 2.7525\n",
      "Epoch 15/50\n",
      "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.8371 - loss: 0.4717 - val_accuracy: 0.2907 - val_loss: 3.0331\n",
      "Epoch 16/50\n",
      "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.8665 - loss: 0.3871 - val_accuracy: 0.3023 - val_loss: 2.9235\n",
      "Epoch 17/50\n",
      "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.8497 - loss: 0.4771 - val_accuracy: 0.3605 - val_loss: 2.9722\n",
      "Epoch 18/50\n",
      "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.8776 - loss: 0.3091 - val_accuracy: 0.2733 - val_loss: 3.6105\n",
      "Epoch 19/50\n",
      "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.8952 - loss: 0.2811 - val_accuracy: 0.2791 - val_loss: 4.0209\n",
      "Epoch 20/50\n",
      "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.9282 - loss: 0.2941 - val_accuracy: 0.3314 - val_loss: 3.9915\n",
      "Epoch 21/50\n",
      "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.9248 - loss: 0.2416 - val_accuracy: 0.2849 - val_loss: 3.8884\n",
      "Epoch 22/50\n",
      "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.9215 - loss: 0.2405 - val_accuracy: 0.2965 - val_loss: 3.9843\n",
      "Epoch 23/50\n",
      "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - accuracy: 0.9272 - loss: 0.1875 - val_accuracy: 0.3140 - val_loss: 3.8285\n",
      "Epoch 24/50\n",
      "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.9366 - loss: 0.1836 - val_accuracy: 0.2849 - val_loss: 4.7380\n",
      "Epoch 25/50\n",
      "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.9497 - loss: 0.2211 - val_accuracy: 0.2965 - val_loss: 4.6857\n",
      "Epoch 26/50\n",
      "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.9500 - loss: 0.1487 - val_accuracy: 0.3605 - val_loss: 4.3759\n",
      "Epoch 27/50\n",
      "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.9462 - loss: 0.1721 - val_accuracy: 0.3140 - val_loss: 4.8576\n",
      "Epoch 28/50\n",
      "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.9465 - loss: 0.1568 - val_accuracy: 0.2907 - val_loss: 5.1421\n",
      "Epoch 29/50\n",
      "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.9512 - loss: 0.1462 - val_accuracy: 0.3256 - val_loss: 5.5054\n",
      "Epoch 30/50\n",
      "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.9631 - loss: 0.1711 - val_accuracy: 0.2674 - val_loss: 6.1122\n",
      "Epoch 31/50\n",
      "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.9598 - loss: 0.1299 - val_accuracy: 0.2209 - val_loss: 6.0670\n",
      "Epoch 32/50\n",
      "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.9381 - loss: 0.1815 - val_accuracy: 0.3081 - val_loss: 5.0258\n",
      "Epoch 33/50\n",
      "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.9393 - loss: 0.1669 - val_accuracy: 0.2384 - val_loss: 6.5094\n",
      "Epoch 34/50\n",
      "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.9255 - loss: 0.3072 - val_accuracy: 0.2209 - val_loss: 4.4744\n",
      "Epoch 35/50\n",
      "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.9491 - loss: 0.1615 - val_accuracy: 0.1686 - val_loss: 5.7334\n",
      "Epoch 36/50\n",
      "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.9551 - loss: 0.1584 - val_accuracy: 0.2384 - val_loss: 5.1716\n",
      "Epoch 37/50\n",
      "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.9556 - loss: 0.1327 - val_accuracy: 0.1860 - val_loss: 6.2278\n",
      "Epoch 38/50\n",
      "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.9627 - loss: 0.1552 - val_accuracy: 0.2500 - val_loss: 5.5820\n",
      "Epoch 39/50\n",
      "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - accuracy: 0.9447 - loss: 0.1837 - val_accuracy: 0.2384 - val_loss: 5.2809\n",
      "Epoch 40/50\n",
      "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.9595 - loss: 0.1432 - val_accuracy: 0.1395 - val_loss: 6.7082\n",
      "Epoch 41/50\n",
      "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.9471 - loss: 0.1700 - val_accuracy: 0.1628 - val_loss: 6.2447\n",
      "Epoch 42/50\n",
      "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.9545 - loss: 0.1267 - val_accuracy: 0.1744 - val_loss: 6.5890\n",
      "Epoch 43/50\n",
      "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.9643 - loss: 0.1206 - val_accuracy: 0.2151 - val_loss: 5.8152\n",
      "Epoch 44/50\n",
      "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.9682 - loss: 0.0919 - val_accuracy: 0.2035 - val_loss: 5.8707\n",
      "Epoch 45/50\n",
      "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.9608 - loss: 0.1413 - val_accuracy: 0.1977 - val_loss: 7.4224\n",
      "Epoch 46/50\n",
      "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.9820 - loss: 0.0734 - val_accuracy: 0.1395 - val_loss: 8.2141\n",
      "Epoch 47/50\n",
      "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.9812 - loss: 0.0534 - val_accuracy: 0.1628 - val_loss: 7.3639\n",
      "Epoch 48/50\n",
      "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.9743 - loss: 0.0749 - val_accuracy: 0.2267 - val_loss: 6.6805\n",
      "Epoch 49/50\n",
      "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.9641 - loss: 0.1026 - val_accuracy: 0.2326 - val_loss: 6.5904\n",
      "Epoch 50/50\n",
      "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.9716 - loss: 0.1561 - val_accuracy: 0.1977 - val_loss: 6.8262\n",
      "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - accuracy: 0.7043 - loss: 1.4297 \n",
      "ANN Test Accuracy: 0.7165\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "from sklearn.preprocessing import LabelEncoder\n",
    "from sklearn.svm import SVC\n",
    "from sklearn.metrics import accuracy_score, classification_report\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "\n",
    "# Load the data\n",
    "train_data = np.load('./layer_features_base_960h/train_6.npz')\n",
    "test_data = np.load('./layer_features_base_960h/test_6.npz')\n",
    "\n",
    "train_features = train_data['features']\n",
    "test_features = test_data['features']\n",
    "\n",
    "# Read Age labels instead of Gender\n",
    "train_labels = pd.read_csv('y_train.csv').Age\n",
    "test_labels = pd.read_csv('y_test.csv').Age\n",
    "\n",
    "# Encode the labels\n",
    "label_encoder = LabelEncoder()\n",
    "train_labels_encoded = label_encoder.fit_transform(train_labels)\n",
    "\n",
    "# Handle unseen labels in test set by filtering out labels not present in train set\n",
    "test_labels_filtered = test_labels[test_labels.isin(train_labels.unique())]\n",
    "test_features_filtered = test_features[test_labels.isin(train_labels.unique())]\n",
    "test_labels_encoded = label_encoder.transform(test_labels_filtered)\n",
    "\n",
    "# Standardize features\n",
    "scaler = StandardScaler()\n",
    "train_features_normalized = scaler.fit_transform(train_features)\n",
    "test_features_normalized = scaler.transform(test_features_filtered)\n",
    "\n",
    "# SVM model\n",
    "svm_model = SVC(kernel='linear', C=10.0, gamma='scale', random_state=42)\n",
    "svm_model.fit(train_features_normalized, train_labels_encoded)\n",
    "\n",
    "# Prediction and Evaluation\n",
    "svm_predictions = svm_model.predict(test_features_normalized)\n",
    "svm_accuracy = accuracy_score(test_labels_encoded, svm_predictions)\n",
    "print(f\"SVM Accuracy: {svm_accuracy:.4f}\")\n",
    "print(\"SVM Classification Report:\")\n",
    "print(classification_report(test_labels_encoded, svm_predictions))\n",
    "\n",
    "# CNN model (TensorFlow)\n",
    "import tensorflow as tf\n",
    "from tensorflow.keras.models import Sequential\n",
    "from tensorflow.keras.layers import Conv1D, Flatten, Dense, Dropout\n",
    "\n",
    "train_features_cnn = np.expand_dims(train_features_normalized, axis=-1)  # Shape: (num_samples, 768, 1)\n",
    "test_features_cnn = np.expand_dims(test_features_normalized, axis=-1)    # Shape: (num_samples, 768, 1)\n",
    "\n",
    "cnn_model = Sequential([\n",
    "    Conv1D(64, kernel_size=5, activation='relu', input_shape=(768, 1)),  # Update input shape to 768 features\n",
    "    Conv1D(128, kernel_size=5, activation='relu'),\n",
    "    Conv1D(256, kernel_size=5, activation='relu'),\n",
    "    Flatten(),\n",
    "    Dense(256, activation='relu'),\n",
    "    Dropout(0.5),\n",
    "    Dense(len(label_encoder.classes_), activation='softmax')\n",
    "])\n",
    "\n",
    "cnn_model.compile(optimizer='adam', loss='sparse_categorical_crossentropy', metrics=['accuracy'])\n",
    "\n",
    "cnn_model.fit(train_features_cnn, train_labels_encoded, epochs=50, batch_size=32, validation_split=0.2)\n",
    "\n",
    "cnn_test_loss, cnn_test_accuracy = cnn_model.evaluate(test_features_cnn, test_labels_encoded)\n",
    "print(f\"CNN Test Accuracy: {cnn_test_accuracy:.4f}\")\n",
    "\n",
    "# ANN model (TensorFlow)\n",
    "ann_model = Sequential([\n",
    "    Dense(512, activation='relu', input_shape=(768,)),  # Update input shape to 768 features\n",
    "    Dropout(0.5),\n",
    "    Dense(256, activation='relu'),\n",
    "    Dropout(0.5),\n",
    "    Dense(128, activation='relu'),\n",
    "    Dropout(0.5),\n",
    "    Dense(len(label_encoder.classes_), activation='softmax')\n",
    "])\n",
    "\n",
    "ann_model.compile(optimizer='adam', loss='sparse_categorical_crossentropy', metrics=['accuracy'])\n",
    "\n",
    "ann_model.fit(train_features_normalized, train_labels_encoded, epochs=50, batch_size=32, validation_split=0.2)\n",
    "\n",
    "ann_test_loss, ann_test_accuracy = ann_model.evaluate(test_features_normalized, test_labels_encoded)\n",
    "print(f\"ANN Test Accuracy: {ann_test_accuracy:.4f}\")\n",
    "\n",
    "# PyTorch CNN Model\n",
    "import torch\n",
    "from torch.utils.data import DataLoader, TensorDataset\n",
    "\n",
    "X_train_tensor = torch.tensor(train_features_cnn, dtype=torch.float32).permute(0, 2, 1)  # Shape: (num_samples, 1, 768)\n",
    "y_train_tensor = torch.tensor(train_labels_encoded, dtype=torch.long)\n",
    "X_test_tensor = torch.tensor(test_features_cnn, dtype=torch.float32).permute(0, 2, 1)    # Shape: (num_samples, 1, 768)\n",
    "y_test_tensor = torch.tensor(test_labels_encoded, dtype=torch.long)\n",
    "\n",
    "train_dataset = TensorDataset(X_train_tensor, y_train_tensor)\n",
    "test_dataset = TensorDataset(X_test_tensor, y_test_tensor)\n",
    "\n",
    "train_loader = DataLoader(train_dataset, batch_size=64, shuffle=True)\n",
    "test_loader = DataLoader(test_dataset, batch_size=64, shuffle=False)\n",
    "\n",
    "import torch.nn as nn\n",
    "import torch.optim as optim\n",
    "\n",
    "class CNN1DModel(nn.Module):\n",
    "    def __init__(self, input_channels, num_classes):\n",
    "        super(CNN1DModel, self).__init__()\n",
    "        self.conv1 = nn.Conv1d(input_channels, 32, kernel_size=5, stride=1, padding=2)\n",
    "        self.bn1 = nn.BatchNorm1d(32)\n",
    "        self.relu = nn.ReLU()\n",
    "        self.conv2 = nn.Conv1d(32, 64, kernel_size=5, stride=1, padding=2)\n",
    "        self.bn2 = nn.BatchNorm1d(64)\n",
    "        self.conv3 = nn.Conv1d(64, 128, kernel_size=5, stride=1, padding=2)\n",
    "        self.bn3 = nn.BatchNorm1d(128)\n",
    "        self.flatten = nn.Flatten()\n",
    "        self.fc1 = nn.Linear(128 * 768, 512)  # Update to 768 features\n",
    "        self.fc2 = nn.Linear(512, num_classes)\n",
    "        self.dropout = nn.Dropout(0.5)\n",
    "    \n",
    "    def forward(self, x):\n",
    "        x = self.relu(self.bn1(self.conv1(x)))\n",
    "        x = self.relu(self.bn2(self.conv2(x)))\n",
    "        x = self.relu(self.bn3(self.conv3(x)))\n",
    "        x = self.flatten(x)\n",
    "        x = self.dropout(self.relu(self.fc1(x)))\n",
    "        x = self.fc2(x)\n",
    "        return x\n",
    "\n",
    "input_channels = 1\n",
    "num_classes = len(label_encoder.classes_)\n",
    "model = CNN1DModel(input_channels, num_classes)\n",
    "criterion = nn.CrossEntropyLoss()\n",
    "optimizer = optim.Adam(model.parameters(), lr=0.001)\n",
    "\n",
    "# Training and testing as before\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "c47a7665",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "SVM Accuracy: 0.8268\n",
      "SVM Classification Report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           1       0.77      0.83      0.80        12\n",
      "           2       0.71      0.62      0.67         8\n",
      "           3       0.93      0.97      0.95        39\n",
      "           4       0.67      0.33      0.44         6\n",
      "           5       0.78      0.90      0.84        42\n",
      "           6       0.89      0.50      0.64        16\n",
      "           7       1.00      1.00      1.00         2\n",
      "           8       0.67      1.00      0.80         2\n",
      "\n",
      "    accuracy                           0.83       127\n",
      "   macro avg       0.80      0.77      0.77       127\n",
      "weighted avg       0.83      0.83      0.82       127\n",
      "\n",
      "Epoch 1/50\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/mojo/.local/lib/python3.10/site-packages/keras/src/layers/convolutional/base_conv.py:107: UserWarning: Do not pass an `input_shape`/`input_dim` argument to a layer. When using Sequential models, prefer using an `Input(shape)` object as the first layer in the model instead.\n",
      "  super().__init__(activity_regularizer=activity_regularizer, **kwargs)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m8s\u001b[0m 346ms/step - accuracy: 0.3055 - loss: 4.3887 - val_accuracy: 0.0058 - val_loss: 2.5008\n",
      "Epoch 2/50\n",
      "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m7s\u001b[0m 340ms/step - accuracy: 0.5224 - loss: 1.3781 - val_accuracy: 0.0465 - val_loss: 2.3078\n",
      "Epoch 3/50\n",
      "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m8s\u001b[0m 343ms/step - accuracy: 0.7088 - loss: 0.7980 - val_accuracy: 0.0698 - val_loss: 3.1663\n",
      "Epoch 4/50\n",
      "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m8s\u001b[0m 347ms/step - accuracy: 0.8276 - loss: 0.4889 - val_accuracy: 0.1570 - val_loss: 3.3898\n",
      "Epoch 5/50\n",
      "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m8s\u001b[0m 349ms/step - accuracy: 0.8890 - loss: 0.3279 - val_accuracy: 0.1047 - val_loss: 4.7337\n",
      "Epoch 6/50\n",
      "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m8s\u001b[0m 357ms/step - accuracy: 0.9589 - loss: 0.1799 - val_accuracy: 0.2151 - val_loss: 2.8731\n",
      "Epoch 7/50\n",
      "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m8s\u001b[0m 356ms/step - accuracy: 0.9698 - loss: 0.1299 - val_accuracy: 0.1919 - val_loss: 4.5814\n",
      "Epoch 8/50\n",
      "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m8s\u001b[0m 346ms/step - accuracy: 0.9438 - loss: 0.1371 - val_accuracy: 0.2209 - val_loss: 3.9923\n",
      "Epoch 9/50\n",
      "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m8s\u001b[0m 350ms/step - accuracy: 0.9803 - loss: 0.0659 - val_accuracy: 0.1221 - val_loss: 6.6184\n",
      "Epoch 10/50\n",
      "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m8s\u001b[0m 348ms/step - accuracy: 0.9827 - loss: 0.0568 - val_accuracy: 0.1860 - val_loss: 5.2364\n",
      "Epoch 11/50\n",
      "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m8s\u001b[0m 349ms/step - accuracy: 0.9820 - loss: 0.0797 - val_accuracy: 0.1802 - val_loss: 5.7468\n",
      "Epoch 12/50\n",
      "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m8s\u001b[0m 350ms/step - accuracy: 0.9760 - loss: 0.0525 - val_accuracy: 0.1802 - val_loss: 5.6827\n",
      "Epoch 13/50\n",
      "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m8s\u001b[0m 350ms/step - accuracy: 0.9818 - loss: 0.0619 - val_accuracy: 0.1802 - val_loss: 4.3328\n",
      "Epoch 14/50\n",
      "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m8s\u001b[0m 348ms/step - accuracy: 0.9859 - loss: 0.0848 - val_accuracy: 0.1802 - val_loss: 6.4040\n",
      "Epoch 15/50\n",
      "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m8s\u001b[0m 351ms/step - accuracy: 0.9813 - loss: 0.0782 - val_accuracy: 0.1279 - val_loss: 5.6391\n",
      "Epoch 16/50\n",
      "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m8s\u001b[0m 350ms/step - accuracy: 0.9888 - loss: 0.0383 - val_accuracy: 0.1919 - val_loss: 5.8609\n",
      "Epoch 17/50\n",
      "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m8s\u001b[0m 348ms/step - accuracy: 0.9958 - loss: 0.0192 - val_accuracy: 0.2674 - val_loss: 4.5667\n",
      "Epoch 18/50\n",
      "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m8s\u001b[0m 357ms/step - accuracy: 0.9895 - loss: 0.0303 - val_accuracy: 0.1977 - val_loss: 6.0368\n",
      "Epoch 19/50\n",
      "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m8s\u001b[0m 356ms/step - accuracy: 0.9879 - loss: 0.0424 - val_accuracy: 0.1279 - val_loss: 7.3331\n",
      "Epoch 20/50\n",
      "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m8s\u001b[0m 361ms/step - accuracy: 0.9948 - loss: 0.0142 - val_accuracy: 0.1395 - val_loss: 6.9942\n",
      "Epoch 21/50\n",
      "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m8s\u001b[0m 353ms/step - accuracy: 0.9958 - loss: 0.0126 - val_accuracy: 0.1977 - val_loss: 6.4300\n",
      "Epoch 22/50\n",
      "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m8s\u001b[0m 355ms/step - accuracy: 0.9993 - loss: 0.0085 - val_accuracy: 0.1802 - val_loss: 6.9475\n",
      "Epoch 23/50\n",
      "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m8s\u001b[0m 352ms/step - accuracy: 0.9903 - loss: 0.0218 - val_accuracy: 0.1628 - val_loss: 5.8992\n",
      "Epoch 24/50\n",
      "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m8s\u001b[0m 354ms/step - accuracy: 0.9885 - loss: 0.0315 - val_accuracy: 0.1628 - val_loss: 6.2177\n",
      "Epoch 25/50\n",
      "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m8s\u001b[0m 358ms/step - accuracy: 0.9921 - loss: 0.0160 - val_accuracy: 0.2093 - val_loss: 6.6965\n",
      "Epoch 26/50\n",
      "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m8s\u001b[0m 356ms/step - accuracy: 0.9997 - loss: 0.0059 - val_accuracy: 0.2035 - val_loss: 7.1634\n",
      "Epoch 27/50\n",
      "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m8s\u001b[0m 362ms/step - accuracy: 0.9896 - loss: 0.0246 - val_accuracy: 0.2093 - val_loss: 5.7123\n",
      "Epoch 28/50\n",
      "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m8s\u001b[0m 361ms/step - accuracy: 0.9948 - loss: 0.0144 - val_accuracy: 0.1628 - val_loss: 8.3735\n",
      "Epoch 29/50\n",
      "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m8s\u001b[0m 363ms/step - accuracy: 0.9979 - loss: 0.0089 - val_accuracy: 0.1919 - val_loss: 6.7525\n",
      "Epoch 30/50\n",
      "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m8s\u001b[0m 364ms/step - accuracy: 0.9942 - loss: 0.0180 - val_accuracy: 0.1512 - val_loss: 7.0950\n",
      "Epoch 31/50\n",
      "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m8s\u001b[0m 361ms/step - accuracy: 0.9953 - loss: 0.0129 - val_accuracy: 0.1977 - val_loss: 7.1003\n",
      "Epoch 32/50\n",
      "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m8s\u001b[0m 358ms/step - accuracy: 0.9984 - loss: 0.0043 - val_accuracy: 0.1919 - val_loss: 7.8538\n",
      "Epoch 33/50\n",
      "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m8s\u001b[0m 361ms/step - accuracy: 0.9932 - loss: 0.0149 - val_accuracy: 0.1977 - val_loss: 7.6080\n",
      "Epoch 34/50\n",
      "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m8s\u001b[0m 359ms/step - accuracy: 0.9992 - loss: 0.0104 - val_accuracy: 0.1802 - val_loss: 8.3404\n",
      "Epoch 35/50\n",
      "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m8s\u001b[0m 358ms/step - accuracy: 0.9959 - loss: 0.0153 - val_accuracy: 0.1686 - val_loss: 7.9084\n",
      "Epoch 36/50\n",
      "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m8s\u001b[0m 359ms/step - accuracy: 0.9998 - loss: 0.0045 - val_accuracy: 0.1919 - val_loss: 7.5572\n",
      "Epoch 37/50\n",
      "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m10s\u001b[0m 358ms/step - accuracy: 1.0000 - loss: 0.0030 - val_accuracy: 0.1919 - val_loss: 8.0911\n",
      "Epoch 38/50\n",
      "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m8s\u001b[0m 359ms/step - accuracy: 0.9997 - loss: 0.0026 - val_accuracy: 0.1686 - val_loss: 9.2354\n",
      "Epoch 39/50\n",
      "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m8s\u001b[0m 363ms/step - accuracy: 0.9957 - loss: 0.0131 - val_accuracy: 0.1570 - val_loss: 8.9378\n",
      "Epoch 40/50\n",
      "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m8s\u001b[0m 358ms/step - accuracy: 0.9937 - loss: 0.0150 - val_accuracy: 0.1279 - val_loss: 8.0111\n",
      "Epoch 41/50\n",
      "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m8s\u001b[0m 361ms/step - accuracy: 0.9927 - loss: 0.0374 - val_accuracy: 0.1453 - val_loss: 5.9150\n",
      "Epoch 42/50\n",
      "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m8s\u001b[0m 364ms/step - accuracy: 0.9985 - loss: 0.0125 - val_accuracy: 0.1744 - val_loss: 6.1882\n",
      "Epoch 43/50\n",
      "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m8s\u001b[0m 359ms/step - accuracy: 0.9973 - loss: 0.0081 - val_accuracy: 0.1686 - val_loss: 6.9053\n",
      "Epoch 44/50\n",
      "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m8s\u001b[0m 362ms/step - accuracy: 0.9980 - loss: 0.0072 - val_accuracy: 0.1686 - val_loss: 7.6810\n",
      "Epoch 45/50\n",
      "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m8s\u001b[0m 361ms/step - accuracy: 0.9993 - loss: 0.0050 - val_accuracy: 0.1221 - val_loss: 9.5898\n",
      "Epoch 46/50\n",
      "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m8s\u001b[0m 363ms/step - accuracy: 0.9995 - loss: 0.0046 - val_accuracy: 0.1512 - val_loss: 9.2816\n",
      "Epoch 47/50\n",
      "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m8s\u001b[0m 361ms/step - accuracy: 0.9988 - loss: 0.0131 - val_accuracy: 0.1163 - val_loss: 8.7479\n",
      "Epoch 48/50\n",
      "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m8s\u001b[0m 359ms/step - accuracy: 0.9988 - loss: 0.0027 - val_accuracy: 0.1337 - val_loss: 10.1672\n",
      "Epoch 49/50\n",
      "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m8s\u001b[0m 361ms/step - accuracy: 0.9994 - loss: 0.0090 - val_accuracy: 0.1395 - val_loss: 10.8433\n",
      "Epoch 50/50\n",
      "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m8s\u001b[0m 360ms/step - accuracy: 0.9996 - loss: 0.0038 - val_accuracy: 0.1744 - val_loss: 10.2872\n",
      "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 38ms/step - accuracy: 0.7073 - loss: 2.1382\n",
      "CNN Test Accuracy: 0.6693\n",
      "Epoch 1/50\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/mojo/.local/lib/python3.10/site-packages/keras/src/layers/core/dense.py:87: UserWarning: Do not pass an `input_shape`/`input_dim` argument to a layer. When using Sequential models, prefer using an `Input(shape)` object as the first layer in the model instead.\n",
      "  super().__init__(activity_regularizer=activity_regularizer, **kwargs)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 8ms/step - accuracy: 0.2919 - loss: 3.0286 - val_accuracy: 0.0000e+00 - val_loss: 2.5678\n",
      "Epoch 2/50\n",
      "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.3946 - loss: 2.0388 - val_accuracy: 0.0407 - val_loss: 2.6269\n",
      "Epoch 3/50\n",
      "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.4385 - loss: 1.7512 - val_accuracy: 0.0174 - val_loss: 2.5124\n",
      "Epoch 4/50\n",
      "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.4819 - loss: 1.5730 - val_accuracy: 0.0465 - val_loss: 2.4561\n",
      "Epoch 5/50\n",
      "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.4961 - loss: 1.5353 - val_accuracy: 0.0698 - val_loss: 2.3005\n",
      "Epoch 6/50\n",
      "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.5410 - loss: 1.3960 - val_accuracy: 0.0407 - val_loss: 2.4698\n",
      "Epoch 7/50\n",
      "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.5810 - loss: 1.2065 - val_accuracy: 0.1395 - val_loss: 2.4332\n",
      "Epoch 8/50\n",
      "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.5688 - loss: 1.2109 - val_accuracy: 0.1570 - val_loss: 2.5632\n",
      "Epoch 9/50\n",
      "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.6263 - loss: 1.0901 - val_accuracy: 0.1977 - val_loss: 2.5279\n",
      "Epoch 10/50\n",
      "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.6322 - loss: 1.0273 - val_accuracy: 0.1395 - val_loss: 2.4529\n",
      "Epoch 11/50\n",
      "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.6492 - loss: 1.0050 - val_accuracy: 0.1802 - val_loss: 2.3543\n",
      "Epoch 12/50\n",
      "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - accuracy: 0.6760 - loss: 0.9315 - val_accuracy: 0.1977 - val_loss: 2.4593\n",
      "Epoch 13/50\n",
      "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.6707 - loss: 0.8755 - val_accuracy: 0.1919 - val_loss: 2.4704\n",
      "Epoch 14/50\n",
      "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.7604 - loss: 0.7393 - val_accuracy: 0.2442 - val_loss: 2.5311\n",
      "Epoch 15/50\n",
      "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.7752 - loss: 0.6031 - val_accuracy: 0.1977 - val_loss: 2.9105\n",
      "Epoch 16/50\n",
      "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.7521 - loss: 0.6838 - val_accuracy: 0.2151 - val_loss: 2.9280\n",
      "Epoch 17/50\n",
      "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.7612 - loss: 0.6527 - val_accuracy: 0.2151 - val_loss: 2.7231\n",
      "Epoch 18/50\n",
      "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.8245 - loss: 0.5459 - val_accuracy: 0.2267 - val_loss: 2.9899\n",
      "Epoch 19/50\n",
      "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.7999 - loss: 0.6176 - val_accuracy: 0.2035 - val_loss: 3.1180\n",
      "Epoch 20/50\n",
      "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.8368 - loss: 0.4840 - val_accuracy: 0.2035 - val_loss: 3.1003\n",
      "Epoch 21/50\n",
      "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.8525 - loss: 0.4565 - val_accuracy: 0.2674 - val_loss: 3.1450\n",
      "Epoch 22/50\n",
      "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - accuracy: 0.8370 - loss: 0.4414 - val_accuracy: 0.2442 - val_loss: 3.5157\n",
      "Epoch 23/50\n",
      "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - accuracy: 0.8324 - loss: 0.4857 - val_accuracy: 0.1860 - val_loss: 3.6068\n",
      "Epoch 24/50\n",
      "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - accuracy: 0.8465 - loss: 0.4627 - val_accuracy: 0.2442 - val_loss: 3.6097\n",
      "Epoch 25/50\n",
      "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.8576 - loss: 0.4093 - val_accuracy: 0.2093 - val_loss: 3.5934\n",
      "Epoch 26/50\n",
      "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.8496 - loss: 0.4356 - val_accuracy: 0.1919 - val_loss: 4.1085\n",
      "Epoch 27/50\n",
      "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.9055 - loss: 0.2758 - val_accuracy: 0.1919 - val_loss: 3.6372\n",
      "Epoch 28/50\n",
      "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.8737 - loss: 0.3780 - val_accuracy: 0.2558 - val_loss: 3.7743\n",
      "Epoch 29/50\n",
      "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.9144 - loss: 0.3009 - val_accuracy: 0.1744 - val_loss: 4.9195\n",
      "Epoch 30/50\n",
      "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.9042 - loss: 0.2647 - val_accuracy: 0.2384 - val_loss: 4.6128\n",
      "Epoch 31/50\n",
      "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.8850 - loss: 0.3352 - val_accuracy: 0.2267 - val_loss: 4.6288\n",
      "Epoch 32/50\n",
      "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.9152 - loss: 0.2396 - val_accuracy: 0.2558 - val_loss: 4.0623\n",
      "Epoch 33/50\n",
      "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.9167 - loss: 0.2379 - val_accuracy: 0.2209 - val_loss: 3.8897\n",
      "Epoch 34/50\n",
      "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.9347 - loss: 0.2619 - val_accuracy: 0.1977 - val_loss: 3.9510\n",
      "Epoch 35/50\n",
      "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.9139 - loss: 0.2466 - val_accuracy: 0.2791 - val_loss: 3.7651\n",
      "Epoch 36/50\n",
      "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.9323 - loss: 0.2302 - val_accuracy: 0.1860 - val_loss: 5.1483\n",
      "Epoch 37/50\n",
      "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.9378 - loss: 0.1663 - val_accuracy: 0.1860 - val_loss: 5.0271\n",
      "Epoch 38/50\n",
      "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.9436 - loss: 0.1666 - val_accuracy: 0.2326 - val_loss: 5.0965\n",
      "Epoch 39/50\n",
      "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.9604 - loss: 0.1205 - val_accuracy: 0.1686 - val_loss: 5.7009\n",
      "Epoch 40/50\n",
      "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.9139 - loss: 0.2317 - val_accuracy: 0.1570 - val_loss: 5.1421\n",
      "Epoch 41/50\n",
      "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.9584 - loss: 0.1329 - val_accuracy: 0.2151 - val_loss: 5.4759\n",
      "Epoch 42/50\n",
      "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.9485 - loss: 0.1900 - val_accuracy: 0.2326 - val_loss: 4.9818\n",
      "Epoch 43/50\n",
      "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.9478 - loss: 0.1938 - val_accuracy: 0.1802 - val_loss: 6.3758\n",
      "Epoch 44/50\n",
      "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.9456 - loss: 0.1879 - val_accuracy: 0.1744 - val_loss: 6.8474\n",
      "Epoch 45/50\n",
      "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.9240 - loss: 0.2597 - val_accuracy: 0.2442 - val_loss: 5.3634\n",
      "Epoch 46/50\n",
      "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.9385 - loss: 0.2239 - val_accuracy: 0.2267 - val_loss: 5.9300\n",
      "Epoch 47/50\n",
      "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.9471 - loss: 0.1723 - val_accuracy: 0.2093 - val_loss: 5.1694\n",
      "Epoch 48/50\n",
      "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.9373 - loss: 0.1817 - val_accuracy: 0.1919 - val_loss: 6.0752\n",
      "Epoch 49/50\n",
      "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.9525 - loss: 0.1296 - val_accuracy: 0.2093 - val_loss: 5.8336\n",
      "Epoch 50/50\n",
      "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.9473 - loss: 0.1459 - val_accuracy: 0.1977 - val_loss: 5.4819\n",
      "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.7701 - loss: 1.3611 \n",
      "ANN Test Accuracy: 0.7795\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "from sklearn.preprocessing import LabelEncoder\n",
    "from sklearn.svm import SVC\n",
    "from sklearn.metrics import accuracy_score, classification_report\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "\n",
    "# Load the data\n",
    "train_data = np.load('./layer_features_base_960h/train_7.npz')\n",
    "test_data = np.load('./layer_features_base_960h/test_7.npz')\n",
    "\n",
    "train_features = train_data['features']\n",
    "test_features = test_data['features']\n",
    "\n",
    "# Read Age labels instead of Gender\n",
    "train_labels = pd.read_csv('y_train.csv').Age\n",
    "test_labels = pd.read_csv('y_test.csv').Age\n",
    "\n",
    "# Encode the labels\n",
    "label_encoder = LabelEncoder()\n",
    "train_labels_encoded = label_encoder.fit_transform(train_labels)\n",
    "\n",
    "# Handle unseen labels in test set by filtering out labels not present in train set\n",
    "test_labels_filtered = test_labels[test_labels.isin(train_labels.unique())]\n",
    "test_features_filtered = test_features[test_labels.isin(train_labels.unique())]\n",
    "test_labels_encoded = label_encoder.transform(test_labels_filtered)\n",
    "\n",
    "# Standardize features\n",
    "scaler = StandardScaler()\n",
    "train_features_normalized = scaler.fit_transform(train_features)\n",
    "test_features_normalized = scaler.transform(test_features_filtered)\n",
    "\n",
    "# SVM model\n",
    "svm_model = SVC(kernel='linear', C=10.0, gamma='scale', random_state=42)\n",
    "svm_model.fit(train_features_normalized, train_labels_encoded)\n",
    "\n",
    "# Prediction and Evaluation\n",
    "svm_predictions = svm_model.predict(test_features_normalized)\n",
    "svm_accuracy = accuracy_score(test_labels_encoded, svm_predictions)\n",
    "print(f\"SVM Accuracy: {svm_accuracy:.4f}\")\n",
    "print(\"SVM Classification Report:\")\n",
    "print(classification_report(test_labels_encoded, svm_predictions))\n",
    "\n",
    "# CNN model (TensorFlow)\n",
    "import tensorflow as tf\n",
    "from tensorflow.keras.models import Sequential\n",
    "from tensorflow.keras.layers import Conv1D, Flatten, Dense, Dropout\n",
    "\n",
    "train_features_cnn = np.expand_dims(train_features_normalized, axis=-1)  # Shape: (num_samples, 768, 1)\n",
    "test_features_cnn = np.expand_dims(test_features_normalized, axis=-1)    # Shape: (num_samples, 768, 1)\n",
    "\n",
    "cnn_model = Sequential([\n",
    "    Conv1D(64, kernel_size=5, activation='relu', input_shape=(768, 1)),  # Update input shape to 768 features\n",
    "    Conv1D(128, kernel_size=5, activation='relu'),\n",
    "    Conv1D(256, kernel_size=5, activation='relu'),\n",
    "    Flatten(),\n",
    "    Dense(256, activation='relu'),\n",
    "    Dropout(0.5),\n",
    "    Dense(len(label_encoder.classes_), activation='softmax')\n",
    "])\n",
    "\n",
    "cnn_model.compile(optimizer='adam', loss='sparse_categorical_crossentropy', metrics=['accuracy'])\n",
    "\n",
    "cnn_model.fit(train_features_cnn, train_labels_encoded, epochs=50, batch_size=32, validation_split=0.2)\n",
    "\n",
    "cnn_test_loss, cnn_test_accuracy = cnn_model.evaluate(test_features_cnn, test_labels_encoded)\n",
    "print(f\"CNN Test Accuracy: {cnn_test_accuracy:.4f}\")\n",
    "\n",
    "# ANN model (TensorFlow)\n",
    "ann_model = Sequential([\n",
    "    Dense(512, activation='relu', input_shape=(768,)),  # Update input shape to 768 features\n",
    "    Dropout(0.5),\n",
    "    Dense(256, activation='relu'),\n",
    "    Dropout(0.5),\n",
    "    Dense(128, activation='relu'),\n",
    "    Dropout(0.5),\n",
    "    Dense(len(label_encoder.classes_), activation='softmax')\n",
    "])\n",
    "\n",
    "ann_model.compile(optimizer='adam', loss='sparse_categorical_crossentropy', metrics=['accuracy'])\n",
    "\n",
    "ann_model.fit(train_features_normalized, train_labels_encoded, epochs=50, batch_size=32, validation_split=0.2)\n",
    "\n",
    "ann_test_loss, ann_test_accuracy = ann_model.evaluate(test_features_normalized, test_labels_encoded)\n",
    "print(f\"ANN Test Accuracy: {ann_test_accuracy:.4f}\")\n",
    "\n",
    "# PyTorch CNN Model\n",
    "import torch\n",
    "from torch.utils.data import DataLoader, TensorDataset\n",
    "\n",
    "X_train_tensor = torch.tensor(train_features_cnn, dtype=torch.float32).permute(0, 2, 1)  # Shape: (num_samples, 1, 768)\n",
    "y_train_tensor = torch.tensor(train_labels_encoded, dtype=torch.long)\n",
    "X_test_tensor = torch.tensor(test_features_cnn, dtype=torch.float32).permute(0, 2, 1)    # Shape: (num_samples, 1, 768)\n",
    "y_test_tensor = torch.tensor(test_labels_encoded, dtype=torch.long)\n",
    "\n",
    "train_dataset = TensorDataset(X_train_tensor, y_train_tensor)\n",
    "test_dataset = TensorDataset(X_test_tensor, y_test_tensor)\n",
    "\n",
    "train_loader = DataLoader(train_dataset, batch_size=64, shuffle=True)\n",
    "test_loader = DataLoader(test_dataset, batch_size=64, shuffle=False)\n",
    "\n",
    "import torch.nn as nn\n",
    "import torch.optim as optim\n",
    "\n",
    "class CNN1DModel(nn.Module):\n",
    "    def __init__(self, input_channels, num_classes):\n",
    "        super(CNN1DModel, self).__init__()\n",
    "        self.conv1 = nn.Conv1d(input_channels, 32, kernel_size=5, stride=1, padding=2)\n",
    "        self.bn1 = nn.BatchNorm1d(32)\n",
    "        self.relu = nn.ReLU()\n",
    "        self.conv2 = nn.Conv1d(32, 64, kernel_size=5, stride=1, padding=2)\n",
    "        self.bn2 = nn.BatchNorm1d(64)\n",
    "        self.conv3 = nn.Conv1d(64, 128, kernel_size=5, stride=1, padding=2)\n",
    "        self.bn3 = nn.BatchNorm1d(128)\n",
    "        self.flatten = nn.Flatten()\n",
    "        self.fc1 = nn.Linear(128 * 768, 512)  # Update to 768 features\n",
    "        self.fc2 = nn.Linear(512, num_classes)\n",
    "        self.dropout = nn.Dropout(0.5)\n",
    "    \n",
    "    def forward(self, x):\n",
    "        x = self.relu(self.bn1(self.conv1(x)))\n",
    "        x = self.relu(self.bn2(self.conv2(x)))\n",
    "        x = self.relu(self.bn3(self.conv3(x)))\n",
    "        x = self.flatten(x)\n",
    "        x = self.dropout(self.relu(self.fc1(x)))\n",
    "        x = self.fc2(x)\n",
    "        return x\n",
    "\n",
    "input_channels = 1\n",
    "num_classes = len(label_encoder.classes_)\n",
    "model = CNN1DModel(input_channels, num_classes)\n",
    "criterion = nn.CrossEntropyLoss()\n",
    "optimizer = optim.Adam(model.parameters(), lr=0.001)\n",
    "\n",
    "# Training and testing as before\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "11a9a6d3",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "SVM Accuracy: 0.7795\n",
      "SVM Classification Report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           1       0.69      0.75      0.72        12\n",
      "           2       0.67      0.25      0.36         8\n",
      "           3       0.79      0.87      0.83        39\n",
      "           4       0.60      0.50      0.55         6\n",
      "           5       0.78      0.93      0.85        42\n",
      "           6       1.00      0.50      0.67        16\n",
      "           7       1.00      1.00      1.00         2\n",
      "           8       0.67      1.00      0.80         2\n",
      "\n",
      "    accuracy                           0.78       127\n",
      "   macro avg       0.77      0.73      0.72       127\n",
      "weighted avg       0.79      0.78      0.76       127\n",
      "\n",
      "Epoch 1/50\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/mojo/.local/lib/python3.10/site-packages/keras/src/layers/convolutional/base_conv.py:107: UserWarning: Do not pass an `input_shape`/`input_dim` argument to a layer. When using Sequential models, prefer using an `Input(shape)` object as the first layer in the model instead.\n",
      "  super().__init__(activity_regularizer=activity_regularizer, **kwargs)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m9s\u001b[0m 369ms/step - accuracy: 0.3105 - loss: 3.0381 - val_accuracy: 0.0000e+00 - val_loss: 2.0279\n",
      "Epoch 2/50\n",
      "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m8s\u001b[0m 363ms/step - accuracy: 0.4862 - loss: 1.5655 - val_accuracy: 0.0465 - val_loss: 3.0335\n",
      "Epoch 3/50\n",
      "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m8s\u001b[0m 366ms/step - accuracy: 0.6146 - loss: 1.0945 - val_accuracy: 0.0523 - val_loss: 2.7184\n",
      "Epoch 4/50\n",
      "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m8s\u001b[0m 360ms/step - accuracy: 0.7042 - loss: 0.7864 - val_accuracy: 0.1047 - val_loss: 2.8049\n",
      "Epoch 5/50\n",
      "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m8s\u001b[0m 362ms/step - accuracy: 0.8293 - loss: 0.4937 - val_accuracy: 0.1628 - val_loss: 2.8286\n",
      "Epoch 6/50\n",
      "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m8s\u001b[0m 358ms/step - accuracy: 0.8974 - loss: 0.3102 - val_accuracy: 0.1686 - val_loss: 3.7242\n",
      "Epoch 7/50\n",
      "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m8s\u001b[0m 352ms/step - accuracy: 0.8950 - loss: 0.2978 - val_accuracy: 0.1860 - val_loss: 4.9621\n",
      "Epoch 8/50\n",
      "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m8s\u001b[0m 354ms/step - accuracy: 0.9272 - loss: 0.2278 - val_accuracy: 0.2151 - val_loss: 3.6767\n",
      "Epoch 9/50\n",
      "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m8s\u001b[0m 355ms/step - accuracy: 0.9430 - loss: 0.1333 - val_accuracy: 0.1512 - val_loss: 4.9715\n",
      "Epoch 10/50\n",
      "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m8s\u001b[0m 353ms/step - accuracy: 0.9516 - loss: 0.1907 - val_accuracy: 0.1512 - val_loss: 4.1922\n",
      "Epoch 11/50\n",
      "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m8s\u001b[0m 355ms/step - accuracy: 0.9578 - loss: 0.1111 - val_accuracy: 0.2209 - val_loss: 5.8590\n",
      "Epoch 12/50\n",
      "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m8s\u001b[0m 353ms/step - accuracy: 0.9561 - loss: 0.1313 - val_accuracy: 0.1919 - val_loss: 4.8108\n",
      "Epoch 13/50\n",
      "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m8s\u001b[0m 354ms/step - accuracy: 0.9687 - loss: 0.0817 - val_accuracy: 0.1512 - val_loss: 5.4965\n",
      "Epoch 14/50\n",
      "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m8s\u001b[0m 355ms/step - accuracy: 0.9625 - loss: 0.1158 - val_accuracy: 0.1919 - val_loss: 4.8112\n",
      "Epoch 15/50\n",
      "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m8s\u001b[0m 353ms/step - accuracy: 0.9873 - loss: 0.0623 - val_accuracy: 0.1512 - val_loss: 6.5365\n",
      "Epoch 16/50\n",
      "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m8s\u001b[0m 355ms/step - accuracy: 0.9650 - loss: 0.1005 - val_accuracy: 0.2093 - val_loss: 4.7907\n",
      "Epoch 17/50\n",
      "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m8s\u001b[0m 356ms/step - accuracy: 0.9816 - loss: 0.0569 - val_accuracy: 0.2209 - val_loss: 5.8540\n",
      "Epoch 18/50\n",
      "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m8s\u001b[0m 359ms/step - accuracy: 0.9882 - loss: 0.0303 - val_accuracy: 0.1977 - val_loss: 6.2162\n",
      "Epoch 19/50\n",
      "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m8s\u001b[0m 358ms/step - accuracy: 0.9851 - loss: 0.0545 - val_accuracy: 0.1512 - val_loss: 5.5328\n",
      "Epoch 20/50\n",
      "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m8s\u001b[0m 354ms/step - accuracy: 0.9910 - loss: 0.0378 - val_accuracy: 0.1453 - val_loss: 6.3545\n",
      "Epoch 21/50\n",
      "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m8s\u001b[0m 354ms/step - accuracy: 0.9898 - loss: 0.0531 - val_accuracy: 0.2151 - val_loss: 4.5149\n",
      "Epoch 22/50\n",
      "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m8s\u001b[0m 352ms/step - accuracy: 0.9911 - loss: 0.0461 - val_accuracy: 0.2151 - val_loss: 5.4523\n",
      "Epoch 23/50\n",
      "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m8s\u001b[0m 351ms/step - accuracy: 0.9907 - loss: 0.0240 - val_accuracy: 0.1163 - val_loss: 7.2514\n",
      "Epoch 24/50\n",
      "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m8s\u001b[0m 352ms/step - accuracy: 0.9905 - loss: 0.0294 - val_accuracy: 0.2267 - val_loss: 5.7597\n",
      "Epoch 25/50\n",
      "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m8s\u001b[0m 354ms/step - accuracy: 0.9966 - loss: 0.0154 - val_accuracy: 0.1977 - val_loss: 6.8008\n",
      "Epoch 26/50\n",
      "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m8s\u001b[0m 352ms/step - accuracy: 0.9904 - loss: 0.0238 - val_accuracy: 0.2093 - val_loss: 6.0982\n",
      "Epoch 27/50\n",
      "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m8s\u001b[0m 355ms/step - accuracy: 0.9856 - loss: 0.1134 - val_accuracy: 0.1686 - val_loss: 5.6844\n",
      "Epoch 28/50\n",
      "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m8s\u001b[0m 354ms/step - accuracy: 0.9980 - loss: 0.0151 - val_accuracy: 0.1919 - val_loss: 7.3447\n",
      "Epoch 29/50\n",
      "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m8s\u001b[0m 355ms/step - accuracy: 0.9927 - loss: 0.0276 - val_accuracy: 0.2442 - val_loss: 5.8058\n",
      "Epoch 30/50\n",
      "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m8s\u001b[0m 357ms/step - accuracy: 0.9944 - loss: 0.0195 - val_accuracy: 0.2151 - val_loss: 6.9547\n",
      "Epoch 31/50\n",
      "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m8s\u001b[0m 357ms/step - accuracy: 0.9936 - loss: 0.0161 - val_accuracy: 0.1744 - val_loss: 7.1012\n",
      "Epoch 32/50\n",
      "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m8s\u001b[0m 357ms/step - accuracy: 0.9888 - loss: 0.0286 - val_accuracy: 0.1744 - val_loss: 6.7599\n",
      "Epoch 33/50\n",
      "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m8s\u001b[0m 359ms/step - accuracy: 0.9925 - loss: 0.0174 - val_accuracy: 0.1570 - val_loss: 8.2467\n",
      "Epoch 34/50\n",
      "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m8s\u001b[0m 356ms/step - accuracy: 0.9931 - loss: 0.0259 - val_accuracy: 0.1570 - val_loss: 7.2196\n",
      "Epoch 35/50\n",
      "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m8s\u001b[0m 358ms/step - accuracy: 0.9986 - loss: 0.0154 - val_accuracy: 0.1919 - val_loss: 6.6797\n",
      "Epoch 36/50\n",
      "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m8s\u001b[0m 354ms/step - accuracy: 0.9923 - loss: 0.0189 - val_accuracy: 0.2209 - val_loss: 6.0071\n",
      "Epoch 37/50\n",
      "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m8s\u001b[0m 356ms/step - accuracy: 0.9987 - loss: 0.0081 - val_accuracy: 0.1570 - val_loss: 7.5314\n",
      "Epoch 38/50\n",
      "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m8s\u001b[0m 356ms/step - accuracy: 0.9977 - loss: 0.0113 - val_accuracy: 0.2616 - val_loss: 5.9968\n",
      "Epoch 39/50\n",
      "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m8s\u001b[0m 356ms/step - accuracy: 0.9956 - loss: 0.0127 - val_accuracy: 0.1512 - val_loss: 8.4539\n",
      "Epoch 40/50\n",
      "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m8s\u001b[0m 353ms/step - accuracy: 0.9850 - loss: 0.0439 - val_accuracy: 0.1105 - val_loss: 6.4454\n",
      "Epoch 41/50\n",
      "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m8s\u001b[0m 353ms/step - accuracy: 0.9833 - loss: 0.0447 - val_accuracy: 0.2093 - val_loss: 7.3237\n",
      "Epoch 42/50\n",
      "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m10s\u001b[0m 342ms/step - accuracy: 0.9930 - loss: 0.0263 - val_accuracy: 0.1744 - val_loss: 7.3140\n",
      "Epoch 43/50\n",
      "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m8s\u001b[0m 348ms/step - accuracy: 0.9924 - loss: 0.0169 - val_accuracy: 0.1337 - val_loss: 8.5408\n",
      "Epoch 44/50\n",
      "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m8s\u001b[0m 348ms/step - accuracy: 0.9968 - loss: 0.0143 - val_accuracy: 0.1337 - val_loss: 8.0172\n",
      "Epoch 45/50\n",
      "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m8s\u001b[0m 349ms/step - accuracy: 0.9939 - loss: 0.0234 - val_accuracy: 0.1512 - val_loss: 6.6534\n",
      "Epoch 46/50\n",
      "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m8s\u001b[0m 351ms/step - accuracy: 0.9934 - loss: 0.0211 - val_accuracy: 0.1279 - val_loss: 7.1186\n",
      "Epoch 47/50\n",
      "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m8s\u001b[0m 347ms/step - accuracy: 0.9948 - loss: 0.0182 - val_accuracy: 0.1221 - val_loss: 8.6392\n",
      "Epoch 48/50\n",
      "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m8s\u001b[0m 349ms/step - accuracy: 0.9917 - loss: 0.0413 - val_accuracy: 0.1686 - val_loss: 6.3612\n",
      "Epoch 49/50\n",
      "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m8s\u001b[0m 348ms/step - accuracy: 0.9971 - loss: 0.0153 - val_accuracy: 0.1570 - val_loss: 7.1002\n",
      "Epoch 50/50\n",
      "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m8s\u001b[0m 350ms/step - accuracy: 0.9947 - loss: 0.0278 - val_accuracy: 0.1337 - val_loss: 7.9649\n",
      "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 35ms/step - accuracy: 0.6174 - loss: 2.2986\n",
      "CNN Test Accuracy: 0.5827\n",
      "Epoch 1/50\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/mojo/.local/lib/python3.10/site-packages/keras/src/layers/core/dense.py:87: UserWarning: Do not pass an `input_shape`/`input_dim` argument to a layer. When using Sequential models, prefer using an `Input(shape)` object as the first layer in the model instead.\n",
      "  super().__init__(activity_regularizer=activity_regularizer, **kwargs)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 7ms/step - accuracy: 0.2527 - loss: 2.9489 - val_accuracy: 0.0000e+00 - val_loss: 2.5345\n",
      "Epoch 2/50\n",
      "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.3738 - loss: 2.2085 - val_accuracy: 0.0349 - val_loss: 2.4381\n",
      "Epoch 3/50\n",
      "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.4017 - loss: 1.9578 - val_accuracy: 0.0291 - val_loss: 2.2327\n",
      "Epoch 4/50\n",
      "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.4326 - loss: 1.8056 - val_accuracy: 0.0174 - val_loss: 2.4156\n",
      "Epoch 5/50\n",
      "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.3860 - loss: 1.8127 - val_accuracy: 0.0640 - val_loss: 2.3312\n",
      "Epoch 6/50\n",
      "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - accuracy: 0.5172 - loss: 1.5510 - val_accuracy: 0.0349 - val_loss: 2.5083\n",
      "Epoch 7/50\n",
      "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.4560 - loss: 1.5663 - val_accuracy: 0.1395 - val_loss: 2.0746\n",
      "Epoch 8/50\n",
      "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.5006 - loss: 1.4798 - val_accuracy: 0.1686 - val_loss: 2.0824\n",
      "Epoch 9/50\n",
      "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.5152 - loss: 1.4024 - val_accuracy: 0.0756 - val_loss: 2.2549\n",
      "Epoch 10/50\n",
      "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.5169 - loss: 1.3692 - val_accuracy: 0.1337 - val_loss: 2.1081\n",
      "Epoch 11/50\n",
      "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.5219 - loss: 1.2523 - val_accuracy: 0.1279 - val_loss: 2.2561\n",
      "Epoch 12/50\n",
      "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.5650 - loss: 1.2247 - val_accuracy: 0.1279 - val_loss: 2.4666\n",
      "Epoch 13/50\n",
      "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.5862 - loss: 1.1127 - val_accuracy: 0.1512 - val_loss: 2.4676\n",
      "Epoch 14/50\n",
      "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.5998 - loss: 1.1008 - val_accuracy: 0.1453 - val_loss: 2.6196\n",
      "Epoch 15/50\n",
      "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.6478 - loss: 1.0055 - val_accuracy: 0.1977 - val_loss: 2.3185\n",
      "Epoch 16/50\n",
      "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.6191 - loss: 1.0264 - val_accuracy: 0.1919 - val_loss: 2.5304\n",
      "Epoch 17/50\n",
      "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.6381 - loss: 1.0169 - val_accuracy: 0.1686 - val_loss: 2.4181\n",
      "Epoch 18/50\n",
      "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.6896 - loss: 0.9200 - val_accuracy: 0.1395 - val_loss: 2.7279\n",
      "Epoch 19/50\n",
      "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.6773 - loss: 0.8740 - val_accuracy: 0.1919 - val_loss: 2.9054\n",
      "Epoch 20/50\n",
      "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.7157 - loss: 0.8032 - val_accuracy: 0.2151 - val_loss: 2.7768\n",
      "Epoch 21/50\n",
      "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.7392 - loss: 0.8633 - val_accuracy: 0.2558 - val_loss: 2.5868\n",
      "Epoch 22/50\n",
      "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.7302 - loss: 0.7624 - val_accuracy: 0.2209 - val_loss: 2.8150\n",
      "Epoch 23/50\n",
      "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.7392 - loss: 0.6983 - val_accuracy: 0.2151 - val_loss: 2.9231\n",
      "Epoch 24/50\n",
      "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.7147 - loss: 0.7508 - val_accuracy: 0.2151 - val_loss: 3.0099\n",
      "Epoch 25/50\n",
      "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.7444 - loss: 0.6877 - val_accuracy: 0.2326 - val_loss: 2.9478\n",
      "Epoch 26/50\n",
      "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.7960 - loss: 0.6092 - val_accuracy: 0.2209 - val_loss: 2.9173\n",
      "Epoch 27/50\n",
      "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.7686 - loss: 0.6887 - val_accuracy: 0.2326 - val_loss: 2.9984\n",
      "Epoch 28/50\n",
      "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.7989 - loss: 0.5800 - val_accuracy: 0.2442 - val_loss: 2.9983\n",
      "Epoch 29/50\n",
      "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.8156 - loss: 0.5482 - val_accuracy: 0.2558 - val_loss: 3.0829\n",
      "Epoch 30/50\n",
      "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.8285 - loss: 0.5001 - val_accuracy: 0.1802 - val_loss: 4.1062\n",
      "Epoch 31/50\n",
      "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.8271 - loss: 0.5644 - val_accuracy: 0.2326 - val_loss: 3.2578\n",
      "Epoch 32/50\n",
      "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.8645 - loss: 0.3982 - val_accuracy: 0.2384 - val_loss: 3.4684\n",
      "Epoch 33/50\n",
      "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.8367 - loss: 0.4482 - val_accuracy: 0.2616 - val_loss: 3.5202\n",
      "Epoch 34/50\n",
      "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.8295 - loss: 0.4919 - val_accuracy: 0.2616 - val_loss: 3.9396\n",
      "Epoch 35/50\n",
      "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.8551 - loss: 0.4365 - val_accuracy: 0.2326 - val_loss: 3.9409\n",
      "Epoch 36/50\n",
      "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.8491 - loss: 0.4353 - val_accuracy: 0.2616 - val_loss: 4.0494\n",
      "Epoch 37/50\n",
      "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.8514 - loss: 0.4763 - val_accuracy: 0.1628 - val_loss: 4.1960\n",
      "Epoch 38/50\n",
      "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.8330 - loss: 0.4372 - val_accuracy: 0.1977 - val_loss: 3.9696\n",
      "Epoch 39/50\n",
      "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.8705 - loss: 0.3937 - val_accuracy: 0.2093 - val_loss: 3.7369\n",
      "Epoch 40/50\n",
      "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.8972 - loss: 0.3773 - val_accuracy: 0.1628 - val_loss: 4.6120\n",
      "Epoch 41/50\n",
      "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.8971 - loss: 0.3045 - val_accuracy: 0.1802 - val_loss: 4.0837\n",
      "Epoch 42/50\n",
      "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.9031 - loss: 0.3036 - val_accuracy: 0.1919 - val_loss: 4.2938\n",
      "Epoch 43/50\n",
      "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.8760 - loss: 0.3531 - val_accuracy: 0.2151 - val_loss: 4.3106\n",
      "Epoch 44/50\n",
      "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.8643 - loss: 0.3913 - val_accuracy: 0.2151 - val_loss: 4.2849\n",
      "Epoch 45/50\n",
      "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.8994 - loss: 0.3055 - val_accuracy: 0.2616 - val_loss: 3.5623\n",
      "Epoch 46/50\n",
      "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.9137 - loss: 0.3093 - val_accuracy: 0.1860 - val_loss: 4.8144\n",
      "Epoch 47/50\n",
      "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.9059 - loss: 0.3122 - val_accuracy: 0.1977 - val_loss: 4.2055\n",
      "Epoch 48/50\n",
      "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.9038 - loss: 0.3112 - val_accuracy: 0.2733 - val_loss: 4.1278\n",
      "Epoch 49/50\n",
      "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.8923 - loss: 0.2997 - val_accuracy: 0.1512 - val_loss: 5.8600\n",
      "Epoch 50/50\n",
      "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.9074 - loss: 0.3292 - val_accuracy: 0.1570 - val_loss: 5.7401\n",
      "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - accuracy: 0.7397 - loss: 1.1813 \n",
      "ANN Test Accuracy: 0.6929\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "from sklearn.preprocessing import LabelEncoder\n",
    "from sklearn.svm import SVC\n",
    "from sklearn.metrics import accuracy_score, classification_report\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "\n",
    "# Load the data\n",
    "train_data = np.load('./layer_features_base_960h/train_8.npz')\n",
    "test_data = np.load('./layer_features_base_960h/test_8.npz')\n",
    "\n",
    "train_features = train_data['features']\n",
    "test_features = test_data['features']\n",
    "\n",
    "# Read Age labels instead of Gender\n",
    "train_labels = pd.read_csv('y_train.csv').Age\n",
    "test_labels = pd.read_csv('y_test.csv').Age\n",
    "\n",
    "# Encode the labels\n",
    "label_encoder = LabelEncoder()\n",
    "train_labels_encoded = label_encoder.fit_transform(train_labels)\n",
    "\n",
    "# Handle unseen labels in test set by filtering out labels not present in train set\n",
    "test_labels_filtered = test_labels[test_labels.isin(train_labels.unique())]\n",
    "test_features_filtered = test_features[test_labels.isin(train_labels.unique())]\n",
    "test_labels_encoded = label_encoder.transform(test_labels_filtered)\n",
    "\n",
    "# Standardize features\n",
    "scaler = StandardScaler()\n",
    "train_features_normalized = scaler.fit_transform(train_features)\n",
    "test_features_normalized = scaler.transform(test_features_filtered)\n",
    "\n",
    "# SVM model\n",
    "svm_model = SVC(kernel='linear', C=10.0, gamma='scale', random_state=42)\n",
    "svm_model.fit(train_features_normalized, train_labels_encoded)\n",
    "\n",
    "# Prediction and Evaluation\n",
    "svm_predictions = svm_model.predict(test_features_normalized)\n",
    "svm_accuracy = accuracy_score(test_labels_encoded, svm_predictions)\n",
    "print(f\"SVM Accuracy: {svm_accuracy:.4f}\")\n",
    "print(\"SVM Classification Report:\")\n",
    "print(classification_report(test_labels_encoded, svm_predictions))\n",
    "\n",
    "# CNN model (TensorFlow)\n",
    "import tensorflow as tf\n",
    "from tensorflow.keras.models import Sequential\n",
    "from tensorflow.keras.layers import Conv1D, Flatten, Dense, Dropout\n",
    "\n",
    "train_features_cnn = np.expand_dims(train_features_normalized, axis=-1)  # Shape: (num_samples, 768, 1)\n",
    "test_features_cnn = np.expand_dims(test_features_normalized, axis=-1)    # Shape: (num_samples, 768, 1)\n",
    "\n",
    "cnn_model = Sequential([\n",
    "    Conv1D(64, kernel_size=5, activation='relu', input_shape=(768, 1)),  # Update input shape to 768 features\n",
    "    Conv1D(128, kernel_size=5, activation='relu'),\n",
    "    Conv1D(256, kernel_size=5, activation='relu'),\n",
    "    Flatten(),\n",
    "    Dense(256, activation='relu'),\n",
    "    Dropout(0.5),\n",
    "    Dense(len(label_encoder.classes_), activation='softmax')\n",
    "])\n",
    "\n",
    "cnn_model.compile(optimizer='adam', loss='sparse_categorical_crossentropy', metrics=['accuracy'])\n",
    "\n",
    "cnn_model.fit(train_features_cnn, train_labels_encoded, epochs=50, batch_size=32, validation_split=0.2)\n",
    "\n",
    "cnn_test_loss, cnn_test_accuracy = cnn_model.evaluate(test_features_cnn, test_labels_encoded)\n",
    "print(f\"CNN Test Accuracy: {cnn_test_accuracy:.4f}\")\n",
    "\n",
    "# ANN model (TensorFlow)\n",
    "ann_model = Sequential([\n",
    "    Dense(512, activation='relu', input_shape=(768,)),  # Update input shape to 768 features\n",
    "    Dropout(0.5),\n",
    "    Dense(256, activation='relu'),\n",
    "    Dropout(0.5),\n",
    "    Dense(128, activation='relu'),\n",
    "    Dropout(0.5),\n",
    "    Dense(len(label_encoder.classes_), activation='softmax')\n",
    "])\n",
    "\n",
    "ann_model.compile(optimizer='adam', loss='sparse_categorical_crossentropy', metrics=['accuracy'])\n",
    "\n",
    "ann_model.fit(train_features_normalized, train_labels_encoded, epochs=50, batch_size=32, validation_split=0.2)\n",
    "\n",
    "ann_test_loss, ann_test_accuracy = ann_model.evaluate(test_features_normalized, test_labels_encoded)\n",
    "print(f\"ANN Test Accuracy: {ann_test_accuracy:.4f}\")\n",
    "\n",
    "# PyTorch CNN Model\n",
    "import torch\n",
    "from torch.utils.data import DataLoader, TensorDataset\n",
    "\n",
    "X_train_tensor = torch.tensor(train_features_cnn, dtype=torch.float32).permute(0, 2, 1)  # Shape: (num_samples, 1, 768)\n",
    "y_train_tensor = torch.tensor(train_labels_encoded, dtype=torch.long)\n",
    "X_test_tensor = torch.tensor(test_features_cnn, dtype=torch.float32).permute(0, 2, 1)    # Shape: (num_samples, 1, 768)\n",
    "y_test_tensor = torch.tensor(test_labels_encoded, dtype=torch.long)\n",
    "\n",
    "train_dataset = TensorDataset(X_train_tensor, y_train_tensor)\n",
    "test_dataset = TensorDataset(X_test_tensor, y_test_tensor)\n",
    "\n",
    "train_loader = DataLoader(train_dataset, batch_size=64, shuffle=True)\n",
    "test_loader = DataLoader(test_dataset, batch_size=64, shuffle=False)\n",
    "\n",
    "import torch.nn as nn\n",
    "import torch.optim as optim\n",
    "\n",
    "class CNN1DModel(nn.Module):\n",
    "    def __init__(self, input_channels, num_classes):\n",
    "        super(CNN1DModel, self).__init__()\n",
    "        self.conv1 = nn.Conv1d(input_channels, 32, kernel_size=5, stride=1, padding=2)\n",
    "        self.bn1 = nn.BatchNorm1d(32)\n",
    "        self.relu = nn.ReLU()\n",
    "        self.conv2 = nn.Conv1d(32, 64, kernel_size=5, stride=1, padding=2)\n",
    "        self.bn2 = nn.BatchNorm1d(64)\n",
    "        self.conv3 = nn.Conv1d(64, 128, kernel_size=5, stride=1, padding=2)\n",
    "        self.bn3 = nn.BatchNorm1d(128)\n",
    "        self.flatten = nn.Flatten()\n",
    "        self.fc1 = nn.Linear(128 * 768, 512)  # Update to 768 features\n",
    "        self.fc2 = nn.Linear(512, num_classes)\n",
    "        self.dropout = nn.Dropout(0.5)\n",
    "    \n",
    "    def forward(self, x):\n",
    "        x = self.relu(self.bn1(self.conv1(x)))\n",
    "        x = self.relu(self.bn2(self.conv2(x)))\n",
    "        x = self.relu(self.bn3(self.conv3(x)))\n",
    "        x = self.flatten(x)\n",
    "        x = self.dropout(self.relu(self.fc1(x)))\n",
    "        x = self.fc2(x)\n",
    "        return x\n",
    "\n",
    "input_channels = 1\n",
    "num_classes = len(label_encoder.classes_)\n",
    "model = CNN1DModel(input_channels, num_classes)\n",
    "criterion = nn.CrossEntropyLoss()\n",
    "optimizer = optim.Adam(model.parameters(), lr=0.001)\n",
    "\n",
    "# Training and testing as before\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "4e3e2a2c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "SVM Accuracy: 0.7795\n",
      "SVM Classification Report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           1       0.64      0.75      0.69        12\n",
      "           2       0.50      0.50      0.50         8\n",
      "           3       0.92      0.85      0.88        39\n",
      "           4       0.75      1.00      0.86         6\n",
      "           5       0.76      0.93      0.84        42\n",
      "           6       0.80      0.25      0.38        16\n",
      "           7       1.00      1.00      1.00         2\n",
      "           8       0.67      1.00      0.80         2\n",
      "\n",
      "    accuracy                           0.78       127\n",
      "   macro avg       0.76      0.78      0.74       127\n",
      "weighted avg       0.79      0.78      0.76       127\n",
      "\n",
      "Epoch 1/50\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/mojo/.local/lib/python3.10/site-packages/keras/src/layers/convolutional/base_conv.py:107: UserWarning: Do not pass an `input_shape`/`input_dim` argument to a layer. When using Sequential models, prefer using an `Input(shape)` object as the first layer in the model instead.\n",
      "  super().__init__(activity_regularizer=activity_regularizer, **kwargs)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m9s\u001b[0m 361ms/step - accuracy: 0.2852 - loss: 3.2041 - val_accuracy: 0.0058 - val_loss: 2.2489\n",
      "Epoch 2/50\n",
      "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m8s\u001b[0m 361ms/step - accuracy: 0.4668 - loss: 1.5210 - val_accuracy: 0.0698 - val_loss: 2.6766\n",
      "Epoch 3/50\n",
      "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m8s\u001b[0m 360ms/step - accuracy: 0.6236 - loss: 0.9854 - val_accuracy: 0.1105 - val_loss: 2.7116\n",
      "Epoch 4/50\n",
      "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m8s\u001b[0m 361ms/step - accuracy: 0.7926 - loss: 0.5965 - val_accuracy: 0.1744 - val_loss: 2.4855\n",
      "Epoch 5/50\n",
      "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m8s\u001b[0m 359ms/step - accuracy: 0.8451 - loss: 0.4830 - val_accuracy: 0.1395 - val_loss: 4.2235\n",
      "Epoch 6/50\n",
      "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m8s\u001b[0m 350ms/step - accuracy: 0.9019 - loss: 0.3091 - val_accuracy: 0.1628 - val_loss: 3.5791\n",
      "Epoch 7/50\n",
      "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m8s\u001b[0m 351ms/step - accuracy: 0.9411 - loss: 0.1955 - val_accuracy: 0.2326 - val_loss: 3.3632\n",
      "Epoch 8/50\n",
      "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m8s\u001b[0m 350ms/step - accuracy: 0.9391 - loss: 0.1740 - val_accuracy: 0.1453 - val_loss: 3.6827\n",
      "Epoch 9/50\n",
      "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m8s\u001b[0m 348ms/step - accuracy: 0.9459 - loss: 0.1362 - val_accuracy: 0.1802 - val_loss: 5.0958\n",
      "Epoch 10/50\n",
      "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m7s\u001b[0m 338ms/step - accuracy: 0.9786 - loss: 0.0782 - val_accuracy: 0.2209 - val_loss: 4.1296\n",
      "Epoch 11/50\n",
      "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m7s\u001b[0m 337ms/step - accuracy: 0.9673 - loss: 0.1003 - val_accuracy: 0.1686 - val_loss: 6.0530\n",
      "Epoch 12/50\n",
      "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m10s\u001b[0m 338ms/step - accuracy: 0.9705 - loss: 0.0791 - val_accuracy: 0.1279 - val_loss: 7.3702\n",
      "Epoch 13/50\n",
      "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m7s\u001b[0m 335ms/step - accuracy: 0.9821 - loss: 0.0805 - val_accuracy: 0.1337 - val_loss: 7.4123\n",
      "Epoch 14/50\n",
      "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m7s\u001b[0m 337ms/step - accuracy: 0.9832 - loss: 0.0424 - val_accuracy: 0.2267 - val_loss: 6.1379\n",
      "Epoch 15/50\n",
      "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m7s\u001b[0m 333ms/step - accuracy: 0.9885 - loss: 0.0364 - val_accuracy: 0.1570 - val_loss: 6.0518\n",
      "Epoch 16/50\n",
      "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m7s\u001b[0m 336ms/step - accuracy: 0.9924 - loss: 0.0270 - val_accuracy: 0.1802 - val_loss: 5.7650\n",
      "Epoch 17/50\n",
      "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m7s\u001b[0m 333ms/step - accuracy: 0.9913 - loss: 0.0281 - val_accuracy: 0.2267 - val_loss: 6.3928\n",
      "Epoch 18/50\n",
      "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m7s\u001b[0m 336ms/step - accuracy: 0.9833 - loss: 0.0261 - val_accuracy: 0.1744 - val_loss: 8.3967\n",
      "Epoch 19/50\n",
      "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m7s\u001b[0m 335ms/step - accuracy: 0.9876 - loss: 0.0302 - val_accuracy: 0.1919 - val_loss: 6.4112\n",
      "Epoch 20/50\n",
      "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m7s\u001b[0m 338ms/step - accuracy: 0.9890 - loss: 0.0507 - val_accuracy: 0.1453 - val_loss: 7.2974\n",
      "Epoch 21/50\n",
      "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m7s\u001b[0m 335ms/step - accuracy: 0.9900 - loss: 0.0299 - val_accuracy: 0.1977 - val_loss: 6.7770\n",
      "Epoch 22/50\n",
      "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m7s\u001b[0m 336ms/step - accuracy: 0.9920 - loss: 0.0261 - val_accuracy: 0.1686 - val_loss: 6.6325\n",
      "Epoch 23/50\n",
      "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m7s\u001b[0m 336ms/step - accuracy: 0.9915 - loss: 0.0320 - val_accuracy: 0.2093 - val_loss: 5.4518\n",
      "Epoch 24/50\n",
      "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m7s\u001b[0m 337ms/step - accuracy: 0.9997 - loss: 0.0126 - val_accuracy: 0.2035 - val_loss: 7.3542\n",
      "Epoch 25/50\n",
      "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m7s\u001b[0m 335ms/step - accuracy: 0.9912 - loss: 0.0314 - val_accuracy: 0.1279 - val_loss: 8.5946\n",
      "Epoch 26/50\n",
      "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m7s\u001b[0m 337ms/step - accuracy: 0.9949 - loss: 0.0207 - val_accuracy: 0.1337 - val_loss: 8.2580\n",
      "Epoch 27/50\n",
      "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m7s\u001b[0m 335ms/step - accuracy: 0.9951 - loss: 0.0184 - val_accuracy: 0.1919 - val_loss: 6.6588\n",
      "Epoch 28/50\n",
      "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m7s\u001b[0m 337ms/step - accuracy: 0.9945 - loss: 0.0173 - val_accuracy: 0.1628 - val_loss: 6.9556\n",
      "Epoch 29/50\n",
      "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m7s\u001b[0m 336ms/step - accuracy: 0.9950 - loss: 0.0237 - val_accuracy: 0.1337 - val_loss: 9.2937\n",
      "Epoch 30/50\n",
      "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m7s\u001b[0m 338ms/step - accuracy: 0.9967 - loss: 0.0170 - val_accuracy: 0.1337 - val_loss: 8.4592\n",
      "Epoch 31/50\n",
      "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m7s\u001b[0m 336ms/step - accuracy: 0.9984 - loss: 0.0066 - val_accuracy: 0.1512 - val_loss: 9.0821\n",
      "Epoch 32/50\n",
      "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m7s\u001b[0m 337ms/step - accuracy: 0.9997 - loss: 0.0038 - val_accuracy: 0.1570 - val_loss: 9.3959\n",
      "Epoch 33/50\n",
      "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m7s\u001b[0m 338ms/step - accuracy: 0.9994 - loss: 0.0035 - val_accuracy: 0.1977 - val_loss: 7.9384\n",
      "Epoch 34/50\n",
      "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m7s\u001b[0m 338ms/step - accuracy: 0.9962 - loss: 0.0079 - val_accuracy: 0.1163 - val_loss: 8.2797\n",
      "Epoch 35/50\n",
      "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m7s\u001b[0m 334ms/step - accuracy: 0.9939 - loss: 0.0289 - val_accuracy: 0.1453 - val_loss: 6.2405\n",
      "Epoch 36/50\n",
      "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m7s\u001b[0m 338ms/step - accuracy: 0.9921 - loss: 0.0274 - val_accuracy: 0.1512 - val_loss: 8.2727\n",
      "Epoch 37/50\n",
      "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m10s\u001b[0m 338ms/step - accuracy: 0.9975 - loss: 0.0117 - val_accuracy: 0.1628 - val_loss: 8.6352\n",
      "Epoch 38/50\n",
      "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m8s\u001b[0m 341ms/step - accuracy: 0.9893 - loss: 0.0304 - val_accuracy: 0.1860 - val_loss: 5.9492\n",
      "Epoch 39/50\n",
      "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m10s\u001b[0m 336ms/step - accuracy: 0.9868 - loss: 0.0389 - val_accuracy: 0.1163 - val_loss: 6.6500\n",
      "Epoch 40/50\n",
      "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m7s\u001b[0m 336ms/step - accuracy: 0.9918 - loss: 0.0234 - val_accuracy: 0.1860 - val_loss: 6.8499\n",
      "Epoch 41/50\n",
      "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m7s\u001b[0m 338ms/step - accuracy: 0.9947 - loss: 0.0184 - val_accuracy: 0.1279 - val_loss: 9.2644\n",
      "Epoch 42/50\n",
      "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m7s\u001b[0m 337ms/step - accuracy: 0.9984 - loss: 0.0049 - val_accuracy: 0.1453 - val_loss: 9.0429\n",
      "Epoch 43/50\n",
      "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m7s\u001b[0m 340ms/step - accuracy: 0.9964 - loss: 0.0081 - val_accuracy: 0.1337 - val_loss: 9.2324\n",
      "Epoch 44/50\n",
      "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m7s\u001b[0m 339ms/step - accuracy: 0.9998 - loss: 0.0073 - val_accuracy: 0.1453 - val_loss: 8.1272\n",
      "Epoch 45/50\n",
      "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m10s\u001b[0m 337ms/step - accuracy: 0.9949 - loss: 0.0484 - val_accuracy: 0.1395 - val_loss: 8.4659\n",
      "Epoch 46/50\n",
      "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m7s\u001b[0m 337ms/step - accuracy: 0.9995 - loss: 0.0064 - val_accuracy: 0.1395 - val_loss: 9.4493\n",
      "Epoch 47/50\n",
      "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m7s\u001b[0m 337ms/step - accuracy: 0.9995 - loss: 0.0031 - val_accuracy: 0.1628 - val_loss: 8.9839\n",
      "Epoch 48/50\n",
      "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m7s\u001b[0m 337ms/step - accuracy: 0.9985 - loss: 0.0085 - val_accuracy: 0.1744 - val_loss: 9.0903\n",
      "Epoch 49/50\n",
      "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m7s\u001b[0m 335ms/step - accuracy: 0.9932 - loss: 0.0267 - val_accuracy: 0.1686 - val_loss: 6.2633\n",
      "Epoch 50/50\n",
      "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m7s\u001b[0m 334ms/step - accuracy: 0.9978 - loss: 0.0100 - val_accuracy: 0.1337 - val_loss: 8.8708\n",
      "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 39ms/step - accuracy: 0.6446 - loss: 2.8137\n",
      "CNN Test Accuracy: 0.5906\n",
      "Epoch 1/50\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/mojo/.local/lib/python3.10/site-packages/keras/src/layers/core/dense.py:87: UserWarning: Do not pass an `input_shape`/`input_dim` argument to a layer. When using Sequential models, prefer using an `Input(shape)` object as the first layer in the model instead.\n",
      "  super().__init__(activity_regularizer=activity_regularizer, **kwargs)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 7ms/step - accuracy: 0.2503 - loss: 3.0087 - val_accuracy: 0.0058 - val_loss: 2.7572\n",
      "Epoch 2/50\n",
      "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.3479 - loss: 2.1193 - val_accuracy: 0.0233 - val_loss: 2.4077\n",
      "Epoch 3/50\n",
      "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.3707 - loss: 1.9251 - val_accuracy: 0.0174 - val_loss: 2.4250\n",
      "Epoch 4/50\n",
      "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.4694 - loss: 1.7284 - val_accuracy: 0.0581 - val_loss: 2.1584\n",
      "Epoch 5/50\n",
      "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.4053 - loss: 1.7736 - val_accuracy: 0.0523 - val_loss: 2.5895\n",
      "Epoch 6/50\n",
      "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.4730 - loss: 1.5955 - val_accuracy: 0.0698 - val_loss: 2.3124\n",
      "Epoch 7/50\n",
      "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.4466 - loss: 1.5611 - val_accuracy: 0.0814 - val_loss: 2.2782\n",
      "Epoch 8/50\n",
      "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.4996 - loss: 1.4110 - val_accuracy: 0.0814 - val_loss: 2.3679\n",
      "Epoch 9/50\n",
      "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.5674 - loss: 1.2625 - val_accuracy: 0.1337 - val_loss: 2.3750\n",
      "Epoch 10/50\n",
      "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.5272 - loss: 1.3021 - val_accuracy: 0.0930 - val_loss: 2.4840\n",
      "Epoch 11/50\n",
      "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.5947 - loss: 1.1170 - val_accuracy: 0.1512 - val_loss: 2.5080\n",
      "Epoch 12/50\n",
      "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.5975 - loss: 1.1338 - val_accuracy: 0.1512 - val_loss: 2.4208\n",
      "Epoch 13/50\n",
      "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.5849 - loss: 1.1402 - val_accuracy: 0.2035 - val_loss: 2.4584\n",
      "Epoch 14/50\n",
      "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.5912 - loss: 1.0659 - val_accuracy: 0.2151 - val_loss: 2.5043\n",
      "Epoch 15/50\n",
      "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.6199 - loss: 1.0219 - val_accuracy: 0.2849 - val_loss: 2.1105\n",
      "Epoch 16/50\n",
      "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.6463 - loss: 0.9354 - val_accuracy: 0.1453 - val_loss: 2.7161\n",
      "Epoch 17/50\n",
      "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.6521 - loss: 0.9040 - val_accuracy: 0.2035 - val_loss: 2.6051\n",
      "Epoch 18/50\n",
      "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.6455 - loss: 0.9420 - val_accuracy: 0.1919 - val_loss: 2.5962\n",
      "Epoch 19/50\n",
      "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - accuracy: 0.7080 - loss: 0.7835 - val_accuracy: 0.1860 - val_loss: 2.6233\n",
      "Epoch 20/50\n",
      "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.6979 - loss: 0.8391 - val_accuracy: 0.2500 - val_loss: 2.8175\n",
      "Epoch 21/50\n",
      "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.7293 - loss: 0.7540 - val_accuracy: 0.1628 - val_loss: 3.2422\n",
      "Epoch 22/50\n",
      "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.7471 - loss: 0.6840 - val_accuracy: 0.1628 - val_loss: 2.8926\n",
      "Epoch 23/50\n",
      "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.7384 - loss: 0.7339 - val_accuracy: 0.1744 - val_loss: 2.9679\n",
      "Epoch 24/50\n",
      "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.8004 - loss: 0.5870 - val_accuracy: 0.2093 - val_loss: 2.8799\n",
      "Epoch 25/50\n",
      "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.7987 - loss: 0.5529 - val_accuracy: 0.2035 - val_loss: 3.2253\n",
      "Epoch 26/50\n",
      "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.7796 - loss: 0.6173 - val_accuracy: 0.1919 - val_loss: 3.3450\n",
      "Epoch 27/50\n",
      "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.8123 - loss: 0.4983 - val_accuracy: 0.1977 - val_loss: 3.2267\n",
      "Epoch 28/50\n",
      "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.8285 - loss: 0.5159 - val_accuracy: 0.2209 - val_loss: 2.9768\n",
      "Epoch 29/50\n",
      "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.8024 - loss: 0.5034 - val_accuracy: 0.1221 - val_loss: 4.0548\n",
      "Epoch 30/50\n",
      "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.8430 - loss: 0.4522 - val_accuracy: 0.2035 - val_loss: 3.4216\n",
      "Epoch 31/50\n",
      "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.8332 - loss: 0.4525 - val_accuracy: 0.2035 - val_loss: 3.4324\n",
      "Epoch 32/50\n",
      "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.8617 - loss: 0.3896 - val_accuracy: 0.2151 - val_loss: 3.4651\n",
      "Epoch 33/50\n",
      "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.8788 - loss: 0.3103 - val_accuracy: 0.2209 - val_loss: 3.9527\n",
      "Epoch 34/50\n",
      "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.8633 - loss: 0.3742 - val_accuracy: 0.1860 - val_loss: 4.3941\n",
      "Epoch 35/50\n",
      "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.8340 - loss: 0.4762 - val_accuracy: 0.2558 - val_loss: 3.3314\n",
      "Epoch 36/50\n",
      "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.8767 - loss: 0.3643 - val_accuracy: 0.2093 - val_loss: 4.0227\n",
      "Epoch 37/50\n",
      "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.8624 - loss: 0.4201 - val_accuracy: 0.2267 - val_loss: 4.9007\n",
      "Epoch 38/50\n",
      "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.8726 - loss: 0.4170 - val_accuracy: 0.2151 - val_loss: 4.5495\n",
      "Epoch 39/50\n",
      "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.8872 - loss: 0.3269 - val_accuracy: 0.2616 - val_loss: 4.1287\n",
      "Epoch 40/50\n",
      "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.8779 - loss: 0.2964 - val_accuracy: 0.2907 - val_loss: 3.6581\n",
      "Epoch 41/50\n",
      "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.8835 - loss: 0.3642 - val_accuracy: 0.2326 - val_loss: 3.9363\n",
      "Epoch 42/50\n",
      "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.8962 - loss: 0.2853 - val_accuracy: 0.2209 - val_loss: 4.9144\n",
      "Epoch 43/50\n",
      "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.9078 - loss: 0.2600 - val_accuracy: 0.1977 - val_loss: 5.1210\n",
      "Epoch 44/50\n",
      "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.9197 - loss: 0.2076 - val_accuracy: 0.2442 - val_loss: 4.6633\n",
      "Epoch 45/50\n",
      "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.9141 - loss: 0.2489 - val_accuracy: 0.2267 - val_loss: 4.7908\n",
      "Epoch 46/50\n",
      "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.9115 - loss: 0.2413 - val_accuracy: 0.2035 - val_loss: 5.1097\n",
      "Epoch 47/50\n",
      "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.8994 - loss: 0.2604 - val_accuracy: 0.1919 - val_loss: 5.1743\n",
      "Epoch 48/50\n",
      "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.9090 - loss: 0.2775 - val_accuracy: 0.2151 - val_loss: 5.2590\n",
      "Epoch 49/50\n",
      "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.9332 - loss: 0.1893 - val_accuracy: 0.2267 - val_loss: 4.4066\n",
      "Epoch 50/50\n",
      "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.8944 - loss: 0.2763 - val_accuracy: 0.2442 - val_loss: 4.6790\n",
      "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - accuracy: 0.7210 - loss: 1.2347 \n",
      "ANN Test Accuracy: 0.7165\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "from sklearn.preprocessing import LabelEncoder\n",
    "from sklearn.svm import SVC\n",
    "from sklearn.metrics import accuracy_score, classification_report\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "\n",
    "# Load the data\n",
    "train_data = np.load('./layer_features_base_960h/train_9.npz')\n",
    "test_data = np.load('./layer_features_base_960h/test_9.npz')\n",
    "\n",
    "train_features = train_data['features']\n",
    "test_features = test_data['features']\n",
    "\n",
    "# Read Age labels instead of Gender\n",
    "train_labels = pd.read_csv('y_train.csv').Age\n",
    "test_labels = pd.read_csv('y_test.csv').Age\n",
    "\n",
    "# Encode the labels\n",
    "label_encoder = LabelEncoder()\n",
    "train_labels_encoded = label_encoder.fit_transform(train_labels)\n",
    "\n",
    "# Handle unseen labels in test set by filtering out labels not present in train set\n",
    "test_labels_filtered = test_labels[test_labels.isin(train_labels.unique())]\n",
    "test_features_filtered = test_features[test_labels.isin(train_labels.unique())]\n",
    "test_labels_encoded = label_encoder.transform(test_labels_filtered)\n",
    "\n",
    "# Standardize features\n",
    "scaler = StandardScaler()\n",
    "train_features_normalized = scaler.fit_transform(train_features)\n",
    "test_features_normalized = scaler.transform(test_features_filtered)\n",
    "\n",
    "# SVM model\n",
    "svm_model = SVC(kernel='linear', C=10.0, gamma='scale', random_state=42)\n",
    "svm_model.fit(train_features_normalized, train_labels_encoded)\n",
    "\n",
    "# Prediction and Evaluation\n",
    "svm_predictions = svm_model.predict(test_features_normalized)\n",
    "svm_accuracy = accuracy_score(test_labels_encoded, svm_predictions)\n",
    "print(f\"SVM Accuracy: {svm_accuracy:.4f}\")\n",
    "print(\"SVM Classification Report:\")\n",
    "print(classification_report(test_labels_encoded, svm_predictions))\n",
    "\n",
    "# CNN model (TensorFlow)\n",
    "import tensorflow as tf\n",
    "from tensorflow.keras.models import Sequential\n",
    "from tensorflow.keras.layers import Conv1D, Flatten, Dense, Dropout\n",
    "\n",
    "train_features_cnn = np.expand_dims(train_features_normalized, axis=-1)  # Shape: (num_samples, 768, 1)\n",
    "test_features_cnn = np.expand_dims(test_features_normalized, axis=-1)    # Shape: (num_samples, 768, 1)\n",
    "\n",
    "cnn_model = Sequential([\n",
    "    Conv1D(64, kernel_size=5, activation='relu', input_shape=(768, 1)),  # Update input shape to 768 features\n",
    "    Conv1D(128, kernel_size=5, activation='relu'),\n",
    "    Conv1D(256, kernel_size=5, activation='relu'),\n",
    "    Flatten(),\n",
    "    Dense(256, activation='relu'),\n",
    "    Dropout(0.5),\n",
    "    Dense(len(label_encoder.classes_), activation='softmax')\n",
    "])\n",
    "\n",
    "cnn_model.compile(optimizer='adam', loss='sparse_categorical_crossentropy', metrics=['accuracy'])\n",
    "\n",
    "cnn_model.fit(train_features_cnn, train_labels_encoded, epochs=50, batch_size=32, validation_split=0.2)\n",
    "\n",
    "cnn_test_loss, cnn_test_accuracy = cnn_model.evaluate(test_features_cnn, test_labels_encoded)\n",
    "print(f\"CNN Test Accuracy: {cnn_test_accuracy:.4f}\")\n",
    "\n",
    "# ANN model (TensorFlow)\n",
    "ann_model = Sequential([\n",
    "    Dense(512, activation='relu', input_shape=(768,)),  # Update input shape to 768 features\n",
    "    Dropout(0.5),\n",
    "    Dense(256, activation='relu'),\n",
    "    Dropout(0.5),\n",
    "    Dense(128, activation='relu'),\n",
    "    Dropout(0.5),\n",
    "    Dense(len(label_encoder.classes_), activation='softmax')\n",
    "])\n",
    "\n",
    "ann_model.compile(optimizer='adam', loss='sparse_categorical_crossentropy', metrics=['accuracy'])\n",
    "\n",
    "ann_model.fit(train_features_normalized, train_labels_encoded, epochs=50, batch_size=32, validation_split=0.2)\n",
    "\n",
    "ann_test_loss, ann_test_accuracy = ann_model.evaluate(test_features_normalized, test_labels_encoded)\n",
    "print(f\"ANN Test Accuracy: {ann_test_accuracy:.4f}\")\n",
    "\n",
    "# PyTorch CNN Model\n",
    "import torch\n",
    "from torch.utils.data import DataLoader, TensorDataset\n",
    "\n",
    "X_train_tensor = torch.tensor(train_features_cnn, dtype=torch.float32).permute(0, 2, 1)  # Shape: (num_samples, 1, 768)\n",
    "y_train_tensor = torch.tensor(train_labels_encoded, dtype=torch.long)\n",
    "X_test_tensor = torch.tensor(test_features_cnn, dtype=torch.float32).permute(0, 2, 1)    # Shape: (num_samples, 1, 768)\n",
    "y_test_tensor = torch.tensor(test_labels_encoded, dtype=torch.long)\n",
    "\n",
    "train_dataset = TensorDataset(X_train_tensor, y_train_tensor)\n",
    "test_dataset = TensorDataset(X_test_tensor, y_test_tensor)\n",
    "\n",
    "train_loader = DataLoader(train_dataset, batch_size=64, shuffle=True)\n",
    "test_loader = DataLoader(test_dataset, batch_size=64, shuffle=False)\n",
    "\n",
    "import torch.nn as nn\n",
    "import torch.optim as optim\n",
    "\n",
    "class CNN1DModel(nn.Module):\n",
    "    def __init__(self, input_channels, num_classes):\n",
    "        super(CNN1DModel, self).__init__()\n",
    "        self.conv1 = nn.Conv1d(input_channels, 32, kernel_size=5, stride=1, padding=2)\n",
    "        self.bn1 = nn.BatchNorm1d(32)\n",
    "        self.relu = nn.ReLU()\n",
    "        self.conv2 = nn.Conv1d(32, 64, kernel_size=5, stride=1, padding=2)\n",
    "        self.bn2 = nn.BatchNorm1d(64)\n",
    "        self.conv3 = nn.Conv1d(64, 128, kernel_size=5, stride=1, padding=2)\n",
    "        self.bn3 = nn.BatchNorm1d(128)\n",
    "        self.flatten = nn.Flatten()\n",
    "        self.fc1 = nn.Linear(128 * 768, 512)  # Update to 768 features\n",
    "        self.fc2 = nn.Linear(512, num_classes)\n",
    "        self.dropout = nn.Dropout(0.5)\n",
    "    \n",
    "    def forward(self, x):\n",
    "        x = self.relu(self.bn1(self.conv1(x)))\n",
    "        x = self.relu(self.bn2(self.conv2(x)))\n",
    "        x = self.relu(self.bn3(self.conv3(x)))\n",
    "        x = self.flatten(x)\n",
    "        x = self.dropout(self.relu(self.fc1(x)))\n",
    "        x = self.fc2(x)\n",
    "        return x\n",
    "\n",
    "input_channels = 1\n",
    "num_classes = len(label_encoder.classes_)\n",
    "model = CNN1DModel(input_channels, num_classes)\n",
    "criterion = nn.CrossEntropyLoss()\n",
    "optimizer = optim.Adam(model.parameters(), lr=0.001)\n",
    "\n",
    "# Training and testing as before\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "0580d14c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "SVM Accuracy: 0.7323\n",
      "SVM Classification Report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           1       0.47      0.58      0.52        12\n",
      "           2       0.50      0.38      0.43         8\n",
      "           3       0.84      0.79      0.82        39\n",
      "           4       0.71      0.83      0.77         6\n",
      "           5       0.73      0.86      0.79        42\n",
      "           6       1.00      0.44      0.61        16\n",
      "           7       0.67      1.00      0.80         2\n",
      "           8       0.67      1.00      0.80         2\n",
      "\n",
      "    accuracy                           0.73       127\n",
      "   macro avg       0.70      0.74      0.69       127\n",
      "weighted avg       0.76      0.73      0.73       127\n",
      "\n",
      "Epoch 1/50\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/mojo/.local/lib/python3.10/site-packages/keras/src/layers/convolutional/base_conv.py:107: UserWarning: Do not pass an `input_shape`/`input_dim` argument to a layer. When using Sequential models, prefer using an `Input(shape)` object as the first layer in the model instead.\n",
      "  super().__init__(activity_regularizer=activity_regularizer, **kwargs)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m9s\u001b[0m 381ms/step - accuracy: 0.2956 - loss: 2.7645 - val_accuracy: 0.0116 - val_loss: 2.4438\n",
      "Epoch 2/50\n",
      "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m8s\u001b[0m 362ms/step - accuracy: 0.4901 - loss: 1.5011 - val_accuracy: 0.0116 - val_loss: 3.2737\n",
      "Epoch 3/50\n",
      "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m8s\u001b[0m 353ms/step - accuracy: 0.5928 - loss: 1.0844 - val_accuracy: 0.1570 - val_loss: 2.5763\n",
      "Epoch 4/50\n",
      "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m8s\u001b[0m 363ms/step - accuracy: 0.7265 - loss: 0.8252 - val_accuracy: 0.2267 - val_loss: 2.8235\n",
      "Epoch 5/50\n",
      "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m8s\u001b[0m 359ms/step - accuracy: 0.8110 - loss: 0.5541 - val_accuracy: 0.1221 - val_loss: 3.4429\n",
      "Epoch 6/50\n",
      "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m8s\u001b[0m 355ms/step - accuracy: 0.8556 - loss: 0.4116 - val_accuracy: 0.1279 - val_loss: 3.8024\n",
      "Epoch 7/50\n",
      "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m8s\u001b[0m 356ms/step - accuracy: 0.9122 - loss: 0.2474 - val_accuracy: 0.1512 - val_loss: 4.3384\n",
      "Epoch 8/50\n",
      "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m8s\u001b[0m 352ms/step - accuracy: 0.9325 - loss: 0.1584 - val_accuracy: 0.2674 - val_loss: 4.7376\n",
      "Epoch 9/50\n",
      "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m8s\u001b[0m 356ms/step - accuracy: 0.9423 - loss: 0.1596 - val_accuracy: 0.1337 - val_loss: 4.6296\n",
      "Epoch 10/50\n",
      "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m8s\u001b[0m 355ms/step - accuracy: 0.9431 - loss: 0.1473 - val_accuracy: 0.2209 - val_loss: 4.6657\n",
      "Epoch 11/50\n",
      "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m8s\u001b[0m 356ms/step - accuracy: 0.9613 - loss: 0.1002 - val_accuracy: 0.1570 - val_loss: 4.5649\n",
      "Epoch 12/50\n",
      "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m8s\u001b[0m 356ms/step - accuracy: 0.9603 - loss: 0.0964 - val_accuracy: 0.1453 - val_loss: 6.5637\n",
      "Epoch 13/50\n",
      "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m8s\u001b[0m 356ms/step - accuracy: 0.9829 - loss: 0.0500 - val_accuracy: 0.1628 - val_loss: 5.5483\n",
      "Epoch 14/50\n",
      "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m8s\u001b[0m 355ms/step - accuracy: 0.9857 - loss: 0.0700 - val_accuracy: 0.1279 - val_loss: 5.9098\n",
      "Epoch 15/50\n",
      "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m8s\u001b[0m 345ms/step - accuracy: 0.9708 - loss: 0.0918 - val_accuracy: 0.1570 - val_loss: 5.4159\n",
      "Epoch 16/50\n",
      "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m8s\u001b[0m 344ms/step - accuracy: 0.9772 - loss: 0.0932 - val_accuracy: 0.1570 - val_loss: 5.0207\n",
      "Epoch 17/50\n",
      "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m8s\u001b[0m 346ms/step - accuracy: 0.9882 - loss: 0.0463 - val_accuracy: 0.1279 - val_loss: 6.1893\n",
      "Epoch 18/50\n",
      "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m8s\u001b[0m 344ms/step - accuracy: 0.9902 - loss: 0.0354 - val_accuracy: 0.1163 - val_loss: 6.5292\n",
      "Epoch 19/50\n",
      "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m8s\u001b[0m 350ms/step - accuracy: 0.9936 - loss: 0.0229 - val_accuracy: 0.1221 - val_loss: 7.7530\n",
      "Epoch 20/50\n",
      "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m8s\u001b[0m 348ms/step - accuracy: 0.9960 - loss: 0.0180 - val_accuracy: 0.1919 - val_loss: 6.7588\n",
      "Epoch 21/50\n",
      "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m8s\u001b[0m 349ms/step - accuracy: 0.9888 - loss: 0.0741 - val_accuracy: 0.1744 - val_loss: 6.1173\n",
      "Epoch 22/50\n",
      "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m10s\u001b[0m 353ms/step - accuracy: 0.9863 - loss: 0.0310 - val_accuracy: 0.1221 - val_loss: 7.8251\n",
      "Epoch 23/50\n",
      "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m8s\u001b[0m 352ms/step - accuracy: 0.9806 - loss: 0.0459 - val_accuracy: 0.1105 - val_loss: 7.3690\n",
      "Epoch 24/50\n",
      "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m8s\u001b[0m 354ms/step - accuracy: 0.9909 - loss: 0.0367 - val_accuracy: 0.1279 - val_loss: 6.7142\n",
      "Epoch 25/50\n",
      "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m8s\u001b[0m 350ms/step - accuracy: 0.9956 - loss: 0.0207 - val_accuracy: 0.1744 - val_loss: 7.3862\n",
      "Epoch 26/50\n",
      "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m8s\u001b[0m 354ms/step - accuracy: 0.9943 - loss: 0.0170 - val_accuracy: 0.1105 - val_loss: 7.8574\n",
      "Epoch 27/50\n",
      "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m8s\u001b[0m 349ms/step - accuracy: 0.9907 - loss: 0.0264 - val_accuracy: 0.1453 - val_loss: 8.0612\n",
      "Epoch 28/50\n",
      "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m8s\u001b[0m 355ms/step - accuracy: 0.9862 - loss: 0.0322 - val_accuracy: 0.1512 - val_loss: 7.5137\n",
      "Epoch 29/50\n",
      "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m8s\u001b[0m 355ms/step - accuracy: 0.9972 - loss: 0.0149 - val_accuracy: 0.1221 - val_loss: 9.0568\n",
      "Epoch 30/50\n",
      "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m8s\u001b[0m 352ms/step - accuracy: 0.9923 - loss: 0.0212 - val_accuracy: 0.1686 - val_loss: 8.1323\n",
      "Epoch 31/50\n",
      "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m8s\u001b[0m 354ms/step - accuracy: 0.9879 - loss: 0.0447 - val_accuracy: 0.1512 - val_loss: 6.6837\n",
      "Epoch 32/50\n",
      "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m8s\u001b[0m 351ms/step - accuracy: 0.9902 - loss: 0.0272 - val_accuracy: 0.1395 - val_loss: 7.2132\n",
      "Epoch 33/50\n",
      "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m8s\u001b[0m 355ms/step - accuracy: 0.9891 - loss: 0.0333 - val_accuracy: 0.1105 - val_loss: 8.5476\n",
      "Epoch 34/50\n",
      "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m8s\u001b[0m 351ms/step - accuracy: 0.9999 - loss: 0.0100 - val_accuracy: 0.1337 - val_loss: 8.6741\n",
      "Epoch 35/50\n",
      "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m8s\u001b[0m 353ms/step - accuracy: 0.9888 - loss: 0.0491 - val_accuracy: 0.1802 - val_loss: 6.2393\n",
      "Epoch 36/50\n",
      "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m8s\u001b[0m 353ms/step - accuracy: 0.9865 - loss: 0.0449 - val_accuracy: 0.1686 - val_loss: 6.8632\n",
      "Epoch 37/50\n",
      "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m8s\u001b[0m 353ms/step - accuracy: 0.9896 - loss: 0.0426 - val_accuracy: 0.1453 - val_loss: 7.2004\n",
      "Epoch 38/50\n",
      "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m8s\u001b[0m 352ms/step - accuracy: 0.9975 - loss: 0.0081 - val_accuracy: 0.1570 - val_loss: 7.7179\n",
      "Epoch 39/50\n",
      "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m8s\u001b[0m 348ms/step - accuracy: 0.9960 - loss: 0.0291 - val_accuracy: 0.1279 - val_loss: 7.4668\n",
      "Epoch 40/50\n",
      "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m8s\u001b[0m 354ms/step - accuracy: 0.9918 - loss: 0.0282 - val_accuracy: 0.1570 - val_loss: 7.4255\n",
      "Epoch 41/50\n",
      "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m8s\u001b[0m 351ms/step - accuracy: 0.9980 - loss: 0.0105 - val_accuracy: 0.1395 - val_loss: 8.2856\n",
      "Epoch 42/50\n",
      "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m8s\u001b[0m 353ms/step - accuracy: 0.9991 - loss: 0.0037 - val_accuracy: 0.1221 - val_loss: 8.5654\n",
      "Epoch 43/50\n",
      "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m8s\u001b[0m 351ms/step - accuracy: 0.9993 - loss: 0.0055 - val_accuracy: 0.1221 - val_loss: 10.3604\n",
      "Epoch 44/50\n",
      "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m8s\u001b[0m 352ms/step - accuracy: 0.9964 - loss: 0.0189 - val_accuracy: 0.1686 - val_loss: 6.3094\n",
      "Epoch 45/50\n",
      "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m8s\u001b[0m 353ms/step - accuracy: 0.9914 - loss: 0.0217 - val_accuracy: 0.1919 - val_loss: 7.1334\n",
      "Epoch 46/50\n",
      "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m8s\u001b[0m 351ms/step - accuracy: 0.9984 - loss: 0.0060 - val_accuracy: 0.1512 - val_loss: 9.4613\n",
      "Epoch 47/50\n",
      "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m8s\u001b[0m 352ms/step - accuracy: 0.9992 - loss: 0.0025 - val_accuracy: 0.1395 - val_loss: 10.1398\n",
      "Epoch 48/50\n",
      "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m8s\u001b[0m 352ms/step - accuracy: 0.9945 - loss: 0.0190 - val_accuracy: 0.1337 - val_loss: 9.1565\n",
      "Epoch 49/50\n",
      "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m8s\u001b[0m 354ms/step - accuracy: 0.9962 - loss: 0.0093 - val_accuracy: 0.1047 - val_loss: 9.7891\n",
      "Epoch 50/50\n",
      "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m8s\u001b[0m 354ms/step - accuracy: 0.9922 - loss: 0.0257 - val_accuracy: 0.1570 - val_loss: 7.7165\n",
      "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 35ms/step - accuracy: 0.5840 - loss: 2.5618\n",
      "CNN Test Accuracy: 0.5591\n",
      "Epoch 1/50\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/mojo/.local/lib/python3.10/site-packages/keras/src/layers/core/dense.py:87: UserWarning: Do not pass an `input_shape`/`input_dim` argument to a layer. When using Sequential models, prefer using an `Input(shape)` object as the first layer in the model instead.\n",
      "  super().__init__(activity_regularizer=activity_regularizer, **kwargs)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 7ms/step - accuracy: 0.2117 - loss: 2.9690 - val_accuracy: 0.0058 - val_loss: 2.5290\n",
      "Epoch 2/50\n",
      "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.3262 - loss: 2.1829 - val_accuracy: 0.0407 - val_loss: 2.5265\n",
      "Epoch 3/50\n",
      "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.3926 - loss: 1.9936 - val_accuracy: 0.0465 - val_loss: 2.4006\n",
      "Epoch 4/50\n",
      "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.4150 - loss: 1.7247 - val_accuracy: 0.0174 - val_loss: 2.4961\n",
      "Epoch 5/50\n",
      "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.4220 - loss: 1.7549 - val_accuracy: 0.0233 - val_loss: 2.5974\n",
      "Epoch 6/50\n",
      "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.4044 - loss: 1.8126 - val_accuracy: 0.0523 - val_loss: 2.4929\n",
      "Epoch 7/50\n",
      "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.4213 - loss: 1.6471 - val_accuracy: 0.0465 - val_loss: 2.4433\n",
      "Epoch 8/50\n",
      "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.4602 - loss: 1.5492 - val_accuracy: 0.0698 - val_loss: 2.3522\n",
      "Epoch 9/50\n",
      "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.4729 - loss: 1.6172 - val_accuracy: 0.0465 - val_loss: 2.4214\n",
      "Epoch 10/50\n",
      "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.4649 - loss: 1.6035 - val_accuracy: 0.0698 - val_loss: 2.2869\n",
      "Epoch 11/50\n",
      "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.5169 - loss: 1.4041 - val_accuracy: 0.1105 - val_loss: 2.3329\n",
      "Epoch 12/50\n",
      "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.5297 - loss: 1.3361 - val_accuracy: 0.1163 - val_loss: 2.3849\n",
      "Epoch 13/50\n",
      "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.5205 - loss: 1.3842 - val_accuracy: 0.1395 - val_loss: 2.2227\n",
      "Epoch 14/50\n",
      "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.5423 - loss: 1.2827 - val_accuracy: 0.1221 - val_loss: 2.4078\n",
      "Epoch 15/50\n",
      "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.5443 - loss: 1.2923 - val_accuracy: 0.1512 - val_loss: 2.2296\n",
      "Epoch 16/50\n",
      "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.5839 - loss: 1.1795 - val_accuracy: 0.1744 - val_loss: 2.1967\n",
      "Epoch 17/50\n",
      "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.5713 - loss: 1.1858 - val_accuracy: 0.1395 - val_loss: 2.4196\n",
      "Epoch 18/50\n",
      "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.5592 - loss: 1.1541 - val_accuracy: 0.1453 - val_loss: 2.4250\n",
      "Epoch 19/50\n",
      "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.5642 - loss: 1.1098 - val_accuracy: 0.2151 - val_loss: 2.0262\n",
      "Epoch 20/50\n",
      "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.5772 - loss: 1.0967 - val_accuracy: 0.2209 - val_loss: 2.2551\n",
      "Epoch 21/50\n",
      "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.6031 - loss: 1.0578 - val_accuracy: 0.1744 - val_loss: 2.3749\n",
      "Epoch 22/50\n",
      "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.6278 - loss: 1.0094 - val_accuracy: 0.1453 - val_loss: 2.5823\n",
      "Epoch 23/50\n",
      "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.6006 - loss: 0.9699 - val_accuracy: 0.1802 - val_loss: 2.4396\n",
      "Epoch 24/50\n",
      "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.6125 - loss: 0.9936 - val_accuracy: 0.1802 - val_loss: 2.4682\n",
      "Epoch 25/50\n",
      "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.6670 - loss: 0.8674 - val_accuracy: 0.1919 - val_loss: 2.5735\n",
      "Epoch 26/50\n",
      "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.6583 - loss: 0.9317 - val_accuracy: 0.2267 - val_loss: 2.3034\n",
      "Epoch 27/50\n",
      "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.6665 - loss: 0.8959 - val_accuracy: 0.2384 - val_loss: 2.4320\n",
      "Epoch 28/50\n",
      "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.6634 - loss: 0.9034 - val_accuracy: 0.1453 - val_loss: 2.7644\n",
      "Epoch 29/50\n",
      "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.6587 - loss: 0.9264 - val_accuracy: 0.2035 - val_loss: 2.5939\n",
      "Epoch 30/50\n",
      "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.6627 - loss: 0.9052 - val_accuracy: 0.1744 - val_loss: 2.7674\n",
      "Epoch 31/50\n",
      "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.7009 - loss: 0.8397 - val_accuracy: 0.1802 - val_loss: 2.7542\n",
      "Epoch 32/50\n",
      "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.7363 - loss: 0.7507 - val_accuracy: 0.2093 - val_loss: 2.7998\n",
      "Epoch 33/50\n",
      "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.6964 - loss: 0.7497 - val_accuracy: 0.2209 - val_loss: 2.5327\n",
      "Epoch 34/50\n",
      "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.7440 - loss: 0.6953 - val_accuracy: 0.1802 - val_loss: 3.0240\n",
      "Epoch 35/50\n",
      "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.7650 - loss: 0.6161 - val_accuracy: 0.2267 - val_loss: 2.7218\n",
      "Epoch 36/50\n",
      "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.7560 - loss: 0.6327 - val_accuracy: 0.1977 - val_loss: 3.1060\n",
      "Epoch 37/50\n",
      "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - accuracy: 0.8092 - loss: 0.5626 - val_accuracy: 0.2093 - val_loss: 2.9075\n",
      "Epoch 38/50\n",
      "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.7919 - loss: 0.5808 - val_accuracy: 0.1802 - val_loss: 3.3464\n",
      "Epoch 39/50\n",
      "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.7993 - loss: 0.5798 - val_accuracy: 0.1744 - val_loss: 3.5695\n",
      "Epoch 40/50\n",
      "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.8004 - loss: 0.5147 - val_accuracy: 0.2209 - val_loss: 3.2565\n",
      "Epoch 41/50\n",
      "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.8176 - loss: 0.5142 - val_accuracy: 0.1628 - val_loss: 3.9531\n",
      "Epoch 42/50\n",
      "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.8274 - loss: 0.5019 - val_accuracy: 0.2035 - val_loss: 3.0629\n",
      "Epoch 43/50\n",
      "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.8331 - loss: 0.5078 - val_accuracy: 0.2500 - val_loss: 3.2741\n",
      "Epoch 44/50\n",
      "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.8329 - loss: 0.4527 - val_accuracy: 0.2209 - val_loss: 3.3480\n",
      "Epoch 45/50\n",
      "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.8427 - loss: 0.4804 - val_accuracy: 0.1686 - val_loss: 3.8191\n",
      "Epoch 46/50\n",
      "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.8336 - loss: 0.4585 - val_accuracy: 0.2151 - val_loss: 3.7704\n",
      "Epoch 47/50\n",
      "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.8512 - loss: 0.4700 - val_accuracy: 0.1860 - val_loss: 3.6535\n",
      "Epoch 48/50\n",
      "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.8115 - loss: 0.4324 - val_accuracy: 0.1395 - val_loss: 4.4535\n",
      "Epoch 49/50\n",
      "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.8363 - loss: 0.4884 - val_accuracy: 0.1395 - val_loss: 3.6207\n",
      "Epoch 50/50\n",
      "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.8503 - loss: 0.4404 - val_accuracy: 0.1860 - val_loss: 3.9265\n",
      "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - accuracy: 0.5642 - loss: 1.7377 \n",
      "ANN Test Accuracy: 0.5512\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "from sklearn.preprocessing import LabelEncoder\n",
    "from sklearn.svm import SVC\n",
    "from sklearn.metrics import accuracy_score, classification_report\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "\n",
    "# Load the data\n",
    "train_data = np.load('./layer_features_base_960h/train_10.npz')\n",
    "test_data = np.load('./layer_features_base_960h/test_10.npz')\n",
    "\n",
    "train_features = train_data['features']\n",
    "test_features = test_data['features']\n",
    "\n",
    "# Read Age labels instead of Gender\n",
    "train_labels = pd.read_csv('y_train.csv').Age\n",
    "test_labels = pd.read_csv('y_test.csv').Age\n",
    "\n",
    "# Encode the labels\n",
    "label_encoder = LabelEncoder()\n",
    "train_labels_encoded = label_encoder.fit_transform(train_labels)\n",
    "\n",
    "# Handle unseen labels in test set by filtering out labels not present in train set\n",
    "test_labels_filtered = test_labels[test_labels.isin(train_labels.unique())]\n",
    "test_features_filtered = test_features[test_labels.isin(train_labels.unique())]\n",
    "test_labels_encoded = label_encoder.transform(test_labels_filtered)\n",
    "\n",
    "# Standardize features\n",
    "scaler = StandardScaler()\n",
    "train_features_normalized = scaler.fit_transform(train_features)\n",
    "test_features_normalized = scaler.transform(test_features_filtered)\n",
    "\n",
    "# SVM model\n",
    "svm_model = SVC(kernel='linear', C=10.0, gamma='scale', random_state=42)\n",
    "svm_model.fit(train_features_normalized, train_labels_encoded)\n",
    "\n",
    "# Prediction and Evaluation\n",
    "svm_predictions = svm_model.predict(test_features_normalized)\n",
    "svm_accuracy = accuracy_score(test_labels_encoded, svm_predictions)\n",
    "print(f\"SVM Accuracy: {svm_accuracy:.4f}\")\n",
    "print(\"SVM Classification Report:\")\n",
    "print(classification_report(test_labels_encoded, svm_predictions))\n",
    "\n",
    "# CNN model (TensorFlow)\n",
    "import tensorflow as tf\n",
    "from tensorflow.keras.models import Sequential\n",
    "from tensorflow.keras.layers import Conv1D, Flatten, Dense, Dropout\n",
    "\n",
    "train_features_cnn = np.expand_dims(train_features_normalized, axis=-1)  # Shape: (num_samples, 768, 1)\n",
    "test_features_cnn = np.expand_dims(test_features_normalized, axis=-1)    # Shape: (num_samples, 768, 1)\n",
    "\n",
    "cnn_model = Sequential([\n",
    "    Conv1D(64, kernel_size=5, activation='relu', input_shape=(768, 1)),  # Update input shape to 768 features\n",
    "    Conv1D(128, kernel_size=5, activation='relu'),\n",
    "    Conv1D(256, kernel_size=5, activation='relu'),\n",
    "    Flatten(),\n",
    "    Dense(256, activation='relu'),\n",
    "    Dropout(0.5),\n",
    "    Dense(len(label_encoder.classes_), activation='softmax')\n",
    "])\n",
    "\n",
    "cnn_model.compile(optimizer='adam', loss='sparse_categorical_crossentropy', metrics=['accuracy'])\n",
    "\n",
    "cnn_model.fit(train_features_cnn, train_labels_encoded, epochs=50, batch_size=32, validation_split=0.2)\n",
    "\n",
    "cnn_test_loss, cnn_test_accuracy = cnn_model.evaluate(test_features_cnn, test_labels_encoded)\n",
    "print(f\"CNN Test Accuracy: {cnn_test_accuracy:.4f}\")\n",
    "\n",
    "# ANN model (TensorFlow)\n",
    "ann_model = Sequential([\n",
    "    Dense(512, activation='relu', input_shape=(768,)),  # Update input shape to 768 features\n",
    "    Dropout(0.5),\n",
    "    Dense(256, activation='relu'),\n",
    "    Dropout(0.5),\n",
    "    Dense(128, activation='relu'),\n",
    "    Dropout(0.5),\n",
    "    Dense(len(label_encoder.classes_), activation='softmax')\n",
    "])\n",
    "\n",
    "ann_model.compile(optimizer='adam', loss='sparse_categorical_crossentropy', metrics=['accuracy'])\n",
    "\n",
    "ann_model.fit(train_features_normalized, train_labels_encoded, epochs=50, batch_size=32, validation_split=0.2)\n",
    "\n",
    "ann_test_loss, ann_test_accuracy = ann_model.evaluate(test_features_normalized, test_labels_encoded)\n",
    "print(f\"ANN Test Accuracy: {ann_test_accuracy:.4f}\")\n",
    "\n",
    "# PyTorch CNN Model\n",
    "import torch\n",
    "from torch.utils.data import DataLoader, TensorDataset\n",
    "\n",
    "X_train_tensor = torch.tensor(train_features_cnn, dtype=torch.float32).permute(0, 2, 1)  # Shape: (num_samples, 1, 768)\n",
    "y_train_tensor = torch.tensor(train_labels_encoded, dtype=torch.long)\n",
    "X_test_tensor = torch.tensor(test_features_cnn, dtype=torch.float32).permute(0, 2, 1)    # Shape: (num_samples, 1, 768)\n",
    "y_test_tensor = torch.tensor(test_labels_encoded, dtype=torch.long)\n",
    "\n",
    "train_dataset = TensorDataset(X_train_tensor, y_train_tensor)\n",
    "test_dataset = TensorDataset(X_test_tensor, y_test_tensor)\n",
    "\n",
    "train_loader = DataLoader(train_dataset, batch_size=64, shuffle=True)\n",
    "test_loader = DataLoader(test_dataset, batch_size=64, shuffle=False)\n",
    "\n",
    "import torch.nn as nn\n",
    "import torch.optim as optim\n",
    "\n",
    "class CNN1DModel(nn.Module):\n",
    "    def __init__(self, input_channels, num_classes):\n",
    "        super(CNN1DModel, self).__init__()\n",
    "        self.conv1 = nn.Conv1d(input_channels, 32, kernel_size=5, stride=1, padding=2)\n",
    "        self.bn1 = nn.BatchNorm1d(32)\n",
    "        self.relu = nn.ReLU()\n",
    "        self.conv2 = nn.Conv1d(32, 64, kernel_size=5, stride=1, padding=2)\n",
    "        self.bn2 = nn.BatchNorm1d(64)\n",
    "        self.conv3 = nn.Conv1d(64, 128, kernel_size=5, stride=1, padding=2)\n",
    "        self.bn3 = nn.BatchNorm1d(128)\n",
    "        self.flatten = nn.Flatten()\n",
    "        self.fc1 = nn.Linear(128 * 768, 512)  # Update to 768 features\n",
    "        self.fc2 = nn.Linear(512, num_classes)\n",
    "        self.dropout = nn.Dropout(0.5)\n",
    "    \n",
    "    def forward(self, x):\n",
    "        x = self.relu(self.bn1(self.conv1(x)))\n",
    "        x = self.relu(self.bn2(self.conv2(x)))\n",
    "        x = self.relu(self.bn3(self.conv3(x)))\n",
    "        x = self.flatten(x)\n",
    "        x = self.dropout(self.relu(self.fc1(x)))\n",
    "        x = self.fc2(x)\n",
    "        return x\n",
    "\n",
    "input_channels = 1\n",
    "num_classes = len(label_encoder.classes_)\n",
    "model = CNN1DModel(input_channels, num_classes)\n",
    "criterion = nn.CrossEntropyLoss()\n",
    "optimizer = optim.Adam(model.parameters(), lr=0.001)\n",
    "\n",
    "# Training and testing as before\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "9d405d97",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "SVM Accuracy: 0.6220\n",
      "SVM Classification Report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           1       0.55      0.50      0.52        12\n",
      "           2       0.40      0.50      0.44         8\n",
      "           3       0.66      0.74      0.70        39\n",
      "           4       0.50      0.67      0.57         6\n",
      "           5       0.70      0.74      0.72        42\n",
      "           6       0.67      0.25      0.36        16\n",
      "           7       0.00      0.00      0.00         2\n",
      "           8       0.50      0.50      0.50         2\n",
      "\n",
      "    accuracy                           0.62       127\n",
      "   macro avg       0.50      0.49      0.48       127\n",
      "weighted avg       0.63      0.62      0.61       127\n",
      "\n",
      "Epoch 1/50\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/mojo/.local/lib/python3.10/site-packages/keras/src/layers/convolutional/base_conv.py:107: UserWarning: Do not pass an `input_shape`/`input_dim` argument to a layer. When using Sequential models, prefer using an `Input(shape)` object as the first layer in the model instead.\n",
      "  super().__init__(activity_regularizer=activity_regularizer, **kwargs)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m9s\u001b[0m 367ms/step - accuracy: 0.3552 - loss: 3.1527 - val_accuracy: 0.0349 - val_loss: 2.5158\n",
      "Epoch 2/50\n",
      "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m8s\u001b[0m 352ms/step - accuracy: 0.4886 - loss: 1.5259 - val_accuracy: 0.0523 - val_loss: 2.5128\n",
      "Epoch 3/50\n",
      "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m8s\u001b[0m 344ms/step - accuracy: 0.5636 - loss: 1.1762 - val_accuracy: 0.1105 - val_loss: 2.3992\n",
      "Epoch 4/50\n",
      "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m7s\u001b[0m 340ms/step - accuracy: 0.6561 - loss: 0.9310 - val_accuracy: 0.0988 - val_loss: 2.6274\n",
      "Epoch 5/50\n",
      "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m7s\u001b[0m 334ms/step - accuracy: 0.7211 - loss: 0.7277 - val_accuracy: 0.1163 - val_loss: 2.8068\n",
      "Epoch 6/50\n",
      "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m7s\u001b[0m 339ms/step - accuracy: 0.8294 - loss: 0.5165 - val_accuracy: 0.1512 - val_loss: 3.2388\n",
      "Epoch 7/50\n",
      "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m8s\u001b[0m 342ms/step - accuracy: 0.8558 - loss: 0.3696 - val_accuracy: 0.1279 - val_loss: 3.5927\n",
      "Epoch 8/50\n",
      "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m8s\u001b[0m 343ms/step - accuracy: 0.9339 - loss: 0.2093 - val_accuracy: 0.1395 - val_loss: 4.1036\n",
      "Epoch 9/50\n",
      "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m7s\u001b[0m 340ms/step - accuracy: 0.9563 - loss: 0.1824 - val_accuracy: 0.1105 - val_loss: 5.4363\n",
      "Epoch 10/50\n",
      "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m8s\u001b[0m 342ms/step - accuracy: 0.9621 - loss: 0.1421 - val_accuracy: 0.1570 - val_loss: 3.9529\n",
      "Epoch 11/50\n",
      "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m7s\u001b[0m 340ms/step - accuracy: 0.9673 - loss: 0.1208 - val_accuracy: 0.1163 - val_loss: 6.2954\n",
      "Epoch 12/50\n",
      "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m8s\u001b[0m 343ms/step - accuracy: 0.9600 - loss: 0.1244 - val_accuracy: 0.1453 - val_loss: 4.7131\n",
      "Epoch 13/50\n",
      "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m8s\u001b[0m 347ms/step - accuracy: 0.9737 - loss: 0.0958 - val_accuracy: 0.1570 - val_loss: 5.2834\n",
      "Epoch 14/50\n",
      "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m8s\u001b[0m 349ms/step - accuracy: 0.9867 - loss: 0.0458 - val_accuracy: 0.1395 - val_loss: 6.1309\n",
      "Epoch 15/50\n",
      "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m8s\u001b[0m 347ms/step - accuracy: 0.9869 - loss: 0.0449 - val_accuracy: 0.1279 - val_loss: 5.5564\n",
      "Epoch 16/50\n",
      "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m8s\u001b[0m 350ms/step - accuracy: 0.9924 - loss: 0.0370 - val_accuracy: 0.0988 - val_loss: 7.3073\n",
      "Epoch 17/50\n",
      "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m8s\u001b[0m 349ms/step - accuracy: 0.9849 - loss: 0.0374 - val_accuracy: 0.1744 - val_loss: 5.9750\n",
      "Epoch 18/50\n",
      "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m8s\u001b[0m 352ms/step - accuracy: 0.9861 - loss: 0.0300 - val_accuracy: 0.1105 - val_loss: 7.9551\n",
      "Epoch 19/50\n",
      "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m8s\u001b[0m 348ms/step - accuracy: 0.9980 - loss: 0.0177 - val_accuracy: 0.1512 - val_loss: 7.2480\n",
      "Epoch 20/50\n",
      "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m8s\u001b[0m 353ms/step - accuracy: 0.9864 - loss: 0.0317 - val_accuracy: 0.1279 - val_loss: 7.6250\n",
      "Epoch 21/50\n",
      "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m8s\u001b[0m 353ms/step - accuracy: 0.9860 - loss: 0.0456 - val_accuracy: 0.0930 - val_loss: 7.6302\n",
      "Epoch 22/50\n",
      "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m8s\u001b[0m 353ms/step - accuracy: 0.9866 - loss: 0.0540 - val_accuracy: 0.1163 - val_loss: 6.8794\n",
      "Epoch 23/50\n",
      "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m8s\u001b[0m 355ms/step - accuracy: 0.9949 - loss: 0.0279 - val_accuracy: 0.1686 - val_loss: 6.3387\n",
      "Epoch 24/50\n",
      "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m8s\u001b[0m 351ms/step - accuracy: 0.9864 - loss: 0.0516 - val_accuracy: 0.0872 - val_loss: 7.2115\n",
      "Epoch 25/50\n",
      "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m8s\u001b[0m 351ms/step - accuracy: 0.9890 - loss: 0.0379 - val_accuracy: 0.1163 - val_loss: 7.0388\n",
      "Epoch 26/50\n",
      "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m8s\u001b[0m 353ms/step - accuracy: 0.9911 - loss: 0.0232 - val_accuracy: 0.1047 - val_loss: 7.8247\n",
      "Epoch 27/50\n",
      "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m8s\u001b[0m 353ms/step - accuracy: 0.9991 - loss: 0.0074 - val_accuracy: 0.1221 - val_loss: 8.2995\n",
      "Epoch 28/50\n",
      "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m8s\u001b[0m 353ms/step - accuracy: 0.9992 - loss: 0.0094 - val_accuracy: 0.1163 - val_loss: 8.6029\n",
      "Epoch 29/50\n",
      "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m8s\u001b[0m 353ms/step - accuracy: 0.9973 - loss: 0.0158 - val_accuracy: 0.1163 - val_loss: 7.6472\n",
      "Epoch 30/50\n",
      "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m8s\u001b[0m 354ms/step - accuracy: 0.9923 - loss: 0.0189 - val_accuracy: 0.1337 - val_loss: 7.4927\n",
      "Epoch 31/50\n",
      "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m8s\u001b[0m 354ms/step - accuracy: 0.9929 - loss: 0.0179 - val_accuracy: 0.0988 - val_loss: 8.1442\n",
      "Epoch 32/50\n",
      "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m8s\u001b[0m 353ms/step - accuracy: 0.9949 - loss: 0.0071 - val_accuracy: 0.1686 - val_loss: 7.8671\n",
      "Epoch 33/50\n",
      "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m8s\u001b[0m 353ms/step - accuracy: 0.9988 - loss: 0.0130 - val_accuracy: 0.1744 - val_loss: 7.4591\n",
      "Epoch 34/50\n",
      "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m8s\u001b[0m 352ms/step - accuracy: 0.9974 - loss: 0.0101 - val_accuracy: 0.1686 - val_loss: 7.4885\n",
      "Epoch 35/50\n",
      "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m8s\u001b[0m 358ms/step - accuracy: 0.9905 - loss: 0.0188 - val_accuracy: 0.1570 - val_loss: 6.7457\n",
      "Epoch 36/50\n",
      "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m8s\u001b[0m 353ms/step - accuracy: 0.9967 - loss: 0.0178 - val_accuracy: 0.1279 - val_loss: 7.7971\n",
      "Epoch 37/50\n",
      "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m8s\u001b[0m 354ms/step - accuracy: 0.9975 - loss: 0.0081 - val_accuracy: 0.1570 - val_loss: 8.2440\n",
      "Epoch 38/50\n",
      "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m8s\u001b[0m 354ms/step - accuracy: 0.9920 - loss: 0.0308 - val_accuracy: 0.1047 - val_loss: 8.0315\n",
      "Epoch 39/50\n",
      "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m8s\u001b[0m 348ms/step - accuracy: 0.9884 - loss: 0.0243 - val_accuracy: 0.1337 - val_loss: 8.2126\n",
      "Epoch 40/50\n",
      "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m8s\u001b[0m 352ms/step - accuracy: 0.9945 - loss: 0.0220 - val_accuracy: 0.1221 - val_loss: 6.7898\n",
      "Epoch 41/50\n",
      "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m8s\u001b[0m 348ms/step - accuracy: 0.9936 - loss: 0.0191 - val_accuracy: 0.1163 - val_loss: 8.5484\n",
      "Epoch 42/50\n",
      "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m8s\u001b[0m 351ms/step - accuracy: 0.9957 - loss: 0.0144 - val_accuracy: 0.1337 - val_loss: 7.1546\n",
      "Epoch 43/50\n",
      "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m8s\u001b[0m 351ms/step - accuracy: 0.9896 - loss: 0.0193 - val_accuracy: 0.1512 - val_loss: 7.5044\n",
      "Epoch 44/50\n",
      "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m8s\u001b[0m 353ms/step - accuracy: 0.9929 - loss: 0.0385 - val_accuracy: 0.1570 - val_loss: 6.4693\n",
      "Epoch 45/50\n",
      "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m8s\u001b[0m 355ms/step - accuracy: 0.9974 - loss: 0.0103 - val_accuracy: 0.1163 - val_loss: 8.5890\n",
      "Epoch 46/50\n",
      "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m8s\u001b[0m 352ms/step - accuracy: 0.9986 - loss: 0.0059 - val_accuracy: 0.1453 - val_loss: 8.5871\n",
      "Epoch 47/50\n",
      "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m8s\u001b[0m 352ms/step - accuracy: 0.9929 - loss: 0.0208 - val_accuracy: 0.1744 - val_loss: 6.7504\n",
      "Epoch 48/50\n",
      "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m8s\u001b[0m 345ms/step - accuracy: 0.9970 - loss: 0.0137 - val_accuracy: 0.1686 - val_loss: 7.8310\n",
      "Epoch 49/50\n",
      "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m8s\u001b[0m 357ms/step - accuracy: 0.9991 - loss: 0.0050 - val_accuracy: 0.1570 - val_loss: 9.4367\n",
      "Epoch 50/50\n",
      "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m8s\u001b[0m 355ms/step - accuracy: 0.9958 - loss: 0.0184 - val_accuracy: 0.1686 - val_loss: 7.7393\n",
      "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 35ms/step - accuracy: 0.5663 - loss: 3.4871\n",
      "CNN Test Accuracy: 0.5354\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/mojo/.local/lib/python3.10/site-packages/keras/src/layers/core/dense.py:87: UserWarning: Do not pass an `input_shape`/`input_dim` argument to a layer. When using Sequential models, prefer using an `Input(shape)` object as the first layer in the model instead.\n",
      "  super().__init__(activity_regularizer=activity_regularizer, **kwargs)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/50\n",
      "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 7ms/step - accuracy: 0.2159 - loss: 3.2111 - val_accuracy: 0.0116 - val_loss: 2.6925\n",
      "Epoch 2/50\n",
      "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.2792 - loss: 2.3996 - val_accuracy: 0.0349 - val_loss: 2.6802\n",
      "Epoch 3/50\n",
      "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.4001 - loss: 1.9754 - val_accuracy: 0.0523 - val_loss: 2.4162\n",
      "Epoch 4/50\n",
      "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.3574 - loss: 1.9646 - val_accuracy: 0.0465 - val_loss: 2.4434\n",
      "Epoch 5/50\n",
      "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.4239 - loss: 1.8697 - val_accuracy: 0.0407 - val_loss: 2.4119\n",
      "Epoch 6/50\n",
      "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.3829 - loss: 1.7898 - val_accuracy: 0.0465 - val_loss: 2.4986\n",
      "Epoch 7/50\n",
      "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.4483 - loss: 1.7661 - val_accuracy: 0.0581 - val_loss: 2.3774\n",
      "Epoch 8/50\n",
      "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.4239 - loss: 1.7253 - val_accuracy: 0.0523 - val_loss: 2.3421\n",
      "Epoch 9/50\n",
      "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.4921 - loss: 1.5558 - val_accuracy: 0.0523 - val_loss: 2.2172\n",
      "Epoch 10/50\n",
      "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.4627 - loss: 1.6596 - val_accuracy: 0.0756 - val_loss: 2.0619\n",
      "Epoch 11/50\n",
      "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.5021 - loss: 1.5211 - val_accuracy: 0.0291 - val_loss: 2.3294\n",
      "Epoch 12/50\n",
      "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.4501 - loss: 1.5512 - val_accuracy: 0.0581 - val_loss: 2.2771\n",
      "Epoch 13/50\n",
      "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.4939 - loss: 1.5327 - val_accuracy: 0.0465 - val_loss: 2.3175\n",
      "Epoch 14/50\n",
      "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.4869 - loss: 1.4746 - val_accuracy: 0.0814 - val_loss: 2.2269\n",
      "Epoch 15/50\n",
      "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.5132 - loss: 1.4328 - val_accuracy: 0.1105 - val_loss: 2.1587\n",
      "Epoch 16/50\n",
      "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.5448 - loss: 1.3420 - val_accuracy: 0.1279 - val_loss: 2.0977\n",
      "Epoch 17/50\n",
      "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.5745 - loss: 1.2795 - val_accuracy: 0.1163 - val_loss: 2.1332\n",
      "Epoch 18/50\n",
      "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.5131 - loss: 1.3188 - val_accuracy: 0.0814 - val_loss: 2.2149\n",
      "Epoch 19/50\n",
      "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.5639 - loss: 1.3438 - val_accuracy: 0.0988 - val_loss: 2.2403\n",
      "Epoch 20/50\n",
      "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.5255 - loss: 1.2764 - val_accuracy: 0.1279 - val_loss: 2.0715\n",
      "Epoch 21/50\n",
      "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.5543 - loss: 1.2802 - val_accuracy: 0.1221 - val_loss: 2.2169\n",
      "Epoch 22/50\n",
      "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.5898 - loss: 1.1982 - val_accuracy: 0.2209 - val_loss: 1.9649\n",
      "Epoch 23/50\n",
      "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.5523 - loss: 1.2029 - val_accuracy: 0.1686 - val_loss: 2.0483\n",
      "Epoch 24/50\n",
      "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.5821 - loss: 1.1574 - val_accuracy: 0.1453 - val_loss: 2.1924\n",
      "Epoch 25/50\n",
      "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.5992 - loss: 1.1520 - val_accuracy: 0.1453 - val_loss: 2.4475\n",
      "Epoch 26/50\n",
      "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.5648 - loss: 1.2987 - val_accuracy: 0.1744 - val_loss: 2.2309\n",
      "Epoch 27/50\n",
      "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.6472 - loss: 1.0035 - val_accuracy: 0.1977 - val_loss: 2.2433\n",
      "Epoch 28/50\n",
      "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.5510 - loss: 1.1719 - val_accuracy: 0.1860 - val_loss: 2.2339\n",
      "Epoch 29/50\n",
      "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.5810 - loss: 1.1629 - val_accuracy: 0.2035 - val_loss: 2.1375\n",
      "Epoch 30/50\n",
      "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.6192 - loss: 1.0447 - val_accuracy: 0.1860 - val_loss: 2.2428\n",
      "Epoch 31/50\n",
      "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.5801 - loss: 1.1489 - val_accuracy: 0.2035 - val_loss: 2.4373\n",
      "Epoch 32/50\n",
      "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.6187 - loss: 0.9706 - val_accuracy: 0.2558 - val_loss: 2.2819\n",
      "Epoch 33/50\n",
      "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.6358 - loss: 0.9908 - val_accuracy: 0.2384 - val_loss: 2.3401\n",
      "Epoch 34/50\n",
      "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.6483 - loss: 1.0582 - val_accuracy: 0.2442 - val_loss: 2.3323\n",
      "Epoch 35/50\n",
      "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.6653 - loss: 0.9529 - val_accuracy: 0.2209 - val_loss: 2.4153\n",
      "Epoch 36/50\n",
      "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.6292 - loss: 0.9659 - val_accuracy: 0.1570 - val_loss: 2.5322\n",
      "Epoch 37/50\n",
      "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.6478 - loss: 0.9427 - val_accuracy: 0.1977 - val_loss: 2.5442\n",
      "Epoch 38/50\n",
      "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.6638 - loss: 0.9713 - val_accuracy: 0.1802 - val_loss: 2.5367\n",
      "Epoch 39/50\n",
      "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.6641 - loss: 0.8553 - val_accuracy: 0.1977 - val_loss: 2.5007\n",
      "Epoch 40/50\n",
      "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.6450 - loss: 0.9712 - val_accuracy: 0.1570 - val_loss: 2.6709\n",
      "Epoch 41/50\n",
      "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.6642 - loss: 0.8645 - val_accuracy: 0.1279 - val_loss: 2.9642\n",
      "Epoch 42/50\n",
      "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.6398 - loss: 0.9118 - val_accuracy: 0.2384 - val_loss: 2.5629\n",
      "Epoch 43/50\n",
      "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.7168 - loss: 0.7691 - val_accuracy: 0.2093 - val_loss: 2.6247\n",
      "Epoch 44/50\n",
      "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.7219 - loss: 0.7529 - val_accuracy: 0.2093 - val_loss: 2.7400\n",
      "Epoch 45/50\n",
      "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.6912 - loss: 0.8021 - val_accuracy: 0.2035 - val_loss: 2.8021\n",
      "Epoch 46/50\n",
      "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.7383 - loss: 0.7230 - val_accuracy: 0.2151 - val_loss: 2.8003\n",
      "Epoch 47/50\n",
      "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.7203 - loss: 0.7165 - val_accuracy: 0.2151 - val_loss: 2.9605\n",
      "Epoch 48/50\n",
      "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.7297 - loss: 0.7649 - val_accuracy: 0.2151 - val_loss: 2.7737\n",
      "Epoch 49/50\n",
      "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.7240 - loss: 0.7781 - val_accuracy: 0.1919 - val_loss: 3.2194\n",
      "Epoch 50/50\n",
      "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.7515 - loss: 0.6766 - val_accuracy: 0.1977 - val_loss: 2.9540\n",
      "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - accuracy: 0.5923 - loss: 1.3148 \n",
      "ANN Test Accuracy: 0.5433\n"
     ]
    },
    {
     "ename": "",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31mThe Kernel crashed while executing code in the current cell or a previous cell. \n",
      "\u001b[1;31mPlease review the code in the cell(s) to identify a possible cause of the failure. \n",
      "\u001b[1;31mClick <a href='https://aka.ms/vscodeJupyterKernelCrash'>here</a> for more info. \n",
      "\u001b[1;31mView Jupyter <a href='command:jupyter.viewOutput'>log</a> for further details."
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "from sklearn.preprocessing import LabelEncoder\n",
    "from sklearn.svm import SVC\n",
    "from sklearn.metrics import accuracy_score, classification_report\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "\n",
    "# Load the data\n",
    "train_data = np.load('./layer_features_base_960h/train_11.npz')\n",
    "test_data = np.load('./layer_features_base_960h/test_11.npz')\n",
    "\n",
    "train_features = train_data['features']\n",
    "test_features = test_data['features']\n",
    "\n",
    "# Read Age labels instead of Gender\n",
    "train_labels = pd.read_csv('y_train.csv').Age\n",
    "test_labels = pd.read_csv('y_test.csv').Age\n",
    "\n",
    "# Encode the labels\n",
    "label_encoder = LabelEncoder()\n",
    "train_labels_encoded = label_encoder.fit_transform(train_labels)\n",
    "\n",
    "# Handle unseen labels in test set by filtering out labels not present in train set\n",
    "test_labels_filtered = test_labels[test_labels.isin(train_labels.unique())]\n",
    "test_features_filtered = test_features[test_labels.isin(train_labels.unique())]\n",
    "test_labels_encoded = label_encoder.transform(test_labels_filtered)\n",
    "\n",
    "# Standardize features\n",
    "scaler = StandardScaler()\n",
    "train_features_normalized = scaler.fit_transform(train_features)\n",
    "test_features_normalized = scaler.transform(test_features_filtered)\n",
    "\n",
    "# SVM model\n",
    "svm_model = SVC(kernel='linear', C=10.0, gamma='scale', random_state=42)\n",
    "svm_model.fit(train_features_normalized, train_labels_encoded)\n",
    "\n",
    "# Prediction and Evaluation\n",
    "svm_predictions = svm_model.predict(test_features_normalized)\n",
    "svm_accuracy = accuracy_score(test_labels_encoded, svm_predictions)\n",
    "print(f\"SVM Accuracy: {svm_accuracy:.4f}\")\n",
    "print(\"SVM Classification Report:\")\n",
    "print(classification_report(test_labels_encoded, svm_predictions))\n",
    "\n",
    "# CNN model (TensorFlow)\n",
    "import tensorflow as tf\n",
    "from tensorflow.keras.models import Sequential\n",
    "from tensorflow.keras.layers import Conv1D, Flatten, Dense, Dropout\n",
    "\n",
    "train_features_cnn = np.expand_dims(train_features_normalized, axis=-1)  # Shape: (num_samples, 768, 1)\n",
    "test_features_cnn = np.expand_dims(test_features_normalized, axis=-1)    # Shape: (num_samples, 768, 1)\n",
    "\n",
    "cnn_model = Sequential([\n",
    "    Conv1D(64, kernel_size=5, activation='relu', input_shape=(768, 1)),  # Update input shape to 768 features\n",
    "    Conv1D(128, kernel_size=5, activation='relu'),\n",
    "    Conv1D(256, kernel_size=5, activation='relu'),\n",
    "    Flatten(),\n",
    "    Dense(256, activation='relu'),\n",
    "    Dropout(0.5),\n",
    "    Dense(len(label_encoder.classes_), activation='softmax')\n",
    "])\n",
    "\n",
    "cnn_model.compile(optimizer='adam', loss='sparse_categorical_crossentropy', metrics=['accuracy'])\n",
    "\n",
    "cnn_model.fit(train_features_cnn, train_labels_encoded, epochs=50, batch_size=32, validation_split=0.2)\n",
    "\n",
    "cnn_test_loss, cnn_test_accuracy = cnn_model.evaluate(test_features_cnn, test_labels_encoded)\n",
    "print(f\"CNN Test Accuracy: {cnn_test_accuracy:.4f}\")\n",
    "\n",
    "# ANN model (TensorFlow)\n",
    "ann_model = Sequential([\n",
    "    Dense(512, activation='relu', input_shape=(768,)),  # Update input shape to 768 features\n",
    "    Dropout(0.5),\n",
    "    Dense(256, activation='relu'),\n",
    "    Dropout(0.5),\n",
    "    Dense(128, activation='relu'),\n",
    "    Dropout(0.5),\n",
    "    Dense(len(label_encoder.classes_), activation='softmax')\n",
    "])\n",
    "\n",
    "ann_model.compile(optimizer='adam', loss='sparse_categorical_crossentropy', metrics=['accuracy'])\n",
    "\n",
    "ann_model.fit(train_features_normalized, train_labels_encoded, epochs=50, batch_size=32, validation_split=0.2)\n",
    "\n",
    "ann_test_loss, ann_test_accuracy = ann_model.evaluate(test_features_normalized, test_labels_encoded)\n",
    "print(f\"ANN Test Accuracy: {ann_test_accuracy:.4f}\")\n",
    "\n",
    "# PyTorch CNN Model\n",
    "import torch\n",
    "from torch.utils.data import DataLoader, TensorDataset\n",
    "\n",
    "X_train_tensor = torch.tensor(train_features_cnn, dtype=torch.float32).permute(0, 2, 1)  # Shape: (num_samples, 1, 768)\n",
    "y_train_tensor = torch.tensor(train_labels_encoded, dtype=torch.long)\n",
    "X_test_tensor = torch.tensor(test_features_cnn, dtype=torch.float32).permute(0, 2, 1)    # Shape: (num_samples, 1, 768)\n",
    "y_test_tensor = torch.tensor(test_labels_encoded, dtype=torch.long)\n",
    "\n",
    "train_dataset = TensorDataset(X_train_tensor, y_train_tensor)\n",
    "test_dataset = TensorDataset(X_test_tensor, y_test_tensor)\n",
    "\n",
    "train_loader = DataLoader(train_dataset, batch_size=64, shuffle=True)\n",
    "test_loader = DataLoader(test_dataset, batch_size=64, shuffle=False)\n",
    "\n",
    "import torch.nn as nn\n",
    "import torch.optim as optim\n",
    "\n",
    "class CNN1DModel(nn.Module):\n",
    "    def __init__(self, input_channels, num_classes):\n",
    "        super(CNN1DModel, self).__init__()\n",
    "        self.conv1 = nn.Conv1d(input_channels, 32, kernel_size=5, stride=1, padding=2)\n",
    "        self.bn1 = nn.BatchNorm1d(32)\n",
    "        self.relu = nn.ReLU()\n",
    "        self.conv2 = nn.Conv1d(32, 64, kernel_size=5, stride=1, padding=2)\n",
    "        self.bn2 = nn.BatchNorm1d(64)\n",
    "        self.conv3 = nn.Conv1d(64, 128, kernel_size=5, stride=1, padding=2)\n",
    "        self.bn3 = nn.BatchNorm1d(128)\n",
    "        self.flatten = nn.Flatten()\n",
    "        self.fc1 = nn.Linear(128 * 768, 512)  # Update to 768 features\n",
    "        self.fc2 = nn.Linear(512, num_classes)\n",
    "        self.dropout = nn.Dropout(0.5)\n",
    "    \n",
    "    def forward(self, x):\n",
    "        x = self.relu(self.bn1(self.conv1(x)))\n",
    "        x = self.relu(self.bn2(self.conv2(x)))\n",
    "        x = self.relu(self.bn3(self.conv3(x)))\n",
    "        x = self.flatten(x)\n",
    "        x = self.dropout(self.relu(self.fc1(x)))\n",
    "        x = self.fc2(x)\n",
    "        return x\n",
    "\n",
    "input_channels = 1\n",
    "num_classes = len(label_encoder.classes_)\n",
    "model = CNN1DModel(input_channels, num_classes)\n",
    "criterion = nn.CrossEntropyLoss()\n",
    "optimizer = optim.Adam(model.parameters(), lr=0.001)\n",
    "\n",
    "# Training and testing as before\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "82888415",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/lib/python3/dist-packages/scipy/__init__.py:146: UserWarning: A NumPy version >=1.17.3 and <1.25.0 is required for this version of SciPy (detected version 1.26.4\n",
      "  warnings.warn(f\"A NumPy version >={np_minversion} and <{np_maxversion}\"\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "SVM Accuracy: 0.4016\n",
      "SVM Classification Report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           1       0.46      0.50      0.48        12\n",
      "           2       0.19      0.38      0.25         8\n",
      "           3       0.43      0.41      0.42        39\n",
      "           4       0.17      0.33      0.22         6\n",
      "           5       0.52      0.40      0.45        42\n",
      "           6       0.50      0.31      0.38        16\n",
      "           7       1.00      0.50      0.67         2\n",
      "           8       0.50      0.50      0.50         2\n",
      "           9       0.00      0.00      0.00         0\n",
      "\n",
      "    accuracy                           0.40       127\n",
      "   macro avg       0.42      0.37      0.38       127\n",
      "weighted avg       0.45      0.40      0.42       127\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/mojo/.local/lib/python3.10/site-packages/sklearn/metrics/_classification.py:1509: UndefinedMetricWarning: Recall is ill-defined and being set to 0.0 in labels with no true samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", len(result))\n",
      "/home/mojo/.local/lib/python3.10/site-packages/sklearn/metrics/_classification.py:1509: UndefinedMetricWarning: Recall is ill-defined and being set to 0.0 in labels with no true samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", len(result))\n",
      "/home/mojo/.local/lib/python3.10/site-packages/sklearn/metrics/_classification.py:1509: UndefinedMetricWarning: Recall is ill-defined and being set to 0.0 in labels with no true samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", len(result))\n",
      "2024-09-08 18:58:11.520643: I tensorflow/core/platform/cpu_feature_guard.cc:210] This TensorFlow binary is optimized to use available CPU instructions in performance-critical operations.\n",
      "To enable the following instructions: AVX2 FMA, in other operations, rebuild TensorFlow with the appropriate compiler flags.\n",
      "2024-09-08 18:58:12.422908: W tensorflow/compiler/tf2tensorrt/utils/py_utils.cc:38] TF-TRT Warning: Could not find TensorRT\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/50\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/mojo/.local/lib/python3.10/site-packages/keras/src/layers/convolutional/base_conv.py:107: UserWarning: Do not pass an `input_shape`/`input_dim` argument to a layer. When using Sequential models, prefer using an `Input(shape)` object as the first layer in the model instead.\n",
      "  super().__init__(activity_regularizer=activity_regularizer, **kwargs)\n",
      "2024-09-08 18:58:13.536568: I external/local_xla/xla/stream_executor/cuda/cuda_executor.cc:998] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero. See more at https://github.com/torvalds/linux/blob/v6.0/Documentation/ABI/testing/sysfs-bus-pci#L344-L355\n",
      "2024-09-08 18:58:13.563197: W tensorflow/core/common_runtime/gpu/gpu_device.cc:2251] Cannot dlopen some GPU libraries. Please make sure the missing libraries mentioned above are installed properly if you would like to use GPU. Follow the guide at https://www.tensorflow.org/install/gpu for how to download and setup the required libraries for your platform.\n",
      "Skipping registering GPU devices...\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m9s\u001b[0m 354ms/step - accuracy: 0.3249 - loss: 4.2051 - val_accuracy: 0.0000e+00 - val_loss: 2.5828\n",
      "Epoch 2/50\n",
      "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m7s\u001b[0m 340ms/step - accuracy: 0.4948 - loss: 1.5711 - val_accuracy: 0.0407 - val_loss: 2.4756\n",
      "Epoch 3/50\n",
      "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m7s\u001b[0m 341ms/step - accuracy: 0.5620 - loss: 1.3041 - val_accuracy: 0.0523 - val_loss: 2.4836\n",
      "Epoch 4/50\n",
      "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m7s\u001b[0m 339ms/step - accuracy: 0.6730 - loss: 0.9800 - val_accuracy: 0.0698 - val_loss: 2.8482\n",
      "Epoch 5/50\n",
      "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m8s\u001b[0m 342ms/step - accuracy: 0.7609 - loss: 0.6947 - val_accuracy: 0.0640 - val_loss: 3.9464\n",
      "Epoch 6/50\n",
      "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m8s\u001b[0m 343ms/step - accuracy: 0.8333 - loss: 0.4439 - val_accuracy: 0.0988 - val_loss: 3.7430\n",
      "Epoch 7/50\n",
      "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m8s\u001b[0m 347ms/step - accuracy: 0.8939 - loss: 0.3317 - val_accuracy: 0.0698 - val_loss: 5.2627\n",
      "Epoch 8/50\n",
      "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m8s\u001b[0m 343ms/step - accuracy: 0.9602 - loss: 0.1715 - val_accuracy: 0.0756 - val_loss: 5.4942\n",
      "Epoch 9/50\n",
      "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m8s\u001b[0m 346ms/step - accuracy: 0.9446 - loss: 0.1860 - val_accuracy: 0.0756 - val_loss: 6.8290\n",
      "Epoch 10/50\n",
      "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m8s\u001b[0m 345ms/step - accuracy: 0.9661 - loss: 0.0873 - val_accuracy: 0.1279 - val_loss: 5.1442\n",
      "Epoch 11/50\n",
      "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m8s\u001b[0m 345ms/step - accuracy: 0.9796 - loss: 0.0687 - val_accuracy: 0.1337 - val_loss: 5.2763\n",
      "Epoch 12/50\n",
      "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m8s\u001b[0m 344ms/step - accuracy: 0.9843 - loss: 0.0763 - val_accuracy: 0.0930 - val_loss: 7.5128\n",
      "Epoch 13/50\n",
      "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m8s\u001b[0m 346ms/step - accuracy: 0.9857 - loss: 0.0429 - val_accuracy: 0.1279 - val_loss: 5.8568\n",
      "Epoch 14/50\n",
      "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m8s\u001b[0m 346ms/step - accuracy: 0.9888 - loss: 0.0553 - val_accuracy: 0.0872 - val_loss: 6.8790\n",
      "Epoch 15/50\n",
      "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m8s\u001b[0m 344ms/step - accuracy: 0.9907 - loss: 0.0258 - val_accuracy: 0.1047 - val_loss: 6.6198\n",
      "Epoch 16/50\n",
      "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m10s\u001b[0m 345ms/step - accuracy: 0.9883 - loss: 0.0389 - val_accuracy: 0.0988 - val_loss: 7.5173\n",
      "Epoch 17/50\n",
      "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m8s\u001b[0m 349ms/step - accuracy: 0.9894 - loss: 0.0288 - val_accuracy: 0.1570 - val_loss: 7.4339\n",
      "Epoch 18/50\n",
      "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m8s\u001b[0m 361ms/step - accuracy: 0.9852 - loss: 0.0471 - val_accuracy: 0.0872 - val_loss: 7.4748\n",
      "Epoch 19/50\n",
      "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m8s\u001b[0m 367ms/step - accuracy: 0.9773 - loss: 0.0681 - val_accuracy: 0.0988 - val_loss: 5.5951\n",
      "Epoch 20/50\n",
      "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m8s\u001b[0m 364ms/step - accuracy: 0.9941 - loss: 0.0262 - val_accuracy: 0.1453 - val_loss: 6.2342\n",
      "Epoch 21/50\n",
      "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m8s\u001b[0m 379ms/step - accuracy: 0.9898 - loss: 0.0421 - val_accuracy: 0.0988 - val_loss: 6.7196\n",
      "Epoch 22/50\n",
      "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m8s\u001b[0m 374ms/step - accuracy: 0.9877 - loss: 0.0262 - val_accuracy: 0.1047 - val_loss: 6.8257\n",
      "Epoch 23/50\n",
      "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m10s\u001b[0m 373ms/step - accuracy: 0.9978 - loss: 0.0121 - val_accuracy: 0.1337 - val_loss: 7.0317\n",
      "Epoch 24/50\n",
      "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m8s\u001b[0m 374ms/step - accuracy: 0.9977 - loss: 0.0182 - val_accuracy: 0.0930 - val_loss: 7.3025\n",
      "Epoch 25/50\n",
      "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m8s\u001b[0m 368ms/step - accuracy: 0.9961 - loss: 0.0216 - val_accuracy: 0.1337 - val_loss: 6.6207\n",
      "Epoch 26/50\n",
      "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m8s\u001b[0m 372ms/step - accuracy: 0.9936 - loss: 0.0194 - val_accuracy: 0.1279 - val_loss: 7.4609\n",
      "Epoch 27/50\n",
      "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m8s\u001b[0m 376ms/step - accuracy: 0.9964 - loss: 0.0098 - val_accuracy: 0.1047 - val_loss: 7.6302\n",
      "Epoch 28/50\n",
      "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m8s\u001b[0m 382ms/step - accuracy: 1.0000 - loss: 0.0049 - val_accuracy: 0.1105 - val_loss: 7.6873\n",
      "Epoch 29/50\n",
      "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m8s\u001b[0m 371ms/step - accuracy: 1.0000 - loss: 0.0050 - val_accuracy: 0.1047 - val_loss: 8.7604\n",
      "Epoch 30/50\n",
      "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m8s\u001b[0m 379ms/step - accuracy: 0.9986 - loss: 0.0065 - val_accuracy: 0.0988 - val_loss: 8.6224\n",
      "Epoch 31/50\n",
      "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m10s\u001b[0m 379ms/step - accuracy: 0.9921 - loss: 0.0291 - val_accuracy: 0.0872 - val_loss: 8.6657\n",
      "Epoch 32/50\n",
      "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m8s\u001b[0m 373ms/step - accuracy: 0.9941 - loss: 0.0108 - val_accuracy: 0.1047 - val_loss: 7.5820\n",
      "Epoch 33/50\n",
      "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m8s\u001b[0m 357ms/step - accuracy: 0.9969 - loss: 0.0136 - val_accuracy: 0.1105 - val_loss: 8.0600\n",
      "Epoch 34/50\n",
      "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m8s\u001b[0m 358ms/step - accuracy: 0.9982 - loss: 0.0086 - val_accuracy: 0.1047 - val_loss: 8.5446\n",
      "Epoch 35/50\n",
      "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m8s\u001b[0m 370ms/step - accuracy: 0.9981 - loss: 0.0127 - val_accuracy: 0.1221 - val_loss: 7.5976\n",
      "Epoch 36/50\n",
      "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m8s\u001b[0m 372ms/step - accuracy: 0.9916 - loss: 0.0296 - val_accuracy: 0.0988 - val_loss: 8.1991\n",
      "Epoch 37/50\n",
      "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m8s\u001b[0m 367ms/step - accuracy: 0.9939 - loss: 0.0210 - val_accuracy: 0.1221 - val_loss: 8.0480\n",
      "Epoch 38/50\n",
      "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m8s\u001b[0m 366ms/step - accuracy: 0.9948 - loss: 0.0110 - val_accuracy: 0.1395 - val_loss: 7.9124\n",
      "Epoch 39/50\n",
      "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m8s\u001b[0m 361ms/step - accuracy: 0.9896 - loss: 0.0224 - val_accuracy: 0.1221 - val_loss: 8.1066\n",
      "Epoch 40/50\n",
      "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m8s\u001b[0m 381ms/step - accuracy: 0.9934 - loss: 0.0150 - val_accuracy: 0.1105 - val_loss: 9.1221\n",
      "Epoch 41/50\n",
      "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m8s\u001b[0m 370ms/step - accuracy: 0.9948 - loss: 0.0149 - val_accuracy: 0.1860 - val_loss: 6.3062\n",
      "Epoch 42/50\n",
      "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m8s\u001b[0m 373ms/step - accuracy: 0.9996 - loss: 0.0075 - val_accuracy: 0.0988 - val_loss: 7.6129\n",
      "Epoch 43/50\n",
      "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m8s\u001b[0m 369ms/step - accuracy: 0.9965 - loss: 0.0107 - val_accuracy: 0.1047 - val_loss: 8.3309\n",
      "Epoch 44/50\n",
      "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m9s\u001b[0m 390ms/step - accuracy: 0.9971 - loss: 0.0081 - val_accuracy: 0.0872 - val_loss: 8.8924\n",
      "Epoch 45/50\n",
      "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m9s\u001b[0m 388ms/step - accuracy: 0.9967 - loss: 0.0099 - val_accuracy: 0.1105 - val_loss: 8.5119\n",
      "Epoch 46/50\n",
      "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m9s\u001b[0m 392ms/step - accuracy: 1.0000 - loss: 0.0067 - val_accuracy: 0.1105 - val_loss: 10.2193\n",
      "Epoch 47/50\n",
      "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m9s\u001b[0m 398ms/step - accuracy: 0.9989 - loss: 0.0037 - val_accuracy: 0.1105 - val_loss: 11.2552\n",
      "Epoch 48/50\n",
      "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m8s\u001b[0m 366ms/step - accuracy: 0.9982 - loss: 0.0049 - val_accuracy: 0.1221 - val_loss: 9.1427\n",
      "Epoch 49/50\n",
      "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m8s\u001b[0m 368ms/step - accuracy: 0.9998 - loss: 0.0039 - val_accuracy: 0.1221 - val_loss: 9.9673\n",
      "Epoch 50/50\n",
      "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m8s\u001b[0m 370ms/step - accuracy: 0.9905 - loss: 0.0161 - val_accuracy: 0.1163 - val_loss: 8.1580\n",
      "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 39ms/step - accuracy: 0.4440 - loss: 3.9997\n",
      "CNN Test Accuracy: 0.4094\n",
      "Epoch 1/50\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/mojo/.local/lib/python3.10/site-packages/keras/src/layers/core/dense.py:87: UserWarning: Do not pass an `input_shape`/`input_dim` argument to a layer. When using Sequential models, prefer using an `Input(shape)` object as the first layer in the model instead.\n",
      "  super().__init__(activity_regularizer=activity_regularizer, **kwargs)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 8ms/step - accuracy: 0.2527 - loss: 2.8600 - val_accuracy: 0.0407 - val_loss: 2.7448\n",
      "Epoch 2/50\n",
      "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.3240 - loss: 2.3535 - val_accuracy: 0.0407 - val_loss: 2.2139\n",
      "Epoch 3/50\n",
      "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.3744 - loss: 2.0463 - val_accuracy: 0.0465 - val_loss: 2.3588\n",
      "Epoch 4/50\n",
      "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.3994 - loss: 1.8536 - val_accuracy: 0.0465 - val_loss: 2.3699\n",
      "Epoch 5/50\n",
      "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.3947 - loss: 1.8680 - val_accuracy: 0.0756 - val_loss: 2.2290\n",
      "Epoch 6/50\n",
      "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.4215 - loss: 1.7375 - val_accuracy: 0.0349 - val_loss: 2.3239\n",
      "Epoch 7/50\n",
      "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.4297 - loss: 1.7273 - val_accuracy: 0.0465 - val_loss: 2.2517\n",
      "Epoch 8/50\n",
      "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - accuracy: 0.4544 - loss: 1.6476 - val_accuracy: 0.0291 - val_loss: 2.2406\n",
      "Epoch 9/50\n",
      "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.4767 - loss: 1.6553 - val_accuracy: 0.0581 - val_loss: 2.2794\n",
      "Epoch 10/50\n",
      "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.4434 - loss: 1.6704 - val_accuracy: 0.0581 - val_loss: 2.2270\n",
      "Epoch 11/50\n",
      "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.4468 - loss: 1.6226 - val_accuracy: 0.0698 - val_loss: 2.4315\n",
      "Epoch 12/50\n",
      "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.4839 - loss: 1.5172 - val_accuracy: 0.1163 - val_loss: 2.1649\n",
      "Epoch 13/50\n",
      "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.4869 - loss: 1.5022 - val_accuracy: 0.0756 - val_loss: 2.2131\n",
      "Epoch 14/50\n",
      "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.4845 - loss: 1.4966 - val_accuracy: 0.0930 - val_loss: 2.1725\n",
      "Epoch 15/50\n",
      "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.5183 - loss: 1.4163 - val_accuracy: 0.1105 - val_loss: 2.1757\n",
      "Epoch 16/50\n",
      "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.4984 - loss: 1.4401 - val_accuracy: 0.0930 - val_loss: 2.1097\n",
      "Epoch 17/50\n",
      "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.5179 - loss: 1.3510 - val_accuracy: 0.0581 - val_loss: 2.2866\n",
      "Epoch 18/50\n",
      "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.4922 - loss: 1.4253 - val_accuracy: 0.0872 - val_loss: 2.2077\n",
      "Epoch 19/50\n",
      "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.5185 - loss: 1.3602 - val_accuracy: 0.1047 - val_loss: 2.2670\n",
      "Epoch 20/50\n",
      "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - accuracy: 0.5766 - loss: 1.2972 - val_accuracy: 0.1221 - val_loss: 2.1061\n",
      "Epoch 21/50\n",
      "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - accuracy: 0.5485 - loss: 1.2804 - val_accuracy: 0.1453 - val_loss: 2.0895\n",
      "Epoch 22/50\n",
      "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.5523 - loss: 1.3216 - val_accuracy: 0.2209 - val_loss: 2.0529\n",
      "Epoch 23/50\n",
      "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - accuracy: 0.5846 - loss: 1.2030 - val_accuracy: 0.1977 - val_loss: 2.1303\n",
      "Epoch 24/50\n",
      "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.5772 - loss: 1.1610 - val_accuracy: 0.1395 - val_loss: 2.2757\n",
      "Epoch 25/50\n",
      "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.5917 - loss: 1.1486 - val_accuracy: 0.1628 - val_loss: 2.0801\n",
      "Epoch 26/50\n",
      "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.5917 - loss: 1.1254 - val_accuracy: 0.0988 - val_loss: 2.4343\n",
      "Epoch 27/50\n",
      "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.5840 - loss: 1.1117 - val_accuracy: 0.1453 - val_loss: 2.3820\n",
      "Epoch 28/50\n",
      "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.6172 - loss: 1.1123 - val_accuracy: 0.1919 - val_loss: 2.1910\n",
      "Epoch 29/50\n",
      "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.5816 - loss: 1.0795 - val_accuracy: 0.1628 - val_loss: 2.2534\n",
      "Epoch 30/50\n",
      "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.5923 - loss: 1.1442 - val_accuracy: 0.1570 - val_loss: 2.4879\n",
      "Epoch 31/50\n",
      "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.6576 - loss: 0.9770 - val_accuracy: 0.2093 - val_loss: 2.2026\n",
      "Epoch 32/50\n",
      "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.6155 - loss: 1.0172 - val_accuracy: 0.1628 - val_loss: 2.3793\n",
      "Epoch 33/50\n",
      "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.6650 - loss: 0.9985 - val_accuracy: 0.2209 - val_loss: 2.1758\n",
      "Epoch 34/50\n",
      "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.6065 - loss: 1.1051 - val_accuracy: 0.1628 - val_loss: 2.5143\n",
      "Epoch 35/50\n",
      "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.6489 - loss: 0.9102 - val_accuracy: 0.1570 - val_loss: 2.5260\n",
      "Epoch 36/50\n",
      "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.6593 - loss: 0.9284 - val_accuracy: 0.1977 - val_loss: 2.6065\n",
      "Epoch 37/50\n",
      "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.7002 - loss: 0.8496 - val_accuracy: 0.1279 - val_loss: 2.5942\n",
      "Epoch 38/50\n",
      "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.6784 - loss: 0.8557 - val_accuracy: 0.1337 - val_loss: 2.3661\n",
      "Epoch 39/50\n",
      "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - accuracy: 0.6699 - loss: 0.8104 - val_accuracy: 0.1802 - val_loss: 2.3315\n",
      "Epoch 40/50\n",
      "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.6821 - loss: 0.8992 - val_accuracy: 0.0698 - val_loss: 2.9314\n",
      "Epoch 41/50\n",
      "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.7400 - loss: 0.7524 - val_accuracy: 0.1279 - val_loss: 2.5123\n",
      "Epoch 42/50\n",
      "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.7136 - loss: 0.8013 - val_accuracy: 0.1860 - val_loss: 2.7526\n",
      "Epoch 43/50\n",
      "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.6938 - loss: 0.8397 - val_accuracy: 0.1047 - val_loss: 2.7077\n",
      "Epoch 44/50\n",
      "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.7129 - loss: 0.7654 - val_accuracy: 0.1628 - val_loss: 2.5056\n",
      "Epoch 45/50\n",
      "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.7285 - loss: 0.7302 - val_accuracy: 0.1686 - val_loss: 2.6119\n",
      "Epoch 46/50\n",
      "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.7431 - loss: 0.7791 - val_accuracy: 0.1395 - val_loss: 2.7811\n",
      "Epoch 47/50\n",
      "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.7299 - loss: 0.7339 - val_accuracy: 0.1744 - val_loss: 2.5455\n",
      "Epoch 48/50\n",
      "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.7793 - loss: 0.6873 - val_accuracy: 0.2267 - val_loss: 2.6710\n",
      "Epoch 49/50\n",
      "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.7292 - loss: 0.7037 - val_accuracy: 0.1221 - val_loss: 3.1440\n",
      "Epoch 50/50\n",
      "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.7532 - loss: 0.7397 - val_accuracy: 0.1512 - val_loss: 2.9174\n",
      "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.4576 - loss: 1.8370 \n",
      "ANN Test Accuracy: 0.4173\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "from sklearn.preprocessing import LabelEncoder\n",
    "from sklearn.svm import SVC\n",
    "from sklearn.metrics import accuracy_score, classification_report\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "\n",
    "# Load the data\n",
    "train_data = np.load('./layer_features_base_960h/train_12.npz')\n",
    "test_data = np.load('./layer_features_base_960h/test_12.npz')\n",
    "\n",
    "train_features = train_data['features']\n",
    "test_features = test_data['features']\n",
    "\n",
    "# Read Age labels instead of Gender\n",
    "train_labels = pd.read_csv('y_train.csv').Age\n",
    "test_labels = pd.read_csv('y_test.csv').Age\n",
    "\n",
    "# Encode the labels\n",
    "label_encoder = LabelEncoder()\n",
    "train_labels_encoded = label_encoder.fit_transform(train_labels)\n",
    "\n",
    "# Handle unseen labels in test set by filtering out labels not present in train set\n",
    "test_labels_filtered = test_labels[test_labels.isin(train_labels.unique())]\n",
    "test_features_filtered = test_features[test_labels.isin(train_labels.unique())]\n",
    "test_labels_encoded = label_encoder.transform(test_labels_filtered)\n",
    "\n",
    "# Standardize features\n",
    "scaler = StandardScaler()\n",
    "train_features_normalized = scaler.fit_transform(train_features)\n",
    "test_features_normalized = scaler.transform(test_features_filtered)\n",
    "\n",
    "# SVM model\n",
    "svm_model = SVC(kernel='linear', C=10.0, gamma='scale', random_state=42)\n",
    "svm_model.fit(train_features_normalized, train_labels_encoded)\n",
    "\n",
    "# Prediction and Evaluation\n",
    "svm_predictions = svm_model.predict(test_features_normalized)\n",
    "svm_accuracy = accuracy_score(test_labels_encoded, svm_predictions)\n",
    "print(f\"SVM Accuracy: {svm_accuracy:.4f}\")\n",
    "print(\"SVM Classification Report:\")\n",
    "print(classification_report(test_labels_encoded, svm_predictions))\n",
    "\n",
    "# CNN model (TensorFlow)\n",
    "import tensorflow as tf\n",
    "from tensorflow.keras.models import Sequential\n",
    "from tensorflow.keras.layers import Conv1D, Flatten, Dense, Dropout\n",
    "\n",
    "train_features_cnn = np.expand_dims(train_features_normalized, axis=-1)  # Shape: (num_samples, 768, 1)\n",
    "test_features_cnn = np.expand_dims(test_features_normalized, axis=-1)    # Shape: (num_samples, 768, 1)\n",
    "\n",
    "cnn_model = Sequential([\n",
    "    Conv1D(64, kernel_size=5, activation='relu', input_shape=(768, 1)),  # Update input shape to 768 features\n",
    "    Conv1D(128, kernel_size=5, activation='relu'),\n",
    "    Conv1D(256, kernel_size=5, activation='relu'),\n",
    "    Flatten(),\n",
    "    Dense(256, activation='relu'),\n",
    "    Dropout(0.5),\n",
    "    Dense(len(label_encoder.classes_), activation='softmax')\n",
    "])\n",
    "\n",
    "cnn_model.compile(optimizer='adam', loss='sparse_categorical_crossentropy', metrics=['accuracy'])\n",
    "\n",
    "cnn_model.fit(train_features_cnn, train_labels_encoded, epochs=50, batch_size=32, validation_split=0.2)\n",
    "\n",
    "cnn_test_loss, cnn_test_accuracy = cnn_model.evaluate(test_features_cnn, test_labels_encoded)\n",
    "print(f\"CNN Test Accuracy: {cnn_test_accuracy:.4f}\")\n",
    "\n",
    "# ANN model (TensorFlow)\n",
    "ann_model = Sequential([\n",
    "    Dense(512, activation='relu', input_shape=(768,)),  # Update input shape to 768 features\n",
    "    Dropout(0.5),\n",
    "    Dense(256, activation='relu'),\n",
    "    Dropout(0.5),\n",
    "    Dense(128, activation='relu'),\n",
    "    Dropout(0.5),\n",
    "    Dense(len(label_encoder.classes_), activation='softmax')\n",
    "])\n",
    "\n",
    "ann_model.compile(optimizer='adam', loss='sparse_categorical_crossentropy', metrics=['accuracy'])\n",
    "\n",
    "ann_model.fit(train_features_normalized, train_labels_encoded, epochs=50, batch_size=32, validation_split=0.2)\n",
    "\n",
    "ann_test_loss, ann_test_accuracy = ann_model.evaluate(test_features_normalized, test_labels_encoded)\n",
    "print(f\"ANN Test Accuracy: {ann_test_accuracy:.4f}\")\n",
    "\n",
    "# PyTorch CNN Model\n",
    "import torch\n",
    "from torch.utils.data import DataLoader, TensorDataset\n",
    "\n",
    "X_train_tensor = torch.tensor(train_features_cnn, dtype=torch.float32).permute(0, 2, 1)  # Shape: (num_samples, 1, 768)\n",
    "y_train_tensor = torch.tensor(train_labels_encoded, dtype=torch.long)\n",
    "X_test_tensor = torch.tensor(test_features_cnn, dtype=torch.float32).permute(0, 2, 1)    # Shape: (num_samples, 1, 768)\n",
    "y_test_tensor = torch.tensor(test_labels_encoded, dtype=torch.long)\n",
    "\n",
    "train_dataset = TensorDataset(X_train_tensor, y_train_tensor)\n",
    "test_dataset = TensorDataset(X_test_tensor, y_test_tensor)\n",
    "\n",
    "train_loader = DataLoader(train_dataset, batch_size=64, shuffle=True)\n",
    "test_loader = DataLoader(test_dataset, batch_size=64, shuffle=False)\n",
    "\n",
    "import torch.nn as nn\n",
    "import torch.optim as optim\n",
    "\n",
    "class CNN1DModel(nn.Module):\n",
    "    def __init__(self, input_channels, num_classes):\n",
    "        super(CNN1DModel, self).__init__()\n",
    "        self.conv1 = nn.Conv1d(input_channels, 32, kernel_size=5, stride=1, padding=2)\n",
    "        self.bn1 = nn.BatchNorm1d(32)\n",
    "        self.relu = nn.ReLU()\n",
    "        self.conv2 = nn.Conv1d(32, 64, kernel_size=5, stride=1, padding=2)\n",
    "        self.bn2 = nn.BatchNorm1d(64)\n",
    "        self.conv3 = nn.Conv1d(64, 128, kernel_size=5, stride=1, padding=2)\n",
    "        self.bn3 = nn.BatchNorm1d(128)\n",
    "        self.flatten = nn.Flatten()\n",
    "        self.fc1 = nn.Linear(128 * 768, 512)  # Update to 768 features\n",
    "        self.fc2 = nn.Linear(512, num_classes)\n",
    "        self.dropout = nn.Dropout(0.5)\n",
    "    \n",
    "    def forward(self, x):\n",
    "        x = self.relu(self.bn1(self.conv1(x)))\n",
    "        x = self.relu(self.bn2(self.conv2(x)))\n",
    "        x = self.relu(self.bn3(self.conv3(x)))\n",
    "        x = self.flatten(x)\n",
    "        x = self.dropout(self.relu(self.fc1(x)))\n",
    "        x = self.fc2(x)\n",
    "        return x\n",
    "\n",
    "input_channels = 1\n",
    "num_classes = len(label_encoder.classes_)\n",
    "model = CNN1DModel(input_channels, num_classes)\n",
    "criterion = nn.CrossEntropyLoss()\n",
    "optimizer = optim.Adam(model.parameters(), lr=0.001)\n",
    "\n",
    "# Training and testing as before\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cd4a1eb7",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "SVM Accuracy: 0.8740\n",
      "SVM Classification Report:\n"
     ]
    },
    {
     "ename": "ValueError",
     "evalue": "Number of classes, 8, does not match size of target_names, 10. Try specifying the labels parameter",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "\u001b[0;32m/tmp/ipykernel_61123/4090148815.py\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m     44\u001b[0m \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34mf\"SVM Accuracy: {svm_accuracy:.4f}\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     45\u001b[0m \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"SVM Classification Report:\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 46\u001b[0;31m \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mclassification_report\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtest_labels_encoded\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0msvm_predictions\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtarget_names\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mlabel_encoder\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mclasses_\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     47\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     48\u001b[0m \u001b[0;31m# CNN model (TensorFlow)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/.local/lib/python3.10/site-packages/sklearn/utils/_param_validation.py\u001b[0m in \u001b[0;36mwrapper\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m    211\u001b[0m                     )\n\u001b[1;32m    212\u001b[0m                 ):\n\u001b[0;32m--> 213\u001b[0;31m                     \u001b[0;32mreturn\u001b[0m \u001b[0mfunc\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    214\u001b[0m             \u001b[0;32mexcept\u001b[0m \u001b[0mInvalidParameterError\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0me\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    215\u001b[0m                 \u001b[0;31m# When the function is just a wrapper around an estimator, we allow\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/.local/lib/python3.10/site-packages/sklearn/metrics/_classification.py\u001b[0m in \u001b[0;36mclassification_report\u001b[0;34m(y_true, y_pred, labels, target_names, sample_weight, digits, output_dict, zero_division)\u001b[0m\n\u001b[1;32m   2624\u001b[0m             )\n\u001b[1;32m   2625\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 2626\u001b[0;31m             raise ValueError(\n\u001b[0m\u001b[1;32m   2627\u001b[0m                 \u001b[0;34m\"Number of classes, {0}, does not match size of \"\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2628\u001b[0m                 \u001b[0;34m\"target_names, {1}. Try specifying the labels \"\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mValueError\u001b[0m: Number of classes, 8, does not match size of target_names, 10. Try specifying the labels parameter"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "from sklearn.preprocessing import LabelEncoder\n",
    "from sklearn.svm import SVC\n",
    "from sklearn.metrics import accuracy_score, classification_report\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "\n",
    "# Load the data\n",
    "# Ensure that the 'features' arrays have 768 features\n",
    "train_data = np.load('./layer_features_base_100/train_6.npz')\n",
    "test_data = np.load('./layer_features_base_100/test_6.npz')\n",
    "\n",
    "train_features = train_data['features']  # Shape: (num_samples, 768)\n",
    "test_features = test_data['features']    # Shape: (num_samples, 768)\n",
    "\n",
    "# Read Age labels instead of Gender\n",
    "train_labels = pd.read_csv('y_train.csv').Age\n",
    "test_labels = pd.read_csv('y_test.csv').Age\n",
    "\n",
    "# Encode the labels\n",
    "label_encoder = LabelEncoder()\n",
    "train_labels_encoded = label_encoder.fit_transform(train_labels)\n",
    "\n",
    "# Handle unseen labels in test set by filtering out labels not present in train set\n",
    "mask = test_labels.isin(train_labels.unique())\n",
    "test_labels_filtered = test_labels[mask]\n",
    "test_features_filtered = test_features[mask]\n",
    "test_labels_encoded = label_encoder.transform(test_labels_filtered)\n",
    "\n",
    "# Standardize features\n",
    "scaler = StandardScaler()\n",
    "train_features_normalized = scaler.fit_transform(train_features)       # Shape: (num_samples, 768)\n",
    "test_features_normalized = scaler.transform(test_features_filtered)     # Shape: (num_samples, 768)\n",
    "\n",
    "# SVM model\n",
    "svm_model = SVC(kernel='linear', C=10.0, gamma='scale', random_state=42)\n",
    "svm_model.fit(train_features_normalized, train_labels_encoded)\n",
    "\n",
    "# Prediction and Evaluation for SVM\n",
    "svm_predictions = svm_model.predict(test_features_normalized)\n",
    "svm_accuracy = accuracy_score(test_labels_encoded, svm_predictions)\n",
    "print(f\"SVM Accuracy: {svm_accuracy:.4f}\")\n",
    "print(\"SVM Classification Report:\")\n",
    "print(classification_report(test_labels_encoded, svm_predictions, target_names=label_encoder.classes_))\n",
    "\n",
    "# CNN model (TensorFlow)\n",
    "import tensorflow as tf\n",
    "from tensorflow.keras.models import Sequential\n",
    "from tensorflow.keras.layers import Conv1D, Flatten, Dense, Dropout\n",
    "\n",
    "# Reshape features for CNN input: (num_samples, 768, 1)\n",
    "train_features_cnn = np.expand_dims(train_features_normalized, axis=-1)  # Shape: (num_samples, 768, 1)\n",
    "test_features_cnn = np.expand_dims(test_features_normalized, axis=-1)    # Shape: (num_samples, 768, 1)\n",
    "\n",
    "cnn_model = Sequential([\n",
    "    Conv1D(64, kernel_size=5, activation='relu', input_shape=(768, 1)),  # Updated input shape to 768 features\n",
    "    Conv1D(128, kernel_size=5, activation='relu'),\n",
    "    Conv1D(256, kernel_size=5, activation='relu'),\n",
    "    Flatten(),\n",
    "    Dense(512, activation='relu'),  # Adjusted Dense layer\n",
    "    Dropout(0.5),\n",
    "    Dense(len(label_encoder.classes_), activation='softmax')\n",
    "])\n",
    "\n",
    "cnn_model.compile(optimizer='adam', loss='sparse_categorical_crossentropy', metrics=['accuracy'])\n",
    "\n",
    "# Training the CNN model\n",
    "cnn_model.fit(train_features_cnn, train_labels_encoded, epochs=50, batch_size=32, validation_split=0.2)\n",
    "\n",
    "# Evaluating the CNN model\n",
    "cnn_test_loss, cnn_test_accuracy = cnn_model.evaluate(test_features_cnn, test_labels_encoded)\n",
    "print(f\"CNN Test Accuracy: {cnn_test_accuracy:.4f}\")\n",
    "\n",
    "# ANN model (TensorFlow)\n",
    "ann_model = Sequential([\n",
    "    Dense(512, activation='relu', input_shape=(768,)),  # Updated input shape to 768 features\n",
    "    Dropout(0.5),\n",
    "    Dense(256, activation='relu'),\n",
    "    Dropout(0.5),\n",
    "    Dense(128, activation='relu'),\n",
    "    Dropout(0.5),\n",
    "    Dense(len(label_encoder.classes_), activation='softmax')\n",
    "])\n",
    "\n",
    "ann_model.compile(optimizer='adam', loss='sparse_categorical_crossentropy', metrics=['accuracy'])\n",
    "\n",
    "# Training the ANN model\n",
    "ann_model.fit(train_features_normalized, train_labels_encoded, epochs=50, batch_size=32, validation_split=0.2)\n",
    "\n",
    "# Evaluating the ANN model\n",
    "ann_test_loss, ann_test_accuracy = ann_model.evaluate(test_features_normalized, test_labels_encoded)\n",
    "print(f\"ANN Test Accuracy: {ann_test_accuracy:.4f}\")\n",
    "\n",
    "# Function to plot classification report with label handling\n",
    "def plot_classification_report(y_true, y_pred, classes, model_name):\n",
    "    # Identify unique labels present in y_true and y_pred\n",
    "    unique_labels = np.unique(np.concatenate((y_true, y_pred)))\n",
    "    target_names = [classes[i] for i in unique_labels]\n",
    "    \n",
    "    # Generate the classification report\n",
    "    report = classification_report(y_true, y_pred, output_dict=True, labels=unique_labels, target_names=target_names)\n",
    "    \n",
    "    df = pd.DataFrame(report).transpose()\n",
    "    \n",
    "    plt.figure(figsize=(10, 6))\n",
    "    sns.heatmap(df.iloc[:-1, :-1].T, annot=True, cmap=\"Blues\", fmt=\".2f\")\n",
    "    plt.title(f'Classification Report for {model_name}')\n",
    "    plt.ylabel('Metrics')\n",
    "    plt.xlabel('Classes')\n",
    "    plt.show()\n",
    "\n",
    "# CNN Predictions and Classification Report Plot\n",
    "cnn_predictions = np.argmax(cnn_model.predict(test_features_cnn), axis=1)\n",
    "plot_classification_report(test_labels_encoded, cnn_predictions, label_encoder.classes_, \"CNN\")\n",
    "\n",
    "# ANN Predictions and Classification Report Plot\n",
    "ann_predictions = np.argmax(ann_model.predict(test_features_normalized), axis=1)\n",
    "plot_classification_report(test_labels_encoded, ann_predictions, label_encoder.classes_, \"ANN\")\n",
    "\n",
    "# PyTorch CNN Model\n",
    "import torch\n",
    "from torch.utils.data import DataLoader, TensorDataset\n",
    "\n",
    "# Convert features to PyTorch tensors\n",
    "X_train_tensor = torch.tensor(train_features_cnn, dtype=torch.float32).permute(0, 2, 1)  # Shape: (num_samples, 1, 768)\n",
    "y_train_tensor = torch.tensor(train_labels_encoded, dtype=torch.long)\n",
    "X_test_tensor = torch.tensor(test_features_cnn, dtype=torch.float32).permute(0, 2, 1)    # Shape: (num_samples, 1, 768)\n",
    "y_test_tensor = torch.tensor(test_labels_encoded, dtype=torch.long)\n",
    "\n",
    "# Create TensorDatasets\n",
    "train_dataset = TensorDataset(X_train_tensor, y_train_tensor)\n",
    "test_dataset = TensorDataset(X_test_tensor, y_test_tensor)\n",
    "\n",
    "# Create DataLoaders\n",
    "train_loader = DataLoader(train_dataset, batch_size=64, shuffle=True)\n",
    "test_loader = DataLoader(test_dataset, batch_size=64, shuffle=False)\n",
    "\n",
    "import torch.nn as nn\n",
    "import torch.optim as optim\n",
    "\n",
    "class CNN1DModel(nn.Module):\n",
    "    def __init__(self, input_channels, num_classes):\n",
    "        super(CNN1DModel, self).__init__()\n",
    "        self.conv1 = nn.Conv1d(input_channels, 32, kernel_size=5, stride=1, padding=2)\n",
    "        self.bn1 = nn.BatchNorm1d(32)\n",
    "        self.relu = nn.ReLU()\n",
    "        self.conv2 = nn.Conv1d(32, 64, kernel_size=5, stride=1, padding=2)\n",
    "        self.bn2 = nn.BatchNorm1d(64)\n",
    "        self.conv3 = nn.Conv1d(64, 128, kernel_size=5, stride=1, padding=2)\n",
    "        self.bn3 = nn.BatchNorm1d(128)\n",
    "        self.flatten = nn.Flatten()\n",
    "        self.fc1 = nn.Linear(128 * 768, 512)  # Updated to 768 features\n",
    "        self.fc2 = nn.Linear(512, num_classes)\n",
    "        self.dropout = nn.Dropout(0.5)\n",
    "    \n",
    "    def forward(self, x):\n",
    "        x = self.relu(self.bn1(self.conv1(x)))  # Shape: (batch_size, 32, 768)\n",
    "        x = self.relu(self.bn2(self.conv2(x)))  # Shape: (batch_size, 64, 768)\n",
    "        x = self.relu(self.bn3(self.conv3(x)))  # Shape: (batch_size, 128, 768)\n",
    "        x = self.flatten(x)                      # Shape: (batch_size, 128*768)\n",
    "        x = self.dropout(self.relu(self.fc1(x))) # Shape: (batch_size, 512)\n",
    "        x = self.fc2(x)                          # Shape: (batch_size, num_classes)\n",
    "        return x\n",
    "\n",
    "# Initialize PyTorch CNN model\n",
    "input_channels = 1\n",
    "num_classes = len(label_encoder.classes_)\n",
    "model = CNN1DModel(input_channels, num_classes)\n",
    "criterion = nn.CrossEntropyLoss()\n",
    "optimizer = optim.Adam(model.parameters(), lr=0.001)\n",
    "\n",
    "# Training PyTorch CNN model\n",
    "num_epochs = 20  # You can adjust the number of epochs as needed\n",
    "\n",
    "for epoch in range(num_epochs):\n",
    "    model.train()\n",
    "    running_loss = 0.0\n",
    "    for inputs, labels in train_loader:\n",
    "        optimizer.zero_grad()\n",
    "        outputs = model(inputs)              # Forward pass\n",
    "        loss = criterion(outputs, labels)    # Compute loss\n",
    "        loss.backward()                       # Backward pass\n",
    "        optimizer.step()                      # Update weights\n",
    "        running_loss += loss.item() * inputs.size(0)\n",
    "    \n",
    "    epoch_loss = running_loss / len(train_loader.dataset)\n",
    "    \n",
    "    # Evaluation on test set\n",
    "    model.eval()\n",
    "    correct = 0\n",
    "    total = 0\n",
    "    with torch.no_grad():\n",
    "        for inputs, labels in test_loader:\n",
    "            outputs = model(inputs)\n",
    "            _, predicted = torch.max(outputs.data, 1)\n",
    "            total += labels.size(0)\n",
    "            correct += (predicted == labels).sum().item()\n",
    "    \n",
    "    epoch_accuracy = correct / total\n",
    "    print(f\"Epoch {epoch+1}/{num_epochs}, Loss: {epoch_loss:.4f}, Test Accuracy: {epoch_accuracy:.4f}\")\n",
    "\n",
    "# Function to evaluate PyTorch model and plot classification report\n",
    "def evaluate_pytorch_model(model, test_loader, label_encoder, classes):\n",
    "    model.eval()\n",
    "    all_preds = []\n",
    "    all_labels = []\n",
    "    with torch.no_grad():\n",
    "        for inputs, labels in test_loader:\n",
    "            outputs = model(inputs)\n",
    "            _, predicted = torch.max(outputs.data, 1)\n",
    "            all_preds.extend(predicted.cpu().numpy())\n",
    "            all_labels.extend(labels.cpu().numpy())\n",
    "    \n",
    "    # Plot classification report\n",
    "    plot_classification_report(all_labels, all_preds, classes, \"PyTorch CNN\")\n",
    "\n",
    "# Evaluate and plot classification report for PyTorch CNN model\n",
    "evaluate_pytorch_model(model, test_loader, label_encoder, label_encoder.classes_)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "83b6d2f8",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 62ms/step\n"
     ]
    },
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 720x432 with 2 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 8ms/step \n"
     ]
    },
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 720x432 with 2 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "# Function to plot classification report\n",
    "def plot_classification_report(y_true, y_pred, classes, model_name):\n",
    "    # Use only the labels that are present in y_true\n",
    "    unique_labels = np.unique(y_true)\n",
    "    target_names = [classes[i] for i in unique_labels]\n",
    "    \n",
    "    # Generate the classification report\n",
    "    report = classification_report(y_true, y_pred, output_dict=True, labels=unique_labels, target_names=target_names)\n",
    "    \n",
    "    df = pd.DataFrame(report).transpose()\n",
    "    \n",
    "    plt.figure(figsize=(10, 6))\n",
    "    sns.heatmap(df.iloc[:-1, :-1].T, annot=True, cmap=\"Blues\")\n",
    "    plt.title(f'Classification Report for {model_name}')\n",
    "    plt.show()\n",
    "\n",
    "# CNN Predictions and Classification Report Plot\n",
    "cnn_predictions = np.argmax(cnn_model.predict(test_features_cnn), axis=1)\n",
    "plot_classification_report(test_labels_encoded, cnn_predictions, label_encoder.classes_, \"CNN\")\n",
    "\n",
    "# ANN Predictions and Classification Report Plot\n",
    "ann_predictions = np.argmax(ann_model.predict(test_features_normalized), axis=1)\n",
    "plot_classification_report(test_labels_encoded, ann_predictions, label_encoder.classes_, \"ANN\")\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
