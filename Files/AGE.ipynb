{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "6defadb4",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "SVM Accuracy: 0.7874\n",
      "SVM Classification Report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           1       0.70      0.58      0.64        12\n",
      "           2       0.67      0.75      0.71         8\n",
      "           3       0.82      0.95      0.88        39\n",
      "           4       1.00      0.83      0.91         6\n",
      "           5       0.80      0.79      0.80        42\n",
      "           6       0.69      0.56      0.62        16\n",
      "           7       0.67      1.00      0.80         2\n",
      "           8       1.00      0.50      0.67         2\n",
      "\n",
      "    accuracy                           0.79       127\n",
      "   macro avg       0.79      0.75      0.75       127\n",
      "weighted avg       0.79      0.79      0.78       127\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/mojo/.local/lib/python3.12/site-packages/keras/src/layers/convolutional/base_conv.py:107: UserWarning: Do not pass an `input_shape`/`input_dim` argument to a layer. When using Sequential models, prefer using an `Input(shape)` object as the first layer in the model instead.\n",
      "  super().__init__(activity_regularizer=activity_regularizer, **kwargs)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/50\n",
      "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m12s\u001b[0m 516ms/step - accuracy: 0.3695 - loss: 3.2475 - val_accuracy: 0.1919 - val_loss: 2.1069\n",
      "Epoch 2/50\n",
      "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m11s\u001b[0m 520ms/step - accuracy: 0.7463 - loss: 0.7620 - val_accuracy: 0.1628 - val_loss: 2.7064\n",
      "Epoch 3/50\n",
      "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m11s\u001b[0m 514ms/step - accuracy: 0.9284 - loss: 0.2281 - val_accuracy: 0.4128 - val_loss: 2.2617\n",
      "Epoch 4/50\n",
      "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m11s\u001b[0m 521ms/step - accuracy: 0.9804 - loss: 0.0972 - val_accuracy: 0.3256 - val_loss: 3.1670\n",
      "Epoch 5/50\n",
      "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m11s\u001b[0m 507ms/step - accuracy: 0.9912 - loss: 0.0354 - val_accuracy: 0.1919 - val_loss: 4.8830\n",
      "Epoch 6/50\n",
      "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m11s\u001b[0m 519ms/step - accuracy: 0.9942 - loss: 0.0292 - val_accuracy: 0.2965 - val_loss: 3.7621\n",
      "Epoch 7/50\n",
      "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m11s\u001b[0m 513ms/step - accuracy: 0.9922 - loss: 0.0213 - val_accuracy: 0.1570 - val_loss: 5.8814\n",
      "Epoch 8/50\n",
      "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m12s\u001b[0m 540ms/step - accuracy: 0.9965 - loss: 0.0138 - val_accuracy: 0.1860 - val_loss: 5.5336\n",
      "Epoch 9/50\n",
      "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m12s\u001b[0m 533ms/step - accuracy: 0.9990 - loss: 0.0073 - val_accuracy: 0.2209 - val_loss: 6.0602\n",
      "Epoch 10/50\n",
      "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m12s\u001b[0m 525ms/step - accuracy: 0.9987 - loss: 0.0083 - val_accuracy: 0.2616 - val_loss: 5.2099\n",
      "Epoch 11/50\n",
      "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m11s\u001b[0m 520ms/step - accuracy: 0.9994 - loss: 0.0062 - val_accuracy: 0.2674 - val_loss: 5.4313\n",
      "Epoch 12/50\n",
      "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m11s\u001b[0m 513ms/step - accuracy: 0.9984 - loss: 0.0050 - val_accuracy: 0.2791 - val_loss: 4.9310\n",
      "Epoch 13/50\n",
      "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m11s\u001b[0m 519ms/step - accuracy: 0.9967 - loss: 0.0127 - val_accuracy: 0.1395 - val_loss: 5.5103\n",
      "Epoch 14/50\n",
      "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m12s\u001b[0m 535ms/step - accuracy: 0.9993 - loss: 0.0115 - val_accuracy: 0.1919 - val_loss: 6.4330\n",
      "Epoch 15/50\n",
      "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m12s\u001b[0m 538ms/step - accuracy: 0.9966 - loss: 0.0193 - val_accuracy: 0.2035 - val_loss: 4.9048\n",
      "Epoch 16/50\n",
      "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m12s\u001b[0m 530ms/step - accuracy: 0.9964 - loss: 0.0190 - val_accuracy: 0.2442 - val_loss: 4.5715\n",
      "Epoch 17/50\n",
      "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m11s\u001b[0m 519ms/step - accuracy: 1.0000 - loss: 0.0043 - val_accuracy: 0.2500 - val_loss: 6.3817\n",
      "Epoch 18/50\n",
      "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m11s\u001b[0m 521ms/step - accuracy: 0.9991 - loss: 0.0065 - val_accuracy: 0.2849 - val_loss: 5.1490\n",
      "Epoch 19/50\n",
      "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m11s\u001b[0m 507ms/step - accuracy: 0.9992 - loss: 0.0057 - val_accuracy: 0.3314 - val_loss: 4.6693\n",
      "Epoch 20/50\n",
      "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m11s\u001b[0m 507ms/step - accuracy: 1.0000 - loss: 0.0024 - val_accuracy: 0.2849 - val_loss: 5.9756\n",
      "Epoch 21/50\n",
      "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m11s\u001b[0m 508ms/step - accuracy: 1.0000 - loss: 0.0014 - val_accuracy: 0.2558 - val_loss: 6.4636\n",
      "Epoch 22/50\n",
      "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m11s\u001b[0m 512ms/step - accuracy: 0.9978 - loss: 0.0048 - val_accuracy: 0.2151 - val_loss: 7.4976\n",
      "Epoch 23/50\n",
      "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m11s\u001b[0m 509ms/step - accuracy: 0.9994 - loss: 0.0057 - val_accuracy: 0.2267 - val_loss: 7.2750\n",
      "Epoch 24/50\n",
      "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m12s\u001b[0m 529ms/step - accuracy: 1.0000 - loss: 0.0024 - val_accuracy: 0.2500 - val_loss: 5.4559\n",
      "Epoch 25/50\n",
      "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m12s\u001b[0m 525ms/step - accuracy: 1.0000 - loss: 0.0057 - val_accuracy: 0.2965 - val_loss: 5.0616\n",
      "Epoch 26/50\n",
      "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m11s\u001b[0m 515ms/step - accuracy: 1.0000 - loss: 0.0011 - val_accuracy: 0.1860 - val_loss: 7.7874\n",
      "Epoch 27/50\n",
      "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m11s\u001b[0m 512ms/step - accuracy: 1.0000 - loss: 8.3075e-04 - val_accuracy: 0.1860 - val_loss: 7.9204\n",
      "Epoch 28/50\n",
      "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m11s\u001b[0m 504ms/step - accuracy: 1.0000 - loss: 2.7246e-04 - val_accuracy: 0.2500 - val_loss: 6.9659\n",
      "Epoch 29/50\n",
      "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m11s\u001b[0m 503ms/step - accuracy: 0.9978 - loss: 0.0040 - val_accuracy: 0.2209 - val_loss: 7.2268\n",
      "Epoch 30/50\n",
      "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m11s\u001b[0m 503ms/step - accuracy: 0.9975 - loss: 0.0110 - val_accuracy: 0.2209 - val_loss: 5.8382\n",
      "Epoch 31/50\n",
      "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m11s\u001b[0m 497ms/step - accuracy: 1.0000 - loss: 9.6096e-04 - val_accuracy: 0.2442 - val_loss: 6.9222\n",
      "Epoch 32/50\n",
      "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m11s\u001b[0m 499ms/step - accuracy: 1.0000 - loss: 7.2869e-04 - val_accuracy: 0.2500 - val_loss: 7.0134\n",
      "Epoch 33/50\n",
      "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m11s\u001b[0m 517ms/step - accuracy: 1.0000 - loss: 3.2028e-04 - val_accuracy: 0.2558 - val_loss: 7.2494\n",
      "Epoch 34/50\n",
      "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m11s\u001b[0m 515ms/step - accuracy: 0.9995 - loss: 0.0013 - val_accuracy: 0.3256 - val_loss: 5.2580\n",
      "Epoch 35/50\n",
      "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m11s\u001b[0m 506ms/step - accuracy: 0.9973 - loss: 0.0054 - val_accuracy: 0.2558 - val_loss: 5.4758\n",
      "Epoch 36/50\n",
      "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m11s\u001b[0m 509ms/step - accuracy: 0.9998 - loss: 0.0010 - val_accuracy: 0.2267 - val_loss: 5.9753\n",
      "Epoch 37/50\n",
      "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m11s\u001b[0m 505ms/step - accuracy: 1.0000 - loss: 0.0021 - val_accuracy: 0.1919 - val_loss: 6.2127\n",
      "Epoch 38/50\n",
      "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m11s\u001b[0m 503ms/step - accuracy: 1.0000 - loss: 6.4189e-04 - val_accuracy: 0.2093 - val_loss: 7.0506\n",
      "Epoch 39/50\n",
      "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m11s\u001b[0m 501ms/step - accuracy: 1.0000 - loss: 3.6132e-04 - val_accuracy: 0.2267 - val_loss: 7.3321\n",
      "Epoch 40/50\n",
      "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m11s\u001b[0m 505ms/step - accuracy: 1.0000 - loss: 1.7263e-04 - val_accuracy: 0.2267 - val_loss: 7.4671\n",
      "Epoch 41/50\n",
      "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m11s\u001b[0m 503ms/step - accuracy: 0.9998 - loss: 7.6583e-04 - val_accuracy: 0.1919 - val_loss: 7.8596\n",
      "Epoch 42/50\n",
      "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m11s\u001b[0m 501ms/step - accuracy: 0.9997 - loss: 0.0016 - val_accuracy: 0.1919 - val_loss: 7.8504\n",
      "Epoch 43/50\n",
      "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m11s\u001b[0m 503ms/step - accuracy: 0.9978 - loss: 0.0146 - val_accuracy: 0.1860 - val_loss: 4.3675\n",
      "Epoch 44/50\n",
      "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m11s\u001b[0m 494ms/step - accuracy: 0.9950 - loss: 0.0186 - val_accuracy: 0.1977 - val_loss: 5.5579\n",
      "Epoch 45/50\n",
      "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m11s\u001b[0m 504ms/step - accuracy: 0.9932 - loss: 0.0308 - val_accuracy: 0.3372 - val_loss: 4.9817\n",
      "Epoch 46/50\n",
      "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m11s\u001b[0m 502ms/step - accuracy: 1.0000 - loss: 0.0021 - val_accuracy: 0.1802 - val_loss: 8.7374\n",
      "Epoch 47/50\n",
      "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m11s\u001b[0m 504ms/step - accuracy: 0.9972 - loss: 0.0064 - val_accuracy: 0.2442 - val_loss: 5.5638\n",
      "Epoch 48/50\n",
      "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m11s\u001b[0m 516ms/step - accuracy: 0.9997 - loss: 0.0023 - val_accuracy: 0.1628 - val_loss: 8.5054\n",
      "Epoch 49/50\n",
      "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m11s\u001b[0m 513ms/step - accuracy: 1.0000 - loss: 0.0031 - val_accuracy: 0.3023 - val_loss: 7.4218\n",
      "Epoch 50/50\n",
      "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m12s\u001b[0m 524ms/step - accuracy: 0.9991 - loss: 0.0028 - val_accuracy: 0.3372 - val_loss: 6.1393\n",
      "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 61ms/step\n",
      "CNN Accuracy: 0.7638\n",
      "CNN Classification Report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           1       0.60      0.75      0.67        12\n",
      "           2       0.80      0.50      0.62         8\n",
      "           3       0.80      0.72      0.76        39\n",
      "           4       0.83      0.83      0.83         6\n",
      "           5       0.75      0.90      0.82        42\n",
      "           6       0.91      0.62      0.74        16\n",
      "           7       0.67      1.00      0.80         2\n",
      "           8       1.00      0.50      0.67         2\n",
      "\n",
      "    accuracy                           0.76       127\n",
      "   macro avg       0.79      0.73      0.74       127\n",
      "weighted avg       0.78      0.76      0.76       127\n",
      "\n",
      "Epoch 1/50\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/mojo/.local/lib/python3.12/site-packages/keras/src/layers/core/dense.py:87: UserWarning: Do not pass an `input_shape`/`input_dim` argument to a layer. When using Sequential models, prefer using an `Input(shape)` object as the first layer in the model instead.\n",
      "  super().__init__(activity_regularizer=activity_regularizer, **kwargs)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 7ms/step - accuracy: 0.2535 - loss: 2.7574 - val_accuracy: 0.2384 - val_loss: 1.9334\n",
      "Epoch 2/50\n",
      "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.4317 - loss: 1.6937 - val_accuracy: 0.1977 - val_loss: 2.4188\n",
      "Epoch 3/50\n",
      "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.5143 - loss: 1.5477 - val_accuracy: 0.2267 - val_loss: 2.2287\n",
      "Epoch 4/50\n",
      "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.6115 - loss: 1.1619 - val_accuracy: 0.2326 - val_loss: 2.4571\n",
      "Epoch 5/50\n",
      "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.6811 - loss: 0.9300 - val_accuracy: 0.2965 - val_loss: 2.3994\n",
      "Epoch 6/50\n",
      "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.7162 - loss: 0.8106 - val_accuracy: 0.2791 - val_loss: 2.5659\n",
      "Epoch 7/50\n",
      "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.7546 - loss: 0.6941 - val_accuracy: 0.3314 - val_loss: 2.2672\n",
      "Epoch 8/50\n",
      "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.7635 - loss: 0.7861 - val_accuracy: 0.2733 - val_loss: 2.8120\n",
      "Epoch 9/50\n",
      "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.8182 - loss: 0.5344 - val_accuracy: 0.2616 - val_loss: 3.1150\n",
      "Epoch 10/50\n",
      "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - accuracy: 0.8194 - loss: 0.5109 - val_accuracy: 0.3256 - val_loss: 2.8986\n",
      "Epoch 11/50\n",
      "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.8562 - loss: 0.4156 - val_accuracy: 0.2965 - val_loss: 3.1926\n",
      "Epoch 12/50\n",
      "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.9101 - loss: 0.3028 - val_accuracy: 0.2733 - val_loss: 3.4934\n",
      "Epoch 13/50\n",
      "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.9019 - loss: 0.2798 - val_accuracy: 0.3198 - val_loss: 3.5077\n",
      "Epoch 14/50\n",
      "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.9121 - loss: 0.2429 - val_accuracy: 0.3314 - val_loss: 3.1301\n",
      "Epoch 15/50\n",
      "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.9385 - loss: 0.1890 - val_accuracy: 0.2907 - val_loss: 3.8565\n",
      "Epoch 16/50\n",
      "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.9102 - loss: 0.2675 - val_accuracy: 0.3023 - val_loss: 3.9369\n",
      "Epoch 17/50\n",
      "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.9253 - loss: 0.2151 - val_accuracy: 0.3023 - val_loss: 4.3151\n",
      "Epoch 18/50\n",
      "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.9290 - loss: 0.1810 - val_accuracy: 0.2442 - val_loss: 4.5843\n",
      "Epoch 19/50\n",
      "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.9158 - loss: 0.2576 - val_accuracy: 0.3023 - val_loss: 4.5323\n",
      "Epoch 20/50\n",
      "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.9364 - loss: 0.2223 - val_accuracy: 0.2500 - val_loss: 4.5328\n",
      "Epoch 21/50\n",
      "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.9352 - loss: 0.1654 - val_accuracy: 0.2326 - val_loss: 4.6891\n",
      "Epoch 22/50\n",
      "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.9415 - loss: 0.1917 - val_accuracy: 0.2326 - val_loss: 5.4539\n",
      "Epoch 23/50\n",
      "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.9599 - loss: 0.1516 - val_accuracy: 0.2791 - val_loss: 4.4338\n",
      "Epoch 24/50\n",
      "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.9502 - loss: 0.1495 - val_accuracy: 0.2384 - val_loss: 4.8283\n",
      "Epoch 25/50\n",
      "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.9721 - loss: 0.0943 - val_accuracy: 0.2326 - val_loss: 5.7119\n",
      "Epoch 26/50\n",
      "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.9528 - loss: 0.1685 - val_accuracy: 0.2326 - val_loss: 5.4976\n",
      "Epoch 27/50\n",
      "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.9711 - loss: 0.0821 - val_accuracy: 0.2558 - val_loss: 5.1172\n",
      "Epoch 28/50\n",
      "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.9557 - loss: 0.1016 - val_accuracy: 0.2442 - val_loss: 5.4324\n",
      "Epoch 29/50\n",
      "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.9545 - loss: 0.1366 - val_accuracy: 0.2093 - val_loss: 6.3008\n",
      "Epoch 30/50\n",
      "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.9723 - loss: 0.0914 - val_accuracy: 0.2384 - val_loss: 6.1578\n",
      "Epoch 31/50\n",
      "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.9709 - loss: 0.0746 - val_accuracy: 0.2326 - val_loss: 6.4099\n",
      "Epoch 32/50\n",
      "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.9540 - loss: 0.1231 - val_accuracy: 0.2558 - val_loss: 6.4937\n",
      "Epoch 33/50\n",
      "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.9727 - loss: 0.0846 - val_accuracy: 0.2616 - val_loss: 6.8614\n",
      "Epoch 34/50\n",
      "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.9728 - loss: 0.1117 - val_accuracy: 0.2616 - val_loss: 7.3945\n",
      "Epoch 35/50\n",
      "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.9734 - loss: 0.0743 - val_accuracy: 0.2674 - val_loss: 7.3641\n",
      "Epoch 36/50\n",
      "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.9710 - loss: 0.0903 - val_accuracy: 0.2500 - val_loss: 7.2327\n",
      "Epoch 37/50\n",
      "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.9724 - loss: 0.0616 - val_accuracy: 0.2093 - val_loss: 7.2762\n",
      "Epoch 38/50\n",
      "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.9746 - loss: 0.0724 - val_accuracy: 0.1977 - val_loss: 8.3832\n",
      "Epoch 39/50\n",
      "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.9627 - loss: 0.1037 - val_accuracy: 0.2442 - val_loss: 7.3372\n",
      "Epoch 40/50\n",
      "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.9602 - loss: 0.1343 - val_accuracy: 0.1628 - val_loss: 8.3790\n",
      "Epoch 41/50\n",
      "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - accuracy: 0.9600 - loss: 0.1148 - val_accuracy: 0.1628 - val_loss: 8.8568\n",
      "Epoch 42/50\n",
      "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.9741 - loss: 0.0877 - val_accuracy: 0.2500 - val_loss: 7.0134\n",
      "Epoch 43/50\n",
      "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.9624 - loss: 0.1004 - val_accuracy: 0.2500 - val_loss: 6.8873\n",
      "Epoch 44/50\n",
      "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.9845 - loss: 0.0515 - val_accuracy: 0.2558 - val_loss: 6.9582\n",
      "Epoch 45/50\n",
      "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.9723 - loss: 0.0760 - val_accuracy: 0.2616 - val_loss: 7.2620\n",
      "Epoch 46/50\n",
      "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.9800 - loss: 0.0664 - val_accuracy: 0.2733 - val_loss: 7.1659\n",
      "Epoch 47/50\n",
      "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.9760 - loss: 0.0877 - val_accuracy: 0.2326 - val_loss: 7.6032\n",
      "Epoch 48/50\n",
      "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.9852 - loss: 0.0452 - val_accuracy: 0.2035 - val_loss: 8.1184\n",
      "Epoch 49/50\n",
      "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.9861 - loss: 0.0630 - val_accuracy: 0.3314 - val_loss: 6.8675\n",
      "Epoch 50/50\n",
      "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.9796 - loss: 0.0610 - val_accuracy: 0.2558 - val_loss: 7.5088\n",
      "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 8ms/step \n",
      "ANN Accuracy: 0.7323\n",
      "ANN Classification Report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           1       0.69      0.75      0.72        12\n",
      "           2       0.60      0.75      0.67         8\n",
      "           3       0.80      0.62      0.70        39\n",
      "           4       0.43      1.00      0.60         6\n",
      "           5       0.79      0.81      0.80        42\n",
      "           6       0.77      0.62      0.69        16\n",
      "           7       1.00      1.00      1.00         2\n",
      "           8       1.00      1.00      1.00         2\n",
      "\n",
      "    accuracy                           0.73       127\n",
      "   macro avg       0.76      0.82      0.77       127\n",
      "weighted avg       0.76      0.73      0.73       127\n",
      "\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "from sklearn.preprocessing import LabelEncoder\n",
    "from sklearn.svm import SVC\n",
    "from sklearn.metrics import accuracy_score, classification_report\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "\n",
    "# Load the data\n",
    "train_data = np.load('./chunk/age/hubert_3s_train_3.npz')\n",
    "test_data = np.load('./chunk/age/hubert_3s_test_3.npz')\n",
    "\n",
    "train_features = train_data['features']  # Ensure these have 1024 features\n",
    "test_features = test_data['features']    # Ensure these have 1024 features\n",
    "\n",
    "# Read Age labels instead of Gender\n",
    "train_labels = pd.read_csv('y_train.csv').Age\n",
    "test_labels = pd.read_csv('y_test.csv').Age\n",
    "\n",
    "# Encode the labels\n",
    "label_encoder = LabelEncoder()\n",
    "train_labels_encoded = label_encoder.fit_transform(train_labels)\n",
    "\n",
    "# Handle unseen labels in test set by filtering out labels not present in train set\n",
    "test_labels_filtered = test_labels[test_labels.isin(train_labels.unique())]\n",
    "test_features_filtered = test_features[test_labels.isin(train_labels.unique())]\n",
    "test_labels_encoded = label_encoder.transform(test_labels_filtered)\n",
    "\n",
    "# Check for NaNs and handle them before standardization\n",
    "train_features = np.nan_to_num(train_features, nan=np.nanmean(train_features))\n",
    "test_features_filtered = np.nan_to_num(test_features_filtered, nan=np.nanmean(test_features_filtered))\n",
    "\n",
    "# Standardize features\n",
    "scaler = StandardScaler()\n",
    "train_features_normalized = scaler.fit_transform(train_features)\n",
    "test_features_normalized = scaler.transform(test_features_filtered)\n",
    "\n",
    "# SVM model\n",
    "svm_model = SVC(kernel='linear', C=10.0, gamma='scale', random_state=42)\n",
    "svm_model.fit(train_features_normalized, train_labels_encoded)\n",
    "\n",
    "# SVM Prediction and Evaluation\n",
    "svm_predictions = svm_model.predict(test_features_normalized)\n",
    "svm_accuracy = accuracy_score(test_labels_encoded, svm_predictions)\n",
    "print(f\"SVM Accuracy: {svm_accuracy:.4f}\")\n",
    "print(\"SVM Classification Report:\")\n",
    "print(classification_report(test_labels_encoded, svm_predictions))\n",
    "\n",
    "# CNN model (TensorFlow)\n",
    "import tensorflow as tf\n",
    "from tensorflow.keras.models import Sequential\n",
    "from tensorflow.keras.layers import Conv1D, Flatten, Dense, Dropout\n",
    "\n",
    "train_features_cnn = np.expand_dims(train_features_normalized, axis=-1)  # Shape: (num_samples, 1024, 1)\n",
    "test_features_cnn = np.expand_dims(test_features_normalized, axis=-1)    # Shape: (num_samples, 1024, 1)\n",
    "\n",
    "cnn_model = Sequential([\n",
    "    Conv1D(64, kernel_size=5, activation='relu', input_shape=(1024, 1)),  # Updated input shape to 1024\n",
    "    Conv1D(128, kernel_size=5, activation='relu'),\n",
    "    Conv1D(256, kernel_size=5, activation='relu'),\n",
    "    Flatten(),\n",
    "    Dense(256, activation='relu'),\n",
    "    Dropout(0.5),\n",
    "    Dense(len(label_encoder.classes_), activation='softmax')\n",
    "])\n",
    "\n",
    "cnn_model.compile(optimizer='adam', loss='sparse_categorical_crossentropy', metrics=['accuracy'])\n",
    "\n",
    "cnn_model.fit(train_features_cnn, train_labels_encoded, epochs=50, batch_size=32, validation_split=0.2)\n",
    "\n",
    "# CNN Prediction and Evaluation\n",
    "cnn_predictions = np.argmax(cnn_model.predict(test_features_cnn), axis=-1)\n",
    "cnn_accuracy = accuracy_score(test_labels_encoded, cnn_predictions)\n",
    "print(f\"CNN Accuracy: {cnn_accuracy:.4f}\")\n",
    "print(\"CNN Classification Report:\")\n",
    "print(classification_report(test_labels_encoded, cnn_predictions))\n",
    "\n",
    "# ANN model (TensorFlow)\n",
    "ann_model = Sequential([\n",
    "    Dense(512, activation='relu', input_shape=(1024,)),  # Updated input shape to 1024\n",
    "    Dropout(0.5),\n",
    "    Dense(256, activation='relu'),\n",
    "    Dropout(0.5),\n",
    "    Dense(128, activation='relu'),\n",
    "    Dropout(0.5),\n",
    "    Dense(len(label_encoder.classes_), activation='softmax')\n",
    "])\n",
    "\n",
    "ann_model.compile(optimizer='adam', loss='sparse_categorical_crossentropy', metrics=['accuracy'])\n",
    "\n",
    "ann_model.fit(train_features_normalized, train_labels_encoded, epochs=50, batch_size=32, validation_split=0.2)\n",
    "\n",
    "# ANN Prediction and Evaluation\n",
    "ann_predictions = np.argmax(ann_model.predict(test_features_normalized), axis=-1)\n",
    "ann_accuracy = accuracy_score(test_labels_encoded, ann_predictions)\n",
    "print(f\"ANN Accuracy: {ann_accuracy:.4f}\")\n",
    "print(\"ANN Classification Report:\")\n",
    "print(classification_report(test_labels_encoded, ann_predictions))\n",
    "\n",
    "# PyTorch CNN Model\n",
    "import torch\n",
    "from torch.utils.data import DataLoader, TensorDataset\n",
    "\n",
    "X_train_tensor = torch.tensor(train_features_cnn, dtype=torch.float32).permute(0, 2, 1)  # Shape: (num_samples, 1, 1024)\n",
    "y_train_tensor = torch.tensor(train_labels_encoded, dtype=torch.long)\n",
    "X_test_tensor = torch.tensor(test_features_cnn, dtype=torch.float32).permute(0, 2, 1)    # Shape: (num_samples, 1, 1024)\n",
    "y_test_tensor = torch.tensor(test_labels_encoded, dtype=torch.long)\n",
    "\n",
    "train_dataset = TensorDataset(X_train_tensor, y_train_tensor)\n",
    "test_dataset = TensorDataset(X_test_tensor, y_test_tensor)\n",
    "\n",
    "train_loader = DataLoader(train_dataset, batch_size=64, shuffle=True)\n",
    "test_loader = DataLoader(test_dataset, batch_size=64, shuffle=False)\n",
    "\n",
    "import torch.nn as nn\n",
    "import torch.optim as optim\n",
    "\n",
    "class CNN1DModel(nn.Module):\n",
    "    def __init__(self, input_channels, num_classes):\n",
    "        super(CNN1DModel, self).__init__()\n",
    "        self.conv1 = nn.Conv1d(input_channels, 32, kernel_size=5, stride=1, padding=2)\n",
    "        self.bn1 = nn.BatchNorm1d(32)\n",
    "        self.relu = nn.ReLU()\n",
    "        self.conv2 = nn.Conv1d(32, 64, kernel_size=5, stride=1, padding=2)\n",
    "        self.bn2 = nn.BatchNorm1d(64)\n",
    "        self.conv3 = nn.Conv1d(64, 128, kernel_size=5, stride=1, padding=2)\n",
    "        self.bn3 = nn.BatchNorm1d(128)\n",
    "        self.flatten = nn.Flatten()\n",
    "        self.fc1 = nn.Linear(128 * 1024, 512)  # Updated to 1024 features\n",
    "        self.fc2 = nn.Linear(512, num_classes)\n",
    "        self.dropout = nn.Dropout(0.5)\n",
    "    \n",
    "    def forward(self, x):\n",
    "        x = self.relu(self.bn1(self.conv1(x)))\n",
    "        x = self.relu(self.bn2(self.conv2(x)))\n",
    "        x = self.relu(self.bn3(self.conv3(x)))\n",
    "        x = self.flatten(x)\n",
    "        x = self.dropout(self.relu(self.fc1(x)))\n",
    "        x = self.fc2(x)\n",
    "        return x\n",
    "\n",
    "input_channels = 1\n",
    "num_classes = len(label_encoder.classes_)\n",
    "model = CNN1DModel(input_channels, num_classes)\n",
    "criterion = nn.CrossEntropyLoss()\n",
    "optimizer = optim.Adam(model.parameters(), lr=0.001)\n",
    "\n",
    "# Training loop and evaluation (not shown in this code block)\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
